{"./":{"url":"./","title":"▶ ︎このサイトについて","keywords":"","body":"Tech-Notebook-GitBook このサイトについて GitBookを使用して作成したサイトです． 静的ファイルの生成元になっているマークダウンは，hiroki-it/tech-notebook-gitbook リポジトリにて管理しております． 使い方 スマホではくPCでの使用を推奨します． 左上の検索フォームからキーワードを検索します． 検索結果が複数のノートにまたがる場合，ノートのタイトルを元に，参照するべきノートを判断します． 該当のノートをクリックすると，説明を確認できます． サイトの目的 どこにでもいるエンジニアの 長谷川広樹 が，以下の目的のために使用しています． インプットしたことを自分の言葉で書き，アウトプットを行う． 誤った知識をその都度修正し，また体系的に整理する． インプットした内容を思い出すために閲覧する． そのため，誤った情報，誤った体系化，わかりにくい日本語，が多く散見されると思います． これらにつきましては，ご容赦いただけると幸いです． 学習方法 本サイトでは，以下を記載し，その概念を学習するようにしております． 定義づけ（演繹的な学習） 例（帰納的な学習） 概念図（視覚優位な学習） そのため，冗長な記載となることをご容赦いただけると幸いです． おわび このサイトで使われている説明や画像につきまして，様々な書籍やサイトから引用させていただいております． あくまで，上記の目的のためだけに使用させていただくという名目で，引用元を十分に記載しておりません． 深くお詫び申し上げます． "},"public/self_introduction.html":{"url":"public/self_introduction.html","title":"▶ ︎長谷川広樹と申します","keywords":"","body":"自己紹介 はじめまして 長谷川広樹と申します． 2019年に理学修士を習得し，大学院を卒業いたしました． その後，バックエンドエンジニア としてキャリアをスタートいたしました． 現在は，SRE として働かさせていただいております． 関心のある技術領域 スケーラビリティ，保守性，可読性を高める技術に関心がございます． DDD，凝集度と結合度，クラウドインフラ，IaC，コンテナ，CI/CD，Go，etc... 経歴，職歴 詳しくは，以下のリンクまでご訪問いただけると幸いです． ▶ GitHub：https://github.com/hiroki-it ▶ Wantedly：https://www.wantedly.com/id/h_hasegawa ▶ Speaker Deck：https://speakerdeck.com/hiroki_hasegawa "},"public/backend_architecture_domain_driven_design_introduction.html":{"url":"public/backend_architecture_domain_driven_design_introduction.html","title":"▶ ︎ドメイン駆動設計概論","keywords":"","body":"ドメイン駆動設計概論 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. MVC MVCとは ドメイン駆動設計が考案される以前，MVCの考え方が主流であった． MVCからドメイン駆動設計への発展 ・MVCの問題点 しかし，特にModelの役割が抽象的過ぎたため，開発規模が大きくなるにつれて，Modelに役割を集中させ過ぎてしまうことがあった． ・MVCからドメイン駆動設計への移行 ドメイン駆動設計が登場したことによって，MVCは発展し，M・V・Cそれぞれの役割がより具体的で精密になった．Modelの肥大化は，Modelがもつビジネスロジックをドメイン層，またCRUD処理をインフラストラクチャ層として分割することによって，対処された． 02. ドメイン駆動設計の手順 戦略的設計にまつわる用語 ・ドメイン ビジネスモデル全体で見た時に，システム化の対象となる部分領域のこと．ビジネスモデル全体をいくつかのドメインを分割する方法として，一連の業務フローの中で，業務の担当者の属性が変化するタイミングに着目すると良い． ＊例＊ インターネット広告代理店の例．ビジネスモデルに基づく複数のドメインを示す．業務フローの担当者の変化として，まず問い合わせで注文を受けて広告アカウントを作成する『営業担当者』，制作した広告をアカウントに入稿する『制作担当者』，入稿された広告を運用して広告効果を高める『マーケティング担当者』，最後に広告の依頼者に料金を請求する『経理担当者』が挙げられる．これにより，インターネット広告代理店のビジネスモデルは，各担当者に対応するドメインに分割できる． 参考：https://labs.septeni.co.jp/entry/2021/04/15/130000 ＊例＊ 完全個室ジムを運営するハコジムの例．ビジネスモデルに基づく複数のドメインを示す．業務フローの担当者の変化として，まず個室ジムに適する物件を探す『物件担当者』，ジムのトレーナーを採用して会員に紹介する『採用担当者』，個室ジムの利用会員を獲得する『営業担当者』が挙げられる．これにより，ハコジムのビジネスモデルは，各担当者に対応するドメインに分割できる． 参考： https://hacogym.jp/ https://zenn.dev/hsshss/articles/e11efefc7011ab ・コアドメイン，サブドメイン，ドメインエキスパートとは 各ドメインのドメインエキスパート（ビジネスルールに詳しい人）と，エンジニアが話し合いながら，ドメイン内の主要業務をコアドメイン，補助的な業務をサブドメインに分類する． 参考： https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 https://labs.septeni.co.jp/entry/2021/04/15/130000 ＊例＊ 完全個室ジムを運営するハコジムの例．ドメインのうちで，個室ジムドメインに基づくコアドメインとサブドメインを示す．コアドメインは予約ドメイン，それ以外はサブドメインとしている． 参考： https://hacogym.jp/ https://zenn.dev/hsshss/articles/e11efefc7011ab ＊例＊ ECサイトを運営するアスクルの例．ドメインのうちで，個人向け販売ドメイン（サイト名はLOHACO）に基づくサブドメインを示す．配送／注文／商品／ユーザ管理／在庫／受注をそれぞれサブドメインとしている（コアドメインは明言されていない）． 参考：https://speakerdeck.com/askul/ddd-and-clean-architecture-at-lohaco?slide=28 ・ユビキタス言語とは ドメインエキスパート間で，特定の『単語』や『動詞』の意味合い／定義づけが異なる場合，これを別々の名前からなるユビキタス言語として定義づける． 参考：https://qiita.com/kmdsbng/items/bf415afbeec239a7fd63 ・境界付けられたコンテキストとは ドメインエキスパートの業務フローの立ち位置が異なれば，同じ『単語』や『動詞』であっても，異なる意味合い／定義づけのユビキタス言語が使用される．異なるユビキタス言語を元にして，境界付けられたコンテキストを定義する．この時，ユビキタス言語は，他の境界付けられたコンテキストでは通じないものであればあるほどよい．境界付けられたコンテキストそれぞれのユビキタス言語に合わせて，異なる名前でモデリングしていく．境界付けられたコンテキストを定義しない場合，異なるユビキタス言語をコアドメインやサブドメイン間で共有することとなり，それぞれの関心に無関係なデータを保持することになってしまう． ＊例＊ 本を販売するECサイトの例．コアドメインとサブドメインに基づいたユビキタス言語と境界付けられたコンテキストを示す．バイヤー（仕入れ）部，マーケティング部，在庫管理部のドメインエキスパートは，『本（商品）』という単語に対する意味合い／定義づけが異なる．そのため，それぞれを『本』『クーポン』『在庫』というユビキタス言語として定義でき，モデル名／データ名はそれぞれのユビキタス言語に合わせた名前になる．例えば，マーケの境界付けられたコンテキストでは，モデル名はCouponとなり，割引期間データを保持する必要があるが，仕入部や在庫部ではこのデータは不要である．一方，ISBNは全ての境界付けられたコンテキストのモデルに必要なデータである．境界付けられたコンテキストを定義しない場合，一つの商品モデルが全てのデータを保持することとなり，それぞれのドメインエキスパートが関心を持たないデータも保持することになってしまう． 参考：https://kenta-kosugi.medium.com/%E3%83%9E%E3%82%A4%E3%82%AF%E3%83%AD%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E4%B8%8A%E6%89%8B%E3%81%AA%E5%88%86%E5%89%B2-ff5bb01d1062 ＊例＊ 完全個室ジムを運営するハコジムの例．個室ジムドメインのコアドメインとサブドメインに基づく境界付けられたコンテキスト．認証コンテキスト，予約コンテキスト，顧客管理コンテキスト，銀行支払いコンテキスト，クレジットカード支払いコンテキストがある． 参考： https://hacogym.jp/ https://zenn.dev/hsshss/articles/e11efefc7011ab ＊例＊ 契約請求管理アプリを提供するアルプの例．コアドメインとサブドメインに基づいたユビキタス言語と境界付けられたコンテキストを示す．契約管理コンテキスト，商品管理コンテキスト，請求管理コンテキスト，がある．取り組みとして，週次でユビキタス言語の更新を行っている． 参考： https://note.com/alpinc/n/nab47ab9273c6 https://thealp.co.jp/ ・コンテキストマップとは 広義のドメイン全体の俯瞰する図のこと．コアドメイン，サブドメイン，境界付けられたコンテキストを定義した後，これらの関係性を視覚化する．異なるサブドメインの間で異なるユビキタス言語を使用する場合，境界付けられたコンテキストはサブドメインをまたがない．一方で，同じユビキタス言語を使用する場合，境界付けられたコンテキストは複数のサブドメインにまたがる．可能な限り，各境界付けられたコンテキストでは異なるユビキタス言語を使用し，境界付けられたコンテキストが複数のサブドメインにまたがないようにした方が良い（これ重要）． 参考：https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 ・コアドメインとサブドメインのモデル化 コアドメインとサブドメインを対象として，境界付けられたコンテキスト内のユビキタス言語に基づいてドメインモデルを設計する．コアドメインのシステムは内製である必要があるが，サブドメインのシステムは外製／内製のいずれでも問題ない． 参考：https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 ＊例＊ 完全個室ジムを運営するハコジムの例．個室ジムドメインのそれぞれの境界付けられたコンテキストに基づくモデリング．コアドメインの予約コンテキストとスマートロックコンテキストは，一つのマイクロサービスとして内製化している．一方で，それ以外の境界付けられたコンテキストは外製化している． 戦術的設計にまつわる用語 ・DDDデザインパターン集 参考：https://www.ogis-ri.co.jp/otc/hiroba/technical/DDDEssence/chap1.html ・レイヤードアーキテクチャ 最初に考案された実現方法． 参考：https://www.amazon.co.jp/dp/4798121967/ref=cm_sw_r_tw_dp_ZD0VGXSNQMNZF7K1ME8J?_encoding=UTF8&psc=1 ・ヘキサゴナルアーキテクチャ 別名『ポートアンドアダプターアーキテクチャ』という．レイヤードアーキテクチャのインフラストラクチャ層に対して，依存性逆転を組み込んだもの．ドメイン層のオブジェクトは，ドメイン層の他のオブジェクトに依存する以外，何のオブジェクトにも外部ライブラリにも依存しない．逆に考えれば，これらに依存するものはドメイン層に置くべきではないと判断できる．本質的には，他の『オニオンアーキテクチャ』『クリーンアーキテクチャ』に同じである． 参考：https://www.amazon.co.jp/dp/B00UX9VJGW/ref=cm_sw_r_tw_dp_S20HJ24MHWTSED7T0ZCP ・オニオンアーキテクチャ レイヤードアーキテクチャのインフラストラクチャ層に対して，依存性逆転を組み込んだもの．ドメイン層のオブジェクトは，ドメイン層の他のオブジェクトに依存する以外，何のオブジェクトにも外部ライブラリにも依存しない．逆に考えれば，これらに依存するものはドメイン層に置くべきではないと判断できる．本質的には，他の『ヘキサゴナルアーキテクチャ』『クリーンアーキテクチャ』に同じである． 参考： https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/ https://little-hands.hatenablog.com/entry/2017/10/11/075634 ・クリーンアーキテクチャ レイヤードアーキテクチャのインフラストラクチャ層に対して，依存性逆転を組み込んだもの．ドメイン層のオブジェクトは，ドメイン層の他のオブジェクトに依存する以外，何のオブジェクトにも外部ライブラリにも依存しない．逆に考えれば，これらに依存するものはドメイン層に置くべきではないと判断できる．本質的には，他の『ヘキサゴナルアーキテクチャ』『オニオンアーキテクチャ』に同じである． 参考：https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html ・ドメインモデル図 クラス図よりも先に作成し，オブジェクト間のAggregation（集約）の粒度を明確にする．ユースケース図から『名詞』を抽出し，これをドメインモデルとして，クラス図と同じようにドメインモデル間の関係を表現する．ただし，クラス図とは異なり，クラスのメソッドは省略し，保持するデータのみに注目する．ドメインモデルを日本語で表現してよい．クラス図におけるクラス間の関係については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html ドメインモデル図の作成手順については，以下を参考にせよ． 参考： https://www.eureka-moments-blog.com/entry/2018/12/29/145802 https://github.com/ShisatoYano/PlantUML/blob/master/DomainModelDiagram/DomainModelDiagram.pdf 03. ドメイン駆動設計の手順まとめ 戦略的設計の手順 戦略的設計では，ドメイン全体から境界付けられたコンテキストを明確にする． 参考：https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 ドメインエキスパートと話し合い，ドメイン全体の中からコアドメインとサブドメインを切り分ける． ドメインエキスパートの部署や業務フローの立ち位置によっては，同じ『単語』や『動詞』であっても，意味合い／定義づけが異なる場合がある．この時，それぞれを別々の名前からなるユビキタス言語として定義づける． ユビキタス言語を元に，境界付けられたコンテキストを定義づける． コンテキストマップを作成し，境界付けられたコンテキスト間の関係を明らかにする． 戦術的設計の手順 戦術的設計では，境界付けられたコンテキストをアーキテクチャやデザインパターンに落とし込む． ドメインエキスパートと話し合い，境界付けられたコンテキストに含まれる要件をヒアリングを行う．この時，ビジネスのルール／制約を十分にヒアリングする． 要件からユースケース図を作成する．この時，『システムが，〇〇を△△する．』と考えるとよい． 通常のオブジェクト指向分析／設計では，ユースケース図の後にクラス図を作成する．しかしドメイン駆動設計では，クラス図作成よりも先に集約の粒度を明確化するために，ユースケース図から『名詞』を抽出し，これを一つのドメインモデルとしたドメインモデル図を作成する．ドメインモデル図では，ビジネスのルール／制約を吹き出しに書き込む．各モデルのルール／制約に依存関係があり，データをセットで扱う必要があるような場合，これらを一つの集約として定義づけるとよい． 必要であればドメインエキスパートに再ヒアリングを行い，ドメインモデル図を改善する． ドメインモデル図を元に，クラス図を作成する．この時，モデルをエンティティや値オブジェクトを切り分けるようにする． アーキテクチャ（レイヤード型，ヘキサゴナル型，オニオン型，クリーンアーキテクチャ）を決め，クラス図を元にドメイン層を実装する． 運用後に問題が起こった場合，モデリングを修正する．場合によっては，デザインパターンに切り分ける． なお，オブジェクト指向分析／設計／プログラミングについては，以下のリンクを参考にせよ． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_analysis_design_programming.html https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_method_data.html "},"public/backend_architecture_cqrs.html":{"url":"public/backend_architecture_cqrs.html","title":"▶ ︎CQRS","keywords":"","body":"Command Query Responsibility Segregation はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. CQRS CQRSとは 『Command Query Responsibility Segregation（コマンドクエリ責務分離）』の略．リポジトリパターンにおける更新系と参照系の処理を分離する設計のこと．更新系のオブジェクトはそのままリポジトリとしてインフラ層に置く．一方で参照系のオブジェクトは，参照のユースケースに応じて『QueryServiceオブジェクト』として設計し，ユースケース層に置く（これ重要）．システムに部分的に組み込むことができる．N+1問題にも対処できる． 参考： https://vaadin.com/learn/tutorials/ddd/tactical_domain_driven_design https://little-hands.hatenablog.com/entry/2019/12/02/cqrs メリット 一覧画面に表示するデータは複数の集約からなるため，それぞれの集約に対応するリポジトリの参照系処理を順々にコールし，取得したデータを組み合わせる必要がある．そのため，一覧表示の度に複数のリポジトリをコールすることとなり，システムのパフォーマンスに悪影響が出る可能性がある．また，異なるリポジトリをまたいでWHERE句を用いることはできないため，複数の集約に渡る絞り込み検索を実装できない．しかしCQRSを用いると，更新系のオブジェクトはリポジトリ，一方で参照系のオブジェクトはユースケースに応じたQueryServiceオブジェクトとして設計することになる．そのため，更新系では集約の単位をそのままにして，集約とは無関係な参照系処理を設計できる． 参考：https://little-hands.hatenablog.com/entry/2019/12/02/cqrs 01-02. 処理系の種類 Command（更新系） ・Commandとは CREATE，UPDATE，DELETE処理を実行する処理フローのこと．今回，クリーンアーキテクチャを前提としてCQRSを説明する．概念や実装方法は以下のリンクを参考にせよ． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_architecture_domain_driven_design_clean_architecture.html https://github.com/hiroki-it/ddd-api-with-laravel#ddd-api-with-laravel ・処理順序 インターフェース層のコントローラにて，リクエストパラメータからリクエストモデルを作成する． ユースケース層のインターラクターにて，リクエストモデルからデータを取り出し，ドメインモデルを作成する．これをインフラ層のリポジトリに渡す． インフラ層の書き込み／読み出しリポジトリにて，IDモデルのデータを用いて，読み出し／書き込みリポジトリでSELECT文を実行し，DBからレコードを配列として取得する．続けて，ドメインモデルからデータを取り出し，配列の値を上書きする．この配列でINSERT／UPDATE文を実行する．インフラ層の実装は，全てを自前で実装せずにORMで代用できる．void型をユースケース層のインターラクターに渡す． ユースケース層のインターラクターにて，リクエストモデルから作成した時に用いたドメインモデルを用いて，レスポンスモデルを作成する．レスポンスモデルをインタフェース層のコントローラに渡す． インターフェース層のコントローラにて，レスポンスモデルをJSONに変換し，レスポンスを返信する． Query（参照系） ・Queryとは READ処理を実行するオブジェクトのこと．今回，クリーンアーキテクチャを前提としてCQRSを説明する．Queryでは概念や実装方法は以下のリンクを参考にせよ． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_architecture_domain_driven_design_clean_architecture.html https://github.com/hiroki-it/ddd-api-with-laravel#ddd-api-with-laravel ・処理順序 インターフェース層のコントローラにて，リクエストパラメータからリクエストモデルを作成する． ユースケース層のインターラクターにて，リクエストモデルからデータを取り出し，QueryCriteriaオブジェクト（参照系検索条件）を作成する．ユースケースに応じたQueryServiceオブジェクトにおいて，QueryCriteriaオブジェクトを用いて，DBからレコードを配列として取得する．この配列からそのユースケースに対応するDTOを作成する．DTOをレスポンスモデルと見なし，そのままインタフェース層のコントローラに渡す． 参考： https://stackoverflow.com/questions/19620404/entity-vs-dto-in-cqrs https://softwareengineering.stackexchange.com/questions/378909/in-what-layer-are-the-dtos-stored-with-cqrs インターフェース層のコントローラにて，DTOをJSONに変換し，レスポンスを返信する． 02. CQRSに基づくイベント駆動アーキテクチャ CQRSとイベントソーシングの関係 イベントソーシングの実装方法は様々ある．イベントソーシングではDBアクセスの処理を更新系と参照系に分離することになるため，CQRSの方法論と相性が良い． 参考： https://little-hands.hatenablog.com/entry/2019/12/02/cqrs https://postd.cc/using-cqrs-with-event-sourcing/ "},"public/backend_architecture_domain_driven_design_clean_architecture.html":{"url":"public/backend_architecture_domain_driven_design_clean_architecture.html","title":"▶ ︎クリーンアーキテクチャ","keywords":"","body":"クリーンアーキテクチャ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. アーキテクチャ概要 ・思想 DDDが適する機能要件の多いアプリケーションだけでなく，あらゆる種類のシステムに適用できる．クリーンアーキテクチャ原著の序文にて，著者は『私は，今まで色々な種類のシステムを作ってきたが，どのシステムもアーキテクチャもルールは同じだった．異なるシステムでも同じルールを共有する必要がある』というようなことを述べている． 参考：https://www.amazon.co.jp/dp/B07FSBHS2V ・構成 参考：https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html 02. インターフェース層（黄緑） コントローラ ・コントローラとは 入力／出力の処理時で，責務を以下のように分類できる．コントローラの責務をデザインパターンに切り分けても良い． 入力時／出力時 責務 補足 入力 インフラ層のルータから入力される認証情報を照合し，認証を実行する． 認証はインターフェース層あるいはユースケース層に実装する．参考：・https://github.com/little-hands/ddd-q-and-a/issues/173 インフラ層のルーターから入力されるパラメータをAPI仕様（必須，書式，など）と照らし合わせ，バリデーションを実行する． データの値がAPI仕様と比較して正しいかどうかを検証することに止まり，データの値が正しいかどうかの検証は，ユースケース層やドメイン層に実装する． インフラ層のルーターから入力されるパラメータをリクエストモデルに変換し，ユースケース層のインターラクターに入力する． リクエストモデル生成処理で，ドメイン層への依存が必要になる．リクエストモデル生成処理を切り分け，ユースケース層に置くと，コントローラがドメイン層に依存することを防げる． 出力 ユースケース層のインターラクターから出力されるレスポンスモデルを，JSONデータとしてフロントエンドにに返信する． バックエンドをAPIとして用いる場合，プレゼンターは不要である． ユースケース層のインターラクターから出力されるプレゼンターをビューモデルに変換し，バックエンドのテンプレートエンジンに出力する． バックエンドでテンプレートエンジンを用いてHTMLを生成する場合，プレゼンターが必要である． プレゼンター ・プレゼンターとは バックエンドからフロントエンドに出力するため，．バックエンドがテンプレートエンジンを持つフレームワークの時に，バックエンドからフロントエンドのロジックを分離するために用いる．一方で，バックエンドとフロントエンドを完全に分離し，バックエンドがJSONデータを返信するAPIとして機能する場合や，フロントエンドにテンプレートエンジンを組み込む場合は，プレゼンターを用いない．補足として，アウトプットバウンダリはプレゼンターのインターフェースのため，プレゼンターを用いなければ，アウトプットバウンダリも用いない． 参考： https://izumisy.work/entry/2019/12/12/000521 https://codezine.jp/article/detail/9749 バリデーションパターン ・バリデーションパターンとは デザインパターンの一つ．インターフェース層のバリデーションでは，データの必須や書式を検証する． ＊実装例＊ 日時データのフォーマットを検証する． validate($dateTime)) { return false; } return true; } } 03. ユースケース層（赤） 処理フロー インターフェース層からユースケース層までの処理の流れを示す． 参考：http://www.plainionist.net/Implementing-Clean-Architecture-Controller-Presenter/ インターラクター ・インターラクターとは 入力／出力の処理時で，責務を以下のように分類できる．ユースケースごとに異なるInteractorクラスを定義する方法と，全てのユースケースを責務としてもつInteractorクラスを定義する方法がある．また，Interactorインターフェースを用意して，インターフェース層のコントローラはこれを経由して，実装Interactorクラスのメソッドをコールするようにする． 入力時／出力時 責務 補足 入力 プレゼンテーション層のコントローラから入力されるリクエストパラメータを，システム上のルールと照らし合わせてバリデーションを実行する． データの値がシステム上あり得ないかどうかを検証する．ビジネス上あり得ない値かどうかはドメイン層にSpecificationパターンとして実装する． ドメイン層のメソッドを組み合わせて，ユーザの要求に対するシステムの振舞（ユースケース）を具現化する． プレゼンテーション層のコントローラから入力されるリクエストパラメータを，ドメイン層のインターフェースリポジトリに渡せるドメインモデルに変換する． 出力 ドメイン層のインターフェースリポジトリから出力されるドメインモデルをレスポンスモデルに変換し，インターフェース層のコントローラに出力する． バックエンドをAPIとして用いる場合，プレゼンターは不要である． ドメイン層のインターフェースリポジトリから出力されるドメインモデルをレスポンスモデルを経てプレゼンターに変換し，インターフェース層のコントローラに出力する． バックエンドでテンプレートエンジンを用いてHTMLを生成する場合，プレゼンターが必要である． ・ユースケースとメソッド名 インターラクターでは，ドメイン層を組み合わせてシステムの振舞（ユースケース）を具現化する．そのため，メソッド名はユースケースを適切に表現した自由な英単語を用いる．Laravelの基本的なメソッド名（index，store，create，show，update，）が参考になる．CREATE処理とUPDATE処理をSAVE処理としてまとめてもよい． メソッド名 引数型 返却値型 処理内容 indexFoo indexFooRequest indexFooResponse showFoo showFooRequest showFooResponse createFoo createFooRequest createFooResponse updateFoo updateFooRequest updateFooResponse saveFoo（upsertFoo） saveFooRequest（upsertFooRequest） saveFooResponse（upsertFooResponse） リポジトリのfindメソッドをコールして重複確認を実行し，その結果に応じてcreateメソッドまたはupdateメソッドをコールする．参考：https://github.com/little-hands/ddd-q-and-a/issues/241 deleteFoo deleteFooRequest deleteFooResponse ・ユースケース図 ユースケース図については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_analysis_design_programming.html ＊実装例＊ バックエンドをAPIとして用いる場合，プレゼンターは不要となる．この場合を示す． fooRepository = $fooRepository; } /** * @param CreateFooRequest $createFooRequest * @return CreateFooResponse */ public function createFoo(CreateFooRequest $createFooRequest): CreateFooResponse { $foo = $this->fooRepository->create( new Bar($createFooRequest->bar), new Baz($createFooRequest->baz) ); // 何らかの処理 } } fooRepository = $fooRepository; } /** * @param CreateFooRequest $createFooRequest * @return CreateFooResponse */ public function createFoo(CreateFooRequest $createFooRequest): CreateFooResponse { $foo = $this->fooRepository->create( new Bar($createFooRequest->bar), new Baz($createFooRequest->baz) ); // 何らかの処理 } /** * @param GetFooRequest $getFooRequest * @return GetFooResponse */ public function getFoo(GetFooRequest $getFooRequest): GetFooResponse { $foo = $this->fooRepository->findById( new FooId($getFooRequest->id) ); // 何らかの処理 } /** * @param UpdateFooRequest $updateFooRequest * @return UpdateFooResponse */ public function updateFoo(UpdateFooRequest $updateFooRequest): UpdateFooResponse { $foo = $this->fooRepository->update( new FooId($updateFooRequest->id), new Bar($updateFooRequest->bar), new Baz($updateFooRequest->baz) ); // 何らかの処理 } /** * @param DeleteFooRequest $deleteFooRequest * @return DeleteFooResponse */ public function deleteFoo(DeleteFooRequest $deleteFooRequest): DeleteFooResponse { $foo = $this->fooRepository->delete( new FooId($deleteFooRequest->id) ); // 何らかの処理 } } インプットバウンダリ ・インプットバウンダリとは インターラクターのインターフェースのこと．上位レイヤーにあるコントローラは，インターラクターインタフェースに依存する． ＊実装例＊ アウトプットバウンダリ ・アウトプットバウンダリとは 上位レイヤーのプレゼンターのインターフェースのこと．インターラクターは，レスポンスモデルではなく．アウトプットバウンダリをインターフェース層に出力する．ただし，アプリケーションをAPIとして用いる場合は，プレゼンターとアウトプットバウンダリが不要になり，これに伴い，インターラクターはレスポンスモデルを返却するようにする． リクエストモデル（インプットデータ） ・リクエストモデルとは インターフェース層のコントローラから入力されるリクエストパラメータをユースケース層に入力する時に，その入力構造を定義する．インターラクターのメソッドごとにリクエストモデルを用意するとよい． fooId = $fooId; $this->fooName = $fooName; } } レスポンスモデル（アウトプットデータ） ・レスポンスモデルとは ユースケース層のインターラクターから出力されるドメインモデルをインターフェース層に出力する時に，その出力構造を定義する．インターラクターのメソッドごとにレスポンスモデルを用意するとよい．またコントローラにて，フレームワーク依存のJSONレスポンスメソッドにレスポンスモデルを渡せるよう，クラス自身の構造を変換するメソッドを持たせるとよい．もし，クラス自身を渡して問題ないJSONレスポンスメソッドであれば，これは不要である． ＊実装例＊ ユースケース層のindexメソッドに対応するレスポンスモデル．JSONレスポンスメソッドが配列構造を引数に受け付けるため，これに渡せるよう，自身を配列構造に変換するメソッドを持たせる． foos = $foos; } /** * @return array */ public function toArray(): array { return [ \"foos\" => $this->foos ]; } } ユースケース層のcreateメソッドに対応するレスポンスモデル． fooId = $fooId; $this->fooName = $fooName; } /** * @return array */ public function toArray(): array { return [ \"id\" => $this->fooId, \"name\" => $this->fooName ]; } } アプリケーションサービス ・アプリケーションサービスとは ユースケース層の中で，ドメイン層のオブジェクトを用いる汎用的なロジックが切り分けられたもの．ドメイン層のドメインサービスとは異なり，あくまでユースケース層のロジックが切り分けられたものである． ・通知処理 ＊実装例＊ Slackへの通知処理をアプリケーションサービスとして切り分ける． message = $message; } public function notify() { // SlackのAPIにメッセージを送信する処理 } } これを，ユースケース層でコールするようにする． notify(); } } 04. ドメイン層（黄） エンティティ ・エンティティとは 後述の説明を参照せよ． 値オブジェクト ・値オブジェクトとは 後述の説明を参照せよ． ドメインイベント ・ドメインイベントとは ドメイン層の中で，ビジネス的な『出来事』をモデリングしたもの．エンティティや値オブジェクトは『物』をモデリングするため，着眼点が異なる．エンティティデザインパターンの一つである『Pub／Subパターン』の概念を用いて，ドメインイベントとイベントリスナー（イベントハンドラー）の紐付きを表現する． Type Code（標準型） ・Type Codeとは Type Codeは概念的な呼び名で，実際は，標準的なライブラリとして利用できるEnumクラスに相当する．一意に識別する必要がないユビキタス言語の中でも，特に『区分』や『種類』などは，値オブジェクトとしてではなく，Enumクラスとしてモデリング／実装する．ただし，類似するパターンとして値オブジェクトのディレクトリ内に配置しても良い． ・色 ＊実装例＊ [\"name\" => \"レッド\"], self::BLUE => [\"name\" => \"ブルー\"] ]; /** * 値 */ private $value; /** * 色名 */ private $name; // インスタンス化の時に，『色の区分値』を受け取る． public function __construct(string $value) { // $kbnValueに応じて，色名をnameデータにセットする． $this->value = $value; $this->name = static::$set[$value][\"name\"]; } /** * 値を返却します． */ public function value(): int { return $this->value; } /** * 色名を返却します． */ public function name(): string { return $this->name; } } ・性別 ＊実装例＊ [\"name\" => \"男性\"], self::WOMAN => [\"name\" => \"女性\"], self::UNKNOWN => [\"name\" => \"不明\"], ]; /** * 値 */ private $value; /** * 名前 */ private $name; public function __construct($value) { $this->value = $value; $this->name = static::$set[$value][\"name\"]; } /** * 値を返却します． */ public function value(): int { return $this->value; } /** * 名前を返却します． */ public function name() { return $this->name; } } ・年号 ＊実装例＊ [\"name\" => \"明治\"], self::TAISHO => [\"name\" => \"大正\"], self::SHOWA => [\"name\" => \"昭和\"], self::HEISEI => [\"name\" => \"平成\"], self::REIWA => [\"name\" => \"令和\"], self::SEIREKI => [\"name\" => \"西暦\"], ]; private static $ymd = [ self::MEIJI => [ \"start\" => [ \"year\" => 1868, \"month\" => 1, \"day\" => 25, ], \"end\" => [ \"year\" => 1912, \"month\" => 7, \"day\" => 29, ], ], self::TAISHO => [ \"start\" => [ \"year\" => 1912, \"month\" => 7, \"day\" => 30, ], \"end\" => [ \"year\" => 1926, \"month\" => 12, \"day\" => 24, ], ], self::SHOWA => [ \"start\" => [ \"year\" => 1926, \"month\" => 12, \"day\" => 25, ], \"end\" => [ \"year\" => 1989, \"month\" => 1, \"day\" => 7, ], ], self::HEISEI => [ \"start\" => [ \"year\" => 1989, \"month\" => 1, \"day\" => 8, ], \"end\" => [ \"year\" => 2019, \"month\" => 4, \"day\" => 30, ], ], self::REIWA => [ \"start\" => [ \"year\" => 2019, \"month\" => 5, \"day\" => 1, ], \"end\" => [ \"year\" => 9999, \"month\" => 12, \"day\" => 31, ], ], ]; /** * 値 * * @var string */ private $value; /** * 年号名 * * @var string */ private $name; /** * 値を返却します * * @return string */ public function value(): string { return $this->value; } /** * @param $value */ public function __construct($value) { $this->value = $value; $this->name = static::$set[$value][\"name\"]; } /** * 年号名を返却します * * @return string */ public function name() { return $this->name; } } ドメインサービス ・ドメインサービスとは ドメイン層のエンティティに持たせるとやや不自然な汎用的なロジック（例：リポジトリを用いて，他のドメインモデルに対するアクセス処理など）を，ユースケース層にメソッドを提供する．この時，エンティティのビジネスロジックがドメインサービスに実装されすぎないように注意する．ちなみに，ドメイン層でリポジトリを用いることを嫌って，ドメインサービスの処理をユースケース層のアプリケーションサービスで定義しても問題ない． 参考： https://github.com/little-hands/ddd-q-and-a/issues/159 https://www.amazon.co.jp/dp/B082WXZVPC ・認可 ドメイン層のリポジトリを用いて，該当のIDのエンティティに対してアクセス可能かを検証する． 参考： https://lessthan12ms.com/authorization-and-authentication-in-clean-architecture.html https://medium.com/@martinezdelariva/authentication-and-authorization-in-ddd-671f7a5596ac https://github.com/lezhnev74/ema/blob/master/src/Domain/Note/Commands/ModifyNote/ModifyNoteAuthorizer.php https://github.com/little-hands/ddd-q-and-a/issues/121 ＊実装例＊ fooRepositoy = $fooRepositoy; } /** * 更新処理を実行可能かを検証します． * * @param FooId $fooId * @param UserId $userId * @return bool */ public function canUpdateById(FooId $fooId, UserId $userId): bool { return $this->fooRepository->findById($fooId)->userId->equals($userId); } } ・重複確認 ドメイン層のリポジトリを用いて，該当の名前のエンティティがDBに存在するかどうかを検証する． 参考： https://stackoverflow.com/questions/45007667/cqrs-ddd-how-to-validate-products-existence-before-adding-them-to-order https://www.amazon.co.jp/dp/B082WXZVPC https://github.com/little-hands/ddd-q-and-a/issues/573 ＊実装例＊ fooRepositoy = $fooRepositoy; } /** * エンティティがすでに存在しているかどうかを判定します． * * @param Foo $foo * @return bool */ public function exists(Foo $foo): bool { $foo = $this->fooRepository->findByName($foo->name()); return $foo !== null; } } ・ドメイン例外 ドメイン層の例外処理をまとめた例外クラス． ＊実装例＊ Specificationパターン ・Specificationパターンとは デザインパターンの一つ．責務として，バリデーション，検索条件入力データを持つ．これらをエンティティや値オブジェクトのメソッド内部に持たせた場合，肥大化の原因となり，また埋もれてしまうため，可読性と保守性が悪い．そこで，こういったビジネスルールをSpecificationオブジェクトとして切り分けておく． ・ビジネスルールのバリデーション 真偽値メソッド（isFooメソッド）のように，オブジェクトのデータを検証して、仕様を要求を満たしているか、何らかの目的のための用意ができているかを調べる処理する． ＊実装例＊ isX) return false; if (!$entity->isY) return false; if (!$entity->isZ) return false; return true; } } ・検索条件入力データ リクエストのパスパラメータとクエリパラメータを引数として，検索条件のオブジェクトを生成する．ビジネスルールのバリデーションを行うSpecificationクラスと区別するために，Criteriaオブジェクトという名前としても用いられる． ＊実装例＊ id = $array[\"id\"]; } if (isset($array[\"name\"])) { $criteria->id = $array[\"name\"]; } if (isset($array[\"email\"])) { $criteria->id = $array[\"email\"]; } return $criteria; } } ドメイン貧血症 ・ドメイン貧血症とは ドメイン層に配置されながらも，ビジネスロジックをほとんど持たないオブジェクトのこと． ・ドメインサービスにおける注意点 ドメイン層のロジックをドメインサービスに切り分けすぎると，ドメイン層のオブジェクトがゲッターとセッターしか持たないオブジェクトになってしまう．これは，ドメイン貧血症の状態である．そのため，ドメインサービス層の構築は控えめにし，可能な限りエンティティ／値オブジェクトとして実装する． 05-02. エンティティ エンティティとは 責務として，ビジネスのルールや制約の定義を持ち，値オブジェクトとは区別される．エンティティの責務をデザインパターンに切り分けても良い． 識別可能 ・識別可能とは オブジェクトが識別子（例：IDなど）を持ち，他のオブジェクトと同じ属性をもっていても，区別される．この識別子は，データベースのプライマリキーに対応している． type = $type; $this->name = $name; $this->number = $number; $this->priceVO = $priceVO; $this->colorVO = $colorVO; } /** * 犬用おもちゃ名（色）を返却します． * * @return string */ public function nameWithColor() { return sprintf( \"%s（%s）\", $this->name->value(), $this->colorVO->name() ); } } 識別子による等価性検証 ・識別子による等価性検証とは 等価性検証用のequalsメソッドを持つ．保持する識別子が，対象のエンティティと同じ場合，同一のものと見なされる． ・等価性の検証方法 全てのエンティティに等価性の検証メソッドを持たせると可読性が低い．そこで，全てのエンティティに等価性検証用のequalsメソッドを持たせることをやめ，継承元の抽象クラスのエンティティにこれを定義するとよい． id->equals($entity->id()); // IDオブジェクトの等価性 } /** * IDクラスを返却します． */ public function id(): Id { return $this->id; } } ・複合主キーへの対応（PHPでは不要） 以降の説明はJavaについて適用されるため，PHPでは不要である．複合主キーを持つオブジェクトに対応するために，主キーとなる方のオブジェクト側に，equalsメソッドとhashメソッドを定義する．これにより，言語標準搭載のequalsメソッドとhashメソッドをオーバーライドし，異なるセッションに渡ってオブジェクトを比較できるようにする．これらを定義しないと，オーバーライドされずに標準搭載のメソッドが用いられる．標準搭載のメソッドでは，異なるセッションに渡ったオブジェクトの比較では，必ず異なるオブジェクトであると判定してしまう． ＊実装例＊ PHPでは不要であるが，参考までに，PHPで実装した． id = $id; } /** * ハッシュ値を返却します． * * NOTE: 複合主キーを持つオブジェクトの等価性を正しく検証するために，標準の関数をオーバーライドします． * * @return string */ public function hash(): string { return $this->id; } /** * オブジェクトの等価性を検証します． * * NOTE: 複合主キーを持つオブジェクトの等価性を正しく検証するために，標準の関数をオーバーライドします．． * * @param Id $id * @return bool */ public function equals(Id $id): bool { return ($id instanceof $this || $this instanceof $id) // IDオブジェクトのデータ型の等価性 && $this->hash() == $id->hash(); // ハッシュ値の等価性 } } データの可変性／不変性 ・可変性／不変性の実現方法（Mutable／Immutable） エンティティのデータは可変／不変データのいずれであってもよい．ただし，そもそもオブジェクトは不変である方が望ましいため，可変的なデータは最小限にする．変化させても問題ないプロパティに対してはセッターを定義し，不変的なデータに対してはコンストラクタインジェクションのみを許可するようにする．もちろん，セッター内ではドメインルールのバリデーションを実行する．不変性の実現方法については，後述の説明を参考にせよ． 05-03. 値オブジェクト 値オブジェクトとは 責務として，ビジネスのルールや制約の定義を持ち，エンティティと区別される．金額，数字，電話番号，文字列，日付，氏名，色などのユビキタス言語に関するデータと，一意で識別できるデータ（例えば，$idデータ）を持つ． 識別不可能 ・識別不可能とは 一意に識別できるデータをもたず，対象のユビキタス言語に関するデータをメソッドを持つ ・金額 金額データの計算をInteractor内処理やエンティティ内メソッドで行うのではなく，金額計算を行う値オブジェクトのメソッドとして分割する． ＊実装例＊ amount = (float) $amount; } /** * 金額を返却します * * @return float */ public function amount() { return $this->amount; } /** * 単位を返却します * * @return string */ public function unit() { return \"円\"; } /** * 足し算の結果を返却します * * @param Money $price * @return $this */ public function add(Money $price) { return new static($this->amount + $price->amount); } /** * 引き算の結果を返却します * * @param Money $price * @return $this */ public function substract(Money $price) { return new static($this->amount - $price->amount); } /** * 掛け算の結果を返却します * * @param Money $price * @return $this */ public function multiply(Money $price) { return new static($this->amount * $price); } } ・所要時間 所要時間データの計算をInteractorクラス内処理やエンティティ内メソッドで行うのではなく，所要時間計算を行う値オブジェクトのメソッドとして分割する． ＊実装例＊ distance = $distance; } /** * 徒歩または車のどちらを用いるかを判定します * * @return bool */ public function isMinuteByWalking(): bool { if ($this->distance * 1000 / self::WALKING_SPEED_PER_MINUTE distance * 1000 / self::WALKING_SPEED_PER_MINUTE; return ceil($minute); } /** * 車での所用時間を計算します * * @return float */ public function minuteByCar(): float { $minute = $this->distance * 1000 / self::CAR_SPEED_PER_MINUTE; return ceil($minute); } } ・住所 郵便番号データとその処理を値オブジェクトとして分割する． ＊実装例＊ city = $city; $this->zip = $zip; $this->address = $address; } /** * 郵便番号を生成し，返却します * * @return string */ public function zip() { return sprintf( \"〒%s-%s\", substr($this->zip, 0, 3), substr($this->zip, 3) ); } /** * 住所を生成し，返却します * * @return string */ public function address(): string { return sprintf( \"%s%s%s\", $this->city->prefecture->name ?? '', $this->city->name ?? '', $this->address ?? '' ); } } ・氏名 氏名，性別，データとその処理を値オブジェクトとして分割する． ＊実装例＊ lastName = $lastName; $this->firstName = $firstName; $this->lastKanaName = $lastKanaName; $this->firstKanaName = $firstKanaName; } /** * 氏名を作成します． */ public function fullName(): string { return $this->lastName . $this->firstName; } /** * カナ氏名を作成します． */ public function fullKanaName(): string { return $this->lastKanaName . $this->firstKanaName; } } データの不変性（Immutable） ・不変性の実現方法 値オブジェクトは不変的であり，インスタンスとして生成されて以降，データは変更されない．オブジェクトの不変性を実現するために，オブジェクトにセッターを定義しないようにし，データの設定にはconstructメソッドだけを用いるようにする． ＊実装例＊ propertyA = $propertyA; $this->propertyB = $propertyB; $this->propertyC = $propertyC; } } ・セッターでは不変的にならない理由 ＊実装例＊ Test01クラスインスタンスの$property01データに値を設定するためには，インスタンスからセッターを呼び出す．セッターは何度でも呼び出せ，その度にデータの値を上書きできてしまう． setProperty01(\"データ01の値\"); $test01->setProperty01(\"新しいデータ01の値\"); Test02クラスインスタンスの$property02データに値を設定するためには，インスタンスを作り直さなければならない．つまり，以前に作ったインスタンスの$property02の値は上書きできない．セッターを持たせずに，constructメソッドだけを持たせれば，不変的なオブジェクトとなる． ・過剰なゲッターへの対処法 不変的なデータはゲッターを用いなければアクセスできない．そのため，値オブジェクトにプロパティ値を返却するだけのゲッターが量産され，ファイルの見通しが悪くなってしまう．そこで，例えばPHPでは，マジックメソッドの__getメソッドを用いて，ゲッターの実装を省略できる．全ての値オブジェクトの基底クラスに，『コールされたゲッターがクラス内に存在していなければ，動的にプロパティにアクセスして返却する』処理を持った__getメソッドを定義しておく．すると，マジックメソッドのオーバーライド機能により，自身で定義した__getメソッドが代わりにコールされるようになり，ゲッターを定義する必要がなくなる． {$name}; } } class Foo { use ImmutableTrait; private $bar; public function __constructor($bar) { $this->bar = $bar } } $foo = new Foo() $foo->bar // __getメソッドが代わりにコールされ，プロパティ値が返却される． 概念的な統一体 交換可能性 オブジェクトが新しくインスタンス化された場合，以前に同一オブジェクトから生成されたインスタンスから新しく置き換える必要がある． 属性による等価性 ・属性による等価性検証とは 等価性を検証するメソッドを持つ．保持する全ての属性が，対象の値オブジェクトと同じ場合，同一のものと見なされる． ・等価性の検証方法 ＊実装例＊ 属性を一つだけ保持する場合，一つの属性のみを検証すれば良いため，以下の通りとなる． value = $value; } /** * @return string */ public function value(): string { return $this->value; } /** * 値オブジェクトの等価性を検証します． * * @param ValueObject $VO * @return bool */ public function equals(ValueObject $VO): bool { // 単一の属性を対象とする． return $this->value() === $VO->value(); } } 属性を複数保持する値オブジェクトの場合，全ての属性を検証する必要があるため，以下の通りとなる． paymentType = $paymentType; $this->contactMail = $contactMail; $this->price = $price; } /** * 値オブジェクトの等価性を検証します． * * @param ValueObject $VO * @return bool */ public function equals(ValueObject $VO): bool { // 複数の属性を対象とする． return $this->paymentType->value() === $VO->paymentType->value() && $this->contactMail->value() === $VO->contactMail->value() && $this->price->value() === $VO->price->value(); } } 全ての値オブジェクトに等価性の検証メソッドを持たせると可読性が低い．そこで，継承元の抽象クラスの値オブジェクトに定義するとよい．その時は，保持している属性を反復的に検証できるように実装するとよい． $value) { if ($this->__get($key) !== $VO->__get($key)) { return false; } } return true; } } 05-04. ルートエンティティとトランザクション ルートエンティティ ・ルートエンティティとは エンティティや値オブジェクトからなる集約の中で，最終的にユースケース層へレスポンスされる集約を，『ルートエンティティ』という． ＊実装例＊ dogToy = $dogToy; $this->dogFood = $dogFood; } /** * 犬用おもちゃを返却します． * * @return DogToy */ public function getDogToy(): DogToy { return $this->dogToy; } /** * 犬えさを返却します． * * @return DogFood */ public function getDogFood(): DogFood { return $this->dogFood; } } ・集約とは データをセットで扱う必要があるエンティティのまとまりのこと．依存関係の観点からみた集約については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html トランザクションとの関係性 インフラ層のリポジトリでは，ルートエンティティの単位で，データの書き込み／読み出しのトランザクション処理を実行する．ルートエンティティを定義づける時の注意点として，集約の単位が大き過ぎると，一部分のエンティティのみトランザクションの対象とすれば良い処理であるのにも関わらず，ルートエンティティ全体まで対象としなければならなくなる．そのため，ビジネスロジックとしてのまとまりと，トランザクションとしてのまとまりの両方から，ルートエンティティの単位を定義づけるとよい． 参考：https://qiita.com/mikesorae/items/ff8192fb9cf106262dbf#%E5%AF%BE%E7%AD%96-1 06. インフラ層（青） インフラ層の依存性逆転 ・DIP（依存性逆転の原則）とは 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html ・依存性を逆転させる方法 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html https://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-falseakitekutiyabian-qian-toyi-cun-xing-ni-zhuan-falseyuan-ze リポジトリ ・リポジトリパターンとは デザインパターンの一つ．一例として，以下のメソッドを持つ．具体的な実装については，インターフェースリポジトリの実装を参考にせよ．CREATE処理とUPDATE処理をSAVE処理としてまとめてもよい． 参考： https://codewithshadman.com/repository-pattern-csharp/ https://sf9v.github.io/posts/generating-the-repository-pattern-in-go/#introduction https://terasolunaorg.github.io/guideline/public_review/ImplementationAtEachLayer/DomainLayer.html#repository-interface-label メソッド名 引数型 返却値型 処理内容 findById Id型 ドメインモデル型 ルートエンティティののドメインモデルを取得する． findAll なし ドメインモデル型を持つ配列 全てのドメインモデルを取得する． findAllByCriteria Criteria型 ドメインモデル型を持つ配列 条件に合致した全てのドメインモデルを取得する． create ルートエンティティのドメインモデル型 void型 ルートエンティティのドメインモデルを作成する． update ルートエンティティのドメインモデル型 void型 ルートエンティティのドメインモデルを更新する． save（upsert） ルートエンティティのドメインモデル型 void型 ルートエンティティのドメインモデルを作成／更新する．SELECT文のIN句を用いて，同じ識別子のエンティティをDBから取得できるかどうかを確認する．取得できない場合は，更新処理を実行する．参考：・https://github.com/little-hands/ddd-q-and-a/issues/241・https://github.com/little-hands/ddd-q-and-a/issues/129 delete Id型 void型 ルートエンティティのドメインモデルを削除する． ・他の類似するデザインパターンとの比較 デザインパターン 駆動の種類 ドメインモデルとテーブルの関連度合い 採用ライブラリ例 適所 補足 Active Record データベース駆動 ・非常に強い．・手順としてテーブル設計が先にあり，一つのドメインモデルが一つのテーブルに対応している．・テーブル間のリレーションシップによって，ドメインモデル間の依存関係が決まる． ・Eloquent（PHP）・Active Record（Ruby）・Hibernate（Java） ビジネスロジックが複雑でないアプリケーション参考：https://www.informit.com/articles/article.aspx?p=1398618&seqNum=3 DataMapperパターンと同じく，ORMの実装方法の一つである．参考：https://culttt.com/2014/06/18/whats-difference-active-record-data-mapper/ Data Mapper ドメイン駆動 ・弱い・Entityマネージャを用いて，ドメインモデルをDBに永続化する． Doctrine ビジネスロジックが複雑なアプリケーション参考：https://www.informit.com/articles/article.aspx?p=1398618&seqNum=3 ActiveRecordパターンと同じく，ORMの実装方法の一つである．参考：https://culttt.com/2014/06/18/whats-difference-active-record-data-mapper/ Repository ドメイン駆動 ・弱い・手順としてドメインモデルの依存関係の設計が先にあり，テーブル間の関係性は自由である．一つのドメインモデルが複数のテーブルを参照してもよい． ビジネスロジックが複雑なアプリケーション DB，RDMS，NoSQL，なんでもでもよい． なし なし 非常に弱い DBファサード ・実装リポジトリ リポジトリパターンを用いる．責務として，DBに対してデータの書き込み／読み出しのトランザクション処理を実行する．トランザクションはルートエンティティを単位として定義する必要があるため，リポジトリも同じくルートエンティティを単位として定義づけることになる．そのため，引数の型はルートエンティティのドメインモデル型になる．リポジトリではルートエンティティを意識して実装する必要がある一方で，DBのどのテーブルにデータが存在しているかを問わない．これにより，ルートエンティティとDBテーブルを別々に設計できる．ルートエンティティとトランザクションの関係性については，前述の説明を参考にせよ．DBテーブル設計については以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_database_operation.html ・インターフェースリポジトリ 依存性逆転の原則を導入する場合に，ドメイン層にインターフェースリポジトリを配置する．インフラ層の実装リポジトリクラスと対応関係にある．実装リポジトリについては，後述の説明を参考にせよ． ＊実装例＊ ・DBに対する書き込み責務（Create，Update，Delete） DBに対する書き込み操作を行う． GET／POSTによって，ユースケース層から値が送信される． ファクトリによって，送信された値からエンティティや値オブジェクトを作成する．さらに，それらからルートエンティティを作成する． リポジトリにルートエンティティを渡す． ルートエンティティをレコードとしてDBに挿入する． 参考： https://www.doctrine-project.org/projects/doctrine-orm/en/2.8/reference/query-builder.html https://github.com/doctrine/dbal/blob/2.12.x/lib/Doctrine/DBAL/Query/QueryBuilder.php ＊実装例＊ CREATE処理のため，DoctrineのQueryBuilderクラスのinsertメソッドを実行する． createQueryBuilder(); // SQLを定義する． $query->insert(\"dog_toy_table\") ->values([ // ルートエンティティの要素をカラム値として設定する．（IDはAutoIncrement） \"name\" => $dogToy->getName()->value(), \"type\" => $dogToy->getType()->value(), \"price\" => $dogToy->getPriceVO()->value(), \"color\" => $dogToy->getColorVO()->value(), ]); } } UPDATE処理のため，DoctrineのQueryBuilderクラスのupdateメソッドを実行する． createQueryBuilder(); // SQLを定義する． $query->update(\"dog_toy_table\", \"dog_toy\") // ルートエンティティの要素をカラム値として設定する． ->set(\"dog_toy.name\", $dogToy->getName()->value()) ->set(\"dog_toy.type\", $dogToy->getType()->value()) ->set(\"dog_toy.price\", $dogToy->getPriceVO()->value()) ->set(\"dog_toy.color\", $dogToy->getColorVO()->value()) ->where(\"dog_toy.id\", $dogToy->getId()->value(); return $query->getResult(); } } DELETE処理（論理削除）のため，DoctrineのQueryBuilderクラスのupdateメソッドを実行する． createQueryBuilder(); // SQLを定義する． $query->update(\"dog_toy_table\", \"dog_toy\") // 論理削除 ->set(\"dog_toy.is_deleted\", FlagConstant::IS_ON) ->where(\"dog_toy.id\", $dogToy->getId()->value(); return $query->getResult(); } } ・DBに対する読み出し責務（Read） DBに対する書き込み操作を行う． ユースケース層から集約がリクエストされる． DBからレコードを取得する． ファクトリによって，レコードからエンティティや値オブジェクトを作成する． リポジトリからルートエンティティを返却し，ユースケース層に渡す． 参考： https://www.doctrine-project.org/projects/doctrine-orm/en/2.8/reference/query-builder.html https://github.com/doctrine/dbal/blob/2.12.x/lib/Doctrine/DBAL/Query/QueryBuilder.php ＊実装例＊ READ処理のため，DoctrineのQueryBuilderクラスのselectメソッドを実行する． createQueryBuilder(); // SQLを設定する． $query->select( \"dog_toy.id AS dog_toy_id\", \"dog_toy.name AS dog_toy_name\", \"dog_toy.type AS dog_toy_type\", \"dog_toy.price AS dog_toy_price\", \"dog_toy.color AS dog_toy_color\" ) ->from(\"dog_toy_table\", \"dog_toy\") // 論理削除されていないもののみ ->where(\"dog_toy.is_deleted\", FlagConstant::IS_OFF) ->getQuery(); // SQLを実行する． $entities = $query->getResult(); $dogToys = []; foreach($entities as $entity){ // 取得したエンティティをドメインモデルに変換する． $dogToys[] = $this->toDogToy($entity); } return $dogToys; } /** * ドメインモデルに変換します． */ private function toDogToy(array $entity): DogToy { $dogToy = new DogToy( new DogId($entity[\"dog_toy_id\"]), new DogName($entity[\"dog_toy_name\"]), new DogToyType($entity[\"dog_toy_type\"]), new PriceVO($entity[\"dog_toy_price\"], new ColorVO($entity[\"dog_toy_color\"] ); return $dogToy; } } ファクトリ ・ファクトリとは 責務として，新たな集約の作成や，既存の集約の再作成を実行する． ＊実装例＊ ルータ ・ルータとは コントローラにリクエストをルーティングする． ミドルウェア ・ミドルウェアとは ルーティング後にコントローラメソッドの前にコールされるBeforeMiddleと，レスポンスの実行時にコールされるAfterMiddlewareがある．最近のフレームワークでも搭載されている． イベントリスナー（イベントハンドラー） ・イベントリスナーとは ドメインイベントが発生した場合に，それに紐づく処理を実行する．フレームワークの機能に依存することになるため，実装の詳細をインフラ層におく． 参考： https://stackoverflow.com/questions/67148194/domain-driven-design-ddd-domain-event-handlers-where-to-place-them https://zenn.dev/fuuuuumin65/articles/2c96e8f0b29c01 ・命名規則 イベントでリスナーを使い回さずに，各イベントごとにリスナーを作成する．そのため，名前は『イベント名』＋Listener（Handler）となる． 参考：https://docs.microsoft.com/ja-jp/dynamicsax-2012/developer/naming-conventions-delegates-and-event-handlers#event-handler-naming-conventions インフラストラクチャサービス ・インフラストラクチャサービスとは インフラ層の中で，汎用的なロジックが切り分けられたもの．実装リポジトリと同様にして，ドメイン層にストラクチャサービスのインターフェースを設け，依存性逆転の原則を満たせるようにする． ・ロギング ・ファイル出力 ・ハッシュ化 パスワードのハッシュ化． 参考：https://dev.to/stevensunflash/using-domain-driven-design-ddd-in-golang-3ee5 07. アーキテクチャにおけるレイヤー別の例外スロー スローされた例外の扱い 各レイヤーでは例外をスローするだけに留まり，スローされた例外を対処する責務は，より上位レイヤーに持たせる．より上位レイヤーでは，そのレイヤーに合った例外に詰め替えて，これをスローする．最終的には，ユーザーインターフェース層まで持ち上げ，画面上のポップアップで警告文としてこれを表示する．例外スローの意義については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_logic_catch_error_throw_exception_logging.html インターフェース層 ・例外 final class PresentationException extends Exception { } ユースケース層 ・例外 final class InteractorException extends Exception { } ドメイン層 ・例外 final class DomainException extends Exception { } インフラ層 ・例外 final class InfrastructureException extends Exception { } "},"public/frontend_architecture.html":{"url":"public/frontend_architecture.html","title":"▶ ︎フロントエンドアーキテクチャ","keywords":"","body":"フロントエンドアーキテクチャ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. フロントエンドアーキテクチャの種類 SPA：Single Page Application ・SPAとは ブラウザレンダリングのステップ 実行者 Loading ブラウザ Scripting ブラウザ Rendering ブラウザ Paiting ブラウザ 1つのWebページの中で，サーバとデータを非同期通信し，ブラウザ側で部分的に静的ファイルを生成する方法のこと．クライアント側でレンダリングを行うため，SSRと比較してCSR：Client Server side Renderingともいう．非同期通信は，Ajaxの手法を用いて実現される．また，静的ファイルの部分的な生成は，MVVMアーキテクチャによって実現する．SPAでは，ページ全体の静的ファイルをリクエストするのは最初のみで，それ以降はページ全体をリクエストすることはない．２回目以降は，ページ部分的にリクエストを行い，サーバ側からJSONを受け取っていく． 参考：https://developers.google.com/analytics/devguides/collection/analyticsjs/single-page-applications?hl=ja ・MVVMアーキテクチャとは Vue.jsでは，意識せずにMVVMアーキテクチャで実装できるようになっている．詳しくは，Vue.jsのノートを参考にせよ． ・Ajaxとは：Asynchronous JavaScript + XML HTML，XHTML，CSS，JavaScript，DOM，XML，XSLT，を組み合わせて非同期通信を実現する手法のこと．これらの技術を以下の順で組み合わせる． urlにアクセスすることにより，サーバからデータがレスポンスされる． DOMのマークアップ言語の解析により，Webページが構成される． ページ上で任意のイベント（ページング操作，フォーム入力など）が発火し，紐づくハンドラ関数が実行される． JavaScript型オブジェクトがJSONに変換される． 非同期通信処理により，バックエンドにリクエストを送信する． コントローラは，JSON型データを受信し，またそれを元にDBからオブジェクトをReadする． コントローラは，PHP型オブジェクトをJSONに変換し，レスポンスを返信する． 非同期通信メソッドがバックエンドからレスポンスを受信する． JSONがJavaScript型オブジェクトに変換される． オブジェクトがマークアップ言語に出力される． DOMを用いて，Webページを再び構成する． ・MPAとSPAの処理速度の違い MPAと比較して，データを非同期的に通信できるため，1つのWebページの中で必要なデータだけを通信すればよく，レンダリングが速い． SSR：Server Side Rendering ・狭義のSSRとは 1つのWebページの中で，サーバとデータを非同期通信し，サーバ側で静的ファイルを生成する方法のこと． 参考： https://ja.nuxtjs.org/docs/2.x/concepts/server-side-rendering https://tadtadya.com/summary-of-the-web-site-display-process-flow/#index-list-8 ブラウザレンダリングのステップ 実行者 Loading サーバ Scripting サーバ Rendering サーバ Paiting ブラウザ ・広義のSSR フレームワークには，バックエンド側のテンプレートエンジンによって静的ファイルを生成する機能を持つものがある．広義のSSRにはこれも含まれる． SSG：Static Site Generation ・SSGとは 事前にビルドを行って静的ファイルを生成しておく．そして，これをレンダリングし，静的サイトとして稼働させる．動的な要素（例：ランダム表示）を含む静的ファイルについては，該当の部分でAjaxを使用できるようにしておく． ISR：Incremental Static Regeneration ・ISRとは SSGの発展型．SSGとは異なり，事前にビルドせず，静的ファイルを生成しない．その代わり，クライアントからリクエストがあって初めて，そのページのみビルドが実行され，レンダリングされる．クライアントから一回でもリクエストがあったページでは，初回時にビルドされた静的ファイルがその都度レンダリングされる． 参考：https://nextjs.org/docs/basic-features/data-fetching#incremental-static-regeneration 02. Ajaxの非同期処理 非同期処理（並行処理／Concurrent Processing） ・非同期処理とは 一連の処理を順不同で実行する．『並行処理』ともいう．シングルスレッド環境下で実現できる． ・並列処理（Parallel Processing）との違い 複数の処理を同時に開始実行する．マルチスレッド環境下で実現できる．言語別の並列処理の実現方法ついては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/hardware.html 非同期処理の実現方法 ・基本実装 歴史的に，非同期処理を実装するための方法がいくつかある． 種類 提供 説明 補足 XMLHttpRequestクラス ビルトインオブジェクト 今では使うことは少ないが，Ajaxが登場した初期の頃によく使われた． 参考：https://developer.mozilla.org/ja/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest fetchメソッド ビルトイン関数 参考：https://developer.mozilla.org/ja/docs/Web/API/Fetch_API/Using_Fetch JQueryオブジェクト JQueryパッケージ getメソッド，postメソッド，ajaxメソッドを使用する． 参考：・https://api.jquery.com/category/ajax/shorthand-methods/・https://api.jquery.com/jquery.ajax axiosオブジェクト Axiosパッケージ 参考：https://github.com/axios/axios#request-method-aliases ・応用実装 コールバック関数地獄など，非同期処理の実装時に起こる問題点を解決するための方法がある． 種類 提供 説明 補足 Promiseオブジェクト ビルトインオブジェクト JQueryのPromiseオブジェクトを参考にして，ES2015から新しく使用できるようになった． 参考：https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise async/awaitを宣言 ビルトインオブジェクト ES2017から新しく使用できるようになった．ビルトインオブジェクトのPromiseオブジェクトをより使用しやすくしたもの． 参考：https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Statements/async_function Deferredオブジェクト JQueryパッケージ 参考：https://api.jquery.com/category/deferred-object/ 02-02. 基本実装 JQueryオブジェクトの場合 ・getメソッド，postメソッド const url = \"https://www.google.co.jp/\"; $.get(url); const url = \"https://www.google.co.jp/\"; const params = { name: \"Hiroki\", }; $.post(url, params); ・ajaxメソッド Ajaxを実現する．HTTPメソッド，URL，ヘッダー，メッセージボディなどを設定し，非同期的にデータを送受信する．Promiseオブジェクトを返却する． 参考：https://api.jquery.com/jquery.ajax ＊実装例＊ const id = 1; $.ajax({ // ################### // リクエストメッセージ // ################### // HTTPメソッドを指定 type: \"POST\", // ルートとパスパラメータを指定 url: \"/xxx/xxx/\" + id + \"/\", // 送信するデータの形式を指定 contentType: \"application/json\", // メッセージボディ data: { param1: \"AAA\", param2: \"BBB\" }, // ################### // レスポンスメッセージ // ################### // 受信するメッセージボディのデータ型を指定 dataType: \"json\", }) Axiosオブジェクトの場合 ・axiosオブジェクトとは Ajaxを実現する．HTTPメソッド，URL，ヘッダー，メッセージボディなどを設定し，非同期的にデータを送受信する．Promiseオブジェクトを返却する． 参考：https://github.com/axios/axios#axios 02-03. 応用実装 JQueryオブジェクトの場合 ・doneメソッド，failメソッド，alwaysメソッド Promiseオブジェクトがもつメソッド．ajaxメソッドによってレスポンスを受信した後，その結果をdone，fail，alwaysの三つに分類し，これに応じたコールバック処理を実行する方法． ＊実装例＊ JQueryパッケージのgetメソッドやpostメソッドを使用した場合． const url = \"https://www.google.co.jp/\"; $.get(url) .done((data) => { console.log(data); }) .fail((error) => { console.log(error); }); const url = \"https://www.google.co.jp/\"; const params = { name: \"Hiroki\", }; $.post(url, params) .done((data) => { console.log(data); }) .fail((error) => { console.log(error); }); JQueryパッケージのajaxメソッドを使用した場合． const id = 1; $.ajax({ type: \"POST\", url: \"/xxx/xxx/\" + id + \"/\", contentType: \"application/json\", data: { param1: \"AAA\", param2: \"BBB\" }, }) // 非同期通信の成功時のコールバック処理 .done((data) => { console.log(data); }) // 非同期通信の失敗時のコールバック処理 .fail((error) => { console.log(data); toastr.error(\"\", \"エラーが発生しました．\"); }) // 非同期通信の成功失敗に関わらず常に実行する処理 .always((data) => { this.isLoaded = false; }); ・thenメソッド Promiseオブジェクトがもつメソッド．ajaxメソッドによってレスポンスを受信した後，その結果をthenメソッドの引数の順番で分類し，これに応じたコールバック処理を実行する方法．非同期処理の後に同期処理を行いたい場合に用いる． ＊実装例＊ JQueryパッケージのajaxメソッドを使用した場合． const id = 1; $.ajax({ type: \"POST\", url: \"/xxx/xxx/\" + id + \"/\", contentType: \"application/json\", data: { param1: \"AAA\", param2: \"BBB\" }, }) // 最初のthen .then( // 引数1つめは通信成功時のコールバック処理 (data) => { }, // 引数2つめは通信失敗時のコールバック処理 (data) => { }) // 次のthen .then( // 引数1つめは通信成功時のコールバック処理 (data) => { }); Promiseオブジェクトの場合 ・Promiseオブジェクトとは 非同期処理を監視し，処理の結果と，その結果のステータスを返却する． 参考：https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise ・resolveメソッド，rejectメソッド Promiseオブジェクト内では暗黙的にtry-catchが実行されており，結果のステータスが成功であればresolveメソッドの結果を返却し，反対に失敗であればrejectメソッドを返却する．両方を実装すると良しなに実行してくれる．resolveメソッドとresolveメソッドのコール時にreturnを使用しないと，後続の処理も実行される．一つ目の書き方として，Promiseインスタンスのコールバック関数に渡す方法がある． const asyncFunc = () => { return new Promise((resolve, reject) => { // ステータスが成功の場合に選択される． resolve(\"SUCCESS\"); // Promise { \"SUCCESS\" } // ステータスが失敗の場合に選択される． reject(\"FAILED\"); // Promise { \"FAILED\" } console.log(\"test\"); }) } console.log(asyncFunc()); // 後続の処理も実行され，resolveメソッドの結果が返却される． // test // Promise { 'SUCCESS' } 一方で，resolveメソッドとresolveメソッドのコール時にreturnを使用すると，後続の処理は実行されない． const asyncFunc = () => { return new Promise((resolve, reject) => { return resolve(\"SUCCESS\"); reject(\"FAILED\"); console.log(\"test\"); }) } console.log(asyncFunc()); // 後続の処理も実行されない． // Promise { 'SUCCESS' } 別の書き方として，Promiseオブジェクトから直接resolveメソッドやrejectメソッドをコールしてもよい．この場合，必ずreturnで返却する必要がある．returnを使用しないと，何も返却されない． const asyncFunc = () => { // ステータスが成功の場合に選択される． return Promise.resolve(\"SUCCESS\"); // Promise { \"SUCCESS\" } } const asyncFunc = () => { // ステータスが失敗の場合に選択される． return Promise.reject(\"FAILED\"); // Promise { \"FAILED\" } } console.log(asyncFunc()); // Promise { 'SUCCESS' } const asyncFunc = () => { return Promise.resolve(\"SUCCESS\"); } asyncFunc() // 失敗時に返却されたrejectをハンドリング .catch((reject) => { // rejectメソッドを実行 reject }) .then((resolve) => { // resolveメソッドを実行 resolve }) console.log(asyncFunc()); // Promise { 'SUCCESS' } 非同期処理内で両方をコールするとエラーになる． const asyncFunc = () => { Promise.resolve(\"SUCCESS\"); Promise.reject(\"FAILED\"); } console.log(asyncFunc()); // エラーになる UnhandledPromiseRejectionWarning: FAILED (Use `node --trace-warnings ...` to show where the warning was created) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). To terminate the node process on unhandled promise rejection, use the CLI flag `--unhandled-rejections=strict` (see https://nodejs.org/api/cli.html#cli_unhandled_rejections_mode). (rejection id: 1) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code. 補足として，NodeのHTTPライブラリの関数は，Promiseインスタンスのコールバック関数として使用しないと，正しく挙動しない． 参考：https://stackoverflow.com/questions/38533580/nodejs-how-to-promisify-http-request-reject-got-called-two-times ・thenメソッド，catchメソッド，finallyメソッド 参考：https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise#instance_methods ＊実装例＊ const resolveFunc = new Promise((resolve, reject) => { return resolve(\"resolve!!\"); }); resolveFunc.then((value) => { // resolveFuncがPromiseを返し、resolve!!がresolveされるため // thenメソッドが実行されコンソールにresolve!!が表示される console.log(value); // resolve!! }); const resolveFunc = () => { // resolveFuncはasync functionではないため、Promiseを返さない return \"resolve!!\"; } resolveFunc.then((value) => { // resolveFuncはPromiseを返さないため、エラーが発生して動かない // Uncaught TypeError: resolveError(...).then is not a function console.log(value); }); const rejectFunc = new Promise((resolve, reject) => { reject(new Error(\"reject!!\")); }); rejectFunc.catch((err) => { // rejectFuncがPromiseを返し、reject!!がrejectされるため // catchメソッドが実行されコンソールにreject!!が表示される console.log(err); // reject!! }); async/await宣言 ・async宣言 任意の関数を非同期関数化する．Promiseオブジェクトを返却するように定義しなくとも，Promiseオブジェクト返却してくれるため，可読性が高まる．ただし，Promiseオブジェクトを返すようにしても，入れ子にならないように処理してくれる． 参考：https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Statements/async_function ＊実装例＊ 以下の全ては，同じ処理を定義している． const asyncFunc = async () => { return \"SUCCESS\" } // 単にreturnとしてもPromiseオブジェクトが返却される． console.log(asyncFunc()); // Promise { \"SUCCESS\" } const asyncFunc = async () => { return new Promise((resolve, reject) => { return resolve(\"SUCCESS\") // Promise { \"SUCCESS\" } }) } // Promiseオブジェクトを返却するようにしても，入れ子にはならない． console.log(asyncFunc()); // Promise { \"SUCCESS\" } const asyncFunc = async () => { return Promise.resolve(\"SUCCESS\") // Promise { \"SUCCESS\" } } // Promiseオブジェクトを返却するようにしても，入れ子にはならない． console.log(asyncFunc()); // Promise { \"SUCCESS\" } また，axiosオブジェクトのようにPromiseオブジェクトを標準で返却するメソッドを使用してもよい． ＊実装例＊ 非道処理としてGETでリクエストを送信している． // axiosオブジェクトのメソッドはPromiseオブジェクトを返却する． const asyncFunc = async () => { axios.get(\"/some/path\").then((res) => { console.log(res.data); // \"some data\" }); } ・await宣言 以降の全処理をthenメソッドに渡す．Promiseオブジェクトのthenメソッドに相当するが，thenメソッドのようにメソッドチェーンする必要はなくなるため，可読性が高い．時間のかかる非同期処理でこれを宣言すると，予期せず処理が流れてしまうことを防げる． ＊実装例＊ // Promiseオブジェクトのthenメソッドを使用した場合 const asyncFunc = async () => { axios.get(\"/some/path\").then((res) => { console.log(res.data); // \"some data\" }); } // awaitを使用した場合 const asyncFunc = async () => { // 以降の全処理がthenメソッドに渡される． const res = await axios.get(\"/some/path\"); console.log(res.data); // \"some data\" } await宣言により，コールバック地獄のソースコードが分かりやすくなる． // Promiseオブジェクトのthenメソッドを使用した場合 const asyncFunc = async () => { // コールバック関数地獄になっている． axios.get(\"/some/path1\").then((res) => { const res1 = res; axios.get(\"/some/path1\").then((res) => { const res2 = res; console.log(res1.data + res2.data); // \"some data\" }); }) } // awaitを使用した場合 const asyncFunc = async () => { const res1 = await axios.get(\"/some/path1\"); const res2 = await axios.get(\"/some/path2\"); console.log(res1.data + res2.data); // \"some data\" } ・エラーハンドリング Promiseオブジェクトのthenメソッド，catchメソッド，finallyメソッドを使用してエラーハンドリングを実装できるが，try-catch構文とawait宣言を組み合わせて，より可読性高く実装できる． 参考：https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Promise#instance_methods ＊実装例＊ const asyncFunc = async () => { return axios.get(\"/some/path1\") .catch((error) => { console.error(error); }) .then((data) => { console.info(data); }); } const asyncFunc = async () => { // 初期化 let response; try { response = await axios.get(\"/some/path1\") console.info(response); } catch (error) { console.error(error); } return response; } ・スリープ 指定した秒数だけ処理を待機する． // 5秒待機する． await new Promise((resolve) => { setTimeout(resolve, 5000) }); "},"public/frontend_and_backend_architecture_microservice.html":{"url":"public/frontend_and_backend_architecture_microservice.html","title":"▶ ︎マイクロサービスアーキテクチャ","keywords":"","body":"マイクロサービスアーキテクチャ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. イントロダクション 特徴 ・ビジネスのスケーリングに強い ビジネスがスケーリングする時，サービスの新規実装または削除を行えば良いため，ドメイン層の激しい変化に強い． ・コンウェイの法則が働く マイクロサービスアーキテクチャにより，組織構造が小さなチームの集まりに変化することを期待できる． ・高頻度でリリース可能 各サービスを独立してデプロイできるため，高頻度でリリースできる． ・障害の影響が部分的 いずれかのサービスに障害が起こったとして，サーキットブレイカーを用いることにより，上流サービスへの障害の波及を食い止められる．そのため，障害の影響が部分的となり，アプリケーション全体が落ちてしまうことがない． ・複数の開発言語を使用可能 サービス間で，共通のデータ記述言語を使用してデータ通信を行えば，各サービスの開発言語が異なっていても問題ない． リポジトリの粒度 ・モノリポジトリ 全てのサービスを一つのリポジトリで管理する．Googleではモノリポジトリによるマイクロサービスアーキテクチャが採用されている． 参考：https://www.fourtheorem.com/blog/monorepo ・ポリレポジトリ 各サービスを異なるリポジトリで管理する． 02. 分散システムの粒度 サービス ・サービスとは マイクロサービスアーキテクチャにおけるバックエンドの分散システムのコンポーネントのこと．特定のサービスが他のサービスに侵食され，サービスの凝集度が低くならないようにするために，ACL：Anti Corruption Layer（腐食防止レイヤー）を設ける必要がある．腐食防止レイヤーは，異なるコンテキストから受信したデータを，そのサービスのコンテキストにあったデータ形式に変換する責務を持つ．CQRSでは，これはプロセスマネージャパターンとして知られている．一方でSagaパターンとも呼ばれるが，分散トランザクションでも同一の用語があるため，混乱を避けるためにプロセスマネージャパターンとする． 参考： https://github.com/czeslavo/process-manager https://www.oreilly.com/library/view/what-is-domain-driven/9781492057802/ch04.html https://docs.microsoft.com/ja-jp/previous-versions/msp-n-p/jj591569(v=pandp.10)?redirectedfrom=MSDN ・各サービスのアーキテクチャ 各サービスのアーキテクチャは自由である．この時，ドメイン駆動設計のアーキテクチャに基づいて実装することが可能である． ＊例＊ 参考：https://little-hands.hatenablog.com/entry/2017/12/07/bouded-context-implementation ECサイトがあり，これの商品販売ドメインを販売サブドメインと配送サブドメインに分割できるとする．この時，それぞれのサブドメインの問題を解決する販売コンテキストと配送コンテキストをサービスの粒度となり，オニオンアーキテクチャのアプリケーション間で同期通信／非同期通信を行う． サービスの分割手法 ・サービスの分割例 アプリケーション リンク 分割方法 サービスの種類 Eコマース https://github.com/GoogleCloudPlatform/microservices-demo ルートエンティティ カート，商品検索とインデックス，通貨の変換，クレジットカード，送料と発送，注文確認メール，注文フロー，レコメンド，広告，合成監視 Eコマース https://github.com/DataDog/ecommerce-workshop ルートエンティティ 広告，割引 ・サブドメイン，境界付けられたコンテキストを単位とした分割 サブドメインをサービスの粒度とする．ここでは，解決領域となる境界付けられたコンテキストがサブドメインの中に一つしか含まれていない場合を指しており，代わりに，境界付けられたコンテキストをサービスの粒度して考えても良い．サブドメインを粒度とすることを第一段階として，さらに小さな粒度に分割するために，次の段階としてルートエンティティを粒度とするとよい． 参考： https://microservices.io/patterns/decomposition/decompose-by-subdomain.html https://www.amazon.co.jp/dp/4873119316/ref=cm_sw_em_r_mt_dp_PVDKB4F74K7S07E4CTFF ・ルートエンティティを単位とした分割 境界付けられたコンテキストを構成するルートエンティティをサービスの単位とする．ただし，イベント駆動方式でアプリケーションを連携した場合に限り，従来のリクエスト方式でアプリケーションを連携する場合のルートエンティティを使用することはアンチパターンである．最良な解決策として，サービスのオブジェクトの状態管理方式として，従来のデータに着目したステートソーシングではなく，振る舞いに着目したイベントソーシングを使用する必要がある．また，各サービスを名詞ではなく動詞で命名するとよい．その他，各サービスでDBを完全に独立させることや，SAGAパターンを使用すること，がある． 参考： https://www.koslib.com/posts/entity-services-anti-pattern/ https://www.michaelnygard.com/blog/2018/01/services-by-lifecycle/ https://medium.com/transferwise-engineering/how-to-avoid-entity-services-58bacbe3ee0b 03. 分散システムの連携 サービスオーケストレーション方式 ・コレオグラフィとは 分散型システムとも言う．オーケストレーションとしてのプログラムは存在せず，各サービスで下流サービスに連携する責務を持たせる設計方法．個々のサービス間の連携では，イベント駆動方式を採用する．一つのリクエストが送信された時に，サービスからサービスに処理が繋がっていく．サービス間のインターフェースとして，キューを設置する．このノートでは，コレオグラフィを用いたアプリケーション層の連携を説明する． ・オーケストレーションとは 中央集権型システムとも言う．全てのサービスを制御する責務を持ったオーケストレーションプログラムを設置する設計方法．個々のサービス間の連携では，リクエストリプライ方式を採用する．一つのリクエストが送信された時に，オーケストレーションプログラムは各サービスをコールしながら処理の結果を繋いでいく． サービス間連携方式 ・イベント駆動方式 サービス間では，メッセージキューを用いた非同期通信を行う．メッセージキューはPub／Subデザインパターンで実装するか，またはAWS-SQSなどのツールを使用する． ・リクエストリプライ方式 サービス間では，RESTfulAPIを用いた同期通信を実行する． サービスの永続化方法 ・イベントソーシング ビジネスの出来事をデータとして永続化する．現在の状態を取得する場合は，初期のデータに全ての出来事を適用する．CQRSと相性が良い． 参考： https://qiita.com/suin/items/f559e3dcde7c811ed4e1 https://martinfowler.com/articles/201701-event-driven.html ・ステートソーシング ビジネスの現在の状態をデータとして永続化する．過去の状態は上書きされる． 参考：http://masuda220.jugem.jp/?eid=435 04. 分散トランザクション 分散トランザクションの種類 ・ローカルトランザクションとは 各サービスに独立したトランザクション処理が存在しており，一つのトランザクション処理によって，特定のサービスのデータベースのみを操作する設計方法．推奨である．このノートでは，ローカルトランザクションを用いたインフラストラクチャ層の連携を説明する． ・グローバルトランザクションとは 分散トランザクションとも言う．一つのトランザクション処理が各サービスに分散しており，一つのトランザクション処理によて，各サービスのデータベースを連続的に操作する設計方法．非推奨である． ローカルトランザクション ・Sagaパターンとは ローカルトランザクションの時に，インフラストラクチャ層を実現する設計方法．上流サービスのデータベースの操作完了をイベントとして，下流サービスのデータベースの操作処理を連続的にコールする．ロールバック時には補償トランザクションが実行され，逆順にデータベースの状態が元に戻される． 05. 分散システムにおけるテスト CDCテスト：Consumer Drive Contract ・CDCテストとは サービスのコントローラがコールされてから，データベースの操作が完了するまでを，テストする．下流サービスのコールはモック化またはスタブ化する． 06. 分散システムの運用 障害対策 ・サーキットブレイカーとは サービス間に設置され，他のサービスに連鎖する障害を吸収するプログラムのこと．下流サービスに障害が起こった時に，上流サービスにエラーを返してしまわないよう，直近の成功時の処理結果を返信する． 横断的な監視 ・分散トレーシングとは サービス間で分散してしまう各ログを，一意なIDで紐づける方法． ・モニタリングサービス Datadogによる分散トレースの監視については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_datadog.html 07. フロントエンドのマイクロサービス化 UI部品合成 ・UI部品合成とは フロントエンドのコンポーネントを，各サービスに対応するように分割する設計方法． BFFパターン：Backends For Frontends ・BFFパターンとは クライアントの種類（モバイル，Web，デスクトップ）に応じたAPIを構築し，このAPIから各サービスにルーティングする設計方法．BFFパターンを実装は可能であるが，AWSでいうAPI Gatewayで代用するとより簡単に実現できる． "},"public/backend_php_object_orientation_analysis_design_programming.html":{"url":"public/backend_php_object_orientation_analysis_design_programming.html","title":"▶ ︎オブジェクト指向分析／設計／プログラミング","keywords":"","body":"オブジェクト指向分析／設計／プログラミング はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. アーキテクチャスタイル アーキテクチャスタイルと分析・設計手法 アーキテクチャスタイル スタイルに基づく設計 デプロイメント構成 クライアント／サーバ クライアントサイド／サーバサイド システム構成 オブジェクト指向 オブジェクト指向分析・設計 Layeredアーキテクチャ Layeredアーキテクチャ設計 MVC MVC設計 データ通信領域 REST RESTful ドメイン領域構成 ドメイン駆動 ドメイン駆動設計 01-02. オブジェクト指向分析・設計 オブジェクト指向分析・設計を取り巻く歴史 02. オブジェクト指向分析 オブジェクト指向分析 ・そもそもオブジェクトとは 互いに密接に関連するデータと手続き（処理手順）をオブジェクトと呼ばれる一つのまとまりとして定義する手法のこと． ・オブジェクト指向分析とは オブジェクト指向分析では，システム化の対象になる領域に存在する概念を，モデリングする． ・モデリングの注意点 モデリングの方法として，実体の『状態』と『動作』を考える． しかし，これは厳密ではない． なぜなら，ビジネス領域を実装する時には，ほとんどの場合で，動作を持たない実体を表現することになるからである． より厳密に理解するために，実体の『状態』と『状態の変更と表示』と考えるべき． オブジェクト指向分析／設計で用いるダイアグラム図の種類 オブジェクト指向分析においては，ダイアグラム図を用いて，オブジェクトを表現することが必要になる． ・機能の視点による分析／設計とは システムの機能と処理の流れに注目し，分析／設計する方法．詳しくは，以降の説明を参照せよ． ・振舞の視点による分析／設計とは システムを実行する順番やタイミングに注目し，分析／設計する方法．詳しくは，以降の説明を参照せよ．シーケンス図は設計の段階で使用する． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_method_data.html ・構造の視点による分析／設計とは システムの構成要素とそれぞれの関係に注目し，分析／設計する方法．詳しくは，以降の説明を参照せよ．クラス図は設計の段階で使用する．オブジェクト指向設計については，以下のリンクを参考にせよ． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_method_data.html UML：Unified Modeling Language（統一モデリング言語） ・UMLとは オブジェクト指向分析・設計に用いられるダイアグラム図．ダイアグラム図のUMLには，構造図，振舞図に分類される． （※ちなみ，UMLは，システム設計だけでなく，データベース設計にも使える） ・分析に用いられるUMLダイアグラム 02-02. 機能の視点 DFD：Data Flow Diagram（データフロー図） ・データフロー図とは ユースケース図 ・ユースケース図とは ユーザの要求に対するシステムの振舞のこと．『システムが，〇〇を△△する．』と考えるとよい． ユースケース間の関係 説明 補足 A > B ユースケースAの実行中に、ユースケースBが実行される >と同じである． A > B ユースケースAが先に実行完了してから、ユースケースBが実行される ＊具体例＊ オンラインショッピングにおけるユースケース ・注意点 ユースケース図はシステムの複雑さを表現できないため，設計図としては役に立たない．そのため，ユースケース図は，設計図として作るのではなく，引き継ぎ時に最初に説明するドキュメントや非エンジニアのための資料として作るようにする．設計図としては，クラス図やシステムシーケンス図の方が適している． アクティビティ図 ・アクティビティ図とは ビジネスロジックや業務フローを手続き的に表記する方法． ＊具体例＊ 02-03. 振舞の視点 システムシーケンス図 ・システムシーケンス図とは アクターからアクターへの振舞の流れを，時間軸に沿って表記する方法．シーケンス図とは異なる．シーケンス図については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html 状態遷移図 ・状態遷移図とは 『状態』を丸，『⁠遷移』を矢印で表現した分析モデル．矢印の横の説明は，遷移のきっかけとなる『イベント（入力）⁠／アクション（出力）⁠』を示す． ・状態遷移表とは 状態遷移図から作成した表．状態遷移表を作成してみると，状態遷移図では，9つあるセルのうち4つのセルしか表現できておらず，残り5つのセルは表現されていないことに気づくことができる． ＊例題＊ 12.2 という状態 初期の状態を『a』として，最初が数字なので，a行の『b』へ移動． 現在の状態『b』から，次は数字なので，b行の『b』へ移動． 現在の状態『b』から，次は小数点なので，b行の『d』へ移動． 現在の状態『d』から，次は数字なので，b行の『e』へ移動． 02-04. 構造の視点 ER図：Entity Relation Diagram ・ER図：Entity Relation Diagramとは データベースの設計に用いられるダイアグラム図．オブジェクトが保持するデータの関係性を表す．『IE 記法』と『IDEF1X 記法』が一般的に用いられる． ・Entity と Attribute ・Relation と Cardinality（多重度） エンティティ間の関係を表す． ・1：1 ・1：多（Relation が曖昧な状態） オブジェクト指向分析が進むにつれ，『1：0 以上の関係』『1：1 以上の関係』のように具体化しく． ・1：1 以上 03. オブジェクト指向設計 以下のリンクを参考にせよ． https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_phpobject_orientation_method_data.html 04. オブジェクト指向プログラミング 以下のリンクを参考にせよ． https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_method_data.html "},"public/backend_php_object_orientation_class.html":{"url":"public/backend_php_object_orientation_class.html","title":"▶ ︎クラスベース（1）","keywords":"","body":"クラスベースのオブジェクト指向プログラミング（１） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. オブジェクト指向設計 オブジェクト指向設計に用いられるUMLダイアグラム オブジェクト指向設計での作業例 1. クラス図による設計 オブジェクトの『構造』を設計するために，オブジェクト指向分析によるユースケース図をもとにクラス図を作る．ただし，クラス図ではオブジェクトの『振舞』を設計できないため，シーケンス図にこれを託す． 2. シーケンス図による設計 オブジェクトの『振舞』を設計するために，シーケンス図を作成する．システムシーケンス図とシーケンス図の違いについて，以下を参考にせよ． 参考： https://stackoverflow.com/questions/16889028/difference-between-sequence-diagram-sd-and-a-system-sequence-diagram-ssd https://en.wikipedia.org/wiki/Sequence_diagram 3. 設計のレビュー 構造を設計するクラス図と，振舞を設計するシーケンス図の間の整合性から，設計を妥当性をレビューする． 参考：https://www.sparxsystems.jp/bin/docs/ClassAndSeq.pdf 4. デザインパターンの導入 クラス図に，デザインパターンを基にしたクラスを導入する． 5. フレームワークのコンポーネントの導入 クラス図に，フレームワークのコンポーネントを導入する． 02. クラス図による設計 クラス図 ・データとして保持する関係性 Association（関連），Aggregation（集約），Composition（合成）が用いられる．詳しくは，後述の説明を参照せよ． ・親子の関係性 Generalization（汎化），Realization（実現）が用いられる．詳しくは，後述の説明を参照せよ． ・引数型／返却値型と使用する関係性 Dependency（依存）が用いられる．詳しくは，後述の説明を参照せよ． クラスの多重度 ・多重度とは クラス間が，何個と何個で関係しているかを表記する方法． ＊具体例＊ 社員は１つの会社にしか所属できない場合 『会社クラス』から見て，対する『社員クラス』の数は1つである．逆に，『社員クラス』から見て，対する『会社クラス』の数は0以上であるという表記． 表記 対するクラスがいくつあるか 1 必ず1 0.. 1 0以上1以下（つまり、0または1） 0.. n 0以上n以下 m.. n m以上n以下 * 0以上無限大以下（つまり、0以上） 0.. * 0以上無限大以下（つまり、0以上） ＊具体例＊ 【 営業部エンティティ 】 親エンティティなし というクラスの継承関係があった時，これを抽象的にまとめると， 【 部エンティティ(0.. *) 】 部エンティティから見て，対する課エンティティは0個以上である． 課エンティティから見て，対する部エンティティは0または1個である． 02-02. シーケンス図による設計 シーケンス図 ・設計例1 5つのライフライン（店員オブジェクト，管理画面オブジェクト，検索画面オブジェクト，商品DBオブジェクト，商品詳細画面オブジェクト）を設定する． 各ライフラインで実行される実行仕様間の命令内容を，メッセージや複合フラグメントで示す． ・設計例2 3つのライフラインを設定する． 各ライフラインで実行される実行仕様間の命令内容を，メッセージや複合フラグメントで示す． 03. データとして保持する関係性 『Association ＞ Aggregation ＞ Composition』の順で，依存性が低くなる． Association（関連） ・Associationとは クラスＡがクラスＢをデータとして保持する関係性のこと．引数型／返却値型として使用する『依存』とは区別する． ・Associationの種類 保持される側のクラスのインスタンスが，データとして保持する側のクラスによって生成されるか否かによって，『Aggregation』または『Composition』に分類できる． Aggregation（集約） ・Aggregationとは 保持される側のクラスのインスタンスが，保持する側のクラスのインスタンスによって生成されずに外側から渡される時，クラス間が『Aggregation』の関係にある． ・例 UserはUserNameをデータとして保持する． name = $name; } } また，UserNameクラスのインスタンスは，Userクラスによって生成されずに外側から渡される．そのため，UserクラスとUserNameクラスは『Aggregation』の関係にある． ＊実装例＊ tire1 = $t1; $this->tire2 = $t2; $this->tire3 = $t3; $this->tire4 = $t4; } } また，Tireクラスのインスタンスは，Carクラスによって生成されずに外側から渡される．そのため，CarクラスとTireクラスは『Aggregation』の関係にある． Composition（合成） ・Compositionとは 保持される側のクラスのインスタンスが，保持する側のクラスのインスタンスによって生成される時，クラス間が『Composition』の関係にある． ・例 ＊実装例＊ UserクラスはUserNameクラスをデータとして保持する． getName(); } } また，UserNameインスタンスは，Userクラスによって生成される．そのため，UserクラスとUserNameクラスは『Composition』の関係にある． ＊実装例＊ CarクラスはLockクラスをデータとして保持する． lock = new Lock(); } } また，Lockクラスのインスタンスは，Carクラスによって生成される．そのため，CarクラスとLockクラスは『Composition』の関係にある． 04. 親子の関係性 Generalization（汎化） ・汎化におけるOverride 汎化の時，子クラスでメソッドの処理内容を再び実装すると，処理内容は上書きされる． ＊実装例＊ name = $name; $this->price = $price; } // ★★★★★★注目★★★★★★ // 商品名と価格を表示するメソッド public function printPrice(): void { print($this->name.\"の価格: ￥\".$this->price.\"\"); } // 商品名のゲッター public function getName(): string { return $this->name; } // 商品価格のゲッター public function getPrice(): int { return $this->price; } } getPrice() * 1.08); // （1） print($this->getName().\"の税込み価格: ￥\".$priceWithTax.\"\"); // （2） } } ・抽象クラス ビジネスロジックとして用いる．多重継承できない． ＊具体例＊ 以下の条件の社員オブジェクトを実装したいとする． 午前９時に出社 営業部・開発部・総務部があり，それぞれが異なる仕事を行う 午後６時に退社 この時，『働くメソッド』は部署ごとに異なってしまうが，どう実装したら良いのか… これを解決するために，例えば，次の２つが実装方法が考えられる． 営業部社員オブジェクト，開発部社員オブジェクト，総務部社員オブジェクトを別々に実装 ⇒メリット：同じ部署の他のオブジェクトに影響を与えられる． ⇒デメリット：各社員オブジェクトで共通の処理を個別に実装しなければならない．共通の処理が同じコードで書かれる保証がない． 一つの社員オブジェクトの中で，働くメソッドに部署ごとで変化する引数を設定 ⇒メリット：全部署の社員を一つのオブジェクトで呼び出せる． ⇒デメリット：一つの修正が，全部署の社員の処理に影響を与えてしまう． 抽象オブジェクトと抽象メソッドを用いると，2つのメリットを生かしつつ，デメリットを解消可能． ＊実装例＊ self::TIME_TO_ARRIVE){ return sprintf( \"%s の遅刻です．\", date(\"H時i分s秒\", $nowTime - self::TIME_TO_ARRIVE) ); } return sprintf( \"%s に出勤しました．\", date(\"H時i分s秒\", $nowTime) ); } // 具象メソッド．退社時間と残業時間を表示． // 子クラスへそのまま継承される．子クラスでオーバーライドしなくても良い． public function toLeave() { $nowTime = strtotime( date(\"H:i:s\") ); return sprintf( \"%sに退社しました．%s の残業です．\", date(\"H時i分s秒\", $nowTime), date(\"H時i分s秒\", $nowTime - self::TIME_TO_LEAVE) ); } } ＊具体例＊ プリウスと各世代プリウスが，抽象クラスと子クラスの関係にある． Realization（実現） ・Realizationとは 実装クラスが正常に機能するために最低限必要なメソッドの実装を強制する．これによって，必ず実装クラスを正常に働かせることができる． ＊具体例＊ オープンソースのライブラリは，ユーザが実装クラスを自身で追加実装することも考慮して，Realizationが用いられている． ＊具体例＊ 各車は，モーター機能を必ず持っていなければ，正常に働くことができない．そこで，モータ機能に最低限必要なメソッドの実装を強制する． 実装クラスに処理内容を記述しなければならない．すなわち，抽象クラスにメソッドの型のみ定義した場合と同じである．多重継承できる． ＊実装例＊ 通常クラス，抽象クラス，インターフェースの違い 通常クラス 抽象クラス インターフェース 役割 専用処理の部品化 通常クラスの共通処理の部品化 ・通常クラスのクラス型を定義する．・実装クラスが正常に機能するために最低限必要なメソッドの実装を強制する． 子クラスでの継承先数 単一継承 単一継承 単一継承｜多重継承 メンバ変数のコール 自身と継承先 継承先のみ 実装先のみ 定数の定義 〇 〇 〇 抽象メソッドの定義 ✕ 〇 〇（abstractは省略） 具象メソッドの定義 〇 〇 ✕ construct() の定義 〇 〇 ✕ ＊具体例＊ 種々の車クラスの共通処理のをもつ抽象クラスとして，Carクラスを作成． 各車は，エンジン機能を必ず持っていなければ，正常に働くことができない．そこで，抽象メソッドによって，エンジン機能に最低限必要なメソッドの実装を強制する． 04-02. 継承 継承によるクラスチェーン ・クラスチェーンとは クラスからデータやメソッドをコールした時，そのクラスにこれらが存在しなければ，継承元まで参照しにいく仕組みを『クラスチェーン』という．類似するものとして，プロトタイプチェーンは以下のノートを参考にせよ． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_object_orientation_prototype.html https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_object_orientation_method_data.html ＊実装例＊ value1; } } subValue; } } getValue(); 継承元の静的メソッドを参照 ＊実装例＊ Trait ・Traitとは 再利用したいメソッドやデータを部品化し，利用したい時にクラスに取り込む．Traitを用いるときは，クラス内でTraitをuse宣言する．Trait自体は不完全なクラスであり，インスタンス化できない．また，親クラスでトレイトを読み込むと，子クラスでもトレイトの機能を使用できる． ＊実装例＊ foo(); // Hello World class Bar extends Foo {} $bar = new Bar(); $bar->foo(); // Hello World ・マジックメソッドを禁止するTrait マジックメソッドを使用すると，処理が多くなるため，パフォーマンスが悪くなる．そこで，各クラスでtraitを使用し，マジックメソッドをコールした時に，開発者向けにエラーが発生させる． ＊実装例＊ マジックゲッターメソッドとマジックセッターメソッドがコールされることを禁止する． 04-03. 委譲 委譲によるメソッドコール ・委譲とは 処理の一部または全てを他のクラスに託すこと．PHPでは，集約や合成の関係性を作り，委譲先クラスのメソッドでは委譲元のコールして，処理を追加実装することに相当する．他に，インターフェースによるRealizationの関係性でも実現できる． ・継承よりも優れた点 参考：https://qiita.com/sonatard/items/2b4b70694fd680f6297c#3-%E3%81%9D%E3%82%82%E3%81%9D%E3%82%82%E4%BD%95%E6%95%85go%E3%81%AF%E7%B6%99%E6%89%BF%E3%82%92%E5%BB%83%E6%AD%A2%E3%81%97%E3%81%A6%E5%A7%94%E8%AD%B2%E3%82%92%E6%8E%A8%E5%A5%A8%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%E3%81%AE%E3%81%8B 04-04. 外部ファイルの読み込み require_onceメソッドによる，クラス，非クラスのメソッドの読み込み ・require_onceメソッドとは 外部ファイルとして定義された，クラス，非クラスのメソッド，を一度だけ読み込める．動的な値は持たず，静的に読み込むことに注意．ただし，チームの各エンジニアが好きな物を読み込んでいたら，スパゲッティコードになりかねない．そこで，チームでの開発では，記述ルールを設けて，require_onceメソッドで読み込んで良いものを決めておくと良い． ・クラスからメソッドをコール className(); } } ・クラスから定数をコール ・非クラスからメソッドをコール useによるクラスの読み込み ・useとは PHP5.3以降では，外部ファイルとして定義されたクラスのnamespaceを，useで指定することによって，そのクラスのみを読み込める．非クラスを読み込むことはできない．動的な値は持たず，静的に読み込むことに注意．ただし，チームの各エンジニアが好きな物を読み込んでいたら，スパゲッティコードになりかねない．そこで，チームでの開発では，記述ルールを設けて，useで読み込んで良いものを決めておくと良い． ・外部ファイルのクラスからメソッドをコール クラスのnamespaceをuse文で指定する． ＊実装例＊ method1(); } } ・外部ファイルのクラスから定数をコール ＊実装例＊ 05. 引数型／返却値型として使用する関係性 Dependency（依存） ・Dependencyとは クラスＡがクラスＢを引数型／返却値型として使用する関係性のこと． 参考： https://stackoverflow.com/questions/1230889/difference-between-association-and-dependency https://stackoverflow.com/questions/41765798/difference-between-aggregation-and-dependency-injection ・例 ＊実装例＊ UserはUserNameを引数として使用する．UserはUserNameに依存している． getName(); } } 結合度 ・結合度とは 依存には，引数の渡し方によって，程度がある．それによって，処理を，どのクラスのデータと操作に振り分けていくかが決まる．結合度はモジュール間の依存度合いについて用いられる用語であるが，より理解しやすくするために，特にクラスを用いて説明する． ・データ結合とは 最も理想的な結合．スカラ型のデータをサプライヤー側として，クライアント側のインスタンスの引数として渡すような関係． ＊実装例＊ ModuleAとModuleBは，データ結合の関係にある． methodA(1, 2, \"です.\"); // スカラ型データを渡すだけ } } ＊実装例＊ デザインパターンのFactoryクラスでは，スカラ型データの値に応じて，インスタンスを作り分ける．Factoryクラスのインスタンスと，これをコールする他インスタンス は，データ結合の関係にある． needsWalking()) { return $walking; } return $car; } } ・スタンプ結合とは object型のデータをサプライヤー側として，クライアント側のインスタンスの引数として渡す関係． ＊実装例＊ ModuleAとModuleBは，スタンプ結合の関係にある． value = $value; } public function getValue() { return $this->value; } } methodB($common); // 1 } } getValue(); // 1 } } 凝集度 ・凝集度とは 凝集度は，『モジュール内の責務の統一度合い』について用いられる用語であるが，より理解しやすくするために，特にクラスを用いて説明する． ・機能的強度とは 最も理想的な凝集．クラスの責務が機能単位になるように，ロジックを振り分ける． 低結合と高凝集 各モジュールは，結合度が低く，凝集度が高いほどよい．例として，以下の画像では，道具モジュールを，キッチン引き出しモジュールとガレージ工具箱モジュールに分け，各クラスの結合度を低く，凝集度を高くするように対応している・ DI：Dependency Injection（依存オブジェクト注入） ・DIとは サプライヤー側（依存対象）の『インスタンス』を，クライアント側のインスタンスの外部から『引数として』注入する実装方法．『依存性注入』と訳すのは混乱を招くため，『依存オブジェクト注入』と訳すようにする． 参考： https://en.wikipedia.org/wiki/Dependency_injection#Types_of_dependency_injection https://little-hands.hatenablog.com/entry/2018/05/27/dependency-injection ・Constructor Injectionとは メソッドの特に，constructメソッド の引数として，サプライヤー側のインスタンスを注入する方法．サプライヤー側をデータとして保持させ，Aggregationの関係性を作ることができる．Constructor Injectionのみが，constructメソッド によって，インスタンス作成のために依存関係の要件を強制できる．また，セッターを完全になくした場合に，インスタンス生成後にオブジェクトの状態を変更不可能になる．そのため，ビジネス上ありえないオブジェクトを生成できなくなり，インジェクションの中で，システムの安全性のために最も優れている． ＊実装例＊ 依存対象のSupplierクラスを，constructメソッドの引数として，Clientクラスに注入する． ＊実装例＊ 依存対象のUserNameクラスを，constructメソッドの引数として，Userクラスに注入する． name = $name; } } ・Setter Injectionとは メソッドの特に，セッターの引数として，サプライヤー側のインスタンスを注入する方法．サプライヤー側をデータとして保持させ，Aggregationの関係性を作ることができる． ＊実装例＊ 依存対象のSupplierクラスを，セッターの引数として，Clientクラスに注入する． setSupplier($supplier) ＊実装例＊ 依存対象のUserNameクラスを，セッターの引数として，Userクラスに注入する． name = $name; } } setUserName($name); // インジェクション ・Method Injectionとは 上記二つ以外のメソッドの引数として，サプライヤー側のインスタンスを注入する方法．サプライヤー側をデータとして保持せず，読み込んでメソッドを使用する． ＊実装例＊ 依存対象のUserNameクラスを，メソッドの引数として，Userクラスに注入する． getName(); // 何らかの処理 } } method($name); // インジェクション DI Container（依存オブジェクト注入コンテナ），Service Container ・DI Container（依存オブジェクト注入コンテナ），Service Containerとは 依存オブジェクト注入の責務に特化したデザインパターンを『Service Container』という．あらかじめクラスを登録（バインド）しておき，必要な時にインスタンスを生成（リゾルブ）してくれる．なお， ＊実装例＊ Pimpleライブラリを使用した場合 ・アンチパターンのService Locater Pattern インスタンスへのコンテナ渡しのファイルを実装せず，コンテナ自体を注入していまう誤った実装方法． ＊実装例＊ logger = $container[\"foo.logger\"]; $this->notification = $container[\"bar.notification\"]; } } 05-02. Dependency Inversion Principle（依存性逆転の原則） DIP ・DIPとは インターフェースに依存するように実装する方法．『逆転』とは，インターフェースを用いた場合に，より下位層の実装クラスが上位層のインターフェイスに依存していることを指して言う．二つの原則からなる． ・原則1 上位レイヤーは下位レイヤーに依存してはならない．どちらのレイヤーも『抽象』に依存すべきである． ・原則2 『抽象』は『実装』に依存してはならない．『実装』が『抽象』に依存すべきである． DIPを満たす実装 ・DIPを満たさない実装の場合（従来） より上位レイヤーのコール処理を配置し，より下位レイヤーでコールされる側の定義を行う．これによって，上位レイヤーのクラスが，下位レイヤーのクラスに依存する関係性になる． ・DIPを満たす実装の場合 インターフェース（または抽象クラス）で抽象メソッドを記述することによって，実装クラスでの実装が強制される．つまり，実装クラスは抽象クラスに依存している．より上位レイヤーにインターフェースを配置することによって，下位レイヤーのクラスが上位レイヤーのクラスに依存しているような逆転関係を作ることができる（原則２）．原則２でいう依存は，引数型／返却値型として使用する関係性の文脈でいう『依存』ではないことに注意する．また，実装クラスをインターフェースをエイリアスとしてコールでききるようにすると，実装クラスに依存するレイヤーは代わりにインターフェースに依存することになる．よって，全てのレイヤーがインターフェースに依存するようになる（原則１）． 参考：https://speakerdeck.com/hiroki_hasegawa/domeinqu-dong-she-ji-falseakitekutiyabian-qian-toyi-cun-xing-ni-zhuan-falseyuan-ze ・DIPに基づくドメイン駆動設計の場合 Repositoryクラスにインターフェースと実装クラスを用意する．これにより，原則２を満たす． Repositoryのインターフェース（抽象クラス）を，より上位のドメイン層に配置する．また，Repositoryの実装クラスを，より下位のインフラストラクチャ層に配置する． 両方のクラスに対して，バインディング（関連付け）を行い，インターフェース（抽象クラス）をコールした時に，実際には実装クラスがコールされるようにする． ２と３により，インフラストラクチャ層とユースケース層の両方が，ドメイン層のインターフェース（抽象クラス）に依存することになる．これは，原則１を満たす． DIPのメリット ・実装リポジトリの差し替えが簡単 実装リポジトリはインターフェースに依存し，特定のメソッドの実装が強制されている．ここで実装リポジトリを異なるものに差し替えたとしても，もう一方でインターフェースに依存するユースケースは，インターフェースのメソッドのコール方法を変える必要がない．つまり，ユースケース層に影響を与えることなく，実装リポジトリのリファクタリングや新しい実装リポジトリへの移行が行える． ・リポジトリが対象とする集約の単位がわかりやすい ドメイン層にインターフェースリポジトリを配置するとする．インターフェースリポジトリは，実装リポジトリよりも定義が簡潔である．そのため，実装リポジトリではなくインターフェースリポジトリを確認することで，そのリポジトリがどの集約に対してCRUD処理を行うのかを認識しやすい． "},"public/backend_php_object_orientation_method_data.html":{"url":"public/backend_php_object_orientation_method_data.html","title":"▶ ︎クラスベース（2）","keywords":"","body":"クラスベースのオブジェクト指向プログラミング（２） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. メソッドとデータ（プロパティ） 本資料の以降では，大きく，操作（メソッド）とデータ（プロパティ）に分けて，説明していく． メソッド ・メソッドとは クラスは，データを操作する．この操作するための処理をメソッドという． ＊実装例＊ data; } } データ（プロパティ） ・ データ（プロパティ）とは クラスは，データをもつ．このデータはプロパティとも呼ばれる．本ノートでは，データであることを意識するために，プロパティという言葉を使わないものとする． ＊実装例＊ data; } } 02. メソッドとデータのカプセル化 public ・publicとは どのオブジェクトでも呼び出せる． ・オブジェクト指向の場合 ＊実装例＊ data = $data; } public function data() { return $this->data; } } ・オブジェクト指向でない場合 オブジェクトの全てのデータがpublicであるなら，オブジェクト指向における隠蔽のメリットは，特にないかもしれない． ＊実装例＊ protected ・protectedとは 同じクラス内と，その子クラス，その親クラスでのみ呼び出せる． https://qiita.com/miyapei/items/6c43e8b38317afb5fdce ・オブジェクト指向の場合 親クラス次第ではあるが，処理において，$dataの中身を隠蔽できる． ＊実装例＊ data = $data; } public function foo() { // dataは親で定義されている return $this->data; } } ・オブジェクト指向でない場合 処理において，$dataの中身を隠蔽できないため，危険である． ＊実装例＊ private ・privateとは 同じオブジェクト内でのみ呼び出せる．オブジェクト指向のメリットを最大限に得られる機能である． ・オブジェクト指向の場合 処理において，$dataの中身を隠蔽できる．カプセル化を参照． ＊実装例＊ data = $data; } public function foo() { return $this->data.$this->Desu(); } // クラス内からしかアクセスできない private function Desu() { return \"です．\"; } } ・オブジェクト指向でない場合 処理において，$dataの中身を隠蔽できないため，危険である． ＊実装例＊ ・Encapsulation（カプセル化） カプセル化とは，システムの実装方法を外部から隠すこと．オブジェクト内のデータにアクセスするには，直接データを扱う事はできず，オブジェクト内のメソッドをコールし，アクセスしなければならない． static ・staticとは 別ファイルでのメソッドの呼び出しにはインスタンス化が必要である．しかし，static修飾子をつけることで，インスタンス化しなくともコールできる．データ値は用いず（静的），引数の値のみを用いて処理を行うメソッドに対して用いる． ＊実装例＊ fooFee); } } ・self:: // ここに実装例 ・static:: // ここに実装例 02-02. メソッド まず読むべき記事 ・ゲッターとセッターをメソッド名のプレフィックスとすることは悪 和訳：https://www.kaitoy.xyz/2015/07/22/getters-setters-evil/ 原典：https://www.yegor256.com/2014/09/16/getters-and-setters-are-evil.html ・セッターによる依存性注入は悪 原典：https://www.yegor256.com/2014/10/03/di-containers-are-evil.html 値を取得するアクセサメソッドの実装 ・Getter Getterでは，データを取得するだけではなく，何かしらの処理を加えたうえで取得すること． ＊実装例＊ property)){ throw new ErrorException(\"データに値がセットされていません．\"); } return $this->property; } } 値を設定するアクセサメソッドの実装 ・Setter 『Mutable』なオブジェクトを実現できる． ＊実装例＊ property01 = $property01; } } ・マジックメソッドの__constructメソッド マジックメソッドの__constructメソッドを持たせることで，このデータを持っていなければならないとい制約を明示することがでできる．Setterを持たせずに，__constructメソッドだけを持たせれば，ValueObjectのような，『Immutable』なオブジェクトを実現できる． ＊実装例＊ property02 = $property02; } } ・『Mutable』と『Immutable』を実現できる理由 Test01クラスインスタンスの$property01に値を設定するためには，インスタンスからSetterをコールする．Setterは何度でも呼び出せ，その度にデータの値を上書きできる． setProperty01(\"データ01の値\"); $test01->setProperty01(\"新しいデータ01の値\"); 一方で，Test02クラスインスタンスの$property02に値を設定するためには，インスタンスを作り直さなければならない．つまり，以前に作ったインスタンスの$property02の値は上書きできない．Setterを持たせずに，__constructメソッドだけを持たせれば，『Immutable』なクラスとなる． Entityは，Mutableであるため，Setterと__constructメソッドの両方を持つことができる．ValueObjectは，Immutableのため，__constructメソッドしか持つことができない． マジックメソッド（Getter系） オブジェクトに対して特定の操作が行われた時に自動的にコールされる特殊なメソッドのこと．自動的に呼び出される仕組みは謎．共通の処理を行うGetter（例えば，値を取得するだけのGetterなど）を無闇に増やしたくない場合に用いることで，コード量の肥大化を防ぐことができる．PHPには最初からマジックメソッドは組み込まれているが，自身で実装した場合，オーバーライドされてコールされる． ・__getメソッド 定義されていないデータや，アクセス権のないデータを取得しようとした時に，代わりに呼び出される．メソッドは定義しているが，データは定義していないような状況で用いる． ＊実装例＊ hoge; // 結果 // hogeデータは存在しないため，値を呼び出せません． ・__callメソッド 定義されていないメソッドや，アクセス権のないメソッドを取得しようとした時に，代わりにコールされる．データは定義しているが，メソッドは定義していないような状況で用いる． ・__callStaticメソッド マジックメソッド（Setter系） 定義されていない静的メソッドや，アクセス権のない静的メソッドを取得しようとした時に，代わりに呼び出される．自動的にコールされる仕組みは謎．共通の処理を行うSetter（例えば，値を設定するだけのSetterなど）を無闇に増やしたくない場合に用いることで，コード量の肥大化を防ぐことができる．PHPには最初からマジックメソッドは組み込まれているが，自身で実装した場合，オーバーライドされて呼び出される． ・__setメソッド 定義されていないデータや，アクセス権のないデータに値を設定しようとした時に，代わりにコールされる．オブジェクトの不変性を実現するために使用される．オブジェクトの不変性は，以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_architecture_domain_driven_design.html ＊実装例＊ class Foo { // 中身は省略 } // 存在しないデータに値をセット． $foo = new Foo(); $foo->hoge = \"HOGE\"; // 結果 // hogeデータは存在しないため，HOGEを設定できません． ・マジックメソッドの__constructメソッド インスタンス化時に自動的に呼び出されるメソッド．インスタンス化時に実行したい処理を記述できる．Setterを持たせずに，__constructメソッドでのみ値の設定を行えば，ValueObjectのような，『Immutable』なオブジェクトを実現できる． ＊実装例＊ property02 = $property02; } } ・『Mutable』と『Immutable』を実現できる理由】 Test01クラスインスタンスの$property01に値を設定するためには，インスタンスからSetterをコールする．Setterは何度でもコールでき，その度にデータの値を上書きできる． setProperty01(\"データ01の値\"); $test01->setProperty01(\"新しいデータ01の値\"); 一方で，Test02クラスインスタンスの$property02に値を設定するためには，インスタンスを作り直さなければならない．つまり，以前に作ったインスタンスの$property02の値は上書きできない．Setterを持たせずに，__constructメソッドだけを持たせれば，『Immutable』なオブジェクトとなる． マジックメソッド（その他） ・__invokeメソッド 定義されたクラスを，関数のように扱うことができる．__invokeメソッド自体は無名関数として扱われる． 1 // [1] => 2 // [2] => 3 // ) ・__cloneメソッド // ここに実装例 インスタンスの生成メソッド ・staticメソッド と selfメソッドの違い どちらも，new演算子と組み合わせて，自身のインスタンスを返却するメソッドであるが，生成の対象になるクラスが異なる． 以下の通り，selfメソッドは定義されたクラスをインスタンス化する．一方で，staticメソッドはコールされたクラスをインスタンス化する．自身のインスタンス化処理が継承される場合は，staticメソッドを用いた方が良い． メソッドのコール ・メソッドチェーン 以下のような，オブジェクトAを最外層とした関係が存在しているとする． 【オブジェクトA（オブジェクトBをデータに持つ）】 objB; } } 【オブジェクトB（オブジェクトCをデータに持つ）】 objC; } } 【オブジェクトC（オブジェクトDをデータに持つ）】 objD; } } 以下のように，返却値のオブジェクトを用いて，より深い層に連続してアクセスしていく場合… objB(); $ObjC = $ObjB->objB(); $ObjD = $ObjC->objD(); 以下のように，メソッドチェーンという書き方が可能． objC()->objC(); // $D には ObjD が格納されている． ・Recursive call：再帰的プログラム 自プログラムから自身自身をコールし，実行できるプログラムのこと． ＊具体例＊ ある関数 fの定義の中に f自身を呼び出している箇所がある． ＊実装例＊ 以下のノートも参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_logic_algorithm.html 適当な値を基準値（Pivot）とする （※できれば中央値が望ましい） Pivotより小さい数を前方，大きい数を後方に分割する． 二分割された各々のデータを，それぞれソートする． ソートを繰り返し実行する． ＊実装例＊ 引数 ・オプション引数 引数が与えられなければ，指定の値を渡す方法 // ここに実装例 値を返却する前の途中終了 ・return; ＊実装例＊ returnMethod(); // returnMethod()です。 // 処理は続く． ・exit; ＊実装例＊ exitMethod(); // exitMethod()です。 // ここで，システム全体の処理が終了する． 値の返却 ・return メソッドがコールされた場所に値を返却した後，その処理が終わる． ・yield メソッドがコールされた場所に値を返却した後，そこで終わらず，yieldの次の処理が続く．返却値は，array型である． ＊実装例＊ oneToThree(); foreach ($oneToThree as $value) { echo \"{$value}\\n\"; } // 1 // 2 // 3 Dispatcher ・Dispatcherとは 特定の名前と関数を紐付け，名前を渡すことで関数をコールするオブジェクトをDispatcherという． addListener($name, $listener); // 文字列からメソッドをコール．ついでに，引数を渡す． $dispatcher->dispatch(\"foo\", \"test\"); ・イベント名と関数の紐付け 名前としてイベント名を定義し，これに関数を紐づける．特定のイベント名が渡された時に，それに対応づけられた関数をコールする． ＊実装例＊ フレームワークのEventDispatcherクラスが簡単である．以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_framework_symfony.html ・計算処理の返却値を保持するオブジェクト 大量のデータを集計するは，その処理に時間がかかる．そこで，そのようなメソッドでは，一度コールされて集計を行った後，データに返却値を保持しておく．そして，再びコールされた時には，返却値をデータから取り出す． ＊実装例＊ funcCollection = $this->addListener(); } /** * 集計メソッド */ public function computeRevenue() { // 時間のかかる集計処理; } /** * @param string $funcName * @return false|mixed */ public function funcNameListener(string $funcName) { // 返却値が設定されていなかった場合，値を設定. if (!isset($this->resultCollection[$funcName])) { // メソッドの返却値をCollectionに設定． $this->resultCollection[$funcName] = $this->dispatch($funcName); } // 返却値が設定されていた場合,そのまま使う． return $this->resultCollection[$funcName]; } /** * 返却値をキャッシュしたいメソッド名を登録しておく * * @return array[] */ private function addListener() { return [ \"computeRevenue\" => [$this, \"computeRevenue\"] ]; } /** * @param string $funcName * @return false|mixed */ private function dispatch(string $funcName) { // call_user_funcでメソッドを実行 return call_user_func( // 登録されているメソッド名から，メソッドをDispatch. $this->funcCollection[$funcName] ); } } 02-03. Closure（無名関数） Closure（無名関数）の定義，変数格納後のコール ・use()のみに引数を渡す場合 ＊実装例＊ optionName(); }; // function()には引数が設定されていないので，コール時に引数は不要． echo $optionName; // 出力結果 // オプションA ・function()とuse()に引数を渡す場合 ＊実装例＊ optionName() . $para; }; // コール時に，$paramをfunction()に渡す． echo $optionName(\"BC\"); // 出力結果 // オプションABC ・データの値として，無名関数を格納しておく裏技 ＊実装例＊ name = function ($para) use ($item) { $item->optionName() . $para; }; // コール時に，$paramをfunction()に渡す． echo $option->name(\"BC\"); // 出力結果 // オプションABC Closure（無名関数）の定義と即コール 定義したその場でコールされる無名関数を『即時関数』と呼ぶ．無名関数をコールしたい時は，call_user_funcメソッドを用いる． ＊実装例＊ optionName() . $param; }); // $paramはすでに即コール時に渡されている． // これはコールではなく，即コール時に格納された返却値の出力． echo $optionName; // 出力結果 // オプションABC 高階関数とClosure（無名関数）の組み合わせ 関数を引数として受け取ったり，関数自体を返したりする関数を『高階関数』と呼ぶ． ・無名関数を用いない場合 ＊実装例＊ test(\"callbackMethod\"); // 出力結果 // 出力に成功しました． higherOrder(\"第一引数\", \"callbackMethod\"); // 出力結果 // 第一引数の出力に成功しました． ・無名関数を用いる場合 ＊実装例＊ higherOrder($parentVar, function () use ($parentVar) { return $parentVar . \"の出力に成功しました．\"; }); // 出力結果 // 親メソッドのスコープの変数の出力に成功しました． 高階関数を使いこなす！ ＊実装例＊ properties as $property) { // 引数の無名関数によって，データに対する加工方法が異なる． // 例えば，判定でtrueのもののみを返すメソッドを渡すと，自データを絞り込むような処理を行える． $returned = call_user_func($property, $callback); if ($returned) { // 再格納． $properties[] = $returned; } } // 他のデータは静的に扱ったうえで，自身を返す． return new static($properties); } } 03. 定数 定数が役に立つ場面 ・フラグON/OFF ・区分値 区分値を整数型の定数として扱う．区分値をデータとして持つオブジェクトについては，ドメイン駆動設計の値オブジェクトを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_architecture_domain_driven_design.html ・数値計算，数値比較 計算処理や数値比較処理では，可読性の観点から，できるだけ数値を直書きしない．数値に意味合いを持たせ，定数として扱うと可読性が高くなる．ドメイン駆動設計の値オブジェクトを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_architecture_domain_driven_design.html ・URL URLを文字列を定数として扱う． 場面に応じた命名 意味づけ 名前 型 個数，回数 NUM_*** int 最大数，最小数 MAX_NUM_*****，MIN_NUM_***** int URL URL_***** string マジカル定数 自動的に値が格納されている定数． ・__DIR__ この定数がコールされたファイルが設置されたディレクトリのパスが，ルートディレクトリ基準で格納されている． ＊実装例＊ 以下の実装を持つファイルを，「/var/www/app」下に置いておき，「/vendor/autoload.php」と結合してパスを通す． ・__FUNCTION__ この定数がコールされたメソッド名が格納されている． ＊実装例＊ foo(); // foo が返却される． ・__METHOD__ この定数がコールされたクラス名とメソッド名が，{クラス名}::{メソッド名}の形式で格納されている． ＊実装例＊ foo(); // Foo::foo が返却される． 04. 変数 変数展開 文字列の中で，変数の中身を取り出すことを『変数展開』と呼ぶ． ※Paizaで検証済み． ・シングルクオーテーションによる変数展開 シングルクオーテーションの中身は全て文字列として認識され，変数は展開されない． ＊実装例＊ ・シングルクオーテーションと波括弧による変数展開 シングルクオーテーションの中身は全て文字列として認識され，変数は展開されない． ＊実装例＊ ・ダブルクオーテーションによる変数展開 変数の前後に半角スペースを置いた場合にのみ，変数は展開される．（※半角スペースがないとエラーになる） ・ダブルクオーテーションと波括弧による変数展開 波括弧を用いると，明示的に変数として扱うことができる．これによって，変数の前後に半角スペースを置かなくとも，変数は展開される． 参照渡しと値渡し ・参照渡し 「参照渡し」とは，変数に代入した値の参照先（メモリアドレス）を渡すこと． ＊実装例＊ 変数の$bには，$aの参照によって10が格納される． ・値渡し 「値渡し」とは，変数に代入した値のコピーを渡すこと． ＊実装例＊ 変数の$bには，$aの一行目の格納によって2が格納される． 05. 組み込みラッパー関数 入出力ストリームへのアクセス ・入出力ストリームとは 一度に全てのデータを入出力するのではなく，少しずつ入出力する処理のこと． ・php://stdin stdin：standard in（標準入力）を意味する．PHPのプロセスが，標準入力に対して，読み出し処理を送信できるようになる． ・php://stdout stdout：standard out（標準出力）を意味する．PHPのプロセスが，標準出力に対して，書き込み処理を送信できるようになる． ・php://stderr stderr：standard error（標準出力エラー）を意味する．PHPのプロセスが，標準エラー出力に対して，書き込み処理を送信できるようになる． 06. その他の関数 ファイルシステム関数 ・file_put_contents ファイルに文字列を出力する． ＊実装例＊ 07. 正規表現とパターン演算子 正規表現 ・正規表現とは 数値，記号，文字列などの種類を簡単に表現する文字列のこと． preg_match関数 ・数字 ＊実装例＊ 『0から9のいずれか』の数字を意味する． ・アルファベット ＊実装例＊ 『aからzのいずれか』または『AからZのいずれか』のアルファベットを意味する． ・メタ文字 エスケープのために，必ずバックスラッシュを付ける必要がある． 参考：https://www-creators.com/archives/3102 ＊実装例＊ 『?』『.』『*』『$』のいずれかのメタ文字を意味する． ・ワイルドカード ワイルドカードは『.*』で表現する． 参考：https://qiita.com/whisky-shusuky/items/d719c92c566c133f51b1 ＊実装例＊ ・オプションとしてのパターン演算子 ＊実装例＊ "},"public/backend_php_object_orientation_data_structure.html":{"url":"public/backend_php_object_orientation_data_structure.html","title":"▶ ︎データ構造","keywords":"","body":"データ構造 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. データ構造の実装方法 ハードウェアが処理を行う時に，データの集合を効率的に扱うためのデータ格納形式をデータ構造という．データ構造のPHPによる実装方法を以下に示す． 配列型 同じデータ型のデータを並べたデータ格納様式のこと． ・インデックス配列 番号キーごとに値が格納された配列型のこと． Array ( [0] => A [1] => B [2] => C ) ・多次元配列 配列の中に配列をもつ配列型のこと．配列の入れ子構造が２段の場合，『二次元配列』と呼ぶ． ( [0] => Array ( [0] => リンゴ [1] => イチゴ [2] => トマト ) [1] => Array ( [0] => メロン [1] => キュウリ [2] => ピーマン ) ) ・連想配列 キー名（赤，緑，黄，果物，野菜）ごとに値が格納された配列型のこと．下の例は，二次元配列かつ連想配列である． Array ( [赤] => Array ( [果物] => リンゴ [果物] => イチゴ [野菜] => トマト ) [緑] => Array ( [果物] => メロン [野菜] => キュウリ [野菜] => ピーマン ) ) LinkedList型 PHPで用いることはあまりないデータ格納様式．詳しくは，JavaにおけるLinkedList型を参照せよ． ・PHPのlistメソッドとは何なのか PHPのlistメソッドは，List型とは意味合いが異なる．配列の要素一つ一つを変数に格納したい場合，List型を使わなければ，冗長ではあるが，以下のように実装する必要がある． ＊実装例＊ しかし，以下の様に，listメソッドを使うことによって，複数の変数への格納を一行で実装することができる． ＊実装例＊ Queue型 PHPでは，array_pushメソッドとarray_shiftメソッドを組み合わせることで実装できる． ＊実装例＊ Blue // [1] => Green // [2] => Red // ) // 配列の最初の要素を取り出す． $theFirst= array_shift($array); print_r($array); // 出力結果 // Array // ( // [0] => Green // [1] => Red // ) // 取り出された値の確認 echo $theFirst; // Blue ・メッセージQueue 送信側の好きなタイミングでファイル（メッセージ）をメッセージQueueに追加できる．また，受信側の好きなタイミングでメッセージを取り出すことができる． Stack型 PHPでは，array_pushメソッドとarray_popメソッドで実装可能． Tree型 ・二分探索木 各ノードにデータが格納されている． ・ヒープ Priority Queueを実現するときに用いられる．各ノードにデータが格納されている． 01-02. Javaにおけるデータ構造の実装方法 データ構造のJavaによる実装方法を以下に示す． 配列型 ・ArrayList ArrayListクラスによって実装される配列型．PHPのインデックス配列に相当する． ・HashMap HashMapクラスによって実装される配列型．PHPの連想配列に相当する． LinkedList型 値をポインタによって順序通り並べたデータ格納形式のこと． ・単方向List ・双方向List ・循環List Queue型 Stack型 Tree型 02. プリミティブデータ型 プリミティブ型 ・プリミティブ型とは スカラー型，複合型，その他，に分類できる．以下のリンクを参考にせよ． 参考：https://www.php.net/manual/ja/language.types.intro.php スカラー型 ・bool T／F データの種類 説明 FALSE $var = 何も格納されていない変数 False 文字としてのFalse 0 数字、文字列 \"\" 空文字 array() 要素数が0個の配列 NULL NULL値 TRUE 上記以外の値 ・float ・int ・string 複合型 ・array ・callable ・iterable ・object name, \"Hello World!\" ); } } $a = new A; var_dump($a); // object(A)#1 (1) { // [\"name\":\"A\":private]=> // string(6) \"Hiroki\" //} print_r($a); // A Object // ( // [name:A:private] => Hiroki // ) その他のデータ型 ・date 厳密にはデータ型ではないが，便宜上，データ型とする．タイムスタンプとは，協定世界時(UTC)を基準にした1970年1月1日の0時0分0秒からの経過秒数を表したもの． フォーマット 実装方法 備考 日付 2019-07-07 区切り記号なし、ドット、スラッシュなども可能 時間 19:07:07 区切り記号なし、も可能 日付と時間 2019-07-07 19:07:07 同上 タイムスタンプ（秒） 1562494027 1970年1月1日の0時0分0秒から2019-07-07 19:07:07 までの経過秒数 ・null ・resource 02-02. データ型の判定／変換 判定関数 ・is_scalar スカラー型（bool，float，int，string）を判定する． キャスト演算子 ・(string) ・(int) ・(bool) ・(float) ・(array) ・(object) "},"public/backend_php_logic_validation.html":{"url":"public/backend_php_logic_validation.html","title":"▶ ︎バックエンド側の検証ロジック","keywords":"","body":"バックエンド側の検証ロジック はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 検証 検証の必要性の有無 ・不要な場合 データベースから取得した後に直接表示する値の場合，データベースでNullにならないように制約をかけられる．そのため，値が想定通りの状態になっているかを改めて検証する必要はない． ・必要な場合 データベースからの値を直接表示する場合と異なり，新しく作られる値を用いる場合，その値が想定外の状態になっている可能性がある．そのため，値が想定通りの状態になっているかを検証する必要がある．検証パターンについては，後述の説明を参考にせよ． 検証パターンと検証メソッドの対応 〇：TRUE ✕：FALSE フロントエンドの検証については以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_logic_validation.html 検証パターン isset($var)，!is_null($var) if($var)，!empty($var) null ✕ ✕ 0 〇 ✕ 1 〇 〇 \"\"（空文字） 〇 ✕ \"あ\" 〇 〇 array(0) 〇 ✕ array(1) 〇 〇 使いどころ nullだけを検証したい場合 null，0，\"\"，[]を検証したい場合 02. 条件式 if-elseif-else ，switch-case-break ＊実装例＊ 曜日を検証し，文字列を出力する． ・if-elseif-else ＊実装例＊ ・switch-case-break 定数ごとに処理が変わる時，こちらの方が可読性が高い． ＊実装例＊ if-elseの回避方法 ・if-elseを用いた場合 可読性が悪いため，避けるべき． ＊実装例＊ routeEntity->options)) { foreach ($this->routeEntity->options as $option) { // if文を通過した場合，メソッドの返却値が格納される． // 通過しない場合，定数が格納される． if ($option->isOptionItemA()) { $result[\"optionItemA\"] = $option->optionItemA(); } else { $result[\"optionItemA\"] = self::noOptionItem; } if ($option->isOptionItemB()) { $result[\"optionItemB\"] = $option->optionItemB(); } else { $result[\"optionItemB\"] = self::noOptionItem; } if ($option->isOptionItemC()) { $result[\"optionItemC\"] = $option->optionItemC(); } else { $result[\"optionItemC\"] = self::noOptionItem; } } } return $result; } } ・三項演算子を用いた場合 よりすっきりした書き方になる． ＊実装例＊ routeEntity->options)) { foreach ($this->routeEntity->options as $option) { // if文を通過した場合，メソッドの返却値が格納される． // 通過しない場合，定数が格納される． $result[\"optionItemA\"] = ($option->isOptionItemA()) ? $option->optionItemA() : self::noOptionItem; $result[\"optionItemB\"] = ($option->isOptionItemB()) ? $option->optionItemB() : self::noOptionItem; $result[\"optionItemC\"] = ($option->isOptionItemC()) ? $option->optionItemC() : self::noOptionItem; }; } return $result; } } ・初期値と上書きのロジックを用いた場合 よりすっきりした書き方になる． ＊実装例＊ routeEntity->options)) { foreach ($this->routeEntity->options as $option) { // if文を通過した場合，メソッドの返却値によって初期値0が上書きされる． // 通過しない場合，初期値0が用いられる． if ($option->isOptionItemA()) { $result[\"optionItemA\"] = $option->optionItemA(); } if ($option->isOptionItemB()) { $result[\"optionItemB\"] = $option->optionItemB(); } if ($option->isOptionItemC()) { $result[\"optionItemC\"] = $option->optionItemC(); } }; } return $result; } } if-elseif-elseの回避方法 ・決定表を用いた条件分岐の整理 ＊実装例＊ うるう年であるかを検証し，文字列を出力する．以下の手順で設計と実装を行う． 条件分岐の処理順序の概要を日本で記述する． 記述内容を，条件部と動作部に分解し，決定表で表す． 決定表を，流れ図で表す． ・if-elseif-elseは用いない 可読性が悪いため，避けるべき． ＊実装例＊ ・ifとreturnを用いた早期リターン 各if文でreturnを用いることで，ifが入れ子状になることを防ぐことができる．これを，早期リターンともいう． ＊実装例＊ ・switch-case-breakを用いた早期リターン if文の代わりに，switch-case-breakによって，実装に，『◯◯の場合に切り換える』という意味合いを持たせられる．ここでは，メソッドに実装することを想定して，breakではなくreturnを用いている． ＊実装例＊ ・ガード節を用いた早期リターン 早期リターンのif文の波括弧を省略した記法を，ガード節という． ＊実装例＊ 02-02. インスタンスの検証 等価演算子 ・イコールが2つの場合 同じオブジェクトから別々に作られたインスタンスであっても，『同じもの』として認識される． ＊実装例＊ ・イコールが3つの場合 同じオブジェクトから別々に作られたインスタンスであっても，『異なるもの』として認識される． ＊実装例＊ 同一のインスタンスの場合のみ，『同じもの』として認識される． ＊実装例＊ "},"public/backend_php_logic_error_and_error_handling.html":{"url":"public/backend_php_logic_error_and_error_handling.html","title":"▶ ︎エラーとエラーハンドリング","keywords":"","body":"エラーとエラーハンドリング はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. エラーとエラーハンドリング エラーとは プログラムの実行が強制停止されるランタイムエラー，停止せずに続行される非ランタイムエラー，に分類される． エラーハンドリングとは エラーハンドリングは以下の４ステップからなる． エラー検出 例外スロー 例外キャッチ ロギング 01-02. エラーハンドリングの意義 データベースにとって データベース更新系の処理の途中にエラーが発生すると，データベースが中途半端な更新状態になってしまう．そのため，メソッドコールしたクラスでエラーを検出し，これをきっかけにロールバック処理を実行する必要がある．なお，下層クラスのエラーの内容自体は握りつぶさずに，スタックトレースとしてメソッドコールしたクラスでロギングしておく． システム開発者にとって エラーが画面上に返却されたとしても，これはシステム開発者にとってわかりにくい．そのため，エラーをメソッドコールしたクラスで検出し，システム開発者にわかる言葉に変換した例外としてスローする必要がある．なお，下層クラスのエラー自体は握りつぶさずに，スタックトレースとしてメソッドコールしたクラスでロギングしておく． ユーザにとって エラーが画面上に返却されたとしても，ユーザにとっては何が起きているのかわからない．また，エラーをメソッドコールしたクラスで検出し，例外としてスローしたとしても，システム開発者にとっては理解できるが，ユーザにとっては理解できない．そのため，例外スローを別の識別子（例えば真偽値）に変えてメソッドコールしたクラスに持ち上げ，最終的には，これをポップアップなどでわかりやすく通知する必要がある．これらは，サーバサイドのtry-catch-finally文や，フロントエンドのポップアップ処理で実現する．なお，下流クラスのエラー自体は握りつぶさずに，スタックトレースとしてメソッドコールしたクラスでロギングしておく． 02. エラー検出と例外スロー エラー検出と例外スローの種類 ・フレームワークの標準機能 多くのフレームワークでは，ランタイムエラーや非ランタイムエラーが発生すると，それを検知して，例外をスローしてくれる． ・独自定義 if-throw文を使用して，エラー検出と例外スローを実行する．ランタイムエラーは検出できないことに注意する．特定の処理の中に，想定できる例外があり，それを例外クラスとしてするために用いる．ここでは，全ての例外クラスの親クラスであるExceptionクラスのインスタンスを投げている． ＊実装例＊ ただし，if-throwでは，都度例外を検証するがあり，様々な可能性を考慮しなければいけなくなる． 例外の種類 ・標準例外クラス いずれもThrowableインターフェースを実装している．以下リンクを参考にせよ． 参考：https://www.php.net/manual/ja/reserved.exceptions.php ・独自例外クラス エラーの種類に合わせて，Exceptionクラスを継承した独自例外クラスを実装し，使い分けるとよい．__constructメソッドに，メッセージやエラーコード（例外コード）などを渡せる．エラーコードの標準値はゼロである． 参考：https://www.php.net/manual/ja/exception.construct.php エラーコードはステータスコードと異なり，例外を識別するためのものである．異常系レスポンスのエラーコードデータとして使用される．混乱を避けるため，例外クラスのエラーコード値にステータスコードを割り当てないようにする．ステータスコードはコントローラにおけるレスポンス処理で割り当てる． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html ＊実装例＊ 『Foo変数が見つからない』というエラーに対応する例外クラスを定義する． アーキテクチャにおける層別の例外スロー 層別の例外については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_architecture_domain_driven_design.html 03. 例外キャッチ 例外キャッチの方法 ・try-catch-finally文とは try-catch-finally文では，特定の処理の中で起こる想定できない例外を捉えることができる．定義されたエラー文は，デバック画面に表示される． ＊実装例＊ finally句は，try句やcatch句の返却処理が行われる直前に実行されるため，finally句では，returnやcontinueを使用しないようにする． （１）～（４）のいずれかで返却される時，返却の直前にfinally句が実行されることがわかる． // （１）の場合 // Aの直前です． // Eです． // Aです． // （２）の場合 // Bの直前です． // Eです． // Bです． // （３）の場合 // Cの直前です． // Eです． // Cです． // （４）の場合 // Dの直前です． // Eです． // Dです． 新たな例外のスローし直し 例外をtry-catch文でキャッチした後，別の新しい例外をスローしてもよい．その場合は，例外のコンストラクタの第三引数（previous）を使用して，元々キャッチされていた例外も検知できるようにする．ちなみに，この例外をロギングする場合，スタックトレースログとして出力される． 参考： http://blog.tojiru.net/article/455279557.html https://www.php.net/manual/ja/exception.construct.php 例外キャッチのレイヤー ・コントローラ／ミドルウェア派 想定外のエラーも含めて，全てのエラーを検出できるように，コントローラまたはミドルウェアにtry-catch文を実装する． 参考： https://www.reddit.com/r/dotnet/comments/kyoe83/web_api_trycatch_in_controller_or_not/ https://softwareengineering.stackexchange.com/questions/393307/where-would-you-handle-exceptions-controller-service-repository ・ユースケース派 コントローラの実装をより単純にするべく，より下位のユースケースにtry-catch文を実装する． 参考：https://www.reddit.com/r/dotnet/comments/kyoe83/web_api_trycatch_in_controller_or_not/ 04. ロギング ロギング関数 ・error_log関数 参考：https://www.php.net/manual/ja/function.error-log.php error_log( \"\", \"\", \"\" ) ＊実装例＊ getMessage(), $exception->getFile(), $exception->getLine() ), 3, __DIR__ . \"/error.log\" ); } } } 他に，Loggerインターフェースを使用することも多い． 参考：https://github.com/php-fig/log logger = $logger; } public function sendMessage() { try { // 下流クラスによる例外スローを含む処理 } catch (\\exception $exception) { $this->logger->error(sprintf( \"ERROR: %s at %s line %s\", $exception->getMessage(), $exception->getFile(), $exception->getLine() )); } } } ロギングのレイヤー try-catch文に伴うロギングの場合，catch句の中でこれを実行する．そのため，ロギングを実行するレイヤーはtray-catch文のレイヤーと同じになる． 種類別の振り分け ・例外ごとのロギング 例えば，メッセージアプリのAPIに対してメッセージ生成のリクエストを送信する時，例外の種類に合わせて，外部APIとの接続失敗によるエラーログを生成と，自社システムなどその他原因によるエラーログを生成を行う必要がある． ＊実装例＊ logger->error(sprintf( \"ERROR: %s at %s line %s\", $exception->getMessage(), $exception->getFile(), $exception->getLine() )); } catch (\\ExternalApiErrorException $exception) { // 下流クラスによる例外スローを含む処理 // 外部APIのシステムエラーをロギング $this->logger->error(sprintf( \"ERROR: %s at %s line %s\", $exception->getMessage(), $exception->getFile(), $exception->getLine() )); } catch (\\Exception $exception) { // 下流クラスによる例外スローを含む処理 // その他（自社システムなど）によるエラーをロギング $this->logger->error(sprintf( \"ERROR: %s at %s line %s\", $exception->getMessage(), $exception->getFile(), $exception->getLine() )); } // 問題なければTRUEを返却． return true; } } "},"public/backend_php_logic_iteration.html":{"url":"public/backend_php_logic_iteration.html","title":"▶ ︎反復ロジック","keywords":"","body":"反復ロジック はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 反復対象のデータ 配列 ・走査（スキャン） 配列内の要素を順に調べていくことを『走査（スキャン）』という．例えば，foreachは，配列内の全ての要素を走査する処理である．下図では，連想配列が表現されている． ・内部ポインタと配列の関係 『内部ポインタ』とは，PHPの配列において，参照したい要素を位置で指定するためのカーソルのこと．Goにおけるポインタは，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_go_logic.html ＊実装例＊ 02. foreach 文法 ・基本 配列を走査する． ・制御文 0) { $sum += $x; } } 一次元配列の走査 ・配列関数 複雑な走査を行うために，組み込み関数が用意されている． https://www.php.net/manual/ja/ref.array.php ・配列の値へのアクセス 単に配列を作るだけでなく，要素にアクセスするためにも使われる． name() == 'オプションA') { $result = 'オプションAが設定されています．'; } if ($option->name() == 'オプションB') { $result = 'オプションBが設定されています．'; } if ($option->name() == 'オプションC') { $result = 'オプションCが設定されています．'; } return $result; } return $result; } } ・配列の各値を加算代入 = $K) { // 加算代入 $topesNumber++; // 長さを元に戻す． $currentLength = 0; } } } ・配列の値を固定 $value) { // vを固定して，以降のvと比較する． for ($i = $key; $i 多次元配列の走査 ・二次元配列を一次元配列に変換 コールバック関数の使用が必要になる．call_user_func_arrayメソッドの第一引数に，コールバック関数のarray_mergeメソッドの文字列を渡し，第二引数に二次元配列を渡す．その結果，平坦になって一次元配列になる．例えば，不要なインデックス（0）で入れ子になっている場合に役に立つ． '2015/11/1', 'score' => 100, 'color' => 'red', ], [ 'date' => '2015/11/2', 'score' => 75, 'color' => 'blue', ] ]; $oneDimension = call_user_func_array( 'array_merge', // 二次元配列 $twoDimension ); ・多次元配列でキー名から値を取得 ＊実装例＊ 例えば，以下のような多次元配列があったとする．配列のscoreキーから値を取り出し，一次元配列を生成する． '2015/11/1', 'score' => 100, 'color' => 'red', ], [ 'date' => '2015/11/2', 'score' => 75, 'color' => 'blue', ] ]; // この配列のscoreキーから値を取り出し，一次元配列を生成する． $oneDimension = array_column($twoDimension, 'score'); // Array // ( // [0] => 100 // [1] => 75 // ) 03. while 文法 ・基本 配列の走査を含む反復処理を行う．ただし，配列の走査は，whileではなくforeachを用いるようにする．また，forとは異なり，反復回数が決まっていない場合に使用する． ・制御文 0) { $sum += $x; } // 代入加算 $count ++; } 無限ループ ・無限ループとは 反復処理では，何らかの状態になった時に反復処理を終えなければならない．しかし，終えることができないと，無限ループが発生してしまう． 04. for 文法 ・基本 配列の走査を含む反復処理を行う．ただし，配列の走査は，forではなくforeachを用いるようにする．また，whileとは異なり，反復回数が決まっている場合に使用する． ・制御文 0) { $sum += $x; } } echo $sum; // 1 05. 反復回数の変更 continue ・continueとは 反復処理の現在のループをスキップし，次のループを開始する． $value) { // キーが偶数の組をスキップする． if (!($key % 2 == 0)) { continue; } echo $value . 'は奇数です' . \"\\n\"; } // 1は奇数です // 3は奇数です // 5は奇数です ・array_walkを使用した代替法 反復処理のループをcontinueでスキップと同じ動作を，配列を扱う関数のコールバック関数で早期リターンで実現できる．continueを使用するより，こちらの方が良い． break ・breakとは 反復処理の現在のループを停止し，以降のループも実行しない． "},"public/backend_php_package.html":{"url":"public/backend_php_package.html","title":"▶ ︎パッケージ","keywords":"","body":"PHPパッケージ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. composerによるパッケージの管理 composer.jsonファイルの実装 ・バージョンを定義 # 個人的に一番おすすめ # キャレット表記 { \"require\": { \"foo\": \"^1.1.1\", # >=1.1.1 and =1.1.0 and =0.0.1 and # チルダ表記 { \"require\": { \"foo\": \"~1.1.1\", # >=1.1.1 and =1.1.0 and =1.1.0 and # エックス，アスタリスク表記 { \"require\": { \"foo\": \"*\", # どんなバージョンでもOK \"bar\": \"1.1.x\", # >=1.1.0 and =1.0.0 and ・名前空間のユーザ定義 名前空間とファイルパスの対応関係を設定する． { \"autoload\": { \"psr-4\": { # \"\": \"\", \"App\\\\\": \"app/\", \"Database\\\\Factories\\\\Infrastructure\\\\DTO\\\\\": \"database/factories/production\", \"Database\\\\Seeders\\\\\": \"database/seeds/production\" }, \"classmap\": [ \"database/seeds\", \"database/factories\" ] } } その後，名前空間の読み込みを登録する． $ composer dump-autoload require ・オプションなし パッケージ名をcomposer.jsonファイルを書き込む．インストールは行わない．コマンドを使用せずに自分で実装しても良い． $ composer require :^x.x install ・オプションなし 初めてパッケージをインストールする時，composer.lockファイルにあるパッケージを全てインストールする．composer.lockファイルのおかげで，リポジトリの利用者が，composer installの実行時に，共通のバージョンのパッケージをインストールできる． $ composer install ・-vvv コマンド処理中のログを表示する $ composer install -vvv ・--no-dev require-devタグ内のパッケージは除いてインストール $ composer install --no-dev ・--prefer-dist Composerの配布サイトからインストールする．prefer-sourceオプションを使用するよりも高速でインストールできる．デフォルトでdistを使用するため，実際は宣言しなくても問題ない． $ composer install --prefer-dist ・--prefer-source GitHubのComposerリポジトリからインストールする．Composerの開発者用である． $ composer install --prefer-source update ・オプションなし パッケージ名をcomposer.jsonファイルを元にして，インストールされていないパッケージをインストールし，さらにバージョン定義をもとに更新可能なパッケージを更新する．また，composer.lockファイルに全てのパッケージ情報を書き込むため，リポジトリの利用者がインストールするパッケージにも影響を与える． $ composer update ・-vvv コマンド処理中のログを表示する $ composer install -vvv ・COMPOSER_MEMORY_LIMIT=-1 phpのメモリ上限を無しにして，任意のcomposerコマンドを実行する．phpバイナリファイルを使用する．Dockerコンテナ内で実行する場合，設定画面からコンテナのCPUやメモリを増設することもできる．． $ COMPOSER_MEMORY_LIMIT=-1 composer update -vvv その他のコマンド ・clear-cache インストール時に生成されたキャッシュを削除する． $ composer clear-cache ・エイリアス名 ユーザが定義したエイリアス名のコマンドを実行する． $ composer あらかじめ，任意のエイリアス名をscriptsキー下に定義する．エイリアスの中で，実行するコマンドのセットを定義する． { \"scripts\": { # エイリアス名 \"post-autoload-dump\": [ # 実行するコマンド \"Illuminate\\\\Foundation\\\\ComposerScripts::postAutoloadDump\", \"@php artisan package:discover --ansi\" ], \"post-root-package-install\": [ \"@php -r \\\"file_exists(\".env\") || copy(\".env.example\", \".env\");\\\"\" ], \"post-create-project-cmd\": [ \"@php artisan key:generate --ansi\" ] } } バージョンアップの手順 ・事前確認の重要性 バージョン更新により，アプリケーションやこれに関係する他のアプリケーションに影響が起こる可能性がある．そのため，予想外の影響が起こらないように，マニュアルやリリースノートにて，バージョン間の差異を全て確認しておく必要がある． 1. バージョン間の互換性を確認 破壊的変更のためにバージョン間で互換性が全くなく，古いバージョンと新しいバージョンで使用方法やオプションが異なる可能性がある．一方で，互換性があるものの，大きな変更がなされている可能性がある． 2. 追加，廃止，非推奨を確認 バージョンアップにより，新しい機能が追加されている可能性がある．一方で，今までの方法が廃止または非推奨に移行している可能性がある． 3. 予約語や関数を確認 バージョンアップにより，予約語や関数が変更されている可能性がある．予約語を自身が使用しているとバッティングしてエラーになってしまう． 4. アプリケーションの修正作業の考慮 バージョンアップに伴ってソースコードの修正が必要なことがわかった場合，バージョンアップの手順自体に修正作業を組み込む必要がある． 5. メンテナンスページの表示 バージョンアップによりダウンタイムが発生する場合，その間はメンテナンスページを表示する必要がある，例えば，ALBにはメンテナンスページを表示するための機能がある． 6. 更新作業をリハーサル テスト環境で更新作業をリハーサルし，問題なく完了することを確認する． 7. アプリケーションのテスト テスト環境のバージョンアップ後に，アプリケーションをテストする必要がある． 8. リードレプリカを最初にアップデート 9. 切り戻し作業の考慮 本番環境のバージョンアップ後に想定外の問題が起こることも考慮して，バージョンアップの手順自体に切り戻し作業を組み込む必要がある． 02. アプリケーションによるパッケージの読み込み エントリポイントにおけるautoload.phpファイルの読み込み パッケージが，vendorディレクトリ下に保存されていると仮定する．パッケージを使用するたびに，各クラスでディレクトリを読み込むことは手間なので，エントリーポイント（index.php）あるいはbootstrap.phpで，最初に読み込んでおき，クラスでは読み込まなくて良いようにする． ＊実装例＊ 03. Doctrineパッケージ Doctrineとは RDBの読み込み系／書き込み系の操作を行うパッケージ．他の同様パッケージとして，PDOがある．PDOについては，以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_database_operation.html SQLの定義 1. createQueryBuilderメソッド https://www.doctrine-project.org/projects/doctrine-dbal/en/2.10/reference/query-builder.html CRUD処理に必要なSQLを保持し，トランザクションによってSQLを実行する． ＊実装例＊ createQueryBuilder(); 2. CREATE処理 QueryBuilderクラスにおけるinsertメソッドに，値を設定する． ＊実装例＊ insert(\"mst_users\") 3. READ処理 QueryBuilderクラスにおけるselectメソッドに，値を設定する． ＊実装例＊ select(\"id\", \"name\") ->from(\"mst_users\"); 4. UPDATE処理 QueryBuilderクラスにおけるupdateメソッドに，値を設定する． ＊実装例＊ update(\"mst_users\"); 5. DELETE処理 QueryBuilderクラスにおけるdeleteメソッドに，値を設定する． ＊実装例＊ delete(\"mst_users\"); 6. データベースへの接続，SQLの実行 データベース接続に関わるgetConnectionメソッドを起点として，返り値から繰り返しメソッドを取得し，fetchAllメソッドで，テーブルのクエリ名をキーとした連想配列が返される． ＊実装例＊ getConnection() // SQLを実行し，レコードを読み出す． ->executeQuery($queryBuilder->getSQL(), $queryBuilder->getParameters() )->fetchAll(); 読み出し系の操作 ・プレースホルダー プリペアードステートメントのSQL中にパラメータを設定し，値をパラメータに渡した上で，SQLとして発行する方法．処理速度が速い．また，パラメータに誤ってSQLが渡されても，これを実行できなくなるため，SQLインジェクションの対策にもなる．SQLインジェクションについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_cyber_attacks.html ＊実装例＊ createQueryBuilder(); // プリペアードステートメントの定義 $queryBuilder->select([ \"dog_toy.type AS dog_toy_type\", \"dog_toy.name AS dog_toy_name\", \"dog_toy.number AS number\", \"dog_toy.price AS dog_toy_price\", \"dog_toy.color_value AS color_value\" ]) // FROMを設定する． ->from(\"mst_dog_toy\", \"dog_toy\") // WHEREを設定する．この時，値はプレースホルダーとしておく． ->where(\"dog_toy.type = :type\") // プレースホルダーに値を設定する．ここでは，引数で渡す『$toyType』とする． ->setParameter(\"type\", $toyType); // データベースに接続． return $queryBuilder->getConnection() // SQLを実行し，レコードを読み出す． ->executeQuery($queryBuilder->getSQL(), $queryBuilder->getParameters() )->fetchAll(); } } ・データのキャッシュ 読み出し系で取得したデータをキャッシュすることができる． createQueryBuilder(); // 何らかのSQLを定義 $query = $queryBuilder->select()->from() // キャッシュがある場合，ArrayStatementオブジェクトを格納 // キャッシュがない場合，ResultCacheStatementを格納 $statement = $this->connection->executeQuery( $query->getSQL(), $query->getParameters(), $queryParameterTypes(), new QueryCacheProfile() ); $result = $statement->fetchAll(); $statement->closeCursor(); return $result; } } 書き込み系の操作 ・トランザクション，コミット，ロールバック RDBの処理用語に相当するbeginTransactionメソッド，commitメソッド，rollBackメソッドを用いて，RDBを操作する． 参照：https://www.doctrine-project.org/projects/doctrine-dbal/en/2.10/reference/transactions.html ＊実装例＊ beginTransaction(); try{ // コミット $conn->commit(); } catch (\\Exception $e) { // ロールバック $conn->rollBack(); throw $e; } 04. Carbonパッケージ Date型 厳密にはデータ型ではないが，便宜上，データ型とする．タイムスタンプとは，協定世界時(UTC)を基準にした1970年1月1日の0時0分0秒からの経過秒数を表したもの． フォーマット 実装方法 備考 日付 2019-07-07 区切り記号なし、ドット、スラッシュなども可能 時間 19:07:07 区切り記号なし、も可能 日時 2019-07-07 19:07:07 同上 タイムスタンプ（秒） 1562494027 1970年1月1日の0時0分0秒から2019-07-07 19:07:07 までの経過秒数 instanceメソッド DateTimeインスタンスを引数として，Carbonインスタンスを作成する． createメソッド 日時の文字列からCarbonインスタンスを作成する． ＊実装例＊ createFromXXXメソッド 指定の文字列から，Carbonインスタンスを作成する． ・日時数字から ＊実装例＊ ・時間数字から ＊実装例＊ ・日付，時間，日時フォーマットから 第一引数でフォーマットを指定する必要がある． ＊実装例＊ ・タイムスタンプフォーマットから ＊実装例＊ parseメソッド 日付，時間，日時フォーマットから，Carbonインスタンスを作成する．createFromFormatメソッドとは異なり，フォーマットを指定する必要がない． ＊実装例＊ 05. Pinqパッケージ Pinqとは：Php Integrated Query 配列データやオブジェクトデータに対して，クエリを実行できるようになる．他の同様パッケージとして，Linqがある． Traversable::fromメソッド SQLのSELECTやWHEREといった単語を用いて，foreachのように，配列データやオブジェクトデータの各要素に対して，処理を行える． ＊実装例＊ Traversable::from($entities) // 一つずつ要素を取り出し，関数に渡す． ->select( function ($entity) { return $this->convertToArray($entity); }) // indexからなる配列として返却． ->asArray(), ]; } } 06. Guzzleパッケージ Guzzleパッケージとは 通常，リクエストメッセージの送受信は，クライアントからサーバに対して，Postmanやcurl関数などを使用して行う．しかし，GuzzleパッケージのClientを使えば，サーバから他サーバ（外部のAPIなど）に対して，リクエストメッセージの送受信ができる． リクエスト ・GET送信 参考：https://docs.guzzlephp.org/en/stable/quickstart.html#query-string-parameters ＊実装例＊ request( \"GET\", \"https://xxxxxxxx\", [ \"query\" => [ \"id\" => 1 ] ] ); ・POST送信 参考：https://docs.guzzlephp.org/en/stable/quickstart.html#post-form-requests \"Hello World!\" ]); // POST送信 $response = $client->request( \"POST\", \"https://xxxxxxxx\", [ \"headers\" => [ \"Authorization\" => $this->token, \"Content-Length\" => strlen($json), \"Content-Type\" => \"application/json\", ], \"form_params\" => [ \"body\" => $message ] ] ); レスポンス ・レスポンスメッセージからボディを取得 ＊実装例＊ \"Hello World!\" ]); // POST送信 $response = $client->request( \"POST\", \"https://xxxxxxxx\", [ \"headers\" => [ \"Authorization\" => $this->token, \"Content-Length\" => strlen($json), \"Content-Type\" => \"application/json\", ], \"form_params\" => [ \"body\" => $message ] ] ); $body = json_decode($response->getBody(), true); 07. Knp/Snappyパッケージ Knp/Snappyとは ローカルまたは指定したURLのhtmlファイルから，PDFや画像のファイルを生成するパッケージ． ・generateFromHtmlメソッド htmlファイルを元にして，ローカルディレクトリにPDFファイルを作成する． ＊実装例＊ generateFromHtml(\"foo.html\", \".../foo.pdf\"); 08. Respect/Validationパッケージ Respect/Validationとは リクエストされたデータが正しいかを，サーバサイド側で検証する．フロントエンドからリクエストされるデータに関しては，JavaScriptとPHPの両方によるバリデーションが必要である． "},"public/backend_php_framework_symfony.html":{"url":"public/backend_php_framework_symfony.html","title":"▶ ︎Symfony","keywords":"","body":"Symfony はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 参考になるリファレンス 参考：https://symfony.com/doc/current/the-fast-track/ja/index.html 01-02. Symfonyのディレクトリ構成 Symfony ├── config　#設定ファイル（カーネルのためのルート定義ファイル等） │ ├── bin　#コマンドラインツール │ ├── console #bin/consoleコマンドの実行ファイル │ └── symfony_requirements │ ├── public | ├── index.php #本番環境で、カーネルとして動く | └── index_dev.php #開発環境で、カーネルとして動く │ ├── src　#主要なPHPファイル │ ├── AppBundle #アプリケーションのソースコード │ │ ├── Controller　#UserCase層 │ │ ├── Entity #エンティティ　⇒　Domain層 │ │ ├── Repository #リポジトリ ⇒ Infrastructure層 │ │ ├── Form #フォーム │ │ └── Resources │ │ └── views #画面テンプレート（※本書では扱わない） │ │ │ └── その他のBundle #汎用的なライブラリのソースコード（※本書では扱わない） | ├── templates　#UserInterface層 │ ├── test #自動テスト（Unit tests等） │ ├── var #自動生成されるファイル │ ├── cache #キャッシュファイル │ ├── logs #ログファイル │ └── sessions │ ├── vendor #外部ライブラリ │ ├── doctrine #ライブラリ │ ├── league #ライブラリ │ ├── sensio │ ├── swiftmailer #ライブラリ │ ├── symfonyコンポーネント #コンポーネント │ └── twig #ライブラリ │ └── asset #ブラウザコンソールに公開されるファイル（css, javascript, image等） ├── admin ├── bootstrap ├── css ├── fontawesome ├── img #画像ファイル ├── jquery #jquery（javascriptフレームワーク） └── js #javascriptファイル 02. 特に汎用的なSymfonyコンポーネント Console HttpFoundation HttpKernel Pimple Security EventDispatcher Routing Cache 03. Console CLI：Command Line Interface ・CLIとは シェルスクリプト（.sh），またはバッチファイル（.bat）におけるコマンドの処理内容を定義できる． ＊実装例＊ setName(\"create:example\"); // コマンド名の後に追加したい引数名 $this->addArgument( \"year-month\", InputArgument::REQUIRED, \"処理年月を設定してください．\" ); } // コマンドの処理内容 protected function execute(InputeInterface $input, OutputInterface $output) { try { // 日時フォーマットからCarbonインスタンスを作成する． $year_month = Carbon::createFromFormat( \"Y-m\", $input->getArgument(\"year-month\") ); } catch (\\Exception $e) { // エラーログの文章を作成 } } } CLIをコールするバッチファイル ・for # txtファイルを変数fに繰り返し格納し，処理を行う． for f in *txt do echo $f; done; ・Cronによるコマンドの自動実行 ＊具体例＊ 10秒ごとに，コマンドを自動実行する． # 10秒ごとに，コマンド処理を実行． for f in `seq 0 10 59`; do (sleep {$f}; create:example) & done; # 15時ごとに，コマンド処理を実行． 0 15 * * * * create:example; 03-02. HttpFoundation AppKernel ・カーネルに必要なオブジェクト Requestオブジェクト グローバル変数から収集した情報やHTTPリクエストのヘッダ情報やコンテンツ情報を保持 カーネルオブジェクトのhandle() 送られてきたURLを基にしたコントローラ／アクションへのルートの特定，特定されたコントローラ／アクションの実行，テンプレートのレンダリング Responseオブジェクト HTTPレスポンスのヘッダ情報やコンテンツ情報などの情報を保持 ・オブジェクトから取り出されたメソッドの役割 カーネルが，クラアントからのHTTPリクエストをリクエストオブジェクトとして受け取る． カーネルが，送られてきたURLとルート定義を基に，リクエストに対応するコントローラアクションを探し，実行させる．その後，テンプレートがURLを生成． カーネルが，その結果をレスポンスオブジェクトとしてクライアントに返す． このカーネルを，特別に『HTTPカーネル』と呼ぶ． 【app.phpの実装例】 loadClassCache(); } $request = Request::createFromGlobals(); //（１） // 以下の実装ファイルも参照せよ． $response = $kernel->handle($request); //（２） $response->send(); //（３） $kernel->terminate($request, $response); 上記のhandle()が定義されているファイル．ここで定義されたhandle()が，C/Aへのルートの特定，特定されたC/Aの実行，テンプレートのレンダリングを行う． boot(); ++$this->requestStackSize; $this->resetServices = true; try { return $this->getHttpKernel()->handle($request, $type, $catch); } finally { --$this->requestStackSize; } } Request，Response ・リクエストメッセージからのデータ取得，JSON型データのレスポンス Ajaxによるリクエストの場合，JSON型データをレスポンスし，かつページレンダリング． Ajaxによるリクエストでない場合，ページレンダリングのみ headers->get(\"content-type\") === \"application/json\") { $xxxRepository = new XxxRepository; $entityObject = $xxxRepository->getEntity(); //-- entityをObject型からArray型に変換する何らかの処理．--// // Ajaxにレンスポンス． return new JsonResponse([ \"value\" => $entityArray ]); } return $this->render(\".../xxx.twig\")->setStatusCode(200); } } ・リクエストヘッダーの取得 query->get('hoge'); // $_POST['hoge'] $request->request->get('hoge'); // ルーティングパラメータ / ex) @Route('/{hoge}') $request->attributes->get('hoge'); // $_COOKIE['hoge'] $request->cookies->get('hoge'); // $_FILES['hoge'] $request->files->get('hoge'); // $_SERVER['SCRIPT_FILENAME'] $request->server->get('SCRIPT_FILENAME'); // $_SERVER['HTTP_USER_AGENT'] $request->headers->get('User-Agent'); // query > attribute > request の順で検索 $request->get('hoge'); 03-03. HttpKernel HttpKernelによるリクエストとレスポンス 03-04. Pimple Service Container Symfonyから提供されるDIコンテナのこと． 03-05. Routing RoutingConfigurator ・RoutingConfiguratorとは コントローラへのルーティングを設定する． add(\"api_post_show\", \"/api/posts/{id}\") ->controller([BlogApiController::class, \"show\"]) ->methods([\"GET\", \"HEAD\"]) ; $routes->add(\"api_post_edit\", \"/api/posts/{id}\") ->controller([BlogApiController::class, \"edit\"]) ->methods([\"PUT\"]) ; }; 03-06. Cache FilesystemAdapter ・FilesystemAdapterとは データをキャッシングできる．オプションで，名前空間，キャッシュ存続時間，キャッシュルートパスを指定できる． getItem(\"stats.products_count\"); // キャッシュIDに紐づくキャッシュアイテムオブジェクトに，データが設定されていない場合 if (!$cacheItemObj->isHit()) { // キャッシュアイテムオブジェクトに，データを設定 $cacheItemObj->set(777); // キャッシュアイテムオブジェクトを紐づける． $cache->save($cacheItemObj); } // キャッシュIDに紐づくデータがあった場合，キャッシュアイテムオブジェクトを取得． $cacheItemObj = $cache->get(); "},"public/backend_php_framework_laravel.html":{"url":"public/backend_php_framework_laravel.html","title":"▶ ︎Laravel","keywords":"","body":"Laravel はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Laravelの全体像 ライフサイクル 大まかな処理フローは以下の通りである． 参考：https://blog.albert-chen.com/the-integration-of-laravel-with-swoole-part-1/ 用語 説明 1 リクエストを受信する． 2 index.phpファイル エントリポイントから処理が始まる． 3 Autoload autoload.phpファイルにて，ライブラリを自動でロードする． 4 Load App bootstrap/app.phpファイルにて，ServiceContainer（Illuminate\\Foundation\\Application.php）を実行する． 5 Http Kernel Kernelを実行する． 6 ・Register ServiceProviders・Boot Service Providers ServiceProviderのregisterメソッドやbootメソッドを実行する．これにより，ServiceContainerにクラスがバインドされる． 7 Middleware BeforeMiddlewareを実行する． 8 ・Dispatch by Router・Routes Match web.phpファイル，app.phpファイルなどのルーティング定義を元に，Routerが実行する． 9 FormRequest バリデーションを実行する． 10 Controller Controllerを基点として，データベースにまで処理が走る． 11 Resource データベースから取得したコレクション型データを配列型データに変換する． 12 Response Responseを実行する．配列型データをJSONデータに変換する． 13 Terminate Middleware AfterMiddlewareが実行される． 14 View bladeファイルに基づいて静的ファイルが構築される． 15 レスポンスを返信する． コンポーネントのソースコード Laravelの各コンポーネントには，似たような名前のメソッドが多く内蔵されている．そのため，同様の機能を実現するために，各々が異なるメソッドを使用しがちになる．その時，各メソッドがブラックボックスにならないように，処理の違いをソースコードから確認する必要がある． 参考：https://laravel.com/api/8.x/Illuminate.html 02. Application App ・設定方法 APP_NAME= APP_ENV= APP_KEY= APP_DEBUG= APP_URL= ・app.phpファイルの基本設定 env(\"APP_NAME\", \"Laravel\"), // 実行環境名 \"env\" => env(\"APP_ENV\", \"production\"), // エラー時のデバッグ画面の有効化 \"debug\" => (bool)env(\"APP_DEBUG\", false), // アプリケーションのURL \"url\" => env(\"APP_URL\", \"http://localhost\"), // assetヘルパーで付与するURL \"asset_url\" => env(\"ASSET_URL\", null), // タイムゾーン \"timezone\" => \"UTC\", // 言語設定 \"locale\" => \"ja\", \"fallback_locale\" => \"en\", \"faker_locale\" => \"ja_JP\", // セッションの作成やパスワードの暗号化に使う認証キー \"key\" => env(\"APP_KEY\"), // 暗号化アルゴリズム \"cipher\" => \"AES-256-CBC\", // サービスプロバイダー \"providers\" => [ ], // クラス名のエイリアス \"aliases\" => [ ], ]; 03. Console Command artisanコマンドで実行可能なコマンド処理を定義する． 参考：https://readouble.com/laravel/8.x/ja/artisan.html#writing-commands argument('bar'); // 何らかのコマンド処理 Log::info('END: artisan do-foo'); } } 定義したCommandクラスは，以下のように実行できる． $ php artisan command:do-foo 04. Database データベース接続 ・設定方法 環境変数を.envファイルに実装する．database.phpファイルから，指定された設定が選択される． DB_CONNECTION= DB_HOST= DB_PORT= DB_DATABASE= DB_USERNAME= DB_PASSWORD= ・RDBとRedisの選択 env(\"DB_CONNECTION\", \"mysql\"), \"connections\" => [ // データベース接続情報（SQLite） \"sqlite\" => [ ], // データベース接続情報（MySQL） \"mysql\" => [ ], // データベース接続情報（pgSQL） \"pgsql\" => [ ], // データベース接続情報（SQLSRV） \"sqlsrv\" => [ ], ], // マイグレーションファイルのあるディレクトリ \"migrations\" => \"migrations\", // Redis接続情報 \"redis\" => [ ], ]; Redis ・クエリCache管理 環境変数を.envファイルに実装する必要がある． CACHE_DRIVER=redis REDIS_HOST= REDIS_PASSWORD= REDIS_PORT= 05. Eloquentモデル artisanコマンドによる操作 ・クラスの自動生成 $ php artisan make:model Active Recordパターン ・Active Recordパターンとは テーブルとモデルが一対一の関係になるデザインパターンのこと．さらに，テーブル間のリレーションシップがそのままモデル間の依存関係にも反映される．ビジネスロジックが複雑でないアプリケーションの開発に適している．オブジェクト間の依存関係については，以下のリンクを参考せよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html ・メリット／デメリット 項目 メリット デメリット 保守性 テーブル間のリレーションが，そのままモデル間の依存関係になるため，モデル間の依存関係を考える必要がなく，開発が早い．そのため，ビジネスロジックが複雑でないアプリケーションの開発に適している． ・反対に，モデル間の依存関係によってテーブル間のリレーションが決まる．そのため，複雑な業務ロジックでモデル間が複雑な依存関係を持つと，テーブル間のリレーションも複雑になっていってしまう．・モデルに対応するテーブルに関して，必要なカラムだけでなく，全てのカラムから取得するため，アプリケーションに余分な負荷がかかる． スケーラビリティ テーブル間のリレーションがモデル間の依存関係によって定義されており，JOIN句を使用せずに，各テーブルから必要なレコードを取得できる．そのため，テーブルを増やすやすい． 可読性 ・モデルとこれのプロパティがそのままテーブルになるため，モデルを作成するためにどのテーブルからレコードを取得するのかを推測しやすい．（Userモデル ⇄ usersテーブル）・リレーションを理解する必要があまりなく，複数のテーブルに対して無秩序にSQLを発行するような設計実装になりにくい． テーブル設計を元にしたEloquentモデル ・Eloquentモデルの継承 Eloquentモデルを継承したクラスは，INSERT文やUPDATE文などのデータアクセスロジックを使用できるようになる． ＊実装例＊ ・テーブルの定義 テーブルを定義するため，tableプロパティにテーブル名を割り当てる．ただし，tableプロパティにテーブル名を代入する必要はない．Eloquentがクラス名の複数形をテーブル名と見なし，これをスネークケースにした文字列をtableプロパティに自動的に代入する．また，テーブル名を独自で命名したい場合は，代入によるOverrideを行っても良い． ＊実装例＊ ・テーブル間リレーションシップの定義 ER図における各テーブルのリレーションシップを元に，モデル間の関連性を定義する．hasOneメソッド，hasManyメソッド，belongsToメソッドを用いて表現する． 参考： https://readouble.com/laravel/8.x/ja/eloquent-relationships.html#one-to-one https://readouble.com/laravel/8.x/ja/eloquent-relationships.html#one-to-many https://readouble.com/laravel/8.x/ja/eloquent-relationships.html#one-to-many-inverse ER図については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_analysis_design_programming.html ＊実装例＊ Departmentモデルにおいて，hasManyメソッドを用いて，Departmentモデル（親）とEmployeesモデル（子）のテーブル関係を定義する． hasMany(Employee::class); } } また，Employeesモデルにおいては，belongsToメソッドを用いて，Departmentモデル（親）とEmployeesモデル（子）のテーブル関係を定義する． belongsTo(Department::class); } } リレーションに基づいてJOIN句のSQLを発行するために，Departmentモデル（親）のhasManyメソッドを実行する．これにより，DepartmentモデルのIDに紐づくEmployeesモデル（子）を配列で参照できる． employees() ・主キーカラムの定義 Eloquentは，primaryKeyプロパティの値を主キーのカラム名と見なす．keyTypeプロパティで主キーのデータ型，またincrementingプロパティで主キーのAutoIncrementを有効化するか否か，を設定できる． ＊実装例＊ ・TIMESTAMP型カラムの定義 Eloquentは，timestampsプロパティの値がtrueの時に，Eloquentモデルに関連付くテーブルのcreated_atカラムとupdated_atカラムを自動的に更新する．また，TIMESTAMP型カラム名を独自で命名したい場合は，代入によるOverideを行っても良い． ＊実装例＊ ・TIMESTAMP型カラム読み出し時のデータ型変換 データベースからタイムスタンプ型カラムを読み出すと同時に，CarbonのDateTimeクラスに変換したい場合，dataプロパティにて，カラム名を設定する． ＊実装例＊ ・カラムデフォルト値の定義 特定のカラムのデフォルト値を設定したい場合，attributesプロパティにて，カラム名と値を定義する． ＊実装例＊ false, ]; } ・変更可能／不可能なカラムの定義 変更可能なカラム名をfillableプロパティを用いて定義する．カラムが増えるたびに，実装する必要がある． ＊実装例＊ もしくは，変更不可能なカラム名をguardedプロパティで定義する．これらのいずれかの設定は，Eloquentモデルにおいて必須である． 使用に注意する機能 ・セッター Laravelでは，プロパティを定義しなくても，Eloquentモデルからプロパティをコールすれば，処理の度に動的にプロパティを定義できる．しかし，この機能はプロパティがpublicアクセスである必要があるため，オブジェクト機能のメリットを享受できない．そのため，この機能を使用せずに，constructorメソッドを使用したコンストラクタインジェクション，またはセッターインジェクションを使用するようにする． ＊実装例＊ fooName = $fooName; } } ・ゲッター Laravelでは，getXxxxYyyyAttributeという名前のメソッドを，xxx_yyyという名前でコールできる．一見，プロパティをコールしているように見えるため，注意が必要である． ＊実装例＊ fooName . \"です．\"; } } name; データ型変換 ・シリアライズ フロントエンドとバックエンド間，またバックエンドとデータベース間のデータ送信のために，配列型オブジェクトをJSONに変換する処理はシリアライズである． ＊実装例＊ 1, \"name\" => \"佐藤太郎\", ], [ \"user_id\" => 2, \"name\" => \"山田次郎\", ], ]); // Array型に変換する $collection->toArray(); toArray(); ・デシリアライズ フロントエンドとバックエンド間，またバックエンドとデータベース間のデータ送信のために，JSONを配列型オブジェクトに変換する処理はデシリアライズである． フィルタリング ・filterメソッド コールバック関数の返却値がtrueであった要素を全て抽出する． ＊実装例＊ $collection = collect([1, 2, 3, 4]); // trueを返却した要素を全て抽出する $filtered = $collection->filter(function ($value, $key) { return $value > 2; }); $filtered->all(); // [3, 4] ちなみに，複数の条件を設定したいときは，早期リターンを使用する必要がある． ＊実装例＊ $collection = collect([1, 2, 3, 4, \"yes\"]); // 複数の条件で抽出する． $filtered = $collection->filter(function ($value, $key) { // まずはyesを検証する． if($value == \"yes\") { return true; } return $value > 2; }); $filtered->all(); // [3, 4, \"yes\"] ・firstメソッド コールバック関数の返却値がtrueであった最初の要素のみを抽出する． ＊実装例＊ $collection = collect([1, 2, 3, 4]); // trueを返却した要素のみ抽出する $filtered = $collection->first(function ($value, $key) { return $value > 2; }); // 3 05-02. Eloquentモデル／ビルダーによるCRUD CRUDメソッドの返却値型と返却値 ・CRUDメソッドを持つクラス Eloquentモデルを継承すると，以下のクラスからメソッドをコールできるようになる．Eloquentモデルにはより上位のメソッドが定義されていないことがあり，もし定義されていないものがコールされた場合，__callStaticメソッド（静的コールによる）や__callメソッド（非静的コールによる）が代わりにコールされ，より上位クラスのメソッドをコールできる．どちらの方法でコールしても同じである． 参考： https://www.php.net/manual/ja/language.oop5.overloading.php#object.call https://qiita.com/mpyw/items/7c7e8dc665584122a275 クラス 名前空間 __callメソッドを経由してコールできるクラス Queryビルダー Illuminate\\Database\\Query\\Builder なし Eloquentビルダー Illuminate\\Database\\Eloquent\\Builder Queryビルダー， Eloquentリレーション Illuminate\\Database\\Eloquent\\Relations\\Relation Queryビルダー，Eloquentビルダー， Eloquentモデル Illuminate\\Database\\Eloquent\\Model Queryビルダー，Eloquentビルダー，Eloquentリレーション ・Eloquentビルダー Eloquentビルダーが持つcrudを実行するメソッドの返却値型と返却値は以下の通りである．その他のメソッドについては，以下のリンクを参考にせよ． 参考：https://laravel.com/api/8.x/Illuminate/Database/Eloquent/Builder.html CRUDメソッドの種類 返却値型 返却値 返却値の説明 create collection／$this {id:1, name: テスト} 作成したオブジェクト find collection／Builder／Model {id:1, name:テスト} 取得したオブジェクト update mixed 0，1，2，3 変更したレコード数 delete mixed 0，1，2，3 変更したレコード数 ・Eloquentモデル Eloquentモデルが持つcrudを実行するメソッドの返却値型と返却値は以下の通りである．その他のメソッドについては，以下のリンクを参考にせよ． 参考：https://laravel.com/api/8.x/Illuminate/Database/Eloquent/Model.html CRUDメソッドの種類 返却値型 返却値 返却値の説明 update bool true，false 結果の真偽値 save bool true，false 結果の真偽値 delete bool true，false 結果の真偽値 CREATE ・createメソッド INSERT文を実行する．Eloquentモデルにはcreateメソッドがないため，代わりにEloquentビルダーが持つcreateメソッドがコールされる．createメソッドに挿入対象のカラムと値を渡し，これを実行する．別の方法として，Eloquentビルダーのfillメソッドで挿入対象のカラムと値を設定し，saveメソッドを実行してもよい．saveメソッドはUPDATE処理も実行できるが，fillメソッドでID値を割り当てない場合は，CREATE処理が実行される．createメソッドまたはsaveメソッドによるCREATE処理では，レコードの挿入後に，lastInsertIdメソッドに相当する処理が実行される．これにより，挿入されたレコードのプライマリキーが取得され，EloquentモデルのID値のプロパティに保持される． 参考： https://codelikes.com/laravel-eloquent-basic/#toc9 https://qiita.com/henriquebremenkanp/items/cd13944b0281297217a9 ＊実装例＊ create($request->all()); // 以下の実装でもよい // $foo->fill($request->all())->save(); // 処理後にはEloquentモデルにID値が保持されている． $foo->id(); // 続きの処理 } } Eloquentモデルにはfillableプロパティを設定しておく． READ ・findメソッド SELECT文を実行し，レコードを一つ取得する．Eloquentモデルにはfindメソッドがないため，代わりにEloquentビルダーが持つfindメソッドがコールされる．引数としてプライマリキーを渡した場合，指定したプライマリキーを持つEloquentモデルを返却する．toArrayメソッドで配列型に変換できる． 参考： https://laravel.com/api/8.x/Illuminate/Database/Query/Builder.html#method_find https://readouble.com/laravel/8.x/ja/eloquent.html#retrieving-single-models ＊実装例＊ find($id); } } ・allメソッド SELECT文を実行し，レコードを全て取得する．MySQLを含むDBエンジンでは，取得結果に標準の並び順が存在しないため，プライマリキーの昇順で取得したい場合は，orderByメソッドを使用して，明示的に並び替えるようにする．Eloquentモデルにはallメソッドがないため，代わりにEloquentビルダーが持つallメソッドがコールされる．全てのプライマリキーのCollection型を配列型として返却する．toArrayメソッドで配列型に再帰的に変換できる． 参考： https://stackoverflow.com/questions/54526479/what-is-the-dafault-ordering-in-laravel-eloquent-modelall-function https://laravel.com/api/8.x/Illuminate/Support/Collection.html#method_all https://readouble.com/laravel/8.x/ja/eloquent.html#retrieving-models ＊実装例＊ all(); } } ・sortByメソッド SELECT文を実行し，レコードを指定したカラムの昇順で並び替えて取得する． 参考：https://readouble.com/laravel/8.x/ja/collections.html#method-sortby ＊実装例＊ all()->sortBy('foo_id'); } } ・sortByDescメソッド SELECT文を実行し，レコードを指定したカラムの降順で並び替えて取得する． 参考：https://readouble.com/laravel/8.x/ja/collections.html#method-sortbydesc all()->sortByDesc('foo_id'); } } ・orderByメソッド SELECT文を実行し，レコードを指定したカラムの昇順／降順で並び替える．並び替えた結果を取得するためには，getメソッドを使用する．プライマリキーの昇順で取得する場合，allメソッドではなく，orderByメソッドを使用して，プライマリキーの昇順を明示的に指定する． 参考：https://readouble.com/laravel/8.x/ja/queries.html#ordering-grouping-limit-and-offset ＊実装例＊ orderBy('foo_id', 'asc')->get(); } /** * @return Collection */ public function findAllByDesc(): Collection { $foo = new Foo(); // 降順 return $foo->orderBy('foo_id', 'desc')->get(); } } ・limitメソッド，offsetメソッド SELECT文を実行し，指定した開始地点から指定した件数のレコードを全て取得する．これにより，ページネーションにおいて，１ページ当たりのレコード数（limit）と，次のページの開始レコード（offset）を定義できる．これらのパラメータはクエリパラメータとして渡すとよい． 参考：https://readouble.com/laravel/8.x/ja/queries.html#ordering-grouping-limit-and-offset ＊実装例＊ offset($request->offset) ->limit($request->limit) ->get(); } } ・withメソッド 親テーブルにアクセスして全てのデータを取得し，親テーブルのEloquentモデルのプロパティに子テーブルのレコードを保持する．この仕組みをEagerロードという．Eloquentモデルにはwithメソッドがないため，代わりにEloquentビルダーが持つwithメソッドがコールされる．テーブル間に一対多（親子）のリレーションシップがある場合に使用する．N+1問題を防げる． 参考：https://readouble.com/laravel/8.x/ja/eloquent-relationships.html#eager-loading ただし，withメソッドに他のメソッドをチェーンしてしまうと，Eagerロードの後にSQLを発行されてしまうため，Eagerロードの恩恵を得られなくなることに注意する． 参考：https://qiita.com/shosho/items/abf6423283f761703d01#%E3%83%AA%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%A1%E3%82%BD%E3%83%89%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%86%E3%81%A8-eager-loading-%E3%81%AB%E3%81%97%E3%81%A6%E3%81%A6%E3%82%82%E6%84%8F%E5%91%B3%E3%81%8C%E3%81%AA%E3%81%84%E3%81%AE%E3%81%A7%E6%B3%A8%E6%84%8F ＊実装例＊ コントローラにて，Department（親）と，これに紐づくEmployee（子）を読み出す．これらのモデルの間では，hasManyメソッドとbelongsToメソッドを使用して，テーブルにおける一対多のリレーションを定義しておく． with(\"employees\")->get(); foreach ($employees as $employee) { // ここではDBアクセスはせずに，プロパティに保持された値を取得するだけ． $name = $employee->name; } // 続きの処理 } } Department（親）に，departmentsテーブルとemployeesテーブルの間に，一対多の関係を定義する． hasMany(Employee::class); } } また，Employee（子）に，反対の多対一の関係を定義する． belongsTo(Department::class); } } UPDATE ・saveメソッド UPDATE文を実行する．Eloquentビルダーのfillメソッドで挿入対象のカラムと値を設定し，saveメソッドを実行する．saveメソッドはCREATE処理も実行できるが，fillメソッドでID値を割り当てた場合は，UPDATE処理が実行される． 参考： https://codelikes.com/laravel-eloquent-basic/#toc9 https://qiita.com/henriquebremenkanp/items/cd13944b0281297217a9 ＊実装例＊ fill($request->all())->save(); // 続きの処理 } } Eloquentモデルにはfillableプロパティを設定しておく． DELETE ・destroy／deleteメソッド（物理削除） DELETE文を実行する．Eloquentモデルのdestroy／deleteメソッドを使用する．手順として，Eloquentビルダーのfindメソッドで削除対象のModelを検索する．返却されたEloquentビルダーのdestroy／deleteメソッドをコールし，自身を削除する． ・SoftDeletesの有効化（論理削除） 削除フラグを更新するUPDATE文を実行する．Eloquentモデルのdestroy／deleteメソッドを使用する．手順として，テーブルに対応するModelにて，SoftDeletesのTraitを読み込む．マイグレーション時に追加されるdelete_atカラムをSQLで取得する時に，DataTimeクラスに変換できるようにしておく． ＊実装例＊ マイグレーションファイルにてsoftDeletesメソッドを使用すると，削除フラグとしてdeleted_atカラムが追加されるようになる．deleted_atカラムのデフォルト値はNULLである． softDeletes(); // ～ 省略 }); } /** * ロールバック * * @return void */ public function down() { Schema::drop(\"foo\"); } } 上記の状態で，同様にdestroy／deleteメソッドを使用して，自身を削除する．物理削除ではなく，deleled_atカラムが更新されるようになる．findメソッドは，deleled_atカラムがNULLでないレコードを読み出さないため，論理削除を実現できる． N+1問題の解決 ・N+1問題とは 親テーブルを経由して子テーブルにアクセスする時に，親テーブルのレコード数分のSQLを発行してしまうアンチパターンのこと． ・問題が起こる実装 反復処理の中で子テーブルのレコードにアクセスしてしまう場合，N+1問題が起こる．内部的には，親テーブルへのSQLと，Where句を持つSQLが親テーブルのレコード数分だけ発行される． employees; // 親テーブルのレコード数分のWhere句SQLが発行される（N回） } # 1回 select * from `departments` # N回 select * from `employees` where `department_id` = 1 select * from `employees` where `department_id` = 2 select * from `employees` where `department_id` = 3 ... ・解決方法 反復処理の前に小テーブルにアクセスしておく．データアクセス時にwithメソッドを使うと，親テーブルへのアクセスに加えて，親テーブルのEloquentモデルのプロパティに子テーブルのレコードを保持するように処理する．そのため，反復処理ではプロパティからデータを取り出すだけになる．内部的には，親テーブルへのSQLと，In句を用いたSQLが発行される． get(); // SQL発行（2回） foreach($departments as $department) { $department->employees; // キャッシュを使うのでSQLの発行はされない（0回） } # 2回 select * from `departments` select * from `employees` where `department_id` in (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ... 100) 05-03. Laravelへのリポジトリパターン導入 背景 LaravelはActive Recordパターンを採用しており，これはビジネスロジックが複雑でないアプリケーションに適している．ただ，ビジネスロジックが複雑なアプリケーションに対しても，Laravelを使用したい場面がある．その場合，Laravelにリポジトリパターンを導入することが選択肢の一つになる．リポジトリパターンについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_architecture_domain_driven_design_clean_architecture.html 工夫 ・DTOクラスの導入 ビジネスロジック用ドメインモデルと，Eloquentモデルを継承した詰め替えモデル（例：DTOクラス）を用意する．詰め替えモデルをドメインモデルに変換する処理をメソッドとして切り分けておくと便利である．ドメインモデルとDTOクラスの間でデータを詰め替えるようにすると，DTOクラスがドメインモデルとデータベースの間でレコードのやり取りを仲介し，これらを疎結合にしてくれる．そのため，Repositoryパターンを実現できる． id), new FooName($this->name), new FooAge($this->age), ); } } CREATE ・createメソッド ＊実装例＊ fooDTO = $fooDTO; } /** * @param Foo $foo * @return void */ public function create(Foo $foo): void { $this->fooDTO // INSERT文を実行する． ->create([ // ドメインモデルのデータをDTOに詰め替える． \"name\" => $foo->name(), \"age\" => $foo->age(), ]); // 以下の実装でもよい． // $this->fooDTO // ->fill([ // \"name\" => $foo->name(), // \"age\" => $foo->age(), // ]) // ->save(); } } READ ・findメソッド ＊実装例＊ fooDTO = $fooDTO; } /** * @param FooId $fooId * @return Foo */ public function findById(FooId $fooId): Foo { $fooDTO = $this->fooDTO ->find($fooId->id()); // DBアクセス処理後のDTOをドメインモデルに変換する． return new Foo( $fooDTO->id(), $fooDTO->name(), $fooDTO->age(), $fooDTO->email() ); } } ・allメソッド ＊実装例＊ fooDTO = $fooDTO; } /** * @return array */ public function findAll(): array { $fooDTOs = $this->fooDTO ->all(); $foos = []; foreach ($fooDTOs as $fooDTO) // DBアクセス後のDTOをドメインモデルに変換する． $foos = new Foo( $fooDTO->id(), $fooDTO->name(), $fooDTO->age(), $fooDTO->email(), ); return $foos; } } ・withメソッド UPDATE ・saveメソッド ＊実装例＊ fooDTO = $fooDTO; } /** * @param Foo $foo * @return void */ public function save(Foo $foo): void { $this->fooDTO // ドメインモデルのデータをDTOに詰め替える． ->fill([ \"name\" => $foo->name(), \"age\" => $foo->age(), ]) // UPDATE文を実行する． ->save(); } } DELETE ・destroy／deleteメソッド ＊実装例＊ fooDTO = $fooDTO; } /** * @param FooId $fooId * @return void */ public function delete(FooId $fooId): void { // destroyメソッドでレコードを削除する． $this->fooDTO->destroy($fooId->id()); // deleteメソッドを使用しても良い． // $this->fooDTO->find($fooId->id())->delete(); } } fooRepository = $fooRepository; } /** * @param FooId $fooId * @return mixed */ public function delete(FooId $fooId) { $this->fooRepository ->delete($fooId); return response()->view(\"foo\") ->setStatusCode(200); } } 06. Event／Listener Event ・データベースアクセス系 Eloquentモデルがデータベースに対して処理を行う前後にイベントを定義できる．例えば，createメソッド，saveメソッド，updateメソッド，destroy／deleteメソッド，の実行後にイベントを定義するためには，createdメソッド，savedメソッド，updatedメソッド，deletedメソッド，を使用する． ＊実装例＊ listen(\"eloquent.{$event}: {$name}\", $callback); } } /** * @param Closure|string $callback * @return void */ public static function saved($callback) { // ModelのイベントをDispatcherに登録します． static::registerModelEvent(\"saved\", $callback); } /** * @param Closure|string $callback * @return void */ public static function updated($callback) { // Modelのsaveメソッド実行後イベントをDispatcherに登録します． static::registerModelEvent(\"updated\", $callback); } /** * @param Closure|string $callback * @return void */ public static function created($callback) { // Modelのcreateメソッド実行後イベントをDispatcherに登録します． static::registerModelEvent(\"created\", $callback); } /** * @param Closure|string $callback * @return void */ public static function deleted($callback) { // Modelのdeleteメソッド実行後イベントをDispatcherに登録します． static::registerModelEvent(\"deleted\", $callback); } // ～ 省略 ～ } ・Traitを使用したイベントの発火 Laravelの多くのコンポーネントに，bootメソッドが定義されている．Eloquentモデルでは，インスタンス生成時にbootメソッドがコールされ，これによりにbootTraitsメソッドが実行される．Traitにboot+という名前の静的メソッドが定義されていると，bootTraitsメソッドはこれをコールする． ＊実装例＊ bootIfNotBooted(); $this->initializeTraits(); $this->syncOriginal(); $this->fill($attributes); } /** * */ protected function bootIfNotBooted() { if (! isset(static::$booted[static::class])) { static::$booted[static::class] = true; $this->fireModelEvent(\"booting\", false); // bootメソッドをコール static::boot(); $this->fireModelEvent(\"booted\", false); } } /** * */ protected static function boot() { // bootTraitsをコール static::bootTraits(); } /** * */ protected static function bootTraits() { $class = static::class; $booted = []; static::$traitInitializers[$class] = []; foreach (class_uses_recursive($class) as $trait) { // useされたTraitにboot+のメソッドが存在するかを判定． $method = \"boot\".class_basename($trait); if (method_exists($class, $method) && ! in_array($method, $booted)) { // 指定した静的メソッドをコール． forward_static_call([$class, $method]); $booted[] = $method; } if (method_exists($class, $method = \"initialize\".class_basename($trait))) { static::$traitInitializers[$class][] = $method; static::$traitInitializers[$class] = array_unique( static::$traitInitializers[$class] ); } } } // ～ 省略 ～ } コールされるTraitでは，savedメソッドにModel更新イベントを登録する． save($options); }); } } $updatedModel = $updatedModel; } } Model更新イベントが発火してコールされるリスナーでは，create_byカラムまたはupdated_byカラムを指定した更新者名に更新できるようにする．なお，イベントとリスナーの対応関係は，EventServiceProviderで登録する． getModelUpdater(); // create_byプロパティに値が設定されているかを判定． if (is_null($updatedModelEvent->updatedModel->created_by)) { $updatedModelEvent->updatedModel->created_by = $by; } $updatedModelEvent->updatedModel->updated_by = $by; $updatedModelEvent->updatedModel->saveWithoutEvents(); } /** * 更新処理の実行者を取得します． * * @return string */ private function getModelUpdater(): string { // コンソール経由で実行されたかを判定． if (app()->runningInConsole()) { return ExecutorConstant::ARTISAN_COMMAND; } // API認証に成功したかを判定． if (auth()->check()) { return ExecutorConstant::STAFF . \":\" . auth()->id(); } return ExecutorConstant::GUEST; } } 実行者名は，定数として管理しておくとよい． Listener 07. Exception Laravelにおけるエラーハンドリング エラーハンドリングは４つのステップからなる．Laravelでは標準でHandlerクラスが全てのステップをカバーしている．また加えて，異常系レスポンスを自動で返信してくれる．エラーハンドリングのステップのうち，エラー検出については言及しないこととする． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_logic_error_and_error_handling.html 例外スロー ・例外 ドキュメントとしてまとめられていないが，標準で様々な例外が備わっている． 参考：https://laravel.com/api/8.x/search.html?search=exception ・スタックトレース Laravelはスローされる例外のメッセージをスタックトレースで生成する．また，Laravel内部で例外キャッチと新たな例外の投げ直しが行われるため，[previous exception]によって例外が結合される．スタックトレースには機密性の高い情報が含まれるため，クライアントへの異常系レスポンスのエラーメッセージには割り当てずに，ロギングだけしておく．エラーが複数行にまたがるため，CloudWatchやFluentBitなどのログ収集ツールでは，各行を繋げて扱えるように設定が必要である．ちなみに，ログの詳細度はAPP_DEBUG環境変数で制御できる． 参考：https://readouble.com/laravel/8.x/ja/errors.html#configuration [2021-09-00 00:00:00] local.ERROR: *****（エラーメッセージ） [stacktrace] #0 /var/www/foo-app/framework/src/Illuminate/Database/Connection.php(652): Illuminate\\\\Database\\\\Connection->runQueryCallback('insert into `us...', Array, Object(Closure)) #1 /var/www/foo-app/framework/src/Illuminate/Database/Connection.php(486): Illuminate\\\\Database\\\\Connection->run('insert into `us...', Array, Object(Closure)) #2 /var/www/foo-app/framework/src/Illuminate/Database/Connection.php(438): Illuminate\\\\Database\\\\Connection->statement('insert into `us...', Array) ... #60 /var/www/foo-app/framework/src/Illuminate/Foundation/Http/Kernel.php(141): Illuminate\\\\Pipeline\\\\Pipeline->then(Object(Closure)) #61 /var/www/foo-app/framework/src/Illuminate/Foundation/Http/Kernel.php(110): Illuminate\\\\Foundation\\\\Http\\\\Kernel->sendRequestThroughRouter(Object(Illuminate\\\\Http\\\\Request)) #62 /var/www/foo-app/public/index.php(55): Illuminate\\\\Foundation\\\\Http\\\\Kernel->handle(Object(Illuminate\\\\Http\\\\Request)) #63 {main} [previous exception] [object] *****（エラーメッセージ） [stacktrace] #0 /var/www/foo-app/vendor/doctrine/dbal/lib/Doctrine/DBAL/Driver/PDOStatement.php(114): Doctrine\\\\DBAL\\\\Driver\\\\PDO\\\\Exception::new(Object(PDOException)) #1 /var/www/foo-app/framework/src/Illuminate/Database/Connection.php(485): Doctrine\\\\DBAL\\\\Driver\\\\PDOStatement->execute() #2 /var/www/foo-app/framework/src/Illuminate/Database/Connection.php(685): Illuminate\\\\Database\\\\Connection->Illuminate\\\\Database\\\\{closure}('insert into `us...', Array) ... #63 /var/www/foo-app/framework/src/Illuminate/Foundation/Http/Kernel.php(141): Illuminate\\\\Pipeline\\\\Pipeline->then(Object(Closure)) #64 /var/www/foo-app/framework/src/Illuminate/Foundation/Http/Kernel.php(110): Illuminate\\\\Foundation\\\\Http\\\\Kernel->sendRequestThroughRouter(Object(Illuminate\\\\Http\\\\Request)) #65 /var/www/foo-app/public/index.php(55): Illuminate\\\\Foundation\\\\Http\\\\Kernel->handle(Object(Illuminate\\\\Http\\\\Request)) #66 {main} [previous exception] [object] *****（エラーメッセージ） [stacktrace] #0 /var/www/foo-app/vendor/doctrine/dbal/lib/Doctrine/DBAL/Driver/PDOStatement.php(112): PDOStatement->execute(NULL) #1 /var/www/foo-app/framework/src/Illuminate/Database/Connection.php(485): Doctrine\\\\DBAL\\\\Driver\\\\PDOStatement->execute() #2 /var/www/foo-app/framework/src/Illuminate/Database/Connection.php(685): Illuminate\\\\Database\\\\Connection->Illuminate\\\\Database\\\\{closure}('insert into `us...', Array) ... #63 /var/www/foo-app/framework/src/Illuminate/Foundation/Http/Kernel.php(141): Illuminate\\\\Pipeline\\\\Pipeline->then(Object(Closure)) #64 /var/www/foo-app/framework/src/Illuminate/Foundation/Http/Kernel.php(110): Illuminate\\\\Foundation\\\\Http\\\\Kernel->sendRequestThroughRouter(Object(Illuminate\\\\Http\\\\Request)) #65 /var/www/foo-app/public/index.php(55): Illuminate\\\\Foundation\\\\Http\\\\Kernel->handle(Object(Illuminate\\\\Http\\\\Request)) #66 {main} \"} ロギング ・reportメソッド Laravel内部でキャッチされた例外に基づいて，ロギングを実行する． 参考：https://cpoint-lab.co.jp/article/201905/9841/ 異常系レスポンスの返信 ・renderメソッド Laravel内部でキャッチされた例外に基づいて，異常系レスポンスを自動で返信する．異常系レスポンスの返信処理をこれに追加することも可能であるが，異常系レスポンス間が密結合になるため，できるだけいじらない．その代わりに，各コントローラにtry-catchと異常系レスポンスの返信処理を実装するようにする． 参考：https://cpoint-lab.co.jp/article/201905/9841/ 08. Facade Facade ・Facadeとは Facadeに登録されたクラス（Facadeクラス）とServiceContainerを繋ぐ静的プロキシとして働く．メソッドをコールできるようになる． ・Facadeを使用しない場合 new演算子でインスタンスを作成する． ＊実装例＊ method(); ・Facadeの静的プロキシ機能を使用する場合 静的メソッドの記法でコールできる．ただし，自作クラスをFacadeの機能を使用してインスタンス化すると，スパゲッティな『Composition（合成）』の依存関係を生じさせてしまう．例えば，Facadeの中でも，Routeのような，代替するよりもFacadeを使ったほうが断然便利である部分以外は，使用しないほうがよい． ＊実装例＊ Facadeとして使用したいクラスを定義する． エイリアス名とクラスの名前空間をconfig/app.phpファイルをaliasesキーに登録すると，そのエイリアス名でインスタンス化とメソッドコールを行えるようになる． [ \"Foo\" => App\\Models\\Foo::class, ] インスタンス化とメソッドコールを行う． ・Facadeを使用した方が良い場合 Facadeがトレイトの代わりになる場合，Facadeを使用することにより，責務がドメインモデルに集中せずにすむ． ＊例＊ NotifiableトレイトをUserクラスで使用せずに，Notificationファサードによるオンデマンド通知を使用することにより，Userクラスが通知処理の責務を持たずに済む．詳しくは，オンデマンド通知の説明を参考にせよ． ・標準登録されたFacadeクラスの種類 以下のクラスは，デフォルトで登録されているFacadeである． エイリアス名 クラス名 サービスコンテナ結合キー App Illuminate\\Foundation\\Application app Artisan Illuminate\\Contracts\\Console\\Kernel artisan Auth Illuminate\\Auth\\AuthManager auth Auth (Instance) Illuminate\\Contracts\\Auth\\Guard auth.driver Blade Illuminate\\View\\Compilers\\BladeCompiler blade.compiler Broadcast Illuminate\\Contracts\\Broadcasting\\Factory Broadcast (Instance) Illuminate\\Contracts\\Broadcasting\\Broadcaster Bus Illuminate\\Contracts\\Bus\\Dispatcher Cache Illuminate\\Cache\\CacheManager cache Cache (Instance) Illuminate\\Cache\\Repository cache.store Config Illuminate\\Config\\Repository config Cookie Illuminate\\Cookie\\CookieJar cookie Crypt Illuminate\\Encryption\\Encrypter encrypter DB Illuminate\\Database\\DatabaseManager db DB (Instance) Illuminate\\Database\\Connection db.connection Event Illuminate\\Events\\Dispatcher events File Illuminate\\Filesystem\\Filesystem files Gate Illuminate\\Contracts\\Auth\\Access\\Gate Hash Illuminate\\Contracts\\Hashing\\Hasher hash Lang Illuminate\\Translation\\Translator translator Log Illuminate\\Log\\LogManager log Mail Illuminate\\Mail\\Mailer mailer Notification Illuminate\\Notifications\\ChannelManager Password Illuminate\\Auth\\Passwords\\PasswordBrokerManager auth.password Password (Instance) Illuminate\\Auth\\Passwords\\PasswordBroker auth.password.broker Queue Illuminate\\Queue\\QueueManager queue Queue (Instance) Illuminate\\Contracts\\Queue\\Queue queue.connection Queue (Base Class) Illuminate\\Queue\\Queue Redirect Illuminate\\Routing\\Redirector redirect Redis Illuminate\\Redis\\RedisManager redis Redis (Instance) Illuminate\\Redis\\Connections\\Connection redis.connection Request Illuminate\\Http\\Request request Response Illuminate\\Contracts\\Routing\\ResponseFactory Response (Instance) Illuminate\\Http\\Response Route Illuminate\\Routing\\Router router Schema Illuminate\\Database\\Schema\\Builder Session Illuminate\\Session\\SessionManager session Session (Instance) Illuminate\\Session\\Store session.store Storage Illuminate\\Filesystem\\FilesystemManager filesystem Storage (Instance) Illuminate\\Contracts\\Filesystem\\Filesystem filesystem.disk URL Illuminate\\Routing\\UrlGenerator url Validator Illuminate\\Validation\\Factory validator Validator (Instance) Illuminate\\Validation\\Validator View Illuminate\\View\\Factory view View (Instance) Illuminate\\View\\View Authファサード ・Authファサードとは 認証に関する処理を提供する．Laravelからあらかじめ提供されている認証を使用しない場合，Authファサードを使用して，認証ロジックを実装できる． DBファサード ・DBファサードとは データベースの操作処理を提供する．Eloquentの代わりに，DBファサードを使用しても良い．Active Recordのロジックを持たないため，Repositoryパターンのロジックとして使用できる． ・transactionメソッド 一連のトランザクション処理を実行する．引数として渡した無名関数が例外を返却した場合，ロールバックを自動的に実行する．例外が発生しなかった場合，無名関数の返却値が，そのままtransactionメソッドの返却値になる．さらにtransactionメソッドの返却値を返却するようにすれば，無名関数の返却値をそのまま使用できる．ちなみに，トランザクション処理は必須ではなく，使用するとアプリケーションがデータベースを操作するために要する時間が増えるため，使用しなくても良い．参考リンクによると，MongoDBに対してトランザクション処理を行う／行わない場合を比較して，処理時間が17%弱長くなったとのこと． 参考：https://rightcode.co.jp/blog/information-technology/node-js-mongodb-transaction-function-use#i-5 ＊実装例＊ fooDTO = $fooDTO; } /** * @param Foo $foo * @throws Throwable */ public function save(Foo $foo): void { // トランザクション処理を開始する． DB::beginTransaction(); try { $this->fooDTO->fill([ \"name\" => $foo->name(), \"age\" => $foo->age(), ]) ->save(); // コミットメントを実行する． DB::commit(); } catch (Exception $e) { // ロールバックを実行する． DB::rollback(); } } } ・beginTransactionメソッド，commitメソッド，rollbackメソッド， トランザクション処理の各操作を分割して実行する．基本的には，transactionメソッドを使用してトランザクション処理を実行すれば良い． ＊実装例＊ fooDTO = $fooDTO; } /** * Fooを更新します． * * @param Foo $foo */ public function save(Foo $foo) { // トランザクション処理を開始する． DB::beginTransaction(); try { $this->fooDTO // オブジェクトにデータを設定する． ->fill([ \"name\" => $foo->name(), \"age\" => $foo->age(), \"email\" => $foo->email() ]) // update文を実行する． ->save(); // コミットメントを実行する． DB::commit(); } catch (\\Exception $e) { // ロールバックを実行する． DB::rollback(); } } } Routeファサード ・Routeファサードとは ルーティング処理を提供する． ・ヘルスチェックへの対応 ALBやGlobal Acceleratorから『/healthcheck』に対してヘルスチェックを設定した上で，200ステータスのレスポンスを返信するようにする．Nginxでヘルスチェックを実装することもできるが，アプリケーションの死活管理としては，Laravelに実装する方が適切である．RouteServiceProviderも参照せよ． ＊実装例＊ ・middlewareメソッド コントローラへのルーティング時に実行するMiddlewareクラスを設定する．引数として，App\\Http\\Kernel.phpファイルで定義されたMiddlewareクラスのエイリアス名を設定する． ＊実装例＊ 認証方法としてWebガードを使用する場合，authエイリアスを設定する． group(function () { Route::get(\"/foos\", [FooController::class, \"getFoo\"]); Route::get(\"/foos/{fooId}\", [FooController::class, \"index\"]); Route::post(\"/foos\", [FooController::class, \"createFoo\"]); Route::put(\"/foos/{fooId}\", [FooController::class, \"updateFoo\"]); Route::delete(\"/foos/{fooId}\", [FooController::class, \"deleteFoo\"]); }); デフォルトでは，App\\Http\\Kernel.phpファイルにて，authエイリアスに\\App\\Http\\Middleware\\Authenticateクラスが関連付けられている． \\App\\Http\\Middleware\\Authenticate::class, ]; // ～ 省略 ～ } 一方で，認証方法としてAPIガードを使用する場合，auth:apiエイリアスを設定する． group(function () { // 何らのルーティング }); ・prefixメソッド エンドポイントが共通として持つ最初のパスを，プレフィクスとして定義する． ＊実装例＊ 各エンドポイントの最初の『foos』をプレフィクスとして定義する． group(function () { Route::get(\"/\", [FooController::class, \"getFoo\"]); Route::get(\"/{fooId}\", [FooController::class, \"index\"]); Route::post(\"/\", [FooController::class, \"createFoo\"]); Route::put(\"/{fooId}\", [FooController::class, \"updateFoo\"]); Route::delete(\"/{fooId}\", [FooController::class, \"deleteFoo\"]); }); ・whereメソッド，patternメソッド パスパラメータに対するバリデーションルールを正規表現で定義し，また実行する．RouteServiceProviderのbootメソッドにて，patternメソッドで制約を設定することによって，ルーティング時にwhereを使用する必要がなくなる． ＊実装例＊ userIdの形式を『0〜9が一つ以上』に設定している． group(function () { Route::get(\"/\", [FooController::class, \"getFoo\"]); Route::get(\"/{fooId}\", [FooController::class, \"index\"]) // バリデーションルール ->where(\"fooId\", \"[0-9]+\"); Route::post(\"/\", [FooController::class, \"createFoo\"]); Route::put(\"/{fooId}\", [FooController::class, \"updateFoo\"]) ->where(\"fooId\", \"[0-9]+\"); Route::delete(\"/{fooId}\", [FooController::class, \"deleteFoo\"]) ->where(\"fooId\", \"[0-9]+\"); }); または，RouteServiceProviderクラスにpatternメソッドを定義すると，各エンドポイントに対する正規表現を一括で実行できる． 参考：https://readouble.com/laravel/8.x/ja/routing.html#parameters-global-constraints ＊実装例＊ ・groupメソッド 複数のグループを組み合わせる場合，groupメソッドを使用する． ＊実装例＊ エンドポイントのプレフィクスとミドルウェアの指定を定義する． \"foo\" , \"middleware\" => \"auth\"], (function () { Route::get(\"/\", [FooController::class, \"getFoo\"]); Route::get(\"/{fooId}\", [FooController::class, \"index\"]); Route::post(\"/\", [FooController::class, \"createFoo\"]); Route::put(\"/{fooId}\", [FooController::class, \"updateFoo\"]); Route::delete(\"/{fooId}\", [FooController::class, \"deleteFoo\"]); }); Storageファサード ・Storageファサードとは ファイルの入出力処理を提供する． ・ローカルストレージ（非公開）の場合 ファイルを/storage/appディレクトリに保存する．このファイルは非公開であり，リクエストによってアクセスできない．事前に，シンボリックリンクを作成する，また，filesystems.phpファイルに設定が必要である． $ php artisan storage:link return [ \"default\" => env(\"FILESYSTEM_DRIVER\", \"local\"), // ～ 省略 ～ \"disks\" => [ \"local\" => [ \"driver\" => \"local\", \"root\" => storage_path(\"app\"), ], // ～ 省略 ～ // シンボリックリンクの関係を定義 \"links\" => [ // 『/var/www/project/public/storage』から『/var/www/project/storage/app/public』へのリンク public_path(\"storage\") => storage_path(\"app/public\"), ], ]; ＊実装例＊ Storageファサードのdiskメソッドを用いてlocalディスクを指定する．file.txtファイルをstorage/app/file.txtとして保存する． Storage::disk(\"local\")->put(\"file.txt\", \"file.txt\"); ただし，filesytems.phpファイルでデフォルトディスクはlocalになっているため，putメソッドを直接使用できる． Storage::put(\"file.txt\", \"file.txt\"); ・ローカルストレージ（公開）の場合 ファイルをstorage/app/publicディレクトリに保存する．このファイルは公開であり，リクエストによってアクセスできる．事前に，filesystems.phpファイルに設定が必要である． return [ \"default\" => env(\"FILESYSTEM_DRIVER\", \"local\"), // ～ 省略 ～ \"disks\" => [ // ～ 省略 ～ \"public\" => [ \"driver\" => \"local\", \"root\" => storage_path(\"app/public\"), \"url\" => env(\"APP_URL\") . \"/storage\", \"visibility\" => \"public\", ], // ～ 省略 ～ ], ]; ＊実装例＊ Storageファサードのdiskメソッドを用いてpublicディスクを指定する．また，file.txtファイルをstorage/app/public/file.txtとして保存する． Storage::disk(\"s3\")->put(\"file.txt\", \"file.txt\"); ただし，環境変数を使用して，filesytems.phpファイルでデフォルトディスクをs3に変更すると，putメソッドを直接使用できる． FILESYSTEM_DRIVER=s3 Storage::put(\"file.txt\", \"file.txt\"); ＊実装例＊ put($saved_file_path, $contents); } } ・クラウドストレージの場合 ファイルをS3バケット内のディレクトリに保存する．環境変数を.envファイルに実装する必要がある．filesystems.phpファイルから，指定された設定が選択される．AWSアカウントの認証情報を環境変数として設定するか，またはS3アクセスポリシーをEC2やECSタスクに付与することにより，S3にアクセスできるようになる．事前に，filesystems.phpファイルに設定が必要である． # S3アクセスポリシーをEC2やECSタスクに付与してもよい AWS_ACCESS_KEY_ID= AWS_SECRET_ACCESS_KEY= AWS_DEFAULT_REGION= # 必須 AWS_BUCKET= return [ \"default\" => env(\"FILESYSTEM_DRIVER\", \"local\"), // ～ 省略 ～ \"disks\" => [ // ～ 省略 ～ \"s3\" => [ \"driver\" => \"s3\", \"key\" => env(\"AWS_ACCESS_KEY_ID\"), \"secret\" => env(\"AWS_SECRET_ACCESS_KEY\"), \"region\" => env(\"AWS_DEFAULT_REGION\"), \"bucket\" => env(\"AWS_BUCKET\"), \"url\" => env(\"AWS_URL\"), \"endpoint\" => env(\"AWS_ENDPOINT\"), ], ], ]; ＊実装例＊ Storageファサードのdiskメソッドを用いてs3ディスクを指定する．また，file.txtファイルをS3バケットのルートにfile.txtとして保存する． Storage::disk(\"s3\")->put(\"file.txt\", \"file.txt\"); 他の実装方法として，環境変数を使用して，filesytems.phpファイルでデフォルトディスクをs3に変更すると，putメソッドを直接使用できる． FILESYSTEM_DRIVER=s3 Storage::put(\"file.txt\", \"file.txt\"); Validatorファサード ・Validatorファサードとは バリデーション処理を提供する．FormRequestクラスのvalidatedメソッドやvalidateメソッドの代わりに，Validatorファサードを使用しても良い． ・Validatorクラス，failsメソッド Validateファサードのmakeメソッドを使用して，ルールを定義する．この時，第一引数で，バリデーションを行うリクエストデータを渡す．ルールに反すると，一つ目のルール名（例えばrequired）に基づき，validation.phpファイルから対応するエラーメッセージを自動的に選択する．次に，failsメソッドを使用して，バリデーションでエラーが起こった場合の処理を定義する． ＊実装例＊ all(), [ \"title\" => \"required|unique:posts|max:255\", \"body\" => \"required\", ]); // バリデーション時にエラーが起こった場合 if ($validator->fails()) { // 指定したページにリダイレクト // validatorを渡すことでエラーメッセージをViewに渡せる． return redirect(\"error\")->withErrors($validator) ->withInput(); } // 続きの処理 } } ・validateメソッド Validatorクラスのvalidateメソッドを使用すると，FormRequestクラスのvalidateメソッドと同様の処理が実行される．バリデーションでエラーが起こった場合，Handlerクラスのinvalidメソッドがコールされ，元々のページにリダイレクトされる． all(), [ \"title\" => \"required|unique:posts|max:255\", \"body\" => \"required\", ])->validate(); // バリデーション時にエラーが起こった場合 if ($validator->fails()) { // 指定したページにリダイレクト // validatorを渡すことでエラーメッセージをViewに渡せる． return redirect(\"error\")->withErrors($validator) ->withInput(); } // 続きの処理 } } 08-02. よく使うグローバルヘルパー関数 ヘルパー関数 ・ヘルパー関数とは グローバルにコールできるLaravel専用のメソッドのこと．基本的には，ヘルパー関数で実行される処理は，Facadeの内部で実行されるものと同じである．どちらを使用するかは好みである． 参考：https://stackoverflow.com/questions/31324226/laravel-performance-of-facades-vs-helper-methods ・一覧 以下リンクを参照せよ． https://readouble.com/laravel/8.x/ja/helpers.html#method-view authヘルパー ・AuthManagerインスタンスの返却 認証処理をもつAuthManagerクラスのインスタンスを返却する． 参考：https://laravel.com/api/8.x/Illuminate/Auth/AuthManager.html configヘルパー ・環境変数ファイルの読み込み 環境変数ファイル名とキー名をドットで指定し，事前に設定された値を出力する． ＊実装例＊ 標準で搭載されているapp.phpファイルのtimezoneキーの値を出力する． ・独自環境変数ファイルの作成と読み込み configディレクトリに任意の名前のphp形式を作成しておく．これは，configヘルパーで読み込むことができる． ＊実装例＊ [ \"endpoint_url\" => env(\"ENDPOINT_URL\", \"\"), \"api_key\" => env(\"API_KEY\"), ], \"bar\" => [ \"endpoint_url\" => env(\"ENDPOINT_URL\", \"\"), \"api_key\" => env(\"API_KEY\"), ] ]; bcryptヘルパー 参考：https://readouble.com/laravel/8.x/ja/helpers.html#method-bcrypt redirectヘルパー 参考：https://blog.capilano-fw.com/?p=566 responseヘルパー ・JSONデータのレスポンス 返却されるResponseFactoryクラスのjsonメソッドにレンダリングしたいJSONデータを設定する．responseヘルパーは初期値として200ステータスが設定されているが，viewメソッドやsetStatusCodeメソッドを使用して，明示的に設定してもよい． 参考：https://github.com/laravel/framework/blob/8.x/src/Illuminate/Contracts/Routing/ResponseFactory.php ＊実装例＊ json([ \"name\" => \"Abigail\", \"state\" => \"CA\" ], 200); } } ・Viewテンプレートのレスポンス 返却されるResponseFactoryクラスのviewメソッドに，レンダリングしたいデータ（テンプレート，array型データ，ステータスコードなど）を設定する．また，ViewクラスのheaderメソッドにHTTPヘッダーの値を設定する．responseヘルパーは初期値として200ステータスが設定されているが，viewメソッドやsetStatusCodeメソッドを使用して，明示的に設定してもよい． ＊実装例＊ view( \"foo\", $data, 200 )->header( \"Content-Type\", $type ); } } view(\"foo\") ->setStatusCode(200); } } routeヘルパー ・ルートエイリアスに基づいてURL生成 ルートにエイリアスがついている場合，エイリアスに応じてURLを生成する．ドメインは自動で補完される． 参考：https://readouble.com/laravel/8.x/ja/helpers.html#method-route name('foos_index'); // https://example.co.jp/foos $url = route('foos_index'); path系ヘルパー ・base_pathヘルパー 引数を設定しない場合，projectルートディレクトリの絶対パスを生成する．また，projectルートディレクトリからの相対パスを引数として，絶対パスを生成する． ・public_pathヘルパー 引数を設定しない場合，publicディレクトリの絶対パスを生成する．また，publicディレクトリからの相対パスを引数として，絶対パスを生成する． ・storage_pathヘルパー 引数を設定しない場合，storageディレクトリの絶対パスを生成する．まあ，storageディレクトリからの相対パスを引数として，絶対パスを生成する． urlヘルパー ・パスに基づいてURL生成 指定したパスに応じてURLを生成する．ドメインは自動で補完される． 参考：https://readouble.com/laravel/5.7/ja/urls.html 09. Factory artisanコマンドによる操作 ・Factoryの生成 $ php artisan make:factory --model= 初期値レコードの定義 ・Fakerによるランダム値生成 Fakerはレコードの値をランダムに生成するためのパッケージである．Farkerクラスは，プロパティにランダムなデータを保持している．このプロパティを特に，Formattersという． 参考：https://fwhy.github.io/faker-docs/ ・Factoryによるレコード定義 ＊実装例＊ $this->faker->name, 'email_address' => $this->faker->unique()->safeEmail, 'password' => 'password', ]; } } ・HasFactoryトレイト Factoryに対応するEloquentモデルで使用する必要がある． 参考：https://readouble.com/laravel/8.x/ja/database-testing.html#creating-models-using-factories class Foo { use HasFactory; } 初期ダミーデータの量産 ・Seederによるダミーデータ量産 Factoryにおける定義を基にして，指定した数だけダミーデータを量産する． ＊実装例＊ FooSeederを定義し，50個のダミーユーザデータを量産する． count(self::NUM_TEST_DATA)->create(); } } また，BarSeederを定義し，50個のダミーユーザデータを量産する． count(self::NUM_TEST_DATA)->create(); } } DatabaseSeederにて，全てのSeederをまとめて実行する． environment(\"dev\")) { $this->call([ // ダミーデータ FooSeeder::class, BarSeeder::class ]); } // ステージング環境用の初期データ if (app()->environment(\"stg\")) { $this->call([ // リアルデータ ]); } // 本番環境用の初期データ if (app()->environment(\"prd\")) { $this->call([ // リアルデータ ]); } } } 10. HTTP｜Controller artisanコマンドによる操作 ・クラスの自動生成 # コントローラクラスを自動作成 $ php artisan make:controller リクエストパラメータの取得 ・クエリパラメータ／メッセージボディ クエリパラメータとメッセージボディの両方を取得する． 参考：https://readouble.com/laravel/8.x/ja/requests.html#retrieving-input ＊実装例＊ all(); // 全てのパラメータを連想配列で取得する． $foo = $request->input('foo'); // 指定したパラメータの値を取得する． $qux = $request->input('foo.qux'); // ネストされたパラメータの値を取得する． $params = $request->only(['foo', 'bar']); // 指定したパラメータを連想配列で取得する． $params = $request->except(['baz']); // 指定したパラメータ以外を連想配列で取得する． $foo = $request->foo; // 指定したパラメータの値を取得する． $foo = request('foo'); // 指定したパラメータの値を取得する． } } ・クエリパラメータ クエリパラメータを取得する． 参考：https://readouble.com/laravel/8.x/ja/requests.html#retrieving-input ＊実装例＊ query(); // 全てのパラメータを連想配列で取得する． $foo = $request->query('foo'); // 指定したパラメータの値を取得する． } } ・パスパラメータ パスパラメータを取得する． 参考： https://laravel.com/api/8.x/Illuminate/Http/Request.html#method_route https://laravel.com/api/8.x/Illuminate/Routing/Route.html#method_parameter ＊実装例＊ route(); // 全てのパラメータを連想配列で取得する． $fooId = $request->route('fooId'); // 指定したパラメータの値を取得する． $fooId = $request->route->parameter('fooId'); // 指定したパラメータの値を取得する． } } コントローラの第二引数にパスパラメータ名を記述することで，パスパラメータの値を取得できる． ＊実装例＊ 10-02. HTTP｜Middleware artisanコマンドによる操作 ・クラスの自動生成 Middlewareクラスを自動生成する． $ php artisan make:middleware Middlewareの仕組み ・Middlewareの種類 ルーティング後にコントローラメソッドの前にコールされるBeforeMiddleと，レスポンスの実行時にコールされるAfterMiddlewareがある ・BeforeMiddleware ルーティング時のコントローラメソッドのコール前に実行する処理を設定できる．一連の処理を終えた後，FormRequestクラスを，次のMiddlewareクラスやControllerクラスに渡す必要がある．これらのクラスはClosure（無名関数）として，next変数に格納されている． ＊実装例＊ ・AfterMiddleware コントローラメソッドのレスポンスの実行後（テンプレートのレンダリングを含む）に実行する処理を設定できる．あらかじめ，FormRequestクラスを，前のMiddlewareクラスやControllerクラスから受け取る必要がある．これらのクラスはClosure（無名関数）として，next変数に格納されている． ＊実装例＊ 標準のMiddleware ・EncryptCookies レスポンス時に，Cookieヘッダーの全ての値を暗号化する．暗号化したくない場合は，Cookieヘッダーのキー名をexceptプロパティに設定する． 参考：https://reffect.co.jp/laravel/laravel-sessions-understand#cookie-2 ・StartSession セッションの開始の起点になる． 参考：https://qiita.com/wim/items/b1db5202cce6b38bc47b また，同一セッションで一意なCSRFトークンを生成する．CSRFトークンによるCSRFの防御については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_cyber_attacks.html ・VerifyCsrfToken セッションファイルに書かれたCSRFトークンと，リクエストボディに割り当てられたトークンを比較する．セッションファイルはstorage/framework/sessionsディレクトリに配置されている．一般的に，CSRFトークンはCookieヘッダーに割り当てることもできるが，Laravelではリクエストボディを使用する必要がある． 参考：https://readouble.com/laravel/8.x/ja/csrf.html#preventing-csrf-requests コール方法のカスタマイズ ・Kernel Middlewareクラスをコールする時の方法をカスタマイズできる． ＊実装例＊ [ ], 'api' => [ 'throttle:60,1', \\Illuminate\\Routing\\Middleware\\SubstituteBindings::class, ], ]; /** * エイリアス名と個別のミドルウェアを定義します． * * @var array */ protected $routeMiddleware = [ 'auth' => \\App\\Http\\Middleware\\Auth\\Authenticate::class, 'auth.basic' => \\Illuminate\\Auth\\Middleware\\AuthenticateWithBasicAuth::class, 'bindings' => \\Illuminate\\Routing\\Middleware\\SubstituteBindings::class, 'cache.headers' => \\Illuminate\\Http\\Middleware\\SetCacheHeaders::class, 'can' => \\Illuminate\\Auth\\Middleware\\Authorize::class, 'guest' => \\App\\Http\\Middleware\\Auth\\RedirectIfAuthenticated::class, 'password.confirm' => \\Illuminate\\Auth\\Middleware\\RequirePassword::class, 'signed' => \\Illuminate\\Routing\\Middleware\\ValidateSignature::class, 'throttle' => \\Illuminate\\Routing\\Middleware\\ThrottleRequests::class, 'verified' => \\Illuminate\\Auth\\Middleware\\EnsureEmailIsVerified::class, // Fooミドルウェアクラス 'foo' => \\App\\Http\\Middleware\\Before\\FooMiddleware::class ]; /** * ミドルウェアをコールする順番を定義します． * * @var string[] */ protected $middlewarePriority = [ \\Illuminate\\Session\\Middleware\\StartSession::class, \\Illuminate\\View\\Middleware\\ShareErrorsFromSession::class, \\App\\Http\\Middleware\\Auth\\Authenticate::class, \\Illuminate\\Routing\\Middleware\\ThrottleRequests::class, \\Illuminate\\Session\\Middleware\\AuthenticateSession::class, \\Illuminate\\Routing\\Middleware\\SubstituteBindings::class, \\Illuminate\\Auth\\Middleware\\Authorize::class, ]; } 10-03. HTTP｜FormRequest artisanコマンドによる操作 ・クラスの自動生成 FormRequestクラスを自動作成する． $ php artisan make:request クエリパラメータ／メッセージボディのバリデーション ・ルール定義 ＆ バリデーション手動実行 同じくFormRequestクラスのvalidateメソッドを使用して，ルールを定義し，さらにバリデーションを実行する．validatedメソッドと間違わないように注意する．ルールに反すると，一つ目のルール名（例えばrequired）に基づき，validation.phpファイルから対応するエラーメッセージを自動的に選択する．バリデーションでエラーが起こった場合，Handlerクラスのinvalidメソッドがコールされ，元々のページにリダイレクトされる． 参考： https://readouble.com/laravel/7.x/ja/validation.html#creating-form-requests https://laravel.com/api/8.x/Illuminate/Http/Request.html#method_validate ＊実装例＊ validate([ \"limit\" => [\"required\", Rule::in([25, 50, 100])], \"order\" => [\"required\", Rule::in([\"ascend\", \"descend\"])], ]); // 続きの処理 } /** * @param Request $request */ public function update(Request $request) { // ルールの定義，バリデーションの実行 // エラーが起こった場合は元々のページにリダイレクト $validated = $request->validate([ \"title\" => [\"required\", \"string\", \"max:255\"], \"body\" => [\"required\", \"string\", \"max:255\"], \"date\" => [\"required\", \"date\"], ]); // 続きの処理 } } なお，ルールによっては，配列を使用せずとも定義できる． ＊実装例＊ validate([ \"title\" => \"required|string|max:5255\", \"body\" => \"required|string|max:255\", \"date\" => \"required|date\", ]); // 続きの処理 } } ・ルール定義 & バリデーション自動実行 Controllerで，FormRequestクラスを引数に指定すると，コントローラのメソッドをコールする前にバリデーションを自動的に実行する．そのため，コントローラの中ではバリデーションを実行する必要はない．代わりに，ルールをFormRequestクラスのruleメソッドに定義する必要がある．FormRequestクラスのvalidatedメソッドを使用して，バリデーション済みのデータを取得できる．バリデーションでエラーが起こった場合，Handlerクラスのinvalidメソッドがコールされ，元々のページにリダイレクトされる． ＊実装例＊ validated(); // 続きの処理 } /** * @param Request $request */ public function update(Request $request) { // メッセージボディのバリデーションを実行する． // エラーが起こった場合は元々のページにリダイレクト $validated = $request->validated(); // 続きの処理 } } FormRequestクラスのrulesメソッドを使用して，ルールを定義する．ルールに反すると，一つ目のルール名（例えばrequired）に基づき，validation.phpファイルから対応するエラーメッセージを自動的に選択する． ＊実装例＊ [\"required\", \"string\", \"max:255\"], \"body\" => [\"required\", \"string\", \"max:255\"], \"type\" => [\"required\", Rule::in([1, 2, 3])], \"author\" => [\"required\", \"string\", new UppercaseRule()], \"date\" => [\"required\", \"date\"], ]; } } パスパラメータのバリデーション ・ルールの定義 ＆ バリデーション自動実行 Routeファサードのpatternメソッドまたはwhereメソッドで定義する．Routeファサードの説明を参考にせよ． エラーメッセージ ・標準のエラーメッセージ 標準のバリデーションメッセージは，resources/lang/ja/validation.phpファイルで定義できる．バリデーションルールの組み合わせによって，validation.phpファイルから自動的にメッセージが選択される．例えばルールとして最大値を設定した場合は，データ型に合わせてメッセージが選択される．日本語翻訳validation.phpファイルについては，以下のリンクを参考にせよ． 参考：https://readouble.com/laravel/8.x/ja/validation-php.html ':attributeは必須です', 'string' => ':attribute は文字列のみ有効です', 'max' => [ 'numeric' => ':attributeには、:max以下の数字を指定してください', 'file' => ':attributeには、:max kB以下のファイルを指定してください', 'string' => ':attributeは、:max文字以下で指定してください', 'array' => ':attributeは:max個以下指定してください', ], 'date' => ':attribute を有効な日付形式にしてください', 'attributes' => [ 'title' => 'タイトル', 'body' => '本文', 'date' => '作成日', ], # 〜 省略 〜 ]; なお，言語設定を行わない場合，標準では/resources/lang/en/validation.phpファイルをバリデーションメッセージとして参照するため，app.phpファイルで言語を変更することと，日本語翻訳validation.phpファイルが必要である． 'ja' # 〜 省略 〜 ]; ・画面上でのエラーメッセージ出力 バリデーションでエラーがあった場合，Handlerクラスのinvalidメソッドがコールされ，MessageBagクラスがViewに渡される．選択されたバリデーションメッセージが配列型でMessageBagクラスに格納されている． 参考： https://laravel.com/api/8.x/Illuminate/Foundation/Exceptions/Handler.html#method_invalid https://laravel.com/api/8.x/Illuminate/Support/MessageBag.html ( [title] => Array ( [0] => タイトルの入力は必須です [1] => タイトルは，最大255文字以下で指定してください ) [body] => Array ( [0] => 本文の入力は必須です [1] => 本文は，最大255文字以下で指定してください ) [data] => Array ( [0] => 作成日の入力は必須です [1] => 作成日を有効な日付形式にしてください ) ) Rule ・existsメソッド 指定されたテーブルのカラムに値が存在しているかを検証する． 参考：https://laravel.com/api/8.x/Illuminate/Validation/Rule.html#method_exists [\"nullable\", \"integer\", Rule::exists(\"prefectures\", \"id\")], \"cityId\" => [\"nullable\", \"integer\", Rule::exists(\"cities\", \"id\")] ]; } } テーブルにカラム数が多い場合は，Where句をつけることで，特定のカラムのみ検証することもできる． [\"nullable\", \"integer\", Rule::exists(\"prefectures\", \"id\")], \"cityId\" => [\"nullable\", \"integer\", Rule::exists(\"cities\", \"id\")->whereNull(\"deleted_at\")], ]; } } ・inメソッド 決められた複数の値に合致する値であるかどうかを検証する． 参考：https://laravel.com/api/8.x/Illuminate/Validation/Rule.html#method_in [\"required\", Rule::in([1, 2, 3])], ]; } } ・独自ルール／メッセージ 独自ルールを定義する場合は，Ruleクラスを継承したクラスを用意し，ruleメソッドの中でインスタンスを作成する．独自Ruleクラスでは，passesメソッドでルールを定義する．また，messagesメソッドでバリデーションメッセージを定義する．validation.phpファイルでメッセージを定義し，これを参照しても良い． 参考：https://laravel.com/docs/8.x/validation#custom-validation-rules ＊実装例＊ [\"required\", \"string\", new UppercaseRule()] ]; } } セッション ・セッション変数の取得 FormRequestクラスのsessionメソッドを使用して，セッション変数を取得する． ＊実装例＊ session() ->get(\"key\"); } } 全てのセッション変数を取得することもできる． $session = $request->session()->all(); ・フラッシュデータの設定 現在のセッションにおいて，今回と次回のリクエストだけで有効な一時データを設定できる． $request->session() ->flash(\"status\", \"Task was successful!\"); Requestの認証 ・authorizeメソッド ユーザがリソースに対してCRUD操作を行う権限を持っているかを，コントローラのメソッドを実行する前に，判定する． ＊実装例＊ /** * ユーザーがこのリクエストの権限を持っているかを判断する * * @return bool */ public function authorize() { $comment = Comment::find($this->route(\"comment\")); return $comment&& $this->user()->can(\"update\", $comment); } ・Authファサード Authファサードの説明を参考にせよ． 11. Logging ログの出力先 ・設定方法 環境変数を.envファイルに実装する．logging.phpファイルから，指定された設定が選択される． 参考：https://readouble.com/laravel/8.x/ja/logging.html#available-channel-drivers LOG_CHANNEL= ・stackキー return [ // ～ 省略 ～ \"default\" => env(\"LOG_CHANNEL\", \"stack\"), \"channels\" => [ \"stack\" => [ \"driver\" => \"stack\", \"channels\" => [\"single\"], \"ignore_exceptions\" => false, ], // ～ 省略 ～ ] ]; ・singleキー 全てのログを/storage/logs/laravel.logファイルに対して出力する． return [ // ～ 省略 ～ \"default\" => env(\"LOG_CHANNEL\", \"stack\"), \"channels\" => [ \"daily\" => [ \"driver\" => \"daily\", \"path\" => storage_path(\"logs/laravel.log\"), \"level\" => env(\"LOG_LEVEL\", \"debug\"), \"days\" => 14, ], // ～ 省略 ～ ] ]; ・dailyキー 全てのログを/storage/logs/laravel-.logファイルに対して出力する． return [ // ～ 省略 ～ \"default\" => env(\"LOG_CHANNEL\", \"stack\"), \"channels\" => [ \"stderr\" => [ \"driver\" => \"monolog\", \"handler\" => StreamHandler::class, \"formatter\" => env(\"LOG_STDERR_FORMATTER\"), \"with\" => [ \"stream\" => \"php://stderr\", ], ], // ～ 省略 ～ ] ]; ・stderrキー 全てのログを標準エラー出力に対して出力する．Docker上でLaravelを稼働させる場合は，生成されるログファイルでコンテナの容量が肥大化することを防ぐために，これを選択する．なお，独自カスタマイズとして，streamキーをstdout変更すれば，標準出力にログを出力することもできる． return [ // ～ 省略 ～ \"default\" => env(\"LOG_CHANNEL\", \"stack\"), \"channels\" => [ \"stderr\" => [ \"driver\" => \"monolog\", \"handler\" => StreamHandler::class, \"formatter\" => env(\"LOG_STDERR_FORMATTER\"), \"with\" => [ \"stream\" => \"php://stderr\", ], ], // ～ 省略 ～ ] ]; ログの出力 ・errorメソッド エラーメッセージを定義する時，sprintfメソッドを使用すると便利である． ＊実装例＊ 外部のAPIに対してリクエストを送信し，データを取得する．取得したJSONデータを，クライアントにレスポンスする．この時，リクエスト処理のために，Guzzleパッケージを使用している． request( \"GET\", $requestUrl, [ \"headers\" => [ \"Content-Type\" => \"application/json\", \"X-API-Key\" => \"api.foo.api_key\", ] ] ); // JSONをクライアントにレスポンス return $response->getBody() ->getContents(); } catch (GuzzleException $e) { Log::error(sprintf( \"%s : %s at %s line %s\", get_class($e), $e->getMessage(), $e->getFile(), $e->getLine()) ); return response()->json( [], $e->getCode() ); } } } [ \"endpoint_url\" => env(\"ENDPOINT_URL\", \"\"), \"api_key\" => env(\"API_KEY\"), ], \"bar\" => [ \"endpoint_url\" => env(\"ENDPOINT_URL\", \"\"), \"api_key\" => env(\"API_KEY\"), ] ]; ・infoメソッド 12. Migration artisanコマンドによる操作 ・マイグレーションファイルを作成 $ php artisan make:migrate create__table ・テーブル作成 マイグレーションファイルを元にテーブルを作成する． $ php artisan migrate コマンド実行時，以下のエラーが出ることがある．マイグレーションファイル名のスネークケースで，これがクラス名のキャメルケースと対応づけられており，ファイル名とクラス名の関係が正しくないために起こるエラーである． Symfony\\Component\\Debug\\Exception\\FatalThrowableError : Class \"CreateXxxxxTable\" not found ・マイグレーションの結果を確認 $ php artisan migrate:status ・指定した履歴数だけテーブルを元に戻す 指定した履歴数だけ，ロールバックを行う． 参考：https://readouble.com/laravel/8.x/ja/migrations.html#rolling-back-migrations $ php artisan migrate:rollback --step= 実際の使用場面として，マイグレーションに失敗した場合に，一つ前の状態にロールバックしてマイグレーションファイルを修正した後，再びマイグレーションを行う． # マイグレーションに失敗したので，一つ前の状態にロールバック． $ php artisan migrate:rollback --step=1 # ファイル修正後にマイグレーションを実行 $ php artisan migrate ・初期の状態までテーブルを元に戻す 初期の状態まで，全てのロールバックを実行する． 参考：https://readouble.com/laravel/8.x/ja/migrations.html#rolling-back-migrations $ php artisan migrate:reset ・テーブルを元に戻してから再作成 全てのロールバック（migrate:reset）を実行し，次いでmigrateを実行する． 参考：https://readouble.com/laravel/8.x/ja/migrations.html#roll-back-migrate-using-a-single-command $ php artisan migrate:refresh ・テーブルを削除してから再作成 全てのテーブルを削除とmigrateを実行する．マイグレーションファイルの構文チェックを行わずに，強制的に実行される． 参考：https://readouble.com/laravel/8.x/ja/migrations.html#drop-all-tables-migrate $ php artisan migrate:fresh マイグレーション時，テーブルがすでに存在するエラーが起こることがある．この場合，テーブルがマイグレーションされる前までロールバックし，マイグレーションを再実行することが最適である．しかしそれが難しければ，このコマンドを実行する必要がある． SQLSTATE[42S01]: table or view already exists ・確認画面の入力をスキップ マイグレーション時，本当に実行して良いか確認画面（Yes／No）が表示される．CICDにおいて，この確認画面でYes／Noを入力することができないため，確認画面をスキップできるようにする必要がある． 参考：https://readouble.com/laravel/8.x/ja/migrations.html#forcing-migrations-to-run-in-production $ php artisan migrate --force テーブルの作成／削除 ・upメソッド，downメソッド コマンドによるマイグレーション時にコールされる．upメソッドでテーブル，カラム，インデックスのCREATEを実行する．downメソッドでCREATEのロールバックを実行する． ＊実装例＊ bigIncrements(\"foo_id\")->comment(\"ID\"); $table->string(\"name\")->comment(\"名前\"); // MigrationMacroServiceProviderのメソッドを使用する． $table->systemColumns(); // deleted_atカラムを追加する． $table->softDeletes(); }); } /** * @return void */ public function down() { Schema::drop(\"foos\"); } } カラムの追加／変更／削除 ・なし 指定したカラムを追加する． ＊実装例＊ カラムを追加するためだけにマイグレーションファイルを作成する． $ php artisan make:migration add_column --table=foos 追加したいカラムのみを定義する． string('foo_name'); }); } } マイグレーションを実行すると，指定したテーブルのカラムが追加される．実行後は，作成したマイグレーションファイルを削除する． $ php artisan migrate ・renameColumnメソッド 指定したカラムの名前を変更する． ＊実装例＊ カラム名を変更するためだけにマイグレーションファイルを作成する． $ php artisan make:migration rename_column --table=foos テーブルのカラム名を定義し，renameColumnメソッドをコールする．変更後でも，ロールバックできるように，downメソッドも定義しておく． renameColumn('id', 'foo_id'); }); } /** * @return void */ public function down() { // データ型の変更後でも，ロールバックできるようにしておく． Schema::table('foos', function (Blueprint $table) { $table->renameColumn('foo_id', 'foo_id'); }); } } マイグレーションを実行すると，指定したテーブルのカラム名が変更される．実行後は，作成したマイグレーションファイルを削除する． $ php artisan migrate ・changeメソッド 指定したカラムのデータ型を変更する． ＊実装例＊ データ型を変更するためだけにマイグレーションファイルを作成する． $ php artisan make:migration change_column_data_type --table=foos テーブルのカラムのデータ型を定義し，changeメソッドをコールする．変更後でも，ロールバックできるように，downメソッドも定義しておく． integer('bar')->change(); }); } /** * @return void */ public function down() { // データ型の変更後でも，ロールバックできるようにしておく． Schema::table('foos', function (Blueprint $table) { $table->string('bar')->change(); }); } } マイグレーションを実行すると，指定したテーブルのカラムのデータ型が変更される．実行後は，作成したマイグレーションファイルを削除する． $ php artisan migrate ・dropColumnメソッド 指定したカラムを削除する． ＊実装例＊ カラムを削除するためだけにマイグレーションファイルを作成する． $ php artisan make:migration drop_column --table=foos 削除するカラムをdropColumnメソッドで指定する．変更後でも，ロールバックできるように，downメソッドも定義しておく． dropColumn('foo_name'); }); } /** * @return void */ public function down() { Schema::table('foos', function (Blueprint $table) { $table->string('foo_name'); }); } } マイグレーションを実行すると，指定したテーブルのカラムが追加される．実行後は，作成したマイグレーションファイルを削除する． $ php artisan migrate よく使うカラムタイプ ・bigIncrementsメソッド AutoIncrementのINT型カラムを作成する． ＊実装例＊ Schema::create(\"foos\", function (Blueprint $table) { // ～ 省略 ～ $table->bigIncrements(\"foo_id\"); // ～ 省略 ～ }); ・stringメソッド VARCHAR型カラムを作成する． ＊実装例＊ Schema::create(\"foos\", function (Blueprint $table) { // ～ 省略 ～ $table->string(\"name\"); // ～ 省略 ～ }); ・timestampメソッド TIMESTAMP型カラムを作成する． ＊実装例＊ Schema::create(\"foos\", function (Blueprint $table) { // ～ 省略 ～ $table->timestamp(\"created_at\"); // ～ 省略 ～ }); 13. Notification artisanコマンドによる操作 通知内容 ・Notification 通知内容を定義する．viaメソッドで受信チャンネルを定義する．この時，Laravelが標準で用意しているチャンネル（Mail，SMS，Slackチャンネル，Databaseチャンネル）以外に送信したい場合，Channelクラスを定義する必要がある．複数の値を設定した場合は，それぞれに通信が送信される．toMailメソッド，toSmsメソッド，toSlackメソッド，toArrayメソッド，を使用して，Laravelの標準のチャンネルに渡す通知内容を定義できる． ＊実装例＊ ・Eメール通知内容の定義 MailMessageクラスのメソッドを使用して，Eメール通知の内容を生成する．markdownメソッドを使用することで，マークダウン形式で定義できる． 参考： https://readouble.com/laravel/8.x/ja/notifications.html#writing-the-message https://laravel.com/api/8.x/Illuminate/Notifications/Messages/MailMessage.html#method_markdown prefers_sms ? [AwsSnsChannel::class] : [EmailChannel::class], // SMSでない場合は，Eメール通知とします． 'database' ]; } /** * @param $notifiable * @return MailMessage */ public function toMail($notifiable) { // Emailのメッセージ内容を返却します． return (new MailMessage())->subject(\"コードを送信いたしました．\") ->markdown(\"template.mail\", [ \"tfa_token\" => $notifiable->tfaToken() ]); } } @component(\"mail::message\") 認証コード『{ $tfa_token }}』を入力して下さい． +++++++++++++++++++++++++++++++++++++ 本アドレスは送信専用です．ご返信頂いてもお答えできませんので、ご了承ください． @endcomponent ・SMS通知内容の定義 参考：https://readouble.com/laravel/8.x/ja/notifications.html#formatting-sms-notifications prefers_sms ? [AwsSnsChannel::class] : [EmailChannel::class], // SMSの場合は，AWS-SNSを使用します． 'database' ]; } /** * @param $notifiable * @return string */ public function toSms($notifiable) { // SMSのメッセージ内容を返却します． return view(\"template.sms\", [ \"subject\" => \"コードを送信いたしました．\", \"tfa_token\" => $notifiable->tfaToken() ]); } } ・Slack通知内容の定義 参考：https://readouble.com/laravel/8.x/ja/notifications.html#formatting-slack-notifications ・DB通知内容の定義 配列でDBに保存する内容を定義する． 参考：https://readouble.com/laravel/7.x/ja/notifications.html#database-notifications prefers_sms ? [AwsSnsChannel::class] : [EmailChannel::class], 'database' // DB受信チャンネル ]; } /** * @param $notifiable * @return array */ public function toArray($notifiable) { // notificationsテーブルのdataカラムに，JSONで保存されます． return [ \"tfa_token\" => $notifiable->tfaToken(), ]; } } 受信チャンネル（通知方法） ・Channel Laravelが標準で用意しているチャンネル以外に送信したい場合に，独自の受信チャンネルを定義する．これは，Notificationクラスのviaメソッドで使用される． ＊実装例＊ AWS SNSを受信チャンネルとする．AWSから配布されているパッケージが必要である． $ composer require aws/aws-sdk-php-laravel awsSnsClient = $awsSnsClient; } /** * @param $notifiable * @param Notification $notification */ public function send($notifiable, Notification $notification) { try { $message = $notification->toSms($notifiable); // AWS SNSにメッセージを送信します． $this->awsSnsClient->publish([ \"Message\" => $message, \"PhoneNumber\" => $this->toE164nizeInJapan( $notifiable->phoneNumber() ), ]); } catch (AwsException $e) { Log::error(sprintf( \"%s : %s at %s line %s\", get_class($e), $e->getMessage(), $e->getFile(), $e->getLine()) ); throw new AwsException($e->getMessage()); } } /** * @param string * @return string */ private function toE164nizeInJapan(string $phoneNumeber): string { // E.164形式の日本電話番号を返却します． return \"+81\" . substr($phoneNumeber, 1); } } 通知対象モデル ・Notifiableトレイトのnotifyメソッド 通知対象となるモデルを定義する．Notifiableトレイトを継承する．これにより，notifyメソッドを使用できるようになる． 参考：https://laravel.com/api/8.x/Illuminate/Notifications/Notifiable.html 通知対象のクラスからnotifyメソッドをコールし，任意のNotificationクラスを渡す．これにより，通知処理が実行される． 参考：https://laravel.com/api/8.x/Illuminate/Notifications/RoutesNotifications.html#method_notify notify(new FooNotification()); ・Notificationファサード 通知対象となるモデルを定義する．Notifiableトレイトを継承する． Notificationファサードに通知対象のモデルと通知クラスを渡す． ・オンデマンド通知 オンデマンド通知を使用すると，通知対象となるモデルがNotificableトレイトに依存せずに通知を実行できる． 参考： https://laracasts.com/discuss/channels/laravel/notifications-without-eloquent-user-model https://readouble.com/laravel/8.x/ja/notifications.html#on-demand-notifications email_address) ->route('nexmo', $user->phone_number) ->route('slack', $slackMessage->usl) ->notify(new FooMotification()); 14. Resource artisanコマンドによる操作 ・Resourceの生成 Resourceクラスを自動生成する． $ php artisan make:resource レスポンスデータ作成前のデータ型変換 ・データ型変換の必要性 EloquentモデルをJSONデータとしてレスポンスする時に，一旦，配列データに変換する必要がある． ・単一のEloquentモデルの配列化 単一のEloquentモデルを配列に変換する．ResourceクラスのtoArrayメソッドにて，this変数は自身ではなく，Resourceクラス名につくEloquentモデル名になる．また，this変数からゲッターを経由せずに直接プロパティにアクセスできる．Controllerにて，ResouceクラスにEloquentモデルを渡すようにする．LaravelはレスポンスのJSONデータを作成するために，まずtoArrayメソッドにより配列化し，さらにこれをJSONデータに変換する． ＊実装例＊ Fooクラスからデータを取り出し，配列化する． $this->id, \"name\" => $this->name, ]; } }． ・複数のEloquentモデル（Collection型）の配列化 複数のEloquentモデル（Collection型）を配列に変換する． // ここに実装例 15. Routing artisanコマンドによる操作 ・ルーティング一覧 # ルーティングを一覧で表示 $ php artisan route:list ・Cache削除 # ルーティングのCacheを削除 $ php artisan route:clear # 全てのCacheを削除 $ php artisan optimize:clear api.phpファイル ・Middlewareの適用 APIのエンドポイントとして働くルーティング処理を実装する．実装したルーティング処理時には，KernelクラスのmiddlewareGroupsプロパティのapiキーで設定したミドルウェアが実行される．APIのエンドポイントは外部公開する必要があるため，webキーと比較して，セキュリティのためのミドルウェアが設定されていない． [ \"throttle:60,1\", \\Illuminate\\Routing\\Middleware\\SubstituteBindings::class, ], ]; // 〜 省略 〜 } web.phpファイル ・Middlewareの適用 API以外のルーティング処理を実装する．実装したルーティング処理時には，KernelクラスのmiddlewareGroupsプロパティのwebキーで設定したミドルウェアが実行される．API以外のルーティングは外部公開する必要がないため，apiキーと比較して，セキュリティのためのミドルウェアが多く設定されている．例えば，CSRF対策のためのVerifyCsrfTokenクラスがある． [ \\App\\Http\\Middleware\\EncryptCookies::class, \\Illuminate\\Cookie\\Middleware\\AddQueuedCookiesToResponse::class, \\Illuminate\\Session\\Middleware\\StartSession::class, // \\Illuminate\\Session\\Middleware\\AuthenticateSession::class, \\Illuminate\\View\\Middleware\\ShareErrorsFromSession::class, \\App\\Http\\Middleware\\VerifyCsrfToken::class, \\Illuminate\\Routing\\Middleware\\SubstituteBindings::class, ], // 〜 省略 〜 ]; // 〜 省略 〜 } guest.phpファイル ヘルスチェックなど，API認証が不要なルーティング処理を実装する． 暗黙のモデル結合 ・コントローラ使用時 ルーティング時に使用するパラメータ名とコントローラのメソッドの引数型と変数名が同じであり，かつパラメータに数値が割り当てられた場合に，その数値をIDとするEloquentモデルが自動的にインジェクションされる． 参考：https://readouble.com/laravel/8.x/ja/routing.html#implicit-binding ＊実装例＊ ルーティング時に，パスパラメータ名をuserとしておく． かつ，コントローラのメソッドの引数型／変数名をUser／$userとする．または．この時，『/users/1』に対してリクエストが送信されると，ユーザIDが1のユーザがDBから読み出され，コントローラにインジェクションされる． id; // パスパラメータのidに紐づくユーザが自動的に渡されている． } } 16. Seeder artisanコマンドによる操作 ・Seederの生成 Seederクラスを自動生成する． $ php artisan make:seeder ・Seederの実行 Seederを新しく作成した時やSeeder名を変更した時，Composerのdump-autoloadを実行する必要がある． $ composer dump-autoload # 特定のSeederを実行 $ php artisan db:seed --class= # DatabaseSeederを指定して，全てのSeederを実行 $ php artisan db:seed --class= 初期リアルデータの定義 ・DBファサードによる定義 insert([ \"product_name\" => \"シャープペンシル\", \"price\" => 300, \"product_type\" => 1, \"created_by\" => ExecutorConstant::ARTISAN_COMMAND, \"updated_by\" => ExecutorConstant::ARTISAN_COMMAND, \"created_at\" => NOW(), \"updated_at\" => NOW(), \"deleted_at\" => NULL ], [ \"product_name\" => \"ノート\", \"price\" => 200, \"product_type\" => 2, \"created_by\" => ExecutorConstant::ARTISAN_COMMAND, \"updated_by\" => ExecutorConstant::ARTISAN_COMMAND, \"created_at\" => NOW(), \"updated_at\" => NOW(), \"deleted_at\" => NULL ], [ \"product_name\" => \"消しゴム\", \"price\" => 100, \"product_type\" => 3, \"created_by\" => ExecutorConstant::ARTISAN_COMMAND, \"updated_by\" => ExecutorConstant::ARTISAN_COMMAND, \"created_at\" => NOW(), \"updated_at\" => NOW(), \"deleted_at\" => NULL ], // ～ 省略 ～ ]); } } 実行者名は，定数として管理しておくとよい． ・CSVファイルによる定義 // ここに実装例 Seederの実行 DatabaseSeederにて，全てのSeederをまとめて実行する． call([ // ダミーデータ ]); } // ステージング環境用の初期データ if (App::environment(\"staging\")) { $this->call([ // リアルデータ ProductsSeeder::class ]); } // 本番環境用の初期データ if (App::environment(\"production\")) { $this->call([ // リアルデータ ProductsSeeder::class ]); } } } 17. ServiceProvider artisanコマンドによる操作 ・クラスの自動生成 $ php artisan make:provider ServiceProvider ・ServiceProviderの用途 用途の種類 説明 AppServiceProvider ・ServiceContainerへのクラスのバインド（登録）・ServiceContainerからのインスタンスのリゾルブ（生成） MacroServiceProvider ServiceContainerへのメソッドのバインド（登録） RouteServiceProvider（app.php，web.phpも使用） ルーティングとコントローラの対応関係の定義 EventServiceProvider EventListenerとEventhandler関数の対応関係の定義 ・ServiceProviderのコール クラスの名前空間を，config/app.phpファイルのproviders配列に登録すると，アプリケーションの起動時にServiceProviderをコールできるため，ServiceContainerへのクラスのバインドが自動的に完了する． ＊実装例＊ [ // 複数のServiceProviderが実装されている App\\Providers\\ComposerServiceProvider::class, ], ServiceContainer ・ServiceContainer，バインド，リゾルブとは ServiceContainer，バインド，リゾルブについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_object_orientation_class.html AppServiceProvider ・単一のクラスをバインド／リゾルブ AppSeriveProviderにて，ServiceContainerにクラスをバインドすることによって，ServiceContainerがインスタンスをリゾルブできるようになる．これにより，メソッドの引数でクラスを指定しさえすれば，そのクラスのインスタンスが渡されるため，自動的に依存オブジェクト注入が実行されたことになる．Laravelでは，クラスはServiceContainerに自動的にバインドされており，引数でクラスを指定するだけでインスタンスが生成されるため，以下の実装を実行する必要はない．ただし，混合型の場合は引数の型を指定できないため，リゾルブは実行できない． 参考：https://readouble.com/laravel/8.x/ja/container.html#automatic-injection ＊実装例＊ バインドする．なお，Laravelでは不要である． app->bind(Foo::class, function ($app) { return new Foo(new Bar, new Baz); }); } } 引数の型を元に，クラスのインスタンスがリゾルブされる． bar; $foo->baz; } } 引数の型を指定しない場合は，手動で渡す必要がある． bar; $foo->baz; } } $foo = new Foo(); $qux = new Qux($foo); // 手動で渡す 混合型の場合は，引数の型を指定できないため，リゾルブを実行できない． bar; $mixed->baz; } } $foo1 = new Foo1(); $foo2 = new Foo2(); $foo3 = new Foo3(); $qux = new Qux($foo1); ・複数のクラスをバインド／リゾルブ メソッドの引数でクラスを指定しさえすれば，そのクラスのインスタンスが渡されるため，自動的に依存オブジェクト注入が実行されたことになる． ＊実装例＊ registerFoo(); $this->registerBar(); $this->registerBaz(); } /** * 一つ目のクラスをバインド */ private function registerFoo() { $this->app->bind(Foo::class, function ($app) { return new Foo(); }); } /** * 二つ目のクラスをバインド */ private function registerBar() { $this->app->bind(Bar::class, function ($app) { return new Bar(); }); } /** * 三つ目のクラスをバインド */ private function registerBaz() { $this->app->bind(Baz::class, function ($app) { return new Baz(); }); } } ・インターフェースをバインドし，実装クラスをリゾルブ Laravelにおいてはクラスが自動的にバインドされ，これのインスタンスがリゾルブされる，しかし，バインドされたクラスとは別のクラスのインスタンスをリゾルブしたい場合は，ServiceProviderにそれを定義すれば，自動的なバインドを上書きできる．これを利用して，インターフェースをバインドし，実装クラスをリゾルブできるようにする．この方法は，上位レイヤーが抽象に依存することが必要な場面（例：依存性逆転の原則）で役立つ． ＊実装例＊ app->bind( \"App\\Domain\\Foo\\Repositories\\FooRepositoryInterface\", // インターフェース \"App\\Infrastructure\\Doo\\Repositories\\FooRepository\" // 実装クラス ); } } fooRepository = $fooRepository; } } ・makeメソッド 引数の型でリゾルブを実行する以外に，makeメソッドを使用することも可能である．makeメソッドの引数にクラスの名前空間を渡すことで，インスタンスがリゾルブされる． 参考：https://readouble.com/laravel/8.x/ja/container.html#the-make-method ＊実装例＊ make(Foo::class) ->method(); // Fooクラスをリゾルブ $foo = App::make(Foo::class); $result = $foo->method(); ・registerメソッドとbootメソッドの違い Laravelのライフサイクルにおいて，ServiceContainerへのクラスのバインドの時には，まずServiceProviderのregisterメソッドが実行され，その後にbootメソッドが実行される．そのため，ServiceProviderが他のServiceProviderをコールするような処理を実装したいとき，これはbootメソッドに実装することが適している． MigrationMacroServiceProvider 複数のテーブルに共通のカラムを構築するマイグレーション処理を提供する． string(\"created_by\") ->comment(\"レコードの作成者\") ->nullable(); $this->string(\"updated_by\") ->comment(\"レコードの最終更新者\") ->nullable(); $this->timestamp(\"created_at\") ->comment(\"レコードの作成日\") ->nullable(); $this->timestamp(\"updated_at\") ->comment(\"レコードの最終更新日\") ->nullable(); $this->timestamp(\"deleted_at\") ->comment(\"レコードの削除日\") ->nullable(); }); Blueprint::macro(\"dropSystemColumns\", function () { $this->dropColumn( \"created_by\", \"updated_by\", \"created_at\", \"updated_at\", \"deleted_at\" ); }); } } マイグレーションファイルにて，定義したsystemColumnメソッドをコールする．softDeletesメソッドについては，以降の説明を参照せよ． bigIncrements(\"foo_id\") ->comment(\"ID\"); $table->string(\"name\") ->comment(\"名前\"); // MigrationMacroServiceProviderのメソッドを使用する． $table->systemColumns(); // deleted_atカラムを追加する． $table->softDeletes(); }); } /** * ロールバック * * @return void */ public function down() { Schema::drop(\"foos\"); } } RouteServiceProvider ・全てのルーティングへの処理 ルーティングの設定ファイルをコールする．また，全てのルーティングに適用する処理を定義する． 参考：https://readouble.com/laravel/8.x/ja/routing.html#parameters-global-constraints ＊実装例＊ middleware('api') ->namespace($this->namespace) ->group(base_path('routes/healthcheck.php')); // API Route::prefix('api') ->middleware('api') ->namespace($this->namespace) ->group(base_path('routes/api.php')); } } ・リクエスト数制限 一分間当たりに許容するリクエスト数とその制限名をconfigureRateLimitingメソッドで定義する．さらに，Throttleミドルウェアに制限名を渡し，指定したルートにリクエスト数制限を適用させる，もし制限を超えた場合，configureRateLimitingメソッドによって，429ステータスでレスポンスが返信される． 参考：https://readouble.com/laravel/8.x/ja/routing.html#rate-limiting ＊実装例＊ [ ], 'api' => [ // throttleミドルウェアを適用する． 'throttle:limit_per_minute', \\Illuminate\\Routing\\Middleware\\SubstituteBindings::class, ], ]; /** * @return void */ public function configureRateLimiting() { RateLimiter::for('limit_per_minute', function (Request $request) { // 一分間当たり1000リクエストまでを許可する． return Limit::perMinute(1000); }); } } EventServiceProvider ・EventとListenerの登録 EventとListenerの対応関係を定義する．なお，Eventを発火させてListenerを実行する方法は，Eventコンポーネントを参照せよ． リスナー] * * @var array */ protected $listen = [ // Eloquentモデル更新イベント UpdatedModelEvent::class => [ UpdatedModelListener::class, ], ]; /** * @return void */ public function boot() { } } セキュリティ ・CSRF対策 セッション開始時にCSRFトークンが生成される．Bladeを使用してサーバ側のCSRFトークンを取り出し，inputタグのhidden属性にCSRFトークンを割り当て送信する． 参考：https://readouble.com/laravel/8.x/ja/csrf.html @csrf ... Bladeを使用しない場合，セッション開始時のレスポンスのSet-CookieにCSRFトークンが割り当てられるため，これを取り出してX-CSRF-TOKENヘッダーやX-XSRF-TOKENヘッダーに割り当てるようにする．リクエストのたびに異なるCSRFトークンがレスポンスされ，これを次のリクエストで使用する必要がある． 参考： https://readouble.com/laravel/8.x/ja/csrf.html#csrf-x-csrf-token https://readouble.com/laravel/8.x/ja/csrf.html#csrf-x-xsrf-token https://stackoverflow.com/questions/42408177/what-is-the-difference-between-x-xsrf-token-and-x-csrf-token ちなみに，PostmanなどのHTTPクライアントツールをフロントエンドの代わりに使用する場合は，レスポンスで返信されるCSRFトークを扱えない，そこで，各リクエストで事前にルートパスのエンドポイントをコールし，CSRFトークンをPostmanの環境変数に保存するようなスクリプトを設定しておくと良い． if (pm.request.method == 'GET') { return true; } return pm.sendRequest(\"http://127.0.0.1:8000\", (error, response, {cookies}) => { if (error) { console.error(error); return false; } const xsrfTokenHeader = cookies.one(\"XSRF-TOKEN\"); if (!xsrfTokenHeader) { console.log(\"トークンがありません\"); return false; } // laravelによってエンコードされたトークンをデコードする． const xsrfToken = decodeURIComponent(xsrfTokenHeader['value']); // 環境変数を挿入するために，該当する環境名をCollection全体に適用しておく必要がある． pm.environment.set('XSRF_TOKEN', xsrfToken); console.log(xsrfToken); return true; }); ・XSS対策 ・常時HTTPS化 MySQL ・単一のデータベースの場合 単一のデータベースに接続する場合，DB_HOSTを一つだけ設定する． env(\"DB_CONNECTION\", \"mysql\"), \"connections\" => [ // ～ 省略 ～ \"mysql\" => [ \"driver\" => \"mysql\", \"url\" => env(\"DATABASE_URL\"), \"host\" => env(\"DB_HOST\", \"127.0.0.1\"), \"port\" => env(\"DB_PORT\", 3306), \"database\" => env(\"DB_DATABASE\", \"forge\"), \"username\" => env(\"DB_USERNAME\", \"forge\"), \"password\" => env(\"DB_PASSWORD\", \"\"), \"unix_socket\" => env(\"DB_SOCKET\", \"\"), \"charset\" => \"utf8mb4\", \"collation\" => \"utf8mb4_unicode_ci\", \"prefix\" => \"\", \"prefix_indexes\" => true, \"strict\" => true, \"engine\" => null, \"options\" => extension_loaded(\"pdo_mysql\") ? array_filter([ PDO::MYSQL_ATTR_SSL_CA => env(\"MYSQL_ATTR_SSL_CA\"), ]) : [], ], ], // ～ 省略 ～ ]; ・RDSクラスターの場合 RDSクラスターに接続する場合，書き込み処理をプライマリインスタンスに向け，また読み出し処理をリードレプリカインスタンスに向けることにより，負荷を分散できる．この場合，環境変数に二つのインスタンスのホストを実装する必要がある． 参考：https://readouble.com/laravel/8.x/ja/database.html#contentContainer:~:text=Read%EF%BC%8FWrite%E6%8E%A5%E7%B6%9A DB_HOST_PRIMARY= DB_HOST_READ= なお，stickyキーを有効化しておくとよい．プライマリインスタンスにおけるデータ更新がリードレプリカインスタンスに同期される前に，リードレプリカインスタンスに対して読み出し処理が起こるような場合，これを防げる． env(\"DB_CONNECTION\", \"mysql\"), \"connections\" => [ // ～ 省略 ～ \"mysql\" => [ \"driver\" => \"mysql\", \"url\" => env(\"DATABASE_URL\"), \"read\" => [ \"host\" => [ env(\"DB_HOST_PRIMARY\", \"127.0.0.1\"), ], ], \"write\" => [ \"host\" => [ env(\"DB_HOST_READ\", \"127.0.0.1\"), ], ], # stickyキーは有効化しておいたほうがよい． \"sticky\" => true, \"port\" => env(\"DB_PORT\", 3306), \"database\" => env(\"DB_DATABASE\", \"forge\"), \"username\" => env(\"DB_USERNAME\", \"forge\"), \"password\" => env(\"DB_PASSWORD\", \"\"), \"unix_socket\" => env(\"DB_SOCKET\", \"\"), \"charset\" => \"utf8mb4\", \"collation\" => \"utf8mb4_unicode_ci\", \"prefix\" => \"\", \"prefix_indexes\" => true, \"strict\" => true, \"engine\" => null, \"options\" => extension_loaded(\"pdo_mysql\") ? array_filter([ PDO::MYSQL_ATTR_SSL_CA => env(\"MYSQL_ATTR_SSL_CA\"), ]) : [], ], ], // ～ 省略 ～ ]; 18. Session セッションの操作 ・設定ファイル env('SESSION_DRIVER', 'file'), 'lifetime' => env('SESSION_LIFETIME', 120), 'expire_on_close' => false, 'encrypt' => false, 'files' => storage_path('framework/sessions'), 'connection' => env('SESSION_CONNECTION', null), 'table' => 'sessions', 'store' => env('SESSION_STORE', null), 'lottery' => [2, 100], 'cookie' => env( 'SESSION_COOKIE', Str::slug(env('APP_NAME', 'laravel'), '_') . '_session' ), 'path' => '/', // Set-Cookieヘッダーのdomain属性に値を割り当てる． 'domain' => env('SESSION_DOMAIN', null), // Set-Cookieヘッダーのsecure属性を有効化する． 'secure' => env('SESSION_SECURE_COOKIE', false), // Set-CookieヘッダーのHttpOnly属性を有効化する． 'http_only' => true, // Set-CookieヘッダーのsameSite属性に値を割り当てる．nullの場合，Laxとなる． 'same_site' => null, ]; ・よく使う操作メソッド FormRequestクラスのsessionメソッドはStoreクラスを返却する．このクラスのメソッドを使用して，セッションを操作できる． メソッド名 説明 get セッションのキー名を指定して，一つの値を取得する． all セッションの全ての値を取得する． forget セッションのキー名を指定して，値を取得する．キー名を配列で渡して，複数個を削除することも可能． flush セッションの全ての値を取得する． pull セッションのキー名を指定して，一つの値を取得し，取得後に削除する． has セッションのキー名を指定して，値が存在しているかを検証する．nullはfalseとして判定する． 参考：https://laravel.com/api/8.x/Illuminate/Session/Store.html ＊実装例＊ session()->get(\"foo\"); // allメソッド $data = $request->session()->all(); // forgetメソッド $request->session()->forget(\"foo\"); $request->session()->forget([\"foo\", \"bar\"]); // flush $request->session()->flush(); // pullメソッド $data = $request->session()->pull(\"foo\"); // hasメソッド if ($request->session()->has(\"foo\")) { } } } ・セッションファイルがStoreクラスに至るまで 全てを追うことは難しいので，StartSessionクラスのhandleメソッドが実行されるところから始めるものとする．ここで，handleStatefulRequestメソッドの中のstartSessionメソッドが実行される．これにより，Storeクラスのstartメソッド，loadSessionメソッド，readFromHandlerメソッドが実行され，SessionHandlerInterfaceの実装クラスのreadメソッドが実行される．readメソッドは，storage/framework/sessionsにあるセッションファイルに書き込まれたセッションを読み出し，attributeプロパティに格納する．Sessionクラスのメソッドは，attributeプロパティを使用して，セッションを操作する．最終的に,handleStatefulRequestでは，saveSessionメソッドの中のsaveメソッドが実行され，セッションファイルに新しい値が書き込まれる． 参考： https://laravel.com/api/8.x/Illuminate/Session/Middleware/StartSession.html#method_handle https://laravel.com/api/8.x/Illuminate/Session/Middleware/StartSession.html#method_handleStatefulRequest https://laravel.com/api/8.x/Illuminate/Session/Middleware/StartSession.html#method_startSession https://laravel.com/api/8.x/Illuminate/Session/Store.html#method_start https://laravel.com/api/8.x/Illuminate/Session/Store.html#method_loadSession https://laravel.com/api/8.x/Illuminate/Session/Store.html#method_readFromHandler https://www.php.net/manual/ja/sessionhandlerinterface.read.php https://laravel.com/api/8.x/Illuminate/Session/Middleware/StartSession.html#method_saveSession https://laravel.com/api/8.x/Illuminate/Session/Store.html#method_save https://www.php.net/manual/ja/sessionhandlerinterface.write.php 19. Views arisanによる操作 ・Cacheの削除 # ビューのCacheを削除 $ php artisan view:clear # 全てのCacheを削除 $ php artisan optimize:clear データの出力 ・データの出力 Controllerクラスから返却されたデータは，{{ 変数名 }}で取得できる．` ＊実装例＊ Hello!! {{ $data }} ・バリデーションメッセージの出力 バリデーションでエラーが起こった場合，バリデーションでエラーがあった場合，Handlerクラスのinvalidメソッドがコールされ，MessageBagクラスがViewに渡される．MessageBagクラスは，Blade上でerrors変数に格納されており，各メソッドをコールしてエラーメッセージを出力できる． 参考：https://laravel.com/api/8.x/Illuminate/Support/MessageBag.html ＊実装例＊ MessageBagクラスのallメソッドで，全てのエラーメッセージを出力する． ポスト作成 @if ($errors->any()) @foreach ($errors->all() as $error) {{ $error }} @endforeach @endif @isset ($status) 登録が完了しました． @endisset .errors { /* 何らかのデザイン */ } .complete { /* 何らかのデザイン */ } 要素の共通化 ・@include（サブビュー） 読み込んだファイル全体を出力する．読み込むファイルに対して，変数を渡すこともできる．@extentdsとの使い分けとして，親子関係のないテンプレートの間で使用するのがよい．両者は，PHPでいうextends（クラスチェーン）とrequire（単なる読み込み）の関係に近い． ＊実装例＊ @include(\"shared.errors\") 要素の継承 ・@yield，@extends，@section，@endsection 子テンプレートのレンダリング時に，子テンプレートで新しく定義したHTMLの要素を，親テンプレートの指定した場所に出力する．親テンプレートにて，@yield(\"foo\")を定義する． ＊実装例＊ アプリケーション タイトル @yield(\"content\") これを子テンプレートで@extendsで継承すると，レンダリング時に，子テンプレートの@section(\"foo\")-@endsectionで定義した要素が，親テンプレートの@yieid()部分に出力される． ＊実装例＊ @extends(\"layouts.parent\") @section(\"content\") 子テンプレートのレンダリング時に，yieldに出力される要素 @endsection ちなみに，子テンプレートは，レンダリング時に以下のように出力される． ＊実装例＊ アプリケーション タイトル 子テンプレートのレンダリング時に，yieldに出力される要素 ・@section，@show，@extends，@parent 子テンプレートのレンダリング時に，親テンプレートと子テンプレートそれぞれで新しく定義したHTMLの要素を，親テンプレートの指定した場所に出力する．親テンプレートにて，@section-@showで要素を定義する． ＊実装例＊ アプリケーション タイトル @section(\"sidebar\") 親テンプレートのサイドバーとなる要素 @show 子テンプレートの@sectionにて，@parentを使用する．親テンプレートと子テンプレートそれぞれの要素が出力される． ＊実装例＊ @extends(\"layouts.app\") @section(\"sidebar\") @parent 子テンレプートのサイドバーに追加される要素 @endsection ちなみに，子テンプレートは，レンダリング時に以下のように出力される． ＊実装例＊ アプリケーション タイトル 親テンプレートのサイドバーとなる要素 子テンレプートのサイドバーに追加される要素 ・@stack，@push 子テンプレートのレンダリング時に，CSSとJavaScriptのファイルを動的に出力する場合に使用する．親テンプレートにて，@stack(\"foo\")を定義する．これを継承した子テンプレートのレンダリング時に，@push(\"foo\")-@endpushで定義した要素が，@stack()部分に出力される． ＊実装例＊ @stack(\"scripts\") @push(\"scripts\") @endpush Twigとの互換 ・Bladeで実装した場合 ＊実装例＊ @yield(\"title\") @section(\"sidebar\") 親テンプレートのサイドバーとなる要素 @show @yield(\"content\") @extends(\"layouts.master\") @section(\"title\", \"子テンプレートのタイトルになる要素\") @section(\"sidebar\") @parent 子テンレプートのサイドバーに追加される要素 @endsection @section(\"content\") 子テンプレートのコンテンツになる要素 @endsection ・Twigで実装した場合 ＊実装例＊ {% block title %}{% endblock %} {% block sidebar %} 親テンプレートのサイドバーとなる要素 {% endblock %} {% block content %} {% endblock %} {% extends \"layouts.master\" %} {% block title %} 子テンプレートのタイトルになる要素 {% endblock %} {% block sidebar %} {{ parent() }} 子テンレプートのサイドバーに追加される要素 {% endblock %} {% block content %} 子テンプレートのコンテンツになる要素 {% endblock %} 20. 認証 ガード ・ガードとは ドライバーとプロバイダーを定義する． 参考：https://readouble.com/laravel/8.x/ja/authentication.html#introduction ガードの種類 説明 Webガード セッションIDを用いたForm認証のために使用する． APIガード Bearer認証，APIキー認証，OAuth認証，などのために使用する．それぞれの認証方法に違いについては，以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html ・カスタムガード Laravelが標準で持たないドライバーとプロバイダーをもつガードを定義する． 参考：https://readouble.com/laravel/8.x/ja/authentication.html#adding-custom-guards APIガードの認証で使用するトークンをJWTに変更したい時には，以下のパッケージがおすすめ． 参考：https://github.com/tymondesigns/jwt-auth ドライバー ・ドライバーとは ドライバーの種類 認証の種類 実装クラス 備考 sessionドライバー セッションIDを用いたForm認証 SessionGuardクラス https://laravel.com/api/8.x/Illuminate/Auth/SessionGuard.html tokenドライバー Bearer認証，APIキー認証，OAuth認証 TokenGuardクラス https://laravel.com/api/8.x/Illuminate/Auth/TokenGuard.html ドライバーの種類に応じて，AuthManagerクラスがGuardインターフェースの実装クラスを返却する．auth.phpファイルにて，例えばtokenドライバーを選んだ場合は，TokenGuardクラスが返却される． 参考： https://teratail.com/questions/171582 https://laravel.com/api/8.x/Illuminate/Auth/AuthManager.html https://laravel.com/api/8.x/Illuminate/Contracts/Auth/Guard.html#method_user https://laravel.com/api/8.x/Illuminate/Auth/TokenGuard.html#method_user [ 'web' => [ // セッションドライバー 'driver' => 'session', 'provider' => 'users', ], 'api' => [ // トークンドライー 'driver' => 'token', 'provider' => 'users', 'hash' => false, ], ], ]; ・ルーティングの保護 BeforeMiddlwareで認証済みのユーザかどうかを検証し，もし未認証の場合は，ログインページにリダイレクトさせる．これにより，未認証のユーザがコントローラを実行することを防ぐ． 参考：https://qiita.com/yamotuki/items/b96978f8e379e285ecb6 プロバイダ ・プロバイダとは 認証データをDBから取得するオブジェクトを定義する． 参考：https://readouble.com/laravel/8.x/ja/authentication.html#introduction セッションIDを用いたForm認証 ・sessionドライバー sessionドライバーを選択する． ・全てのユーザが同一権限を持つ場合 SessionGuardクラスのattemptメソッドをコールしてパスワードをハッシュ化し，DBのハッシュ値と照合する．認証が成功すると，認証セッションを開始する．redirectメソッドで，認証後の初期ページにリダイレクトする． 参考：https://readouble.com/laravel/8.x/ja/authentication.html#authenticating-users validated(); if (Auth::attempt($validated)) { // セッションID固定化を防ぐために，認証後にセッションを再作成します． $authenticationRequest->session()->regenerate(); // 認証後ページにリダイレクトします． return redirect(RouteServiceProvider::HOME); } // 未認証ページにリダイレクトします． return redirect(RouteServiceProvider::UNAUTHORIZED); } } 認証後のページはRouteServiceProviderクラスで定義しておく． ・一部のユーザが異なる権限を持つ場合 ユーザごとに認証方法を区別しつつ，同一の認証後ページにリダイレクトさせることができる． 参考：https://blog.capilano-fw.com/?p=8159 ＊実装例＊ 権限の異なるユーザに応じたガード，またガードに関連づけるEloquentモデルをプロバイダを定義しておく． [ 'web' => [ 'driver' => 'session', 'provider' => 'users', ], 'api' => [ 'driver' => 'token', 'provider' => 'users', 'hash' => false, ], // 一般ユーザ 'users' => [ 'driver' => 'session', 'provider' => 'users', ], // 管理者 'administrators' => [ 'driver' => 'session', 'provider' => 'administrators', ], ], // プロバイダ 'providers' => [ // 一般ユーザ 'users' => [ 'driver' => 'eloquent', 'model' => App\\Models\\User::class, ], // 管理者 'administrators' => [ 'driver' => 'eloquent', 'model' => App\\Models\\Administrator::class, ] ], ]; Authファサードのguardメソッドを使用して，ガードに応じた認証を実行する．これにより，同一の認証後ページにリダイレクトした後に，ユーザのEloquentモデルに応じた処理を実行できるようになる． validated(); // guardに応じた認証を行います． if (Auth::guard($authenticationRequest->guard)->attempt($validated)) { // セッションID固定化を防ぐために，認証後にセッションを再作成します． $authenticationRequest->session()->regenerate(); // ユーザ用認証後ページにリダイレクトします． return redirect(RouteServiceProvider::HOME); } // 未認証ページにリダイレクトします． return redirect(RouteServiceProvider::UNAUTHORIZED); } } 認証済みかどうかの判定 ・userメソッド 現在のセッションにおけるユーザが認証済みであれば，ユーザのEloquentモデルを取得する． user(); ・checkメソッド 現在のセッションにおけるユーザが認証済みであれば，trueを返却する． ＊実装例＊ 認証済みのユーザがブラウザを閉じたとしても，セッションが続いている（例：ログアウトしない）限り，認証処理を改めて実行する必要はない．そのために，BeforeMiddlewareを使用して，認証済みのユーザからのリクエストを認証済みページにリダイレクトさせる． guard($guard)->check()) { // ユーザが認証済みの場合は，認証後のページにリダイレクトします． return redirect(RouteServiceProvider::HOME); } } return $next($request); } } 20-02. 認可 ゲート ・ゲートとは Eloquentモデルレベルの認可スコープを定義する．指定したEloquentモデルに紐づく全てのDBレコードにアクセスできなくなる． ポリシー ・ポリシーとは DBレコードレベルの認可スコープを定義する．Eloquentモデルに紐づく特定のレコードにアクセスできなくなる．Policyクラスのメソッドによって，リクエスト中の認証済みユーザが自動的にインジェクションされる．EloquentモデルとPolicyクラスの関連づけはAuthServiceProviderクラスで定義する 参考：https://qiita.com/mpyw/items/8c5413b99b8e299f7002#%E7%AC%AC1%E5%BC%95%E6%95%B0%E3%81%AF%E5%BF%85%E3%81%9A-authenticatable-%E3%81%AB%E3%81%AA%E3%82%8B%E4%BD%86%E3%81%97 id; // 認証中のユーザ } /** * @param User $user * @param Foo $foo * @param int $barId * @return bool */ public function show(User $user, Foo $foo, int $barId): bool { $id = $foo->id; // ルーターまたはコントローラから渡されたインスタンス } /** * @param User $user * @param Foo $foo * @param int $barId * @return bool */ public function update(User $user, Foo $foo, int $barId): bool { // } /** * @param User $user * @param Foo $foo * @param int $barId * @return bool */ public function delete(User $user, Foo $foo, int $barId): bool { // } } FooPolicy::class, ]; /** * @return void */ public function boot() { $this->registerPolicies(); } } ・AuthorizeMiddlewareによる認可 ルーティング時にDBレコードレベルの認可スコープを定義する．AuthorizeMiddlewareのエイリアス名は標準でcanであり，Kernelクラスに定義されている．第一引数にPolicyクラスのメソッド名，第二引数に関連するEloquentモデルのクラスの名前空間またはそのインスタンスを渡す．名前空間を渡す場合は，これをハードコーディングせず，関数で名前空間を取得して文字列と結合するようにする．インスタンスを渡す場合は，暗黙のモデル結合を使用する必要がある．認可に失敗した場合，403ステータスのレスポンスを返信する． 参考：https://readouble.com/laravel/8.x/ja/authorization.html#via-middleware ＊実装例＊ ['auth:web']], function () { Route::group(['prefix' => 'foos'], function () { Route::get('/{id}', [FooController::class, 'showFoo'])->middleware('can:show,'. Foo::class); Route::get('/', [FooController::class, 'indexFoo']); Route::post('/', [FooController::class, 'createFoo']); Route::put('/{id}', [FooController::class, 'updateFoo'])->middleware('can:update,'. Foo::class); Route::delete('/{id}', [FooController::class, 'deleteFoo'])->middleware('can:delete,'. Foo::class); }); }); ・authorizationメソッドによる認可 コントローラ実行時にDBレコードレベルの認可スコープを定義する．基底コントローラを継承したコントローラではauthorizationメソッドをコールでき，現在認証されているユーザのDBアクセスが認可スコープの範囲内かどうかを検証する．第二引数に，ポリシーに紐づくクラス名前空間あるいはそのインスタンスを渡す．認可に失敗した場合にAuthorizationExceptionを投げるため，その後は自前で403ステータスのレスポンスするようにする． 参考： https://readouble.com/laravel/8.x/ja/authorization.html#via-controller-helpers https://readouble.com/laravel/8.x/ja/authorization.html#supplying-additional-context ＊実装例＊ ユーザが該当IDのFooモデルを更新する権限があるかどうかを検証する． authorize('update', [$foo->find($id), $request->barId]); // Eloquentモデルが不要な検証であれば名前空間 // $this->authorize('create', Foo::class); $foo->fill($request->all())->save(); } catch (Throwable $e) { // 自前で403ステータスのレスポンスを返信する． return response()->json(['error' => $e->getMessage()], 403); } // 続きの処理 } } ・canメソッドによる認可 コントローラ実行時にDBレコードレベルの認可スコープを定義する．現在認証されているユーザのインスタンスからcanメソッドをコールできる．第二引数として，ポリシーに紐づくクラス名前空間またはそのクラスのインスタンスを渡す．DBアクセスが，そのユーザの認可スコープの範囲内かどうかを検証する．認可に失敗した場合にfalseを返却するため，その後は自前で403ステータスのレスポンスするようにする． 参考： https://readouble.com/laravel/8.x/ja/authorization.html#via-the-user-model https://readouble.com/laravel/8.x/ja/authorization.html#supplying-additional-context ＊実装例＊ ユーザがFooモデルを作成する権限があるかどうかを検証する． user()->can('update', [$foo->find($id), $request->barId])) { // 自前で403ステータスのレスポンスを返信する． return response()->json(['error' => '認可エラー'], 403); } // Eloquentモデルが不要な検証であれば名前空間 // if (!auth()->user()->can('update', Foo::class) {} $foo->fill($request->all())->save(); } } 20-03. Passportパッケージ Passportパッケージとは Ouath認証を実装できる．OAuth認証については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html 導入方法 ・インストール composerでインストールする必要がある． 参考：https://readouble.com/laravel/8.x/ja/passport.html $ composer require laravel/passport ・OAuth認証のトークン管理テーブルを生成 事前に，Passportの管理テーブルを生成する必要があるため，マイグレーションを実行する． $ php artisan migrate Migrating: 2014_10_12_000000_create_users_table Migrated: 2014_10_12_000000_create_users_table (0.02 seconds) Migrating: 2014_10_12_100000_create_password_resets_table Migrated: 2014_10_12_100000_create_password_resets_table (0 seconds) Migrating: 2016_06_01_000001_create_oauth_auth_codes_table Migrated: 2016_06_01_000001_create_oauth_auth_codes_table (0 seconds) Migrating: 2016_06_01_000002_create_oauth_access_tokens_table Migrated: 2016_06_01_000002_create_oauth_access_tokens_table (0 seconds) Migrating: 2016_06_01_000003_create_oauth_refresh_tokens_table Migrated: 2016_06_01_000003_create_oauth_refresh_tokens_table (0 seconds) Migrating: 2016_06_01_000004_create_oauth_clients_table Migrated: 2016_06_01_000004_create_oauth_clients_table (0 seconds) Migrating: 2016_06_01_000005_create_oauth_personal_access_clients_table Migrated: 2016_06_01_000005_create_oauth_personal_access_clients_table マイグレーション後，以下のテーブルが作成される． テーブル名 説明 oauth_access_tokens 全てのアクセストークンを管理する． oauth_auth_codes Authorization Code Grantタイプの情報を管理する． oauth_clients Passportで使用している付与タイプを管理する． oauth_personal_access_clients Personal Access Tokenタイプの情報を管理する． oauth_refresh_tokens リフレッシュトークンを管理する．アクセストークンの有効期限が切れた時に，再生成をリクエストするために使用する．参考：https://auth0.com/blog/jp-refresh-tokens-what-are-they-and-when-to-use-them/ ・トークンを生成 コマンド実行により，/storage/oauthキー，Personal Access Client，Password Grant Clientを生成する． $ php artisan passport:install Personal access client created successfully. Client ID: 3 Client secret: xxxxxxxxxxxx Password grant client created successfully. Client ID: 4 Client secret: xxxxxxxxxxxx ただし，生成コマンドを個別に実行してもよい． # 暗号キーを生成 $ php artisan passport:keys # クライアントを生成 ## Persinal Access Tokenの場合 $ php artisan passport:client --personal ## Password Grant Tokenの場合 $ php artisan passport:client --password 実装可能なOAuth認証の種類 ・OAuth認証 OAuth認証に関して，以下のトークン付与タイプを実装できる． 付与タイプ 説明 Authorization Code Grant 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html Client Credentials Grant 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html Implicit Grant 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html Password Grant 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html ・その他 認証方法 説明 Personal Access Token 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html Password Grant ・バックエンド側の実装 guardsキーにて，認証方式を設定する．ここでは，apiを設定する．認証方法については，認証と認可のノートを参照せよ． return [ // ～ 省略 ～ \"defaults\" => [ \"guard\" => \"api\", \"passwords\" => \"users\", ], // ～ 省略 ～ ]; OAuth認証（認証フェーズ＋認可フェーズ）を行うために，auth.phpファイルで，driverキーにpassportドライバを設定する．また，providerキーで，usersを設定する． ＊実装例＊ return [ // ～ 省略 ～ \"guards\" => [ \"web\" => [ \"driver\" => \"session\", \"provider\" => \"users\", ], \"api\" => [ \"driver\" => \"passport\", \"provider\" => \"users\", \"hash\" => false, ], ], // ～ 省略 ～ ]; auth.phpファイルにて，driverキーにeloquentドライバを設定する．また，modelキーで認証情報テーブルに対応するEloquentのEloquentモデルを設定する．ここでは，Userクラスを設定する．Laravelでは，Eloquentモデルに対応するテーブル名はクラス名の複数形になるため，usersテーブルに認証情報が格納されることになる．もしDBファサードのクエリビルダを使用したい場合は，databaseドライバを指定する． return [ // ～ 省略 ～ \"providers\" => [ \"users\" => [ \"driver\" => \"eloquent\", // Eloquentモデルは自由に指定できる． \"model\" => App\\Models\\User::class, ], // \"users\" => [ // \"driver\" => \"database\", // \"table\" => \"users\", // ], ], // ～ 省略 ～ ]; Userへのルーティング時に，middlewareメソッドによる認証ガードを行う．これにより，OAuth認証に成功したユーザのみがルーティングを行えるようになる． ＊実装例＊ Route::get(\"user\", \"UserController@index\")->middleware(\"auth:api\"); 認証ガードを行ったEloquentモデルに対して，HasAPIToken，NotifiableのTraitをコールするようにする． ＊実装例＊ Passportのroutesメソッドをコールするようにする．これにより，Passportの認証フェーズに関わる全てのルーティング（/oauth/xxx）が有効になる．また，アクセストークンを発行できるよになる． ＊実装例＊ registerPolicies(); Passport::routes(); } } 暗号キーとユーザを作成する． $ php artisan passport:keys $ php artisan passport:client --password ・クライアントアプリ側の実装 『認証』のために，アクセストークンのリクエストを送信する．ユーザ側のアプリケーションは，/oauth/authorizeへリクエストを送信する必要がある．ここでは，リクエストGuzzleパッケージを使用して，リクエストを送信するものとする． ＊実装例＊ post(\"http://your-app.com/oauth/token\", [ \"form_params\" => [ \"grant_type\" => \"password\", \"client_id\" => \"client-id\", \"client_secret\" => \"client-secret\", \"username\" => \"taylor@laravel.com\", \"password\" => \"my-password\", \"scope\" => \"\", ], ]); アクセストークンを含むJSON型データを受信する． ＊実装例＊ { \"token_type\":\"Bearer\", \"expires_in\":31536000, \"access_token\":\"xxxxx\" } ヘッダーにアクセストークンを含めて，認証ガードの設定されたバックエンド側のルーティングに対して，リクエストを送信する．レスポンスのメッセージボディからデータを取得する． ＊実装例＊ request(\"GET\", \"/api/user\", [ \"headers\" => [ \"Accept\" => \"application/json\", \"Authorization\" => \"Bearer xxxxx\", ] ]); return (string)$response->getBody(); ・APIガード用のテーブル ＊実装例＊ bigIncrements(\"user_id\")->comment(\"ユーザID\"); $table->string(\"name\")->comment(\"ユーザ名\"); $table->string(\"api_token\")->unique()->comment(\"APIトークン\"); // MigrationMacroServiceProviderのメソッドを使用する． $table->systemColumns(); // deleted_atカラムを追加する． $table->softDeletes(); }); } /** * @return void */ public function down() { Schema::drop(\"users\"); } } Personal Access Token ・バックエンド側の実装 暗号キーとユーザを作成する． $ php artisan passport:keys $ php artisan passport:client --personal 作成したユーザに，クライアントIDを付与する． /** * 全認証／認可の登録 * * @return void */ public function boot() { $this->registerPolicies(); Passport::routes(); Passport::personalAccessClientId(\"client-id\"); } ユーザからのリクエスト時，クライアントIDを元に『認証』を行い，アクセストークンをレスポンスする． createToken(\"Token Name\")->accessToken; // スコープ付きのトークンを作成する $token = $user->createToken(\"My Token\", [\"place-orders\"])->accessToken; 20-04. Sanctumパッケージ Sanctumパッケージとは APIキー認証とセッションIDを用いたForm認証機能の認証処理のみを提供する．ルーティングとDBアクセスに関する処理は提供しない． 参考：https://readouble.com/laravel/8.x/ja/sanctum.html APIキー認証とセッションIDを用いたForm認証については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html 導入方法 ・インストール $ composer require laravel/sanctum APIトークン認証 フロントエンド（外部のアプリケーションを含む）は任意とし，APIのみを実装する場合に，使用が適している． 参考： https://readouble.com/laravel/8.x/ja/sanctum.html#api-token-authentication https://stackoverflow.com/questions/65550823/laravel-sanctum-api-token-security https://laracasts.com/discuss/channels/laravel/why-is-it-bad-to-use-sanctum-api-tokens-to-authenticate-your-own-first-party-spa SPA認証 フロントエンドにファーストパーティのSPA（自社のSPA）を使用し，バックエンドのAPIを実装する場合に，使用が適している． 参考： https://readouble.com/laravel/8.x/ja/sanctum.html#spa-authentication https://stackoverflow.com/questions/65550823/laravel-sanctum-api-token-security https://laracasts.com/discuss/channels/laravel/why-is-it-bad-to-use-sanctum-api-tokens-to-authenticate-your-own-first-party-spa 20-05. Fortifyパッケージ Fortifyパッケージとは Laravelが持つ全ての認証機能のバックエンド処理を提供する． 参考： https://readouble.com/laravel/8.x/ja/fortify.html https://readouble.com/laravel/8.x/ja/fortify.html#laravel-fortify-and-laravel-sanctum 20-06. Breezeパッケージ Breezeパッケージとは Laravelが持つ全ての認証機能のバックエンド（認証＋ルーティング＋DBアクセス）処理と，これに対応するフロントエンド処理を提供する． 参考： https://readouble.com/laravel/8.x/ja/starter-kits.html#laravel-breeze https://readouble.com/laravel/8.x/ja/fortify.html#laravel-fortify-and-laravel-sanctum 導入方法 参考：https://github.com/laravel/breeze ・インストール パッケージをインストールする． $ composer require laravel/breeze:^1.0 --dev ・認証処理ファイルの自動生成 認証処理に関連するクラスを自動生成できる．Bladeに組み合わせるJavaScriptを選べる． $ php artisan breeze:install 20-07. UIパッケージ（Laravel 7系以前） UIパッケージとは Laravelが持つ全ての認証機能のバックエンド（認証＋ルーティング＋DBアクセス）処理と，これに対応するフロントエンド処理を提供する． 参考：https://readouble.com/laravel/7.x/ja/authentication.html 導入方法 ・インストール パッケージをインストールする． $ composer require laravel/ui:^1.0 --dev ・認証処理ファイルの自動生成 認証処理に関連するクラスを自動生成できる．Bladeに組み合わせるJavaScriptを選べる． # Vuejsを使用する場合． $ php artisan ui vue --auth # Reactを使用する場合 $ php artisan ui react --auth # Bootstrapを使用する場合． $ php artisan ui bootstrap --auth 21. Laravel Mixパッケージ Laravel Mixパッケージとは WebpackをLaravelを介して操作できるパッケージのこと．Breezeパッケージにも同梱されている． 参考：https://readouble.com/laravel/8.x/ja/mix.html Webpackを操作するコマンド ・アセットの初期コンパイル アセットのコンパイルを実行する． $ npm run dev ・アセットの自動再コンパイル アセットのソースコードが変更された時に，これと検知し，自動的に再コンパイルを実行する． $ npm run watch 22. 非公式パッケージ laravel-enum ・ソースコード 参考：https://github.com/BenSampo/laravel-enum ・Enumクラスの定義 BenSampoのEnumクラスを継承し，区分値と判定メソッドを実装する． ＊実装例＊ is(self::CALL_ROLE); } /** * 開発職の区分値をもつかを判定します． */ public function isDevelopmentRole() { return $this->is(self::DEVELOPMENT_ROLE); } /** * 経理職の区分値をもつかどうかを判定します． */ public function isFinanceRole() { return $this->is(self::FINANCE_ROLE); } /** * 企画職の区分値をもつかどうかを判定します． */ public function isPlanRole() { return $this->is(self::PLAN_ROLE); } /** * 営業職の区分値をもつかどうかを判定します． */ public function isSalesRole() { return $this->is(self::SALES_ROLE); } } ・Enumクラスの使い方 ＊実装例＊ データベースから区分値をSELECTした後，これを元にEnumクラスを作成する． roleType = new RoleType($fetched[\"role_type\"]); // 以下の方法でもよい． // $staff->roleType = RoleType::fromValue($fetched[\"role_type\"]); // StaffがいずれのRoleTypeをもつか $staff->roleType->isDevelopmentRole(); // true $staff->roleType->isSalesRole(); // false ＊実装例＊ リクエストメッセージからデータを取り出した後，これを元にEnumクラスを作成する． laravel-ide-helper ・laravel-ide-helperとは PHPStromでLaravelを開発する場合に，拡張機能を提供する． 参考：https://github.com/barryvdh/laravel-ide-helper#phpstorm-meta-for-container-instances ・Facade $ php artisan ide-helper:generate ・アノテーション生成 LaravelのEloquentモデルで，アノテーションを自動生成する． $ php artisan ide-helper:models ・予測表示 Laravelのメソッドを予測表示するため，phpstorm.meta.phpファイルを生成する． $ php artisan ide-helper:meta "},"public/backend_php_testing.html":{"url":"public/backend_php_testing.html","title":"▶ ︎テスト","keywords":"","body":"テスト はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コードベースのテスト テスト手順 ソースコードを整形する． ソースコードの静的解析を行う． ユニットテストと機能テストを行う． 整形ツール PhpStorm，PHP-CS-Fixer 静的解析ツール PhpStorm，PHPStan，Larastan ユニットテストツール，機能テストツール PHPUnit 02. テスト仕様書ベースのテスト テスト手順 テスト仕様書に基づく，ユニットテスト，Integrationテスト，User Acceptanceテストを行う． グラフによるテストの可視化 "},"public/backend_php_testing_based_on_code.html":{"url":"public/backend_php_testing_based_on_code.html","title":"▶ ︎コードベースのテスト","keywords":"","body":"コードベースのテスト はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ユニットテスト／機能テストの要素 構成図 各テストケース（テスト関数）はテストスイート（テストの組）から構成され，全てはテストプランでまとめられる． 02-02. PHPUnitによるユニットテスト／機能テスト コマンド ・オプション無し 全てのテストファイルを対象として，定義されたメソッドを実行する． $ vendor/bin/phpunit PHPUnit 9.5.0 by Sebastian Bergmann and contributors. ... 3 / 3 (100%) Time: 621 ms, Memory: 24.00 MB OK (3 tests, 3 assertions) ・--filter 特定のテストファイルを対象として，定義されたメソッドを実行する． $ vendor/bin/phpunit --filter Foo PHPUnit 9.5.0 by Sebastian Bergmann and contributors. ... 1 / 1 (100%) Time: 207 ms, Memory: 8.00 MB OK (1 tests, 1 assertions) ・--list-tests 実行の対象となるテストファイルを一覧で表示する． $ vendor/bin/phpunit --list-tests PHPUnit 9.5.0 by Sebastian Bergmann and contributors. Available test(s): - Tests\\Unit\\FooTest::testFooMethod - Tests\\Feature\\FooTest::testFooMethod phpunit.xmlファイル ・phpunit.xmlファイルとは PHPUnitの設定を行う．標準の設定では，あらかじめルートディレクトリにtestsディレクトリを配置し，これをUnitsディレクトリまたはFeatureディレクトリに分割しておく．また，Testで終わるphpファイルを作成しておく必要がある． 参考：http://phpunit.readthedocs.io/ja/latest/configuration.html ・testsuitesタグ テストスイートを定義できる．testsuitesタグ内のtestsuitesタグを追加変更すると，検証対象のディレクトリを増やし，また対象のディレクトリ名を変更できる． 参考：https://phpunit.readthedocs.io/ja/latest/configuration.html#appendixes-configuration-testsuites ... ./tests/Unit ./tests/Feature ... ・phpタグ PHPUnitの実行前に設定するini_set関数，define関数，グローバル変数，を定義できる．タグ名との対応関係については，以下を参考にせよ． 参考：https://phpunit.readthedocs.io/ja/latest/configuration.html#php-ini ＊実装例＊ composerの実行時にメモリ不足にならないようにメモリを拡張する．また，テスト用のデータベースに接続できるよう，データベースに関する環境変数を設定する． ... --> ... アサーションメソッド ・アサーションメソッドとは 実際の値と期待値を比較し，結果に応じてSUCCESSまたはFAILURESを返却する．非staticまたはstaticとしてコールできる． 参考：https://phpunit.readthedocs.io/ja/latest/assertions.html $this->assertTrue(); self::assertTrue() ・assertTrue 実際値がtrueかどうかを検証する． $this->assertTrue($response->isOk()); ・assertEquals 「==」を使用して，期待値と実際値の整合性を検証する．データ型を検証できないため，assertSameメソッドを使用する方が良い． $this->assertSame(200, $response->getStatusCode()); ・assertSame 「===」を使用して，期待値と実際値の整合性を検証する．値だけでなく，データ型も検証できる． $this->assertSame(200, $response->getStatusCode()); ユニットテスト ・ユニットテストとは クラスのメソッドが，それ単体で仕様通りに処理が動作するかを検証する方法．検証対象以外の処理はスタブとして定義する．理想としては，アーキテクチャの層ごとにユニットテストを行う必要がある．この時，データアクセスに関わる層のユニットテストのために，本来のDBとは別に，あらかじめテスト用DBを用意した方が良い．テスト用DBをdocker-compose.ymlファイルによって用意する方法については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_virtualization_container_orchestration.html ＊実装例＊ 以降のテスト例では，次のような通知クラスとメッセージクラスが前提にあるとする． httpClient = $httpClient; $this->token = $token; $this->logger = $logger; } public function sendMessage(FooMessage $fooMessage) { if (empty($this->token)) { throw new CouldNotSendMessageException(\"API requests is required.\"); } if (empty($fooMessage->channel_id)) { throw new CouldNotSendMessageException(\"Channnel ID is required.\"); } $json = json_encode($fooMessage->message); try { $this->httpClient->request( \"POST\", \"https://xxxxxxxx\", [ \"headers\" => [ \"Authorization\" => $this->token, \"Content-Length\" => strlen($json), \"Content-Type\" => \"application/json\", ], \"form_params\" => [ \"body\" => $fooMessage->message ] ] ); } catch (ClientException $exception) { $this->logger->error(sprintf( \"ERROR: %s at %s line %s\", $exception->getMessage(), $exception->getFile(), $exception->getLine() )); throw new CouldNotSendMessageException($exception->getMessage()); } catch (\\Exception $exception) { $this->logger->error(sprintf( \"ERROR: %s at %s line %s\", $exception->getMessage(), $exception->getFile(), $exception->getLine() )); throw new CouldNotSendMessageException($exception->getMessage()); } return true; } } channel_id = $channel_id; $this->message = $message; } } ・正常系テスト例 メソッドのアノテーションで，@testを宣言する． ＊実装例＊ リクエストにて，チャンネルとメッセージを送信した時に，レスポンスとしてTRUEが返信されるかを検証する． client = \\Phake::mock(Client::class); $this->logger = \\Phake::mock(LoggerInterface::class); } /** * @test */ public function testSendMessage_FooMessage_ReturnTrue() { $fooNotification = new FooNotification( $this->client, \"xxxxxxx\", $this->logger ); $fooMessage = new FooMessage(\"test\", \"X-CHANNEL\"); $this->assertTrue( $fooNotification->sendMessage($fooMessage) ); } } # Time: x seconds # OK ・異常系テスト例 メソッドのアノテーションで，@testと@expectedExceptionを宣言する． ＊実装例＊ リクエストにて，メッセージのみを送信しようとした時に，例外を発生させられるかを検証する． client = \\Phake::mock(Client::class); $this->logger = \\Phake::mock(LoggerInterface::class); } /** * @test * @expectedException */ public function testSendMessage_EmptyMessage_ExceptionThrown() { $fooNotification = new FooNotification( $this->client, \"xxxxxxx\", $this->logger ); $fooMessage = new FooMessage(\"test\", \"\"); $fooNotification->sendMessage($fooMessage); } } # Time: x seconds # OK 機能テスト ・機能テストとは エンドポイントにリクエストを送信し，レスポンスが正しく返信されるかどうかを検証する方法．スタブを使用することは少ない．メソッドのアノテーションで，@testを宣言する必要がある． ＊実装例＊ request( \"GET\", \"https://xxxxxxxx\", [ \"query\" => [ \"id\" => 1 ] ] ); // レスポンスの実際値と期待値の整合性を検証する． } } ・テストケース例 HTTPメソッド 分類 データの条件 assertメソッドの検証内容例 POST，PUT 正常系 リクエストのボディにて，必須パラメータにデータが割り当てられている場合． ・Controllerが200ステータスのレスポンスを返信すること．・更新されたデータのIDが期待通りであること．・レスポンスされたデータが期待通りであること． リクエストのボディにて，任意パラメータにデータが割り当てられていない場合． ・Controllerが200ステータスのレスポンスを返信すること．・更新されたデータのIDが期待通りであること．・レスポンスされたデータが期待通りであること． リクエストのボディにて，空文字やnullが許可されたパラメータに，データが割り当てられていない場合． ・Controllerが200ステータスのレスポンスを返信すること．・更新されたデータのIDが期待通りであること．・レスポンスされたデータが期待通りであること． 異常系 リクエストのボディにて，必須パラメータにデータが割り当てられていない場合． ・Controllerが400ステータスのレスポンスを返信すること．・レスポンスされたデータが期待通りであること． リクエストのボディにて，空文字やnullが許可されたパラメータに，空文字やnullが割り当てられている場合． ・Controllerが400ステータスのレスポンスを返信すること．・レスポンスされたデータが期待通りであること． リクエストのボディにて，パラメータのデータ型が誤っている場合． ・Controllerが400ステータスのレスポンスを返信すること．・レスポンスされたデータが期待通りであること． GET 正常系 リクエストにて，パラメータにデータが割り当てられている場合． Controllerが200ステータスのレスポンスを返信すること． 異常系 リクエストのボディにて，パラメータに参照禁止のデータが割り当てられている場合（認可の失敗）． Controllerが403ステータスのレスポンスを返信すること． DELETE 正常系 リクエストのボディにて，パラメータにデータが割り当てられている場合． ・Controllerが200ステータスのレスポンスを返信すること．・削除されたデータのIDが期待通りであること．・レスポンスされたデータが期待通りであること． 異常系 リクエストのボディにて，パラメータに削除禁止のデータが割り当てられている場合（認可の失敗）． ・Controllerが400ステータスのレスポンスを返信すること．・レスポンスされたデータが期待通りであること． 認証認可 正常系 リクエストのヘッダーにて，認証されているトークンが割り当てられている場合（認証の成功）． Controllerが200ステータスのレスポンスを返信すること． 異常系 リクエストのヘッダーにて，認証されていないトークンが割り当てられている場合（認証の失敗）． Controllerが401ステータスのレスポンスを返信すること． リクエストのボディにて，パラメータにアクセス禁止のデータが割り当てられている場合（認可の失敗）． Controllerが403ステータスのレスポンスを返信すること． ・正常系GET Controllerが200ステータスのレスポンスを返信することを検証する． ＊実装例＊ request( \"GET\", \"/xxx/yyy/\" ); $response = $client->getResponse(); // 200ステータスが返却されるかを検証する． $this->assertSame(200, $response->getStatusCode()); } } ・正常系POST Controllerが200ステータスのレスポンスを返信すること，更新されたデータのIDが期待通りであること，レスポンスされたデータが期待通りであることを検証する． ＊実装例＊ request( \"POST\", \"/xxx/yyy/\", [ \"id\" => 1, \"message\" => \"Hello World!\" ], [ \"HTTP_X_API_Token\" => \"Bearer xxxxxx\" ] ); $response = $client->getResponse(); // 200ステータスが返却されるかを検証する． $this->assertSame(200, $response->getStatusCode()); // レスポンスデータを抽出する． $actual = json_decode($response->getContent(), true); // 更新されたデータのIDが正しいかを検証する． $this->assertSame(1, $actual[\"id\"]); // レスポンスされたメッセージが正しいかを検証する． $this->assertSame( [ \"データを変更しました．\" ], $actual[\"message\"] ); } } ・異常系POST Controllerが400ステータスのレスポンスを返信すること，レスポンスされたデータが期待通りであること，を検証する． ＊実装例＊ request( \"POST\", \"/xxx/yyy/\", [ \"id\" => 1, \"message\" => \"\" ], [ \"HTTP_X_API_Token\" => \"Bearer xxxxxx\" ] ); $response = $client->getResponse(); // 400ステータスが返却されるかを検証する． $this->assertSame(400, $response->getStatusCode()); // レスポンスデータのエラーを抽出する． $actual = json_decode($response->getContent(), true); // レスポンスされたエラーメッセージが正しいかを検証する． $this->assertSame( [ \"IDは必ず入力してください．\", \"メッセージは必ず入力してください．\" ], $actual[\"errors\"] ); } } テストデータ ・Data Provider テスト対象のメソッドの引数を事前に用意する．メソッドのアノテーションで，@testと@dataProvider データプロバイダ名を宣言する．データプロバイダの返却値として配列を設定し，配列の値の順番で，引数に値を渡すことができる． 参考：https://phpunit.readthedocs.io/ja/latest/writing-tests-for-phpunit.html#writing-tests-for-phpunit-data-providers ＊実装例＊ 前処理と後処理 ・setUpメソッド 前処理として，全てのテスト関数の前にコールされるメソッドである． ＊実装例＊ DIコンテナを事前に生成する． container[\"option\"]; } } ＊実装例＊ 単体テストで検証するクラスが実際の処理の中でインスタンス化される時，依存対象のクラスはすでにインスタンス化されているはずである．そのため，これと同じように依存対象のクラスのモックを事前に生成しておく． hoge = Phake::mock(Hoge::class); } public function testFoo_Xxx_Xxx() { // 実際の処理では，インスタンス化時に，FooクラスはHogeクラスに依存している． $foo = new Foo($this->hoge) // 何らかのテストコード } } ・tearDownメソッド 後処理として，全てのテスト関数の後にコールされるメソッドである．グローバル変数やサービスコンテナにデータを格納する場合，後の検証でもそのデータが誤って使用されてしまわないように，サービスコンテナを破棄するために用いられる． ＊実装例＊ container[\"option\"]; } // 全てのテスト関数の後に実行される． protected function tearDown() { // DIコンテナにnullを格納する． $this->container = null; } } 命名規則 ・テストケース名 Roy Osherove氏の命名規則に従って，『テスト対象のメソッド名』『入力値』『期待される返却値』の三要素でテスト関数を命名する．期待される返却値の命名で『正常系テスト』か『異常系テスト』かと識別する．例えば，正常系であれば『testFoo_Xxx_ReturnXxx』，また異常系であれば『testFoo_Xxx_ExceptionThrown』や『testFoo_Xxx_ErrorThrown』とする．Roy Osherove氏の命名規則については，以下のリンクを参考にせよ． 参考：https://osherove.com/blog/2005/4/3/naming-standards-for-unit-tests.html ・アサーションの比較値 アサーションで値を比較する場合，値を定数として管理した方がよい． 参考：https://osherove.com/blog/2005/4/3/naming-standards-for-unit-tests.html 02-03. Test Double（テストダブル） テストダブルの種類 ・モックツール，スタブツール PHPUnit，Phake，Mockery，JUnit ・モック 上層クラスが下層クラスを正しくコールできるかどうかを検証したい時に，上層クラス以外の部分の処理は不要であり，下層クラスの実体があるかのように見せかける．この時，見せかけの下層クラスとして使用する擬似オブジェクトを『モック』という．スタブとは，用いられるテストが異なるが，どちらも擬似オブジェクトである．スタブについては後述の説明を参考にせよ．モックにおいては，クラスのメソッドとデータが全てダミー実装に置き換えられている．もし下層クラスを正しい回数実行できているかを検証したい場合は，下層クラスのモックを定義し，実体のある上層クラスが下層クラスにパラメータを渡した時のコール回数と指定回数を比較する．なお，用語の定義はテストフレームワークごとにやや異なることに注意する．PHPUnitにおけるモックについては，以下のリンクを参考にせよ． 参考：https://phpunit.readthedocs.io/ja/latest/test-doubles.html#test-doubles-mock-objects ツール名 モックのメソッドの返却値 補足 PHPUnit メソッドは，nullを返却する． 注意点として，final，privateなメソッドはモック化されず，実体をそのまま引き継ぐ．また，staticなメソッドはBadMethodCallExceptionをスローするモックに置き換えられる． JUnit メソッドは，元のオブジェクトのメソッドの返却値の型に基づいて，初期値を返却する（例：bool型ならfalse） ・スタブ クラスのメソッドの処理を検証したい時に，検証対象外のクラスに依存している部分は，実体があるかのように見せかける．この時，見せかけの下層クラスとして使用する擬似オブジェクトを『スタブ』という．モックとは，用いられるテストが異なるが，どちらも擬似オブジェクトである．モックと同様にスタブにおいても，クラスのメソッドとデータが全てダミー実装に置き換えられている．スタブには，正しい処理を実行するように引数と返却値を持つメソッドを定義し，その他の実体のある処理が正しく実行されるかを検証する．これらにより，検証対象の処理のみが実体であっても，一連の処理を実行できる．なお，用語の定義はテストフレームワークごとにやや異なることに注意する．PHPUnitにおけるスタブについては，以下のリンクを参考にせよ． 参考：https://phpunit.readthedocs.io/ja/latest/test-doubles.html#test-doubles-stubs PHPUnit ・createMockメソッド クラスの名前空間を元に，モックまたはスタブとして使用する擬似オブジェクトを生成する．以降の処理での用途によって，呼び名が異なることに注意する．ちなみに，PHPUnitの場合，モックのメソッドはnullを返却する． createMock(Foo::class); // null $foo = $mock->find(1) } } ・methodメソッド モックまたはスタブのメソッドに対して，処理の内容を定義する．特定の変数が渡された時に，特定の値を返却させることができる． createMock(Foo::class); // スタブのメソッドに処理内容を定義する． $stub->method(\"find\") ->with(1) ->willReturn([]); // []（空配列） $result = $stub->find(1) } } Phake ・Phakeとは モックとスタブを提供するライブラリ． 参考：https://github.com/mlively/Phake#phake ・mockメソッド クラスの名前空間を元に，モックまたはスタブとして使用する擬似オブジェクトを生成する．以降の処理での用途によって，呼び名が異なることに注意する． ・whenメソッド モックまたはスタブのメソッドに対して，処理の内容を定義する．また，特定の変数が渡された時に，特定の値を返却させることができる． ＊実装例＊ モックのfindメソッドは，1が渡された時に，空配列を返却する． find(1) ->thenReturn([]); ・verifyメソッド 上層オブジェクトが下層オブジェクトをコールできることを確認するために，モックのメソッドがn回実行できたことを検証する． ＊実装例＊ find($fooId) ->thenReturn(new User(1)); // 上層クラスに対して，下層クラスのモックのインジェクションを行う $foo = new Foo($mockFooRepository); // 上層クラスの内部にある下層モックのfindメソッドをコールする $foo->getUser($fooId) // 上層のクラスが，下層モックにパラメータを渡し，メソッドを実行したことを検証する． Phake::verify($mockFooRepository, Phake::times(1))->find($fooId); } } 03. ブラックテスト/ホワイトボックステスト ブラックボックステスト ・ブラックボックステストとは ホワイトボックステストと組み合わせてユニットテストを構成する．実装内容は気にせず，入力に対して，適切な出力が行われているかを検証する．ユニットテストとホワイト/ブラックボックステストの関係性については，以下の書籍を参考にせよ． 参考：https://www.amazon.co.jp/dp/477415377X/ ホワイトボックステスト ・ホワイトボックステストとは ブラックボックステストと組み合わせてユニットテストを構成する．実装内容が適切かを確認しながら，入力に対して，適切な出力が行われているかを検証する．網羅条件がいくつかあり，求められるソフトウェア品質に応じたものを採用する．ユニットテストとホワイト/ブラックボックステストの関係性については，以下の書籍を参考にせよ． 参考：https://www.amazon.co.jp/dp/477415377X/ ＊実装例＊ if (A = 1 && B = 1) { 　return X; } ・C０：Statement Coverage（命令網羅） 全ての命令が実行されるかを検証する． ＊例＊ AとBは，『1』または『0』になり得るとする． 条件 処理実行の有無 A = 1，B = 1 return X が実行されること． ・C１：Decision Coverage（判定条件網羅） 全ての判定が実行されるかを検証する． ＊例＊ AとBは，『1』または『0』になり得るとする． 条件 処理実行の有無 A = 1，B = 1 return X が実行されること． A = 1，B = 0 return X が実行されないこと． ・C２：Condition Coverage（条件網羅） 各条件が，取り得る全ての値で実行されるかを検証する． ＊例＊ AとBは，『1』または『0』になり得るとする． 条件 処理実行の有無 A = 1，B = 0 return X が実行されないこと． A = 0，B = 1 return X が実行されないこと． または，次の組み合わせでもよい． 条件 処理実行の有無 A = 1，B = 1 return X が実行されること． A = 0，B = 0 return X が実行されないこと． ・MCC：Multiple Condition Coverage（複数条件網羅） 各条件が，取り得る全ての値で，かつ全ての組み合わせが実行されるかを検証する．Webシステムでは，一般的に複数条件網羅を採用すれば，最低限のソフトウェア品質を担保できていると言える． ＊例＊ AとBは，『1』または『0』になり得るとする． 条件 処理実行の有無 A = 1，B = 1 return X が実行されること． A = 1，B = 0 return X が実行されないこと． A = 0，B = 1 return X が実行されないこと． A = 0，B = 0 return X が実行されないこと． ホワイトボックステストの指標 ・網羅率 採用した網羅で考えられる全ての条件のうち，テストで検証できている割合のこと． 網羅率はテストスイートやパッケージを単位として解析され，これは言語別に異なる．PHPUnitで網羅率を解析する方法については，以下のリンクを参考にせよ． 参考：https://phpunit.readthedocs.io/ja/latest/code-coverage-analysis.html ・循環的複雑度 テスト対象がどれだけ複雑な実装方法になっているかの程度のこと．おおそよ，分岐網羅の経路数の程度である． 参考：https://jp.mathworks.com/discovery/cyclomatic-complexity.html 循環的複雑度 複雑さの状態 バグ混入率 10以下 非常に良い 25% 30以上 構造的なリスクあり 40% 50以上 テスト不可能 70% 75以上 変更によって誤修正が生じる． 98% 04. PHPStanによる静的解析 コマンド ・オプション無し 全てのファイルを対象として，静的解析を行う． $ vendor/bin/phpstan analyse phpstan.neonファイル ・phpstan.neonファイルとは PHPStanの設定を行う． ・includes includes: - ./vendor/nunomaduro/larastan/extension.neon ・parameters 静的解析の設定を行う． ＊実装例＊ parameters: # 解析対象のディレクトリ paths: - src # 解析の厳格さ（最大レベルは８）．各レベルの解析項目については以下を参考にせよ． # https://phpstan.org/user-guide/rule-levels level: 5 # 発生を無視するエラーメッセージ ignoreErrors: - '#Unsafe usage of new static#' # 解析対象として除外するディレクトリ excludes_analyse: - ./src/Foo/* checkMissingIterableValueType: false inferPrivatePropertyTypeFromConstructor: true "},"public/backend_php_testing_based_on_test_specification.html":{"url":"public/backend_php_testing_based_on_test_specification.html","title":"▶ ︎テスト仕様書ベースのテスト","keywords":"","body":"テスト仕様書ベースのテスト はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. テスト仕様書に基づく結合テスト 結合テストとは 単体テストの次に行うテスト．複数のモジュールを繋げ，モジュール間のインターフェイスが適切に動いているかを検証． 結合テストの方向 ・トップダウンテスト 上層のモジュールから下層のモジュールに向かって，結合テストを行う．下層にはテストダブルのスタブを作成する． ・ボトムアップテスト 下層のモジュールから上層のモジュールに向かって，結合テストを行う．上層にはテストダブルのドライバーを作成する． Scenarioテスト 実際の業務フローを参考にし，ユーザが操作する順にテストを行う． 02. テスト仕様書に基づくシステムテスト システムテスト ・システムテストとは 結合テストの次に行うテスト．システム全体が適切に動いているかを検証する．User Acceptanceテスト，また総合テストともいう． ・テストケース例 以下の操作を対象として検証するとよい． 大分類 中分類 検証対象の操作 機能 正常系 基本操作（登録，参照，更新，削除），画面遷移，状態遷移，セキュリティ，など 異常系 基本操作（登録，参照，更新，削除），など 組み合わせ 同時操作，割り込み操作，排他制御に関わる操作，など 業務シナリオ シナリオに沿ったユーザによる一連の操作 開発者シナリオ シナリオに沿った開発者による一連の操作（手動コマンドなど） 外部システム連携 外部のAPIとの連携処理に関わる操作 非機能 負荷耐性や性能 各種負荷テスト（性能テスト，限界テスト，耐久テスト） 機能テスト 機能要件を満たせているかを検証する．PHPUnitでの機能テストとは意味合いが異なるので注意． 負荷テスト ・負荷テストとは 実際の運用時に，想定したリクエスト数に耐えられるか，を検証する．また，テスト結果から，運用時の監視で参考にするための，安全範囲（青信号），危険範囲（黄色信号），限界値（赤信号），を導く必要がある． 参考：https://www.oracle.com/jp/technical-resources/article/ats-tech/tech/useful-class-8.html ・負荷テストのパラメータ 項目 説明 スレッド数 ユーザ数に相当する． ループ数 ユーザ当たりのリクエスト送信数に相当する． RampUp秒 リクエストを送信する期間に相当する．長くし過ぎすると，全てのリクエスト数を送信するまでに時間がかかるようになるため，負荷が小さくなる． ・性能テスト 一定時間内に，ユーザが一連のリクエスト（例：ログイン，閲覧，登録，ログアウト）を行った時に，システムのスループットとレスポンス時間にどのような変化があるかを検証する．具体的にはテスト時に，アクセス数を段階的に増加させて，その結果をグラフ化する．グラフ結果を元に，想定されるリクエスト数が現在の性能にどの程度の負荷をかけるのかを確認し，また性能の負荷が最大になる値を導く．これらを運用時の監視の参考値にする． ・限界テスト 性能の限界値に達するほどのリクエスト数が送信された時に，障害回避処理（例：アクセスが込み合っている旨のページを表示）が実行されるかを検証する．具体的にはテスト時に，障害回避処理以外の動作（エラー，間違った処理，障害回復後にも復旧できない，システムダウン）が起こらないかを確認する． ・耐久テスト 長時間の大量リクエストが送信された時に，短時間では検出できないどのような問題が存在するかを検証する．具体的にはテスト時に，長時間の大量リクエストを処理させ，問題（例：微量のメモリリークが蓄積してメモリを圧迫，セッション情報が蓄積してメモリやディスクを圧迫，ログが蓄積してディスクを圧迫，ヒープやトランザクションログがCPUやI/O処理を圧迫） 再現テスト ・再現テストとは 障害発生後の措置としてスペックを上げる場合，そのスペックが障害発生時の負荷に耐えられるかを検証する． ・テストケース例 開始からピークまでに，次のようにリクエスト数が増し，障害が起こったとする．その後，データを収集した． 障害発生期間 合計閲覧ページ数(PV数/min) 平均ユーザ数(UA数/min) ユーザ当たり閲覧ページ数(PV数/UA数) 13:00 ~ 13:05（開始） 300 100 3 13:05 ~ 13:10 600 200 3 13:10 ~ 13:15（ピーク） 900 300 3 ランキング URL 割合 1 /aaa/bbb/* 40 % 2 /ccc/ddd/* 30 % 3 /eee/fff/* 20 % 4 /ggg/hhh/* 10 % ＊テスト例＊ ユーザ当たりの閲覧ページ数はループ数に置き換えられるので，ループ数は「3回」になる．障害発生期間の閲覧ページ数はスレッド数に置き換えられるので，スレッド数は「1800個（300 + 600 + 900）」になる．障害発生期間は，Ramp-Upに置き換えられるので，Ramp-Up期間は「900秒（15分間）」 スレッド数（個） ループ数（回） Ramp-Up期間(sec) 1800 3 900 ポストモーテム ・ポストモーテムとは 障害報告書とは異なり，原因特定とシステム改善に重きを置いた報告書のこと．障害報告書は，責任の報告の意味合いが強くなってしまう． ・テンプレート 参考：https://ueokande.github.io/incident-response-docs-ja/after/post_mortem_template/ # ポストモーテム ## タイトル ## 日付 ## 担当者 **※担当者を絶対に責めず，障害は誰のせいでもないという意識を強く持つ．** ## 原因と対応 **※原因特定とシステム改善に重きを置くこと．** ## システム的/収益的な影響範囲 ## 幸運だったこと ## 仕組みの改善策 **※「以後は注意する」ではなく，再発しない仕組み作りになるようにする．** ## 障害発生から対応までのタイムライン ・他社事例 参考：https://ueokande.github.io/incident-response-docs-ja/after/post_mortem_process/#_6 サービス リンク AWS https://aws.amazon.com/jp/message/5467D2/ Heroku https://status.heroku.com/incidents/151 Twilio https://www.twilio.com/blog/2013/07/billing-incident-post-mortem-breakdown-analysis-and-root-cause.html 03. その他のテスト Regressionテスト（回帰テスト） システムを変更した後，他のプログラムに悪影響を与えていないかを検証． 04. グラフによるテストの可視化 バグ管理図 プロジェクトの時，残存テスト数と不良摘出数（バグ発見数）を縦軸にとり，時間を横軸にとることで，バグ管理図を作成する．それぞれの曲線の状態から，プロジェクトの進捗状況を読み取ることができる． 不良摘出実績線（信頼度成長曲線）は，プログラムの品質の状態を表し，S字型でないものはプログラムの品質が良くないことを表す． "},"public/backend_php_debug.html":{"url":"public/backend_php_debug.html","title":"▶ ︎デバッグのコツ","keywords":"","body":"バックエンドのデバッグの豆知識 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. デバッグのTips var_dumpメソッドでデータの中身を確認 ・ 基本形 ブラウザの『デベロッパーツール＞Network＞出力先ページのPreviewタブまたはResponseタブ』で確認できる． ＊実装例＊ ・例外処理との組み合わせ ブラウザのデベロッパーツール＞Network＞出力先ページのPreviewタブで例外エラー画面が表示される．エラー画面の上部で，var_dump($var)の結果を確認できる． ＊実装例＊ var_dumpメソッドの結果が表示されない ・処理の通過地点の特定 処理がvar_dumpメソッドを通過していないことが原因．任意の場所にvar_dump(\"文字列\")を記述し，どこに記述した時に文字列が出力されるかを確認する． ＊実装例＊ 500エラーの位置を特定できない ・エラー箇所の特定 任意の場所にexitメソッドを記述し，どこに記述した時に，500エラーが起こらずに処理が終了する（レスポンス無し）かを確認する． ＊実装例＊ ・文字コードの修正 文字コードが異なっていることが原因．以下を，var_dumpメソッドよりも上流に追加する． 02. Xdebugによるデバッグ 導入方法 1. ローカルサーバへのインストール ローカルサーバで以下のコマンドを実行． $ sudo pecl install xdebug-2.2.7 2. Xdebugの設定 Xdebugのあるローカルサーバから見て，PhpStromビルトインサーバを接続先と見なす． zend_extension=/usr/lib64/php/modules/xdebug.so xdebug.default_enable=1 # リモートデバッグの有効化． xdebug.remote_enable=1 # DBGプロトコル xdebug.remote_handler=dbgp # エディタサーバのプライベートIPアドレス． xdebug.remote_host=10.0.2.2 # エディタサーバの開放ポート． xdebug.remote_port=9001 # 常にデバッグセッションを実行． xdebug.remote_autostart=1 # DBGpハンドラーに渡すIDEキーを設定． xdebug.idekey=PhpStorm 3. ローカルサーバを再起動 $ sudo service httpd restart 4. PhpStormビルトインサーバの設定 デバッグにおける通信の仕組み 1. エディタサーバの構築 エディタはサーバを構築し，ポート9000を開放する． 2. エディタからデバッガーエンジンへのリクエスト デバッガーエンジン（Xdebug）はポート80を開放する．エディタサーバはこれに対して，セッション開始のリクエストをHTTPプロトコルで送信する． 3. デバッガーエンジンからサーバへのリクエスト デバッガーエンジン（Xdebug）はセッションを開始し，エディタサーバのポート9000に対して，レスポンスを送信する． 4. Breakpointの設定 エディタサーバは，デバッガーエンジンに対して，Breakpointを設定するリクエストを送信する． 5. DBGプロトコル：Debuggerプロトコルによる相互通信の確立 DBGプロトコルを使用し，エディタサーバとデバッガーエンジンの間の相互通信を確立する． 6. 相互通信の実行 エディタは，デバッガーエンジンに対してソースコードを送信する．デバッガーエンジンは，Breakpointまでの各変数の中身を解析し，エディタサーバに返信する． "},"public/backend_go_logic.html":{"url":"public/backend_go_logic.html","title":"▶ 文法","keywords":"","body":"Go はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. イントロダクション 特長 ・並列処理が実装可能 個人的にGoで最大の特長．並列処理を簡単に実装できる．並行処理しても結果に影響しなければ，処理を高速化できる．並列処理については，本ノート内の説明を参考にせよ． ・ほどよくシンプル 黒魔術的な関数やライブラリがない一方で，基本的な機能は揃っているため，処理の可読性が高い．そのため，後続者が開発しやすく，実装がスケーリングしやすい． ・型付けの厳格さと型推論 型付けルールが厳しく，定義に必ず型付けが必要である一方で，型推論で型付けの実装を省略できる．そのため，型付けの実装なしに静的型付けのメリットを享受できる．特にバグが許されないような基盤部分に適している． ・高速なコンパイル 他の静的型付け言語のJavaのコンパイルでは，ソースコードを一度中間言語に変換し，その後機械語に翻訳する．しかしGoのコンパイルでは，プログラムを直接機械語に翻訳するため，より高速である． ・メモリの安全性を担保する仕組み メモリアドレスに割り当てられている数値同士を演算する『ポインタ演算』の機能を意図して廃止している．ポインタ演算の具体例として，10番アドレスと20番アドレスの数値を足して，30番アドレスに新しく割り当てる，といった処理を行う．この時，何らかの原因で片方のアドレスが文字列だった場合，30番アドレスに予期しない値（数値＋文字列）が割り当てられることになる．これは，不具合や悪意ある操作に繋がるため，Goではポインタ演算子の機能がない． ・クラスや継承がない 継承はカプセル化を壊すため，これを回避できる『委譲』の方が優れているとされている．そのため，思想としてクラスや継承を廃止している．埋め込みによって，委譲を実現する．埋め込みについては，本ノート内の説明を参考にせよ． ディレクトリ構造 ・$GOPATH パスは好みであるが，$HOME/goとすることが多い．ディレクトリ構造のベストプラクティスは以下を参考にせよ． 参考：https://github.com/golang-standards/project-layout $GOPATH # 例えば，『$HOME/go』とする． ├── bin ├── pkg └── src ├── build # Dockerfileを配置するディレクトリ ├── cmd # main.goファイルや，サブmainパッケージを配置するディレクトリ │ ├── main.go │ └── foo │ └── foo.go │ ├── configs │ └── envrc.template │ ├── docs（ドキュメントを配置する） │ ├── BUG.md │ ├── ROUTING.md │ └── TODO.md │ ├── internal # cmdディレクトリ内でインポートさせないファイルを配置するディレクトリ │ └── pkg │ ├── pkg # cmdディレクトリ内でインポートする独自goパッケージを配置するディレクトリ │ └── public │ └── add.go │ ├── scripts │ └── Makefile │ ├── test │ └── test.go │ └── web（画像，CSS，など） ├── static └── template ・bin ビルドされたアーティファクト（バイナリファイル）を配置するディレクトリ．バイナリファイル名を指定すると，処理を実行できる． ・pkg アーティファクトとは別に生成されるファイルを配置するディレクトリ ・src ソースコードを配置するディレクトリ ファイルの要素 ・package 名前空間として，パッケージ名を定義する．一つのディレクトリ内では，一つのパッケージ名しか宣言できない． package main ・import ビルトインパッケージ，内部パッケージ，事前にインストールされた外部パッケージを読み込む． import \"\" 互いにインポートし合うと，循環参照エラー（mport cycle not allowed）になる．インターフェースと構造体の両方を同じパッケージに置いていると，インターフェースが他からインポートされ，構造体が他をインポートするようになり，起こりやすい． ・func 詳しくは，関数を参考にせよ． func xxx() { } ・文の区切り Goでは文の処理はセミコロンで区切られる．ただし，セミコロンはコンパイル時に補完され，実装時には省略できる． 命名規則 ・ディレクトリ名 小文字一単語またはケバブケースで命名する．ビルド時にシンタックスエラーとなる可能性があるため，可能な限りハイフンを使用しない方が良い． ・パッケージ名 小文字一単語で命名する．ディレクトリ名に小文字一単語が使用されている場合は，これと同じにするとなお良い．また，処理中の変数名と被るとパッケージのインポートに失敗するため，変数名と被らないように，できるだけ省略しない名前の方が良い．ただし，テストファイルに関しては，パッケージ名を『xxxxx_test』としてよい． 参考：https://github.com/golang/go/wiki/CodeReviewComments#package-names ・ファイル名 小文字一単語またはスネークケースで命名する．ファイル名とパッケージ名は合わせる必要はないが，独自ルールを設けても良い．例えばドメイン駆動設計の場合に，ルートエンティティのファイル名とパッケージ名を合わせるように工夫できる． 参考：https://ja.stackoverflow.com/q/41599 参考： ・関数，type，構造体 アッパーキャメルケースまたはローワーキャメルケースで命名する． ・インターフェース名 末尾に『er』をつける． 参考：https://golang.org/doc/effective_go#interface-names ・レシーバ名 構造体名の頭一文字または頭二文字を取って命名する．アプリケーション内で構造体名の頭文字が重複すると，同じレシーバ名の構造体が乱立してしまうため，これを防ぐために二文字を取るとよい．また，修飾語と組み合わせて構成される構造体名の場合，被修飾語の頭二文字を取る．オブジェクト指向で使われる『this』『self』 参考： https://github.com/golang/go/wiki/CodeReviewComments#receiver-names https://yyh-gl.github.io/tech-blog/blog/go-ddd-entity-vo/ ＊例＊ httpClientであれば，修飾語は『http』被修飾語『client』である．そのため，レシーバ名または引数名では『cl』とする．` ・一時的な変数名 英単語の頭一文字，頭二文字，略語，で命名する．これは，実際の処理を強調し，変数を目立たなくするためである．ただし，スコープの大きな変数に省略した名前をつけると，重複する可能性があるため，省略せずにローワーキャメルケースで命名してもよい． 参考：https://github.com/golang/go/wiki/CodeReviewComments#variable-names 省略名については，略語検索サイトで探す．あるいは，Goリファレンスからその単語がどう省略されているかを探してもよい． 参考：https://www.allacronyms.com/ ・モックの変数 モック構造体を代入するための変数は，『m』とする． ・error構造体の変数 error構造体を変数に代入する場合，『Err』とプレフィクスをつける． ・キー名の検証 マップ型やスライス型において，指定したキー名が存在するか検証する場合，真偽値を代入する変数を『ok』とする． ＊実装例＊ package main import ( \"fmt\" \"log\" ) func main() { userIds := map[string]int{ \"user_id\": 1, } // user_idキーが存在する場合，okにtrueが返却される． userId, ok := userIds[\"user_id\"] if ok == false { log.Fatal(\"user_id does not exist\") // 2009/11/10 23:00:00 user_id does not exist } fmt.Printf(\"%#v\\n\", userId) // 1 } その他のお作法 ・コメントの書式 参考：https://github.com/golang/go/wiki/CodeReviewComments#comment-sentences ・Uber風のお作法 Uber社が採用しているお作法． 参考：https://github.com/uber-go/guide/blob/master/style.md 01-02. コマンド install ・オプション無し ソースコードと外部パッケージに対してbuildコマンドを実行し，$GOPATH以下のbinディレクトリまたはpkgディレクトリにインストール（配置）する．内部または外部のソースコードからビルドされたアーティファクト（バイナリファイル）であればbinディレクトリに配置し，それ以外（例：.aファイル）であればpkgディレクトリに配置する． $ go install get ・オプション無し 指定したパスからパッケージをダウンロードし，これに対してinstallコマンドを実行する．これにより，内部または外部のソースコードからビルドされたアーティファクト（バイナリファイル）であればbinディレクトリに配置し，それ以外（例：.aファイル）であればpkgディレクトリに配置する． $ go get build ・オプション無し 指定したパスをビルド対象として，ビルドのアーティファクトを生成する．xxxxx_test.goファイルはビルドから自動的に除外される． # cmdディレクトリをビルド対象として，ルートディレクトリにcmdアーティファクトを生成する． $ go build ./cmd ・-o 指定したパスにビルドのアーティファクトを生成する．ビルド対象パスを指定しない場合，ルートディレクトリのgoファイルをビルドの対象とする． # ルートディレクトリ内のgoファイルをビルド対象として # $HOME/go/binディレクトリにルートディレクトリ名アーティファクトを生成する． $ go build -o $HOME/go/bin また，指定したパス内のgoファイルをビルド対象として，指定したパスにビルドのアーティファクトを生成することもできる． # cmdディレクトリ内のgoファイルをビルド対象として # $HOME/go/binディレクトリにcmdアーティファクトを生成する． $ go build -o $HOME/go/bin ./cmd ちなみに，事前のインストールに失敗に，ビルド対象が存在していないと，以下のようなエラーになる． package xxxxx is not in GOROOT (/usr/local/go/src/xxxxx) env ・オプション無し Goに関する環境変数を出力する． ＊実装例＊ $ go env # go.modの有効化 GO111MODULE=\"on\" # コンパイラが実行されるCPUアーキテクチャ GOARCH=\"amd64\" # installコマンドによるアーティファクトを配置するディレクトリ（指定無しの場合，$GOPATH/bin） GOBIN=\"\" GOCACHE=\"/root/.cache/go-build\" GOENV=\"/root/.config/go/env\" GOEXE=\"\" GOFLAGS=\"\" GOHOSTARCH=\"amd64\" # コンパイラが実行されるOS GOHOSTOS=\"linux\" GOINSECURE=\"\" GOMODCACHE=\"/go/pkg/mod\" GONOPROXY=\"\" GONOSUMDB=\"\" GOOS=\"linux\" # ソースコードが配置されるディレクトリ GOPATH=\"/go\" GOPRIVATE=\"\" GOPROXY=\"https://proxy.golang.org,direct\" # Go本体を配置するディレクトリ GOROOT=\"/usr/local/go\" GOSUMDB=\"sum.golang.org\" GOTMPDIR=\"\" GOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\" GCCGO=\"gccgo\" AR=\"ar\" CC=\"gcc\" CXX=\"g++\" # c言語製のライブラリの有効化．無効化しないと，vetコマンドが失敗する． CGO_ENABLED=\"0\" GOMOD=\"/go/src/go.mod\" CGO_CFLAGS=\"-g -O2\" CGO_CPPFLAGS=\"\" CGO_CXXFLAGS=\"-g -O2\" CGO_FFLAGS=\"-g -O2\" CGO_LDFLAGS=\"-g -O2\" PKG_CONFIG=\"pkg-config\" GOGCCFLAGS=\"-fPIC -m64 -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build887404645=/tmp/go-build -gno-record-gcc-switches\" fmt ・オプション無し 指定したパスのファイルのインデントを整形する．パスとして『./...』を指定して，再帰的に実行するのがおすすめ． $ go fmt ./... vet ・オプション無し 指定したパスのファイルに対して静的解析を行う．パスとして『./...』を指定して，再帰的に実行するのがおすすめ． $ go vet ./... test ・オプション無し 指定したパスのxxxxx_test.goファイルで『Test』から始まるテスト関数を実行する．testディレクトリ内を再帰的に実行するのがおすすめ． $ go test ./... ・-v テスト時にテストの実行時間を出力する． $ go test -v ./... ・-cover テスト時に，xxxxx_test.goファイルがあるパッケージ内ファイルの命令網羅の網羅率を解析する．反対に，xxxxx_test.goファイルがなければ，そのパッケージの網羅率は解析しない．網羅条件については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_testing.html $ go test -cover ./... 02. データ型 データ型の種類 ・データ型の初期値 データ型には，値が代入されていない時，初期値が代入されている． ・プリミティブ型に属するデータ型 データ型 表記 初期値 数値 int，float 0 文字列 string \"\"（空文字） 真偽値 boolean false ・合成型に属するデータ型 データ型 表記 初期値 構造体 struct 配列 [i] ・参照型に属するデータ型 データ型 表記 初期値 ポインタ * nil スライス [] nil（要素数，容量：0） マップ nil チャネル nil プリミティブ型のまとめ ・プリミティブ型とは ＊実装例＊ // 定義（初期値として『0』が割り当てられる） var number int // 代入 number = 5 ・Defined Typeによる独自のプリミティブ型 Defined Typeを使用して，独自のプリミティブ型を定義する．元のプリミティブ型とは互換性がなくなる． ＊実装例＊ int型を元に，Age型を定義する． type Age int ＊実装例＊ パッケージの型を元に，MyAppWriter型を定義する． type MyAppWriter io.Writer ・プリミティブ型とメモリの関係 プリミティブ型の変数を定義すると，データ型のバイト数に応じて，空いているメモリ領域に，変数が割り当てられる．一つのメモリアドレス当たり１バイトに相当する． ・各データ型のサイズ 種類 型名 サイズ(bit) 説明 int（符号付き整数） int8 8 int16 16 int32 32 int64 64 int 32 or 64 実装環境によって異なる． uint（符号なし整数） uint8 8 uint16 16 unit32 32 uint64 64 uint 32 or 64 実装環境によって異なる． float（浮動小数点） float32 32 float64 64 complex（複素数） complex64 64 実部：float32，虚部：float32 complex128 128 実部：float64，虚部：float64 構造体 ・構造体とは 他の言語でいう『データのみを保持するオブジェクト』に相当する． ＊実装例＊ 構造体を定義し，変数に代入する． var person struct { Name string } ・Defined Typeによる独自の構造体 Defined Typeを使用して，独自のデータ型の構造体を定義する．フィールド名の頭文字を大文字にした場合は，パッケージ外からのアクセスをパブリックに，小文字にした場合はプライベートになる． ＊実装例＊ パブリックなフィールドを持つ構造体は以下の通り． type Person struct { // パブリック Name string } プライベートなフィールドを持つ構造体は以下の通り． type Person struct { // プライベート name string } ・使用不可のフィールド名 小文字の『type』は予約語のため使用不可である．大文字のTypeは可能． type Person struct { // 定義不可エラー type string // 定義可能 Type string } ・初期化 すでに値が代入されている構造体を初期化する場合，いくつか記法がある．その中では，タグ付きリテラルが推奨される．初期化によって構築する構造体は，ポインタ型または非ポインタ型のいずれでも問題ない．ただし，多くの関数がポインタ型を引数型としていることから，それに合わせてポインタ型を構築することが多い． ＊実装例＊ まずは，タグ付きリテラル表記． package main import \"fmt\" type Person struct { Name string } func main() { person := &Person{ // タグ付きリテラル表記 Name: \"Hiroki\", } fmt.Printf(\"%#v\\n\", person.Name) // \"Hiroki\" } 二つ目に，タグ無しリテラル表記がある． package main import \"fmt\" type Person struct { Name string } func main() { person := &Person{ // タグ無しリテラル表記 \"Hiroki\", } fmt.Printf(\"%#v\\n\", person.Name) // \"Hiroki\" } 三つ目に，new関数とデータ代入による初期化がある．new関数は，データが代入されていない構造体を作成するため，リテラル表記時でも表現できる．new関数は，構造体以外のデータ型でも使用できる．ポインタ型の構造体を返却する． package main import \"fmt\" type Person struct { Name string } /** * 型のコンストラクタ * ※スコープはパッケージ内のみとする． */ func newPerson(name string) *Person { // new関数を使用する． // &Person{} に同じ． person := new(Person) // ポインタ型の初期化された構造体が返却される． fmt.Printf(\"%#v\\n\", person) // &main.Person{Name:\"\"} // フィールドに代入する person.Name = name return person } func main() { person := newPerson(\"Hiroki\") fmt.Printf(\"%#v\\n\", person.Name) // \"Hiroki\" } ・DI（依存性注入） 構造体のフィールドとして構造体を保持することにより，依存関係を構成する．依存される側をサプライヤー，また依存する側をクライアントという．構造体間に依存関係を構成するには，クライアントにサプライヤーを注入する．注入方法には，『Constructor Injection』『Setter Injection』『Setter Injection』がある．詳しくは，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_object_orientation_class.html package main import \"fmt\" //======================== // サプライヤー側 //======================== type Name struct { FirstName string LastName string } func NewName(firstName string, lastName string) *Name { return &Name{ FirstName: firstName, LastName: lastName, } } func (n *Name) fullName() string { return fmt.Sprintf(\"%s %s\", n.FirstName, n.LastName) } //======================== // クライアント側 //======================== type Person struct { Name *Name } func NewPerson(name *Name) *Person { return &Person{ Name: name, } } func (p *Person) getName() *Name { return p.Name } func main() { name := NewName(\"Hiroki\", \"Hasegawa\") // コンストラクタインジェクションによるDI person := NewPerson(name) fmt.Printf(\"%#v\\n\", person.getName().fullName()) // \"Hiroki Hasegawa\" } ・埋め込みによる委譲 Goには継承がなく，代わりに委譲がある．構造体のフィールドとして別の構造体を埋め込むことにより，埋め込まれた構造体に処理を委譲する．委譲する側の構造体を宣言するだけでなく，フィールドとして渡す必要がある．この時，実装者が委譲を意識しなくて良くなるように，コンストラクタの中で初期化するようにする．インターフェースの委譲とは異なり，アップキャストは行えない．つまり，委譲された構造体は委譲する構造体のデータ型にキャストでき，同一のデータ型として扱えない． ＊実装例＊ package main import \"fmt\" //======================== // 委譲する側（埋め込む構造体） //======================== type Name struct { FirstName string LastName string } func (n *Name) fullName() string { return fmt.Sprintf(\"%s %s\", n.FirstName, n.LastName) } //======================== // 委譲される側（埋め込まれる構造体） //======================== type MyName struct { *Name } func NewMyName(firstName string, lastName string) *MyName { return &MyName{ // コンストラクタ内で委譲する構造体を初期化する． Name: &Name{ FirstName: firstName, LastName: lastName, }, } } //================ // main //================ func main() { myName := NewMyName(\"Hiroki\", \"Hasegawa\") // myName構造体は，Name構造体のメソッドをコールできる． fmt.Printf(\"%#v\\n\", myName.fullName()) // \"Hiroki Hasegawa\" } もし，委譲する側と委譲される側に，同じ名前のメソッド／フィールドが存在する場合は，委譲された側のものが優先してコールされる． package main import \"fmt\" //======================== // 委譲する側（埋め込む構造体） //======================== type Name struct { FirstName string LastName string } func (n *Name) fullName() string { return fmt.Sprintf(\"%s %s\", n.FirstName, n.LastName) } //======================== // 委譲される側（埋め込まれる構造体） //======================== type MyName struct { *Name } func NewMyName(firstName string, lastName string) *MyName { return &MyName{ // コンストラクタ内で委譲する構造体を初期化する． Name: &Name{ FirstName: firstName, LastName: lastName, }, } } // 委譲する側と委譲される側で同じメソッド func (n *MyName) fullName() string { return fmt.Sprintf(\"%s\", \"委譲された構造体です\") } //================ // main //================ func main() { myName := NewMyName(\"Hiroki\", \"Hasegawa\") // 同じメソッドがある場合，委譲された側が優先． fmt.Printf(\"%#v\\n\", myName.fullName()) // \"委譲された構造体です\" } ・無名構造体 構造体の定義と初期化を同時に行う．構造体に名前がなく，データ型を割り当てることができないため，返却値としては使用できないことに注意する． ＊実装例＊ package main import \"fmt\" type Person struct { Name string } func main() { person := &struct { Name string }{ // タグ付きリテラル表記（タグ無しリテラル表記も可能） Name: \"Hiroki\", } fmt.Printf(\"%#v\\n\", person.Name) // \"Hiroki\" } JSON ・JSONと構造体のマッピング 構造体とJSONの間でパースを実行する時，構造体の各フィールドと，JSONのキー名を，マッピングしておくことができる． ＊実装例＊ package main import ( \"encoding/json\" \"fmt\" \"log\" ) type Person struct { Name string `json:\"name\"` } func main() { person := &Person{ Name: \"Hiroki\", } byteJson, err := json.Marshal(person) if err != nil { log.Println(\"JSONエンコードに失敗しました。\") } // エンコード結果を出力 fmt.Printf(\"%#v\\n\", string(byteJson)) // \"{\\\"Name\\\":\\\"Hiroki\\\"}\" } ・omitempty 値が『false，0，nil，空配列，空slice，空map，空文字』の時に，JSONエンコードでこれを除外できる．構造体を除外したい場合は，nilになりうるポインタ型としておく． ＊実装例＊ package main import ( \"encoding/json\" \"fmt\" \"log\" ) type Person struct { // false，0，nil，空配列，空slice，空map，空文字を除外できる． Id int `json:\"id\"` // 構造体はポインタ型としておく Name *Name `json:\"name,omitempty\"` } type Name struct { FirstName string `json:\"first_name\"` LastName string `json:\"last_name\"` } func main() { person := &Person{ Id: 1, // Name構造体はnilにしておく } byteJson, err := json.Marshal(person) if err != nil { log.Println(\"JSONエンコードに失敗しました。\") } // エンコード結果を出力 fmt.Printf(\"%#v\\n\", string(byteJson)) // \"{\\\"id\\\":1}\" } 配列 ・配列とは 要素，各要素のメモリアドレス，からなるデータのこと． ・宣言と代入 配列を宣言し，変数に代入する． ＊実装例＊ 宣言と代入を別々に行う．また，要素数の定義が必要である． package main import \"fmt\" func main() { var z [2]string z[0] = \"Hiroki\" z[1] = \"Gopher\" fmt.Printf(\"%#v\\n\", z) // [Hiroki Gopher] fmt.Printf(\"%#v\\n\", z) // [2]string{\"Hiroki\", \"Gopher\"} } 宣言と代入を同時に行う．また，要素数の定義が必要である． package main import \"fmt\" func main() { var y [2]string = [2]string{\"Hiroki\", \"Gopher\"} fmt.Printf(\"%#v\\n\", y) // [Hiroki Gopher] fmt.Printf(\"%#v\\n\", y) // [2]string{\"Hiroki\", \"Gopher\"} } 宣言と代入を同時に行う．また，型推論と要素数省略を行う． package main import \"fmt\" func main() { x := [...]string{\"Hiroki\", \"Gopher\"} fmt.Printf(\"%#v\\n\", x) // [Hiroki Gopher] fmt.Printf(\"%#v\\n\", x) // [2]string{\"Hiroki\", \"Gopher\"} } ・配列とメモリの関係 配列型の変数を定義すると，空いているメモリ領域に，配列がまとまって割り当てられる．一つのメモリアドレス当たり１バイトに相当する． ポインタ ・ポインタ型とは メモリアドレスを代入できるデータ型のこと． ・参照演算子（&） 定義された変数に対して，&（アンパサンド）を宣言すると，メモリアドレスを参照できる．参照したメモリアドレス値は，ポインタ型の変数に代入する必要があるが，型推論で記述すればこれを意識しなくてよい．PHPにおけるポインタは，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_object_orientation_method_data.html ＊実装例＊ package main import \"fmt\" func main() { x := \"a\" // メモリアドレスを参照する． var p *string = &x // p := &x と同じ // メモリアドレスを参照する前 fmt.Printf(\"%#v\\n\", x) // \"a\" // メモリアドレスを参照した後 fmt.Printf(\"%#v\\n\", p) // (*string)(0xc0000841e0) } ・間接参照演算子（*） ポインタ型の変数に対してアスタリスクを宣言すると，メモリアドレスに割り当てられているデータの実体を取得できる．ポインタを用いてデータの実体を取得することを『逆参照（デリファレンス）』という． package main import \"fmt\" func main() { x := \"a\" p := &x // メモリアドレスの実体を取得する（デリファレンス）． y := *p // メモリアドレスを参照する前 fmt.Printf(\"%#v\\n\", x) // \"a\" // メモリアドレスを参照した後 fmt.Printf(\"%#v\\n\", p) // (*string)(0xc0000841e0) // メモリアドレスに割り当てられたデータ fmt.Printf(\"%#v\\n\", y) // \"a\" } ・ポインタ型で扱うべきデータ型 データ型 ポインタ型で扱うべきか 説明 構造体 ◯ ポインタ型として扱うと，構造体が持つメモリアドレスを処理するだけでよくなる．ポインタ型としない場合と比べて，少ないメモリ消費で構造体を扱える． slice，map，chan， func △ データサイズの大きさによる． プリミティブ型 × ポインタ型で扱うメリットはない． スライス ・スライスとは 参照先の配列に対するポインタ，長さ，容量を持つデータ型である． // Goのソースコードより type slice struct { array unsafe.Pointer len int cap int } 参考：https://github.com/golang/go/blob/04a4dca2ac3d4f963e3c740045ce7a2959bf0319/src/runtime/slice.go#L13-L17 ・宣言と代入 ＊実装例＊ 宣言と代入を同時に行う． package main import \"fmt\" func main() { var y []string = []string{\"Hiroki\", \"Gopher\"} fmt.Printf(\"%+v\\n\", y) // [Hiroki Gopher] fmt.Printf(\"%#v\\n\", y) // []string{\"Hiroki\", \"Gopher\"} } 文字列の宣言と代入を同時に行う．また，型推論を行う． package main import \"fmt\" func main() { x := []string{\"Hiroki\", \"Gopher\"} fmt.Printf(\"%+v\\n\", x) // [Hiroki Gopher] fmt.Printf(\"%#v\\n\", x) // []string{\"Hiroki\", \"Gopher\"} } バイト文字列の宣言と代入を同時に行う．また，型推論を行う． package main import \"fmt\" func main() { x := []byte(\"abc\") fmt.Printf(\"%+v\\n\", x) // [97 98 99] fmt.Printf(\"%#v\\n\", x) // []byte{0x61, 0x62, 0x63} } 構造体のスライスの宣言と代入を同時に行う．また，型推論を行う． package main import \"fmt\" type Person struct { Name string } func main() { person := []Person{{Name: \"Hiroki\"}} fmt.Printf(\"%+v\\n\", person) // [{Name:Hiroki}] fmt.Printf(\"%#v\\n\", person) // []main.Person{main.Person{Name:\"Hiroki\"}} } ・配列の値の参照 全てのスライスが共通の配列を参照しているため，例えば，xb変数しか上書きしていないのにもかかわらず，他のスライスにもその上書きが反映される． package main import \"fmt\" func main() { // 最後の要素の後にもカンマが必要である． x := [5]string{\"あ\", \"い\", \"う\", \"え\", \"お\"} fmt.Printf(\"%#v\\n\", x) // [5]string{\"あ\", \"い\", \"う\", \"え\", \"お\"} // 0から3番目を参照する． xa := x[0:3] fmt.Printf(\"%#v\\n\", xa) // []string{\"あ\", \"い\", \"う\"} // 2から5番目を参照する． xb := x[2:5] fmt.Printf(\"%#v\\n\", xb) // []string{\"う\", \"え\", \"お\"} // xbスライスの0番目（\"う\"）を上書きする． xb[0] = \"Hiroki\" // xbしか上書きしていないが，他のスライスにも反映される． fmt.Printf(\"%#v\\n\", xa) // []string{\"あ\", \"い\", \"Hiroki\"} fmt.Printf(\"%#v\\n\", xb) // []string{\"Hiroki\", \"え\", \"お\"} fmt.Printf(\"%#v\\n\", x) // [5]string{\"あ\", \"い\", \"Hiroki\", \"え\", \"お\"} } ・要素の追加 渡されたスライスで，後ろから要素を追加する． package main import ( \"fmt\" ) func main() { s := []int{10, 20, 30, 40} fmt.Println(s) // [10 20 30 40] // 要素を追加． s = append(s, 50, 60, 70, 80) fmt.Println(s) // [10 20 30 40 50 60 70 80] } マップ ・単一のプリミティブ型を値に持つマップ マップの定義と代入を同時に行う． package main import \"fmt\" func main() { // 『数値:文字列』のマップ m := map[int]string{ 0: \"Hiroki\", 1: \"Hiroko\", 2: \"Hiroshi\", } fmt.Println(m) // map[0:Hiroki 1:Hiroko 2:Hiroshi] } 定義と代入を別々に行う． package main import \"fmt\" func main() { // 『数値:文字列』のマップ m := map[int]string{} m[0] = \"Hiroki\" m[1] = \"Hiroshi\" m[2] = \"Hiroshi\" fmt.Println(m) // map[0:Hiroki 1:Hiroko 2:Hiroshi] } または，make関数を使用してマップを作成することもできる． package main import \"fmt\" func main() { // 『数値:文字列』のマップ m := make(map[int]string) m[0] = \"Hiroki\" m[1] = \"Hiroshi\" m[2] = \"Hiroshi\" fmt.Println(m) // map[0:Hiroki 1:Hiroko 2:Hiroshi] } ・スライス型を値に持つマップ package main import ( \"fmt\" ) func main() { // 『文字列:スライス』のマップ m := map[string][]string{ \"errors\": { 0: \"エラーメッセージ0\", 1: \"エラーメッセージ1\", 2: \"エラーメッセージ2\", }, } fmt.Println(m) // map[errors:[エラーメッセージ0 エラーメッセージ1 エラーメッセージ2]] } ・複数のデータ型を持つマップ マップ型データの値をインターフェース型とすることで，複数のデータ型を表現できる． package main import \"fmt\" func main() { // 『文字列:複数のプリミティブ型』のマップ m := map[string]interface{}{ \"id\": 1, \"name\": \"Hiroki Hasegawa\", } fmt.Println(m) // map[id:1 name:Hiroki Hasegawa] } ・マップ値の抽出 package main import \"fmt\" func main() { m := map[int]string{ 1: \"Hiroki\", 2: \"Hiroko\", 3: \"Hiroshi\", } // 値の抽出 v, ok := m[1] // エラーハンドリング if ok != true { fmt.Println(\"Value is not found.\") // Value is not found. } fmt.Println(v) // Hiroki } インターフェース ・埋め込みによる委譲 構造体のフィールドとして別のインターフェースを埋め込むことにより，埋め込まれた構造体に処理の全てを委譲する．ただし，構造体に明示的にインターフェースを埋め込む必要はなく，インターフェースを満たす関数を構造体に関連づけると，インターフェースを暗黙的に実装できる．構造体の委譲とは異なり，アップキャストを行うことができる．つまり，委譲された構造体は委譲するインターフェースのデータ型にキャストでき，同一のデータ型として扱える． ＊実装例＊ InspectImpl構造体にAnimalインターフェースを埋め込み，構造体にEatメソッド，Sleepメソッド，Matingメソッド，の処理を委譲する． package main import \"fmt\" // インターフェースとそのメソッドを定義する． type AnimalInterface interface { Name() string Eat() string Sleep() string } type InsectImpl struct { name string } type FishImpl struct { name string } type MammalImpl struct { name string } // コンストラクタ func NewInsect(name string) (*InsectImpl, error) { return &InsectImpl{ name: name, }, nil } // 構造体に関数を関連付ける．インターフェースを暗黙的に実装する． func (i *InsectImpl) Name() string { return i.name } func (i *InsectImpl) Eat() string { return \"食べる\" } func (i *InsectImpl) Sleep() string { return \"眠る\" } func main() { insect, err := NewInsect(\"カブトムシ\") if err != nil { fmt.Println(err) } // メソッドを実行する． fmt.Println(insect.Name()) fmt.Println(insect.Eat()) fmt.Println(insect.Sleep()) } ・アップキャストの可否を利用した検証 もし，構造体に実装されたメソッドに不足があると，委譲が自動的に取り消される．エラーは発生しないため，実装されたメソッドが十分であることを実装者が知らなければならない．アップキャストの可否を利用して，意図的にエラーを発生させるテクニックがある． 参考：https://github.com/uber-go/guide/blob/master/style.md#verify-interface-compliance package main import \"fmt\" // アップキャストの可否を利用して，構造体がインターフェースを満たしているを検証する． var _ AnimalInterface = &InsectImpl{} // もしくは (*InsectImpl)(nil) // インターフェースとそのメソッドを定義する． type AnimalInterface interface { Name() string Eat() string } type InsectImpl struct { name string } // コンストラクタ func NewInsect(name string) (*InsectImpl, error) { return &InsectImpl{ name: name, }, nil } // 構造体に関数を関連付ける．インターフェースを暗黙的に実装する． func (i *InsectImpl) Name() string { return i.name } func main() { insect, err := NewInsect(\"カブトムシ\") if err != nil { fmt.Println(err) } // メソッドを実行する． fmt.Println(insect.Name()) } # Eatメソッドを関連付けていない場合 cannot use insect (type Insect) as type Animal in assignment: Insect does not implement Animal (missing Eat method) ・緩い型としてのインターフェース 様々な値をインターフェース型として定義できる．また，他の型に変換することもできる． ＊実装例＊ package main import ( \"fmt\" ) func main() { var x interface{} x = 1 fmt.Printf(\"%#v\\n\", x) // 1 x = 3.14 fmt.Printf(\"%#v\\n\", x) // 3.14 x = \"Hiroki\" fmt.Printf(\"%#v\\n\", x) // \"Hiroki\" x = [...]uint8{1, 2, 3, 4, 5} fmt.Printf(\"%#v\\n\", x) // [5]uint8{0x1, 0x2, 0x3, 0x4, 0x5} } なお，インターフェース型はは演算できない． package main import ( \"fmt\" ) func main() { var x, y interface{} // インターフェース型 x, y = 1, 2 fmt.Printf(\"%#v\\n\", x) // 1 fmt.Printf(\"%#v\\n\", y) // 2 // エラーになる． // invalid operation: x + y (operator + not defined on interface) z := x + y fmt.Printf(\"%#v\\n\", z) } ・型アサーション インターフェース型を他の型に変換する．インターフェース型の変数で『.(データ型)』を宣言する． package main import ( \"fmt\" ) func main() { var x, y interface{} // インターフェース型 x, y = 1, 2 // インターフェース型から整数型に変換（変換しないと演算できない） a := x.(int) b := y.(int) z := a + b fmt.Printf(\"%#v\\n\", z) } ・errorインターフェース Goには，標準搭載されているインターフェースがある．このインターフェースが強制するメソッドを実装した構造体を定義すると，自動的に委譲が行われる． ＊例＊ errorインターフェースの委譲については，本ノート内の説明を参考にせよ． type error interface { Error() string } ・stringインターフェース 構造体にStringメソッドを定義しておくと，Print系関数に構造体を渡した時に，これが実行される． ＊実装例＊ package main import \"fmt\" type Foo struct{} func (f *Foo) String() string { return \"Stringメソッドを実行しました．\" } func main() { f := &Foo{} fmt.Println(f) } nil ・nilとは いくつかのデータ型における初期値のこと． ・ポインタの場合 ＊実装例＊ package main import \"fmt\" func main() { x := \"x\" // ポインタ型の定義のみ var p1 *string // ポインタ型の変数を定義代入 var p2 *string = &x fmt.Printf(\"%#v\\n\", p1) // (*string)(nil) fmt.Printf(\"%#v\\n\", p2) // (*string)(0xc0000841e0) } ・インターフェースの場合 ＊実装例＊ package main import \"fmt\" func main() { var x interface{} fmt.Printf(\"%#v\\n\", x) // } 03. 関数 main関数 ・main関数とは goのエントリポイントとなる．goのプログラムが起動したときに，各パッケージのinit関数が実行された後，main関数が実行される．main関数をビルド対象に指定すると，これを起点として読み込まれるファイルが枝分かれ状にビルドされていく．ステータス『0』でプロセスを終了する． ＊実装例＊ package main import \"fmt\" func main() { fmt.Printf(\"%#v\\n\", \"Hello world!\") } 当然，mainパッケージやmain関数が無いと，goのプログラムの起動時にエラーが発生する． $ go run server.go go run: cannot run non-main package $ go run server.go # command-line-arguments runtime.main: call to external function main.main runtime.main: main.main: not defined runtime.main: undefined: main.main 独自関数 ・関数とは 構造体に関連付けられていない関数のこと． ＊実装例＊ package main import \"fmt\" // 頭文字を大文字する func Foo(x string) string { fmt.Println(x) } func main() { Foo(\"Hello world!\") } ・引数の型 引数の型として，構造体の場合はポインタ型，それ以外のデータの場合はポインタ型以外が推奨される． https://github.com/golang/go/wiki/CodeReviewComments#pass-values ・Closure（無名関数）とは 名前のない関数のこと． ・即時関数とは 定義したその場でコールされる無名関数のこと． ＊実装例＊ main関数で即時関数を実行する． package main import \"fmt\" func main() { result := func() string { return \"Closure is working!\" }() fmt.Printf(\"%#v\\n\", result) } ＊実装例＊ 即時関数に引数を設定できる．その場合，仮引数と引数の両方を設定する必要がある． package main import \"fmt\" func main() { // 仮引数を設定 result := func(x string) string { return x }(\"Closure is working!\") // 引数に値を渡す fmt.Printf(\"%#v\\n\", result) } メソッド ・メソッドとは データ型や型リテラルに関連付けられている関数のこと．Goは，言語としてオブジェクトという機能を持っていないが，構造体に関数を関連付けることで，擬似的にオブジェクトを表現できる． ・レシーバによる関連付け データ型や型リテラルなどを関数のレシーバとして渡すことによって，それに関数を関連づけられる．関連付け後，関数はメソッドと呼ばれるようになる．メソッド名とフィールド名に同じ名前は使用できない． ＊実装例＊ int型を値レシーバとして渡し，構造体に関数を関連付ける． package main import \"fmt\" type Age int func (a Age) PrintAge() string { return fmt.Sprintf(\"%dです．\", a) } func main() { var age Age = 20 fmt.Printf(\"%#v\\n\", age.printAge()) } ＊実装例＊ 構造体を値レシーバとして渡し，構造体に関数を関連付ける． package main import \"fmt\" // 構造体を定義 type Person struct { name string } // コンストラクタ func NewPerson(name string) *Person { return &Person{ name: name, } } // 構造体に関数を関連付ける． func (p Person) GetName() string { return p.name } // 構造体から関数をコール func main() { // 構造体を初期化 person := NewPerson(\"Hiroki\") fmt.Printf(\"%#v\\n\", person.GetName()) // \"Hiroki\" } ・値レシーバ 構造体の実体と関数を直接的に関連づける．関連付け後，関数はメソッドと呼ばれるようになる．レシーバとして渡された引数をメソッド内でコピーしてから使用する．値レシーバによって関連付けられると，そのメソッドは構造体の状態を変えられなくなるので，構造体をイミュータブルにしたい場合は，値レシーバを使うと良い． ＊実装例＊ 構造体を値レシーバとして渡し，構造体に関数を関連付ける． package main import \"fmt\" type Person struct { name string } // コンストラクタ func NewPerson(name string) *Person { return &Person{ name: name, } } // 値レシーバ func (p Person) SetName(name string) { // 引数の構造体をコピーしてから使用 p.name = name } func (p Person) GetName() string { return p.name } func main() { person := NewPerson(\"Gopher\") person.SetName(\"Hiroki\") fmt.Printf(\"%#v\\n\", person.GetName()) // \"Gopher\" } ・ポインタレシーバ 構造体のポインタを用いて，関数と構造体の実体を関連づける．関連付け後，関数はメソッドと呼ばれるようになる．レシーバとして渡された引数をメソッド内でそのまま使用する．ポインタレシーバによって関連付けられると，そのメソッドは構造体の状態を変えられるようになるので，構造体をミュータブルにしたい場合は，ポインタレシーバを使うと良い．構造体を初期化する処理を持つコンストラクタ関数のみをポインタレシーバとし，他のメソッドを全て値レシーバとすると，最低限にミュータブルなプログラムを実装できる．また，構造体はポインタ型として扱った方がメモリを節約できる． ＊実装例＊ package main import \"fmt\" type Person struct { Name string } // ポインタレシーバ func (p *Person) SetName(name string) { // 引数の構造体をそのまま使用 p.Name = name } func (p *Person) GetName() string { return p.Name } func main() { person := Person{Name: \"Gopher\"} person.SetName(\"Hiroki\") fmt.Printf(\"%#v\\n\", person.GetName()) // \"Hiroki\" } defer関数 ・defer関数とは 全ての処理の最後に必ず実行される遅延実行関数のこと．たとえ，ランタイムエラーのように処理が強制的に途中終了しても実行される． ＊実装例＊ 即時関数をdefer関数化している．処理の最後にランタイムエラーが起こったとき，これをrecoverメソッドで吸収できる． package main import \"fmt\" func main() { fmt.Println(\"Start\") // あらかじめdefer関数を定義しておく defer func() { err := recover() if err != nil { fmt.Printf(\"Recover: %#v\\n\", err) } fmt.Println(\"End\") }() // ここで意図的に処理を停止させている． panic(\"Runtime error\") } // Start // Recover: \"Runtime error\" // End ・複数のdefer関数 deferは複数の関数で宣言できる．複数宣言した場合，後に宣言されたものから実行される． ＊実装例＊ package main import \"fmt\" func main() { defer fmt.Println(\"1\") defer fmt.Println(\"2\") defer fmt.Println(\"3\") } // 3 // 2 // 1 返却値 ・複数の返却値 ＊実装例＊ package main import \"fmt\" func division(x int, y int) (int, int) { // 商を計算する． quotient := x / y // 余りを計算する． remainder := x % y // 商と余りを返却する． return quotient, remainder } func main() { // 10÷3を計算する． q, r := division(10, 3) fmt.Printf(\"商=%d，余り=%d\", q, r) } ・返却値の破棄 関数から複数の値が返却される時，使わない値をアンダースコアに代入することで，これを破棄できる． ＊実装例＊ package main import ( \"fmt\" \"os\" ) func main() { // errorインターフェースを破棄 file, _ := os.Open(\"filename.txt\") // エラーキャッチする必要がなくなる fmt.Printf(\"%#v\\n\", flle) } 04. 変数 定義（宣言＋代入） ・明示的な定義 ＊実装例＊ // 一つの変数を定義（宣言と代入が同時でない） var number int number = 5 // 一つの変数を定義（宣言と代入が同時） var number int = 5 // 複数の変数を定義 var x, y, z int x, y, z = 1, 3, 5 ・暗黙的な定義（型推論） ＊実装例＊ // データ型が自動的に認識される w := 1 x := true y := 3.14 z := \"abc\" var w = 1 var ( x = true y = 3.14 z = \"abc\" ) package main import \"fmt\" func quotient(x int, y int) int { // 商を計算する． quotient := x / y // を返却する． return quotient } func main() { fmt.Println(quotient(2, 2)) } ・再宣言 基本的には，同じスコープ内で既存の変数を再宣言できない．ただし，複数の変数を宣言する時に，いずれかに新しい変数の宣言が含まれていれば，既存の変数を宣言したとしても，代入のみが実行される． ＊実装例＊ package main import ( \"fmt\" ) func main() { x := 1 // 新しい変数の宣言が含まれている x, y := 2, 3 fmt.Printf(\"%#v\\n\", x) // 2 fmt.Printf(\"%#v\\n\", y) // 3 } 定義位置の種類 ・パッケージ変数 関数の外部で定義された変数のこと．スコープとして，宣言されたパッケージ外部でも使用できる． ＊実装例＊ パッケージ変数を宣言し，関数内で値を代入する． package main import ( \"fmt\" ) // パッケージ変数 var text string func main() { text = \"Hello World!\" fmt.Printf(\"%#v\\n\", text) } 変数への値の代入は関数内でしかできないため，宣言と代入を同時に行う型推論を使用するとエラーになる． package main import ( \"fmt\" ) // エラーになる． text := \"Hello World!\" func main() { fmt.Printf(\"%#v\\n\", text) } ・ローカル変数 関数の内部で定義された変数のこと．スコープとして，宣言されたパッケージ内部でしか使用できない． ＊実装例＊ package main import ( \"fmt\" ) func main() { // ローカル変数 text := \"Hello World!\" fmt.Printf(\"%#v\\n\", text) } 05. スコープ 変数，定数 ・パッケージ内外から参照可能 変数名または定数名の頭文字を大文字すると，パッケージ内外でこれをコールできるようになる． ＊実装例＊ package foo // 定数を定義する． const ( X = \"X\" ) package main import ( \"fmt\" ) func main() { fmt.Printf(\"%#v\\n\", X) // X } ・パッケージ内のみ参照可能 変数名または定数名の頭文字を小文字すると，パッケージ外でこれをコールできなくなる． ＊実装例＊ package main import ( \"fmt\" ) // 定数を定義する． const ( yZ = \"yZ\" ) func main() { fmt.Printf(\"%#v\\n\", yZ) // yZ } 関数 ・パッケージ内外から参照可能 関数名の頭文字を大文字すると，パッケージ内外でこれをコールできるようになる． ＊実装例＊ package foo func Foo() { // 何らかの処理 } package main func main() { Foo() } ・パッケージ内のみ参照可能 関数名の頭文字を小文字すると，パッケージ外でこれをコールできなくなる． ＊実装例＊ package main func foo() { // 何らかの処理 } func main() { foo() } 06. 制御文 配列またはスライスの走査 ・for ... range 配列またはスライスを走査する．PHPのforeachに相当する． package main import ( \"fmt\" ) func main() { slice := []string{\"a\", \"b\", \"c\"} for key, value := range slice { fmt.Println(key, value) } } // 0 a // 1 b // 2 c 07. 処理の種類 同期処理 ・同期処理とは 前の処理を待って，次の処理を開始する． ＊実装例＊ package main import \"fmt\" func main() { fmt.Println(\"1\") fmt.Println(\"2\") fmt.Println(\"3\") } // 1 // 2 // 3 非同期処理（並行処理） ・非同期処理（並行処理）とは 前の処理の終了を待たずに次の処理を開始し，それぞれの処理が独立して終了する．結果，終了する順番は順不同になる． 参考：https://golang.org/pkg/sync/ ＊実装例＊ 並列処理 ・並列処理 指定した処理を同時に開始し，それぞれの処理が独立して終了する．結果，終了する順番は順不同になる．関数でGoルーチンを宣言すると，その関数のコールを並列化できる．ただし，main関数はGoルーチン宣言された関数の完了を待たずに終了してしまうため，この関数の実行完了を待つようにする必要がある．方法には，以下の三つがある． ・channel キューとして機能する．キューに値を格納し，またキューから値を取り出せる． package main import \"fmt\" func main() { // チャンネルを任意のデータ型で作成 channel := make(chan string) go func() { // チャンネルに値を格納 channel ・WaitGroup 一つまたは複数の関数でGoルーチンを宣言したい時に使用する． ＊実装例＊ 並列処理により，反復処理を素早く完了できる．実行完了に一秒かかる関数があると仮定する．反復処理でこの関数をコールする場合，毎回の走査に一秒かかるため，反復の回数だけ秒数が増える．しかし，Goルーチンを宣言し並列化することにより，各走査が全て並列に実行されるため，反復回数が何回であっても，一秒で処理が終わる． package main import ( \"fmt\" \"sync\" \"time\" ) func print(key int, value string) { fmt.Println(key, value) time.Sleep(time.Second * 1) // 処理完了に一秒かかると仮定する． } func main() { wg := &sync.WaitGroup{} slice := []string{\"a\", \"b\", \"c\"} // 処理の開始時刻を取得 start := time.Now() for key, value := range slice { wg.Add(1) // go routineの宣言の数 // Goルーチンを宣言して並列化 go func(key int, value string) { defer wg.Done() // 時間のかかる関数 print(key, value) }(key, value) } // Add関数で指定した数のgo routineが実行されるまで待機 wg.Wait() // 開始時刻から経過した秒数を取得 fmt.Printf(\"経過秒数: %s\", time.Since(start)) } // 2 c // 0 a // 1 b // 経過秒数: 1s ・errgroup エラー処理を含む関数でGoルーチンを宣言したい時に使用する． ＊実装例＊ 08. エラーキャッチ，例外スロー Goにおけるエラーキャッチと例外スロー ・例外スローのある言語の場合 例外スローの意義は，以下の参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_logic_validation.html ・Goには例外が無い 例えばPHPでは，エラーをキャッチし，システム開発者にわかる言葉に変換した例外としてスローする．Goには例外クラスに相当するものが無い．その代わり，エラーそのものがerrorインターフェースに保持されており，これを一つの値として扱える．下流で発生したerrorインターフェースを，そのまま上流に返却する． エラーキャッチ ・nilの比較検証 関数から返却されたerrインターフェースが，nilでなかった場合に，エラーであると見なすようにする． if err != nil { // 何らかの処理 } errorインターフェース ・標準エラー Goでは複数の値を返却できるため，多くの関数では標準で，最後にerrorインターフェースが返却されるようになっている．errorインターフェースは暗黙的にErrorメソッドをコールする． type error interface { Error() string } ＊実装例＊ osパッケージのOpenメソッドからerrorインターフェースが返却される．errorインターフェースはErrorメソッドを自動的に実行し，標準エラー出力に出力する． package main import ( \"fmt\" \"log\" \"os\" ) func main() { // 処理結果とerrorインターフェースが返却される． file, err := os.Open(\"filename.txt\") if err != nil { // エラーの内容を出力する． log.Fatalf(\"ERROR: %#v\\n\", err) } fmt.Printf(\"%#v\\n\", flle) } ・New関数による独自エラー errorsパッケージのNewメソッドにエラーを設定する．これにより，独自のエラーを保持するerrorインターフェースを定義できる．errorインターフェースはErrorメソッドを自動的に実行する． 参考：https://golang.org/pkg/errors/#New ＊実装例＊ package main import ( \"errors\" \"fmt\" \"log\" \"os\" ) func NewError() error { return errors.New(\"\") } func main() { file, err := os.Open(\"filename.txt\") if err != nil { // 独自エラーメッセージを設定する． myErr := NewError() log.Fatalf(\"ERROR: %#v\\n\", myErr) } fmt.Printf(\"%#v\\n\", flle) } ・fmt.Errorfメソッドによる独自エラー fmtパッケージのErrorfメソッドで独自エラーを作成できる．事前に定義したフォーマットを元にエラーを設定する．これにより，独自のエラーを保持するerrorインターフェースを定義できる．errorインターフェースはErrorメソッドを自動的に実行する． 参考：https://golang.org/pkg/fmt/#Errorf ＊実装例＊ package main import ( \"fmt\" \"os\" ) func main() { file, err := os.Open(\"filename.txt\") if err != nil { fmt.Errorf(\"ERROR: %s\", err) } fmt.Printf(\"%#v\\n\", flle) } ・構造体による独自エラー 構造体にErrorメソッドを定義すると，この構造体にerrorインターフェースが自動的に委譲される．これにより，独自のエラーを保持するerrorインターフェースを定義できる．errorインターフェースはErrorメソッドを自動的に実行する． ＊実装例＊ package main import ( \"fmt\" \"os\" ) type Error struct { Message string } func (error *Error) Error() string { return fmt.Sprintf(\"ERROR: %s\", error.Message) } func main() { file, err := os.Open(\"filename.txt\") if err != nil { // 構造体に値を設定する． myError := &Error{Message: \"エラーが発生したため，処理を終了しました．\"} // 構造体をコールするだけで，Errorメソッドが実行される． fmt.Printf(\"%#v\\n\", myError) os.Exit(1) } fmt.Printf(\"%#v\\n\", flle) } xerrorsパッケージ ・xerrorsパッケージとは 標準のerrorsパッケージには，エラーにスタックトレース情報が含まれていない．xerrorsパッケージによって生成されるerrorインターフェースには，errorインターフェースが返却された行数がスタックトレースとして含まれている． ・New関数によるトレース付与 ＊実装例＊ package main import ( \"fmt\" \"golang.org/x/xerrors\" \"log\" \"os\" ) func NewErrorWithTrace() error { return xerrors.New(\"\") } func main() { file, err := os.Open(\"filename.txt\") if err != nil { // errorインターフェースが返却された行数が付与される． errWithStack := NewErrorWithTrace() // %+v\\n を使用する． log.Fatalf(\"ERROR: %+v\\n\", errWithStack) } fmt.Printf(\"%#v\\n\", flle) } ・Errorfメソッドによるトレース付与 package main import ( \"fmt\" \"golang.org/x/xerrors\" \"log\" \"os\" ) func main() { file, err := os.Open(\"filename.txt\") if err != nil { // errorインターフェースが返却された行数が付与される． errWithStack := xerrors.Errorf(\"ERROR: %w\", err) // %+v\\n を使用する． log.Fatalf(\"ERROR: %+v\\n\", errWithStack) } fmt.Printf(\"%#v\\n\", flle) } 08-02. ロギング logパッケージ ・logパッケージとは Goには標準で，ロギング用パッケージが用意されている．ただし，機能が乏しいので，外部パッケージ（例：logrus）も推奨である． 参考： https://pkg.go.dev/log https://github.com/sirupsen/logrus ・接尾辞Printメソッド 渡された値を標準出力に出力する． ＊実装例＊ 渡されたerrorインターフェースを標準出力に出力する． if err != nil { log.Printf(\"ERROR: %#v\\n\", err) } ・接尾辞Fatalメソッド 渡された値を標準出力に出力し，os.Exit(1)を実行して，ステータス『1』で処理を終了する． ＊実装例＊ 渡されたerrorインターフェースを標準出力に出力する． if err != nil { // 内部でos.Exit(1)を実行する． log.Fatalf(\"ERROR: %#v\\n\", err) } ・接尾辞Panicメソッド 渡された値を標準出力に出力し，予期せぬエラーが起きたと見なしてpanicメソッドを実行する．ちなみに，panicメソッドによって，エラーメッセージ出力，スタックトレース出力，処理停止が行われる．使用は非推奨である． 参考：https://github.com/golang/go/wiki/CodeReviewComments#dont-panic ＊実装例＊ 渡されたerrorインターフェースを標準出力に出力する． if err != nil { // panicメソッドを実行する． log.Panicf(\"ERROR: %#v\\n\", err) } 09. テスト ユニットテスト ・テストの単位 ユニットテストは構造体をテストスイートの単位として行う． ・構成 ブラックボックステストとホワイトボックステストから構成される．以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_testing.html ブラックボックステスト ・実現方法 テストファイルのパッケージ名が，同じディレクトリにある実際の処理ファイルに『_test』を加えたパッケージ名の場合，それはブラックボックステストになる．ちなみに，Goでは一つのディレクトリ内に一つのパッケージ名しか宣言できないが，ブラックボックステストのために『_test』を加えることは許されている． ホワイトボックステスト ・実現方法 テストファイルのパッケージ名が，同じディレクトリにある実際の処理ファイルのパッケージ名と同じ場合，それはホワイトボックステストになる． ・網羅率 網羅率はパッケージを単位として解析される．網羅については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_testing.html テストの実装方法のTips ・インターフェースの導入 テストできない構造体はモックに差し替えられることなる．この時，あらかじめ実際の構造体をインターフェースの実装にしておく．テスト時に，モックもインターフェイスの実装とすれば，モックが実際の構造体と同じデータ型として認識されるようになる．これにより，モックに差し替えられるようになる． ・テーブル駆動テスト 参考：https://github.com/golang/go/wiki/TableDrivenTests ・回帰テスト 回帰テストを実現するため，過去のテスト結果をテストデータを保存しておき，今回のテスト結果が過去のものと一致するかを確認する．Goでは，このテストデータをファイルを『Golden File』という．Golden（金）は化学的に安定した物質であることに由来しており，『安定したプロダクト』とかけている．回帰テストについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_testing.html ・POSTデータの切り分け POSTリクエストを受信するテストを行う時に，JSONデータをファイルに切り分けておく．これをReadFile関数で読み出すようにする． ＊実装例＊ package test import ( \"io/ioutil\" ) /** * mainメソッドをテストします． */ func TestMain(t *testing.T) { // jsonファイルの読み出し data, err := ioutil.ReadFile(\"../testdata/foo.json\") // 以下にテストコードを実装していく } 10. ビルトインパッケージ パッケージのソースコード 参考：https://golang.org/pkg/ bytes ・Bufferメソッド 渡された文字列を結合し，標準出力に出力する． ＊実装例＊ package main import ( \"bytes\" \"fmt\" ) func main() { var buffer bytes.Buffer buffer.WriteString(\"Hello \") buffer.WriteString(\"world!\") fmt.Printf(\"%#v\\n\", buffer.String()) // \"Hello world!\" } encoding/json ・Marshal関数 構造体をJSONに変換する．変換前に，マッピングを行うようにする．引数のデータ型は，ポインタ型または非ポインタ型のいずれでも問題ない．ただし，他の多くの関数がポインタ型を引数型としていることから，それに合わせてポインタ型で渡すことが多い． 参考：https://golang.org/pkg/encoding/json/#Marshal ＊実装例＊ package main import ( \"encoding/json\" \"fmt\" \"log\" ) type Person struct { // Marshalに渡す構造体のフィールドはパブリックが必須 Name string `json:\"name\"` } func main() { person := &Person{Name: \"Hiroki\"} // ポインタ型と非ポインタ型の両方の引数に対応 byteJson, err := json.Marshal(person) if err != nil { log.Fatalf(\"ERROR: %#v\\n\", err) } // エンコード結果を出力 fmt.Printf(\"%#v\\n\", string(byteJson)) // \"{\\\"Name\\\":\\\"Hiroki\\\"}\" } この時，構造体のフィールドはパブリックにする必要がある．しかし，MarshalJSON関数を構造体に定義すると，Marshal関数の代わりにこれがコールされるようになる．構造体にゲッターを用意して，MarshalJSON関数でパブリックな構造体を作成するようにすると，プライベートな構造体に対してもMarshal関数を使用できるようになる． package main import ( \"encoding/json\" \"fmt\" \"log\" ) type Person struct { name string } func NewPerson(name string) *Person { return &Person{ name: name, } } func (p *Person) Name() string { return p.name } func (p *Person) MarshalJSON() ([]byte, error) { byteJson, err := json.Marshal(&struct { // ここでjsonタグを定義する． Name string `json:\"name\"` }{ Name: p.Name(), }) return byteJson, err } func main() { person := NewPerson(\"Hiroki\") byteJson, err := json.Marshal(person) if err != nil { log.Fatalf(\"ERROR: %#v\\n\", err) } // エンコード結果を出力 fmt.Printf(\"%#v\\n\", string(byteJson)) // \"{\\\"Name\\\":\\\"Hiroki\\\"}\" } ・Unmarshal関数 JSONを構造体に変換する．リクエストの受信によく使われる．リクエストのメッセージボディにはバイト型データが割り当てられているため，Unmarshal関数の第一引数はバイト型になる．また，第二引数として，変換後の構造体のメモリアドレスを渡すことにより，第一引数がその構造体に変換される．内部的には，そのメモリアドレスに割り当てられている変数を書き換えている．Unmarshal関数に渡す構造体のフィールドはパブリックが必要であるが，Marshal関数と同様にして，UnMarshalJSON関数を構造体に定義すれば，代わりにこれをコールできる． 参考：https://golang.org/pkg/encoding/json/#Unmarshal ＊実装例＊ package main import ( \"encoding/json\" \"fmt\" \"log\" ) type Person struct { // Unmarshalに渡す構造体のフィールドはパブリックが必須 Name string } func main() { // リクエストを受信した場合を想定する． byte := []byte(`{\"name\":\"Hiroki\"}`) var person Person fmt.Printf(\"%#v\\n\", person) // main.Person{Name:\"\"}（変数はまだ書き換えられていない） // person変数を変換後の値に書き換えている． err := json.Unmarshal(byteJson, &person) if err != nil { log.Fatalf(\"ERROR: %#v\\n\", err) } fmt.Printf(\"%#v\\n\", person) // main.Person{Name:\"Hiroki\"}（変数が書き換えられた） } ・RawMessage関数 JSONから構造体にパースするためにUnmarshal関数を実行した時に，部分的にパースせずにJSONのまま取得できる． ＊実装例＊ CloudWatchは様々なイベントを扱うため，一部のJSON構造が動的に変化する．そのため，RawMessage関数が使用されている． 参考：https://github.com/aws/aws-lambda-go/blob/master/events/cloudwatch_events.go package events import ( \"encoding/json\" \"time\" ) type CloudWatchEvent struct { Version string `json:\"version\"` // ～ 省略 ～ Resources []string `json:\"resources\"` // 動的に変化するJSON構造 Detail json.RawMessage `json:\"detail\"` } イベントのJSONを文字列のまま取得できる． package handler import ( \"fmt\" ) /** * Lambdaハンドラー関数 */ func HandleRequest(event events.CloudWatchEvent) (string) { return fmt.Printf(\"%#v\\n\", event.Detail) } ・Indent関数 渡されたJSONにインデントを挿入する．タブを挿入する場合は『\\t』，空白二つを挿入する場合は『 』を設定する．標準出力に出力すると，整形されたJSONを確認できる． package main import ( \"bytes\" \"encoding/json\" \"fmt\" \"log\" ) type Objects struct { Id int Name string } func main() { objects := []Objects{ {1, \"Hiroki\"}, {2, \"Hiroko\"}, {3, \"Hiroshi\"}, } byteJson, err := json.Marshal(objects) if err != nil { log.Fatal(err) } var buf bytes.Buffer // インデント（タブ，空白）を挿入する． json.Indent(&buf, byteJson, \"\", \"\\t\") // json.Indent(&buf, byteJson, \"\", \" \") fmt.Println(buf.String()) } /* 結果 [ { \"Id\": 1, \"Name\": \"Hiroki\" }, { \"Id\": 2, \"Name\": \"Hiroko\" }, { \"Id\": 3, \"Name\": \"Hiroshi\" } ] */ fmt ・接頭接尾辞無しメソッド 接頭接尾辞の無いメソッド（Printメソッド，Sprintメソッド，Fprintメソッド，など）が属する．複数の引数をスペースを挟んで繋ぐ． 参考： https://golang.org/pkg/fmt/#Print https://golang.org/pkg/fmt/#Fprint https://golang.org/pkg/fmt/#Sprint ＊実装例＊ package mainimport \"fmt\"func main() { fmt.Print(\"Hello world!\") // Hello world! } ＊実装例＊ package main import \"fmt\" func main() { // 複数の引数をスペースで挟んで繋ぐ fmt.Print(1, 2, 3) // 1 2 3 } ただし，引数のいずれかが文字列の値の場合，スペースが挿入されない． package main import \"fmt\" func main() { // いずれかが文字列 fmt.Print(\"Hello\", \"world!\", 12345) // Helloworld!12345 } また，連続で使用しても，改行が挿入されない． package main import \"fmt\" func main() { fmt.Print(\"Hello\", \"world!\") fmt.Print(\"Hello\", \"world!\") // Hello world!Hello world! } ・接頭辞Sメソッド 接頭辞にSのあるメソッド（Sprintメソッド，Sprintfメソッド，Sprintlnメソッド，など）が属する．接頭辞がFやPのメソッドとは異なり，処理結果を標準出力に出力せずに返却する．標準出力に出力できる他の関数の引数として渡す必要がある． 参考： https://golang.org/pkg/fmt/#Sprint https://golang.org/pkg/fmt/#Sprintf https://golang.org/pkg/fmt/#Sprintln ＊実装例＊ package mainimport \"fmt\"func main() { // Sprintは返却するだけ fmt.Print(fmt.Sprint(1, 2, 3)) // 1 2 3} ・接尾辞lnメソッド 接尾辞にlnのあるメソッド（Printlnメソッド，Fprintlnメソッド，Sprintlnメソッド，など）が属する．複数の引数をスペースを挟んで繋ぎ，最後に改行を挿入して結合する． 参考： https://golang.org/pkg/fmt/#Println https://golang.org/pkg/fmt/#Fprintln https://golang.org/pkg/fmt/#Sprintln ＊実装例＊ 文字を連続で標準出力に出力する． package mainimport \"fmt\"func main() { fmt.Println(\"Hello\", \"world!\") fmt.Println(\"Hello\", \"world!\") // Hello world! // Hello world!} ・接尾辞fメソッド 渡された引数を，事前に定義したフォーマットにも基づいて結合する． よく使う識別子 標準出力に出力されるもの 備考 %s 文字列またはスライスとして %p ポインタとして %+v フィールドを含む構造体として データの構造を確認できるため，デバッグに有効である． %#v Go構文として データの構造を確認できるため，デバッグに有効である． 参考： https://golang.org/pkg/fmt/#Printf https://golang.org/pkg/fmt/#Fprintf https://golang.org/pkg/fmt/#Sprintf ＊実装例＊ 渡された引数を文字列として結合する package main import \"fmt\" func main() { fmt.Printf(\"String is %s\", \"Hello world!\") } また，連続して使用しても，改行は挿入されない． package main import \"fmt\" func main() { fmt.Printf(\"String is %s\", \"Hello world!\") fmt.Printf(\"String is %s\", \"Hello world!\") // String is Hello world!String is Hello world! } ＊実装例＊ 渡された引数をポインタとして結合する． package main import \"fmt\" type Person struct { Name string } func main() { person:= new(Person) person.Name = \"Hiroki\" fmt.Printf(\"Pointer is %p\", person) // 0xc0000821e0 } ＊実装例＊ 渡された複数の引数を文字列として結合する． package mainimport \"fmt\"func main() { var first string = \"Hiroki\" var last string = \"Hasegawa\" fmt.Printf(\"Im %s %s\", first, last) // Im Hiroki Hasegawa} net/http ・httpパッケージとは HTTPクライアントまたはWebサーバを提供する．そのため，GoではNginxやApacheが不要である．ただ，GoによるWebサーバは機能が不十分である，そのため，NginxやApacheをWebサーバとして，GoをAppサーバとして使用した方が良い． 参考： https://golang.org/pkg/net/http/#pkg-index https://stackoverflow.com/questions/17776584/what-are-the-benefits-of-using-nginx-in-front-of-a-webserver-for-go ・Getメソッド ＊実装例＊ package mainimport ( \"fmt\" \"log\" \"net/http\")func main() { response, err := http.Get(\"http://xxx/api.com\") defer response.Body.Close() if err != nil { log.Fatal(err) } fmt.Println(response.Body)} ・Postメソッド ＊実装例＊ package mainimport ( \"bytes\" \"encoding/json\" \"fmt\" \"log\" \"net/http\")type User struct { id int `json:\"id\"` name string `json:\"name\"`}// コンストラクタfunc NewUser(id int, name string) *User { return &User{ id: id, name: name, }}func main() { user := NewUser(1, \"Hiroki\") byteJson, err := json.Marshal(user) response, err := http.Post( \"http://xxx/api.com\", // URL \"application/json\", // Content-Type bytes.NewBuffer(byteJson), // メッセージボディ ) defer response.Body.Close() if err != nil { log.Fatal(err) } fmt.Println(response.Body)} ・NewRequestメソッド ＊実装例＊ package main import ( \"bytes\" \"encoding/json\" \"fmt\" \"log\" \"net/http\" ) type User struct { id int `json:\"id\"` name string `json:\"name\"` } // コンストラクタ func NewUser(id int, name string) *User { return &User{ id: id, name: name, } } func main() { user := NewUser(1, \"Hiroki\") byteJson, err := json.Marshal(user) // リクエストを作成する． request, err := http.NewRequest( \"POST\", // HTTPメソッド \"http://xxx/api.com\", // URL bytes.NewBuffer(byteJson), // メッセージボディ ) // ヘッダーを作成する． request.Header.Set(\"Content-Type\", \"application/json\") // Content-Type // クライアントを作成する． client := &http.Client{} // リクエストを送信する． response, err := client.Do(request) defer response.Body.Close() if err != nil || response.StatusCode != 200 { log.Fatal(err) } // レスポンスのボディを取得する． // 代わりに，httputil.DumpResponseを使用してもよい． body, _ := ioutil.ReadAll(response.Body) log.Println(string(body)) } ・ListenAndServeメソッド サーバを起動する．第一引数にサーバのURL，第二引数にServeMux関数（マルチプレクサ関数）を渡す．第二引数にnilを渡した場合，デフォルト引数としてhttp.DefaultServeMuxが渡される． ＊実装例＊ package main import ( \"net/http\" \"log\" ) func main() { err := http.ListenAndServe(\":8080\", nil) // 以下でも同じ． // http.ListenAndServe(\":8080\", http.DefaultServeMux) if err != nil { log.Fatal(\"Error ListenAndServe : \", err) } } ・NewServeMuxメソッド サーバーを起動するListenAndServeメソッドに対して，自身で定義したServeMux関数を渡す場合，NewServeMuxメソッドを使用する必要がある．これのHandleFunc関数に対してルーティングと関数を定義する． ＊実装例＊ HTMLをレスポンスとして返信するサーバ（http://localhost:8080/）を起動する． package main import ( \"log\" \"net/http\" ) func myHandler(writer http.ResponseWriter, request *http.Request) { // HTMLをレスポンスとして返信する． fmt.Fprintf(writer, \"Hello world!\") } func main() { mux := http.NewServeMux() // ルーティングと関数を設定する． mux.HandleFunc(\"/\", myHandler) // サーバを起動する． err := http.ListenAndServe(\":8080\", mux) if err != nil { log.Fatal(\"Error ListenAndServe : \", err) } } JSONをレスポンスとして返信するサーバ（http://localhost:8080/）を起動する． package main import ( \"encoding/json\" \"log\" \"net/http\" ) type User struct { Id int `json:\"id\"` Name string `json:\"name\"` } // コンストラクタ func NewUser(id int, name string) *User { return &User{ Id: id, Name: name, } } func myHandler(writer http.ResponseWriter, request *http.Request) { user := NewUser(1, \"Hiroki\") byteJson, err := json.Marshal(user) if err != nil { log.Fatal(err) } // JSONをレスポンスとして返信する． writer.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\") writer.Write(byteJson) } func main() { mux := http.NewServeMux() // ルーティングと関数を設定する． mux.HandleFunc(\"/\", myHandler) // サーバを起動する． err := http.ListenAndServe(\":8080\", mux) if err != nil { log.Fatal(err) } } os ・Open関数 ファイルをReadOnly状態にする． package main import ( \"fmt\" \"os\" ) func main() { file, err := os.Open(\"filename.txt\") if err != nil { log.Fatalf(\"ERROR: %#v\\n\", err) } fmt.Printf(\"%#v\\n\", file) } reflect ・TypeOfメソッド，ValueOfメソッド 構造体からフィールド情報を取得する．フィールドが複数ある場合は，要素番号の指定が必要になるため，事前に要素数を取得するようにしておく． package main import ( \"fmt\" \"reflect\" ) type Foo struct { bar string baz int } func main() { foo := &Foo{bar: \"BAR\", baz: 1} fields := reflect.TypeOf(*foo) fmt.Println(fields) values := reflect.ValueOf(*foo) // 再帰的にフィールドと値を取得する for i := 0; i strings ・Builder関数 渡された文字列を結合し，標準出力に出力する． ＊実装例＊ package main import ( \"fmt\" \"strings\" ) func main() { var builder strings.Builder builder.WriteString(\"Hello \") builder.WriteString(\"world!\") fmt.Println(builder.String()) // Hello world! } "},"public/backend_go_package.html":{"url":"public/backend_go_package.html","title":"▶ パッケージ","keywords":"","body":"Goパッケージ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ビルトインパッケージ 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_go_logic.html 02. aws-sdk-go-v2 aws-sdk-go-v2とは 参考：https://pkg.go.dev/github.com/aws/aws-sdk-go-v2?tab=versions awsとは 汎用的な関数が同梱されている． 参考：https://pkg.go.dev/github.com/aws/aws-sdk-go-v2/aws?tab=versions ポインタ型から文字列型に変換するToString関数や，反対に文字列型からポインタ型に変換するString関数をよく使う． 参考： https://pkg.go.dev/github.com/aws/aws-sdk-go-v2/aws#String https://pkg.go.dev/github.com/aws/aws-sdk-go-v2/aws#ToString ・serviceパッケージ 参考：https://pkg.go.dev/github.com/aws/aws-sdk-go-v2/service/amplify?tab=versions 03. aws-lambda-go 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws_lambda_function.html 04. gorm gormとは Go製のORMである． Gormモデル ・Gormモデル埋め込み 構造体にGormモデルを埋め込むと，IDやタイムスタンプレコードがフィールドとして追加される．構造体をマッピングしたテーブルに，idカラム，created_atカラム，updated_atカラム，deleted_atカラムが追加される． 参考：https://gorm.io/ja_JP/docs/models.html#embedded_struct type User struct { gorm.Model Name string } // 以下と同じ type User struct { ID uint `gorm:\"primaryKey\"` Name string CreatedAt time.Time UpdatedAt time.Time DeletedAt gorm.DeleteAt `gorm:\"index\"` } ・プライマリキー 『ID』という名前のフィールドを認識して，これをプライマリキーとしてデータをマッピングする．もし，他の名前のフィールドをIDとして使用したい場合は，gorm:\"primaryKey\"タグをつける． 参考：https://gorm.io/ja_JP/docs/conventions.html#ID-as-Primary-Key type User struct { ID string // プライマリキーとして使用される． Name string } type User struct { UserID string `gorm:\"primaryKey\"` // プライマリキーとして使用される． Name string } ・SoftDelete 構造体が，gorm.DeleteAtをデータ型とするフィールドを持っていると，その構造体を用いたDELETE処理では論理削除が実行される．Gormモデルを埋め込むことによりこのフィールドを持たせるか，または独自定義することにより，SoftDeleteを有効化できる． 参考：https://gorm.io/ja_JP/docs/delete.html#Soft-Delete type User struct { ID int Deleted gorm.DeletedAt Name string } user := User{Id:111} // user's ID is `111` db.Delete(&user) // UPDATE users SET deleted_at=\"2013-10-29 10:23\" WHERE id = 111; // Batch Delete db.Where(\"age = ?\", 20).Delete(&User{}) // UPDATE users SET deleted_at=\"2013-10-29 10:23\" WHERE age = 20; // Soft deleted records will be ignored when querying db.Where(\"age = 20\").Find(&user) // SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL; マイグレーション ・TableNameメソッド 標準ではGormモデルの名前をスネークケースに変更し，また複数形とした名前のテーブルが生成される．TableNameメソッドにより，独自のテーブル名をつけられる． 参考：https://gorm.io/ja_JP/docs/conventions.html#TableName // テーブル名は標準では『users』になる． type User struct { ID int Deleted gorm.DeletedAt Name string } // テーブル名を『foo』になる． func (User) TableName() string { return \"foo\" } Create Gormモデルのフィールドに設定された値を元に，カラムを作成する．作成したカラムのプライマリキーを，構造体から取得できる． 参考：https://gorm.io/docs/create.html#Create-Record user := User{Name: \"Jinzhu\", Age: 18, Birthday: time.Now()} result := db.Create(&user) // pass pointer of data to Create user.ID // returns inserted data's primary key result.Error // returns error result.RowsAffected // returns inserted records count Read ・全カラム取得 参考：https://gorm.io/ja_JP/docs/query.html#Retrieving-all-objects user := User{} // Get all records result := db.Find(&users) // SELECT * FROM users; result.RowsAffected // returns found records count, equals `len(users)` result.Error // returns error ・単一／複数カラム取得 Gormモデルとプライマリキーを指定して，プライマリキーのモデルに関連づけられたカラムを取得する． 参考：https://gorm.io/ja_JP/docs/query.html#Retrieving-objects-with-primary-key user := User{} db.First(&user, 10) // SELECT * FROM users WHERE id = 10; db.First(&user, \"10\") // SELECT * FROM users WHERE id = 10; db.Find(&users, []int{1,2,3}) // SELECT * FROM users WHERE id IN (1,2,3); Update ・単一カラム更新（暗黙的） フィールドとは無関係に，渡された値を元にUPDATE分を実行する． 参考：https://gorm.io/ja_JP/docs/update.html#Update-single-column // Update with conditions db.Model(&User{}).Where(\"active = ?\", true).Update(\"name\", \"hello\") // UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE active=true; user := User{Id:111} // User's ID is `111`: db.Model(&user).Update(\"name\", \"hello\") // UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE id=111; // Update with conditions and model value db.Model(&user).Where(\"active = ?\", true).Update(\"name\", \"hello\") // UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE id=111 AND active=true; ・複数カラム更新（暗黙的） Gormモデルのフィールドを暗黙的に指定して，複数のカラム値を更新する．または，フィールドとは無関係に，マップデータを元にUPDATE文を実行する．Gormモデルを使用した場合，フィールド値がゼロ値であると，これに関連づけられたカラム値の更新はスキップされてしまう． 参考：https://gorm.io/ja_JP/docs/update.html#Updates-multiple-columns user := User{Id:111} // Update attributes with `struct`, will only update non-zero fields db.Model(&user).Updates(User{Name: \"hello\", Age: 18, Active: false}) // UPDATE users SET name='hello', age=18, updated_at = '2013-11-17 21:34:10' WHERE id = 111; // Update attributes with `map` db.Model(&user).Updates(map[string]interface{}{\"name\": \"hello\", \"age\": 18, \"active\": false}) // UPDATE users SET name='hello', age=18, active=false, updated_at='2013-11-17 21:34:10' WHERE id=111; ・複数カラム更新（明示的） Gormモデルのフィールドを明示的に指定して，複数のカラム値を更新する．フィールド値がゼロ値であっても，スキップされない． 参考：https://gorm.io/ja_JP/docs/update.html#Update-Selected-Fields user := User{Id:111} // Select with Struct (select zero value fields) db.Model(&user).Select(\"Name\", \"Age\").Updates(User{Name: \"new_name\", Age: 0}) // UPDATE users SET name='new_name', age=0 WHERE id=111; // Select all fields (select all fields include zero value fields) db.Model(&user).Select(\"*\").Updates(User{Name: \"jinzhu\", Role: \"admin\", Age: 0}) // UPDATE users SET name='new_name', age=0 WHERE id=111; ・全カラム更新 Gormモデルのフィールドを暗黙的に全て指定して，全てのカラム値を強制的に更新する． 参考：https://gorm.io/ja_JP/docs/update.html#Save-All-Fields user := User{Id:111} db.First(&user) user.Name = \"jinzhu 2\" user.Age = 100 db.Save(&user) // UPDATE users SET name='jinzhu 2', age=100, birthday='2016-01-01', updated_at = '2013-11-17 21:34:10' WHERE id=111; 05. testify testifyとは モック，スタブ，アサーションメソッドを提供するライブラリ．Goではオブジェクトの概念がないため，モックオブジェクトとは言わない．モックとスタブについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_testing.html mock，assert ・モック化 よく使うメソッド 説明 なし データとして，構造体にMockを設定すれば，その構造体はモック化される． ＊実装例＊ AWSクライアントをモック化する． package amplify import ( \"github.com/stretchr/testify/mock\" ) /** * AWSクライアントをモック化します． */ type MockedAwsClient struct { mock.Mock } ・スタブ化 参考：https://pkg.go.dev/github.com/stretchr/testify/mock?tab=versions よく使うメソッド 説明 Mock.Calledメソッド 関数の一部の処理をスタブ化する時に使用する．関数に値が渡されたことをモックに伝える． Arguments.Getメソッド 関数の一部の処理をスタブ化する時に使用する．引数として，返却値の順番を渡す．独自のデータ型を返却する処理を定義する． Arguments.Errorメソッド 関数の一部の処理をスタブ化する時に使用する．引数として，返却値の順番を渡す．エラーを返却する処理を定義する． ＊実装例＊ 関数の一部の処理をスタブ化し，これをAWSクライアントのモックに関連付ける． package amplify import ( aws_amplify \"github.com/aws/aws-sdk-go-v2/service/amplify\" \"github.com/stretchr/testify/mock\" ) type MockedAmplifyAPI struct { mock.Mock } /** * AmplifyのGetBranch関数の処理をスタブ化します． */ func (mock *MockedAmplifyAPI) GetBranch(ctx context.Context, params *aws_amplify.GetBranchInput, optFns ...func(*aws_amplify.Options)) (*aws_amplify.GetBranchOutput, error) { arguments := mock.Called(ctx, params, optFns) return arguments.Get(0).(*aws_amplify.GetBranchOutput), arguments.Error(1) } ・アサーションメソッドによる検証 参考： https://pkg.go.dev/github.com/stretchr/testify/mock?tab=versions https://pkg.go.dev/github.com/stretchr/testify/assert?tab=versions よく使うメソッド 説明 Mock.Onメソッド 関数の検証時に使用する．関数内部のスタブに引数として渡される値と，その時の返却値を定義する． Mock.AssertExpectationsメソッド 関数の検証時に使用する．関数内部のスタブが正しく実行されたかどうかを検証する． assert.Exactlyメソッド 関数の検証時に使用する．期待値と実際値の整合性を検証する．値だけでなく，データ型も検証できる． ・前処理と後処理 テスト関数を実行する直前に，前処理を実行する．モックの生成のために使用するとよい．PHPUnitにおける前処理と後処理については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_testing.html 前処理と後処理については，以下のリンクを参考にせよ． 参考：https://github.com/google/go-github/blob/master/github/github_test.go#L36-L66 よく使う関数 実行タイミング 説明 SetupSuite 1 テストスイート内の全てのテストの前処理として，一回だけ実行する． SetupTest 2 テストスイート内の各テストの前処理として，テストの度に事前に実行する．BeforeTest関数よりも前に実行されることに注意する． BeforeTest 3 テストスイート内の各テストの直前の前処理として，テストの度に事前に実行する．必ず，『suiteName』『testName』を引数として設定する必要がある． AfterTest 4 テストスイート内の各テストの直後の後処理として，テストの度に事後に実行する．必ず，『suiteName』『testName』を引数として設定する必要がある． TearDownTest 5 テストスイート内の各テストの後処理として，テストの度に事後に実行する．BeforeTest関数よりも後に実行されることに注意する． TearDownSuite 6 テストスイート内の全てのテストの後処理として，一回だけ実行する． ＊実装例＊ 事前にモックを生成するために，BeforeTest関数を使用する． package foo import ( \"testing\" ) /** * ユニットテストのテストスイートを構成する． */ type FooSuite struct { suite.Suite fooMock *FooMock } /** * ユニットテストの直前の前処理を実行する． */ func (suite *FooSuite) BeforeTest(suiteName string, testName string) { // モックを生成する． suite.fooMock = &FooMock{} } /** * ユニットテストのテストスイートを実行する． */ func TestFooSuite(t *testing.T) { suite.Run(t, &FooSuite{}) } package foo import ( \"github.com/stretchr/testify/assert\" ) /** * Methodメソッドが成功することをテストする． */ func (suite *FooSuite) TestMethod() { suite.T().Helper() // 前処理で生成したモックを使用する． fooMock := suite.fooMock // 以降にテスト処理 } 06. validator validatorとは バリデーションとエラーメッセージ package validators import ( \"fmt\" \"github.com/go-playground/validator\" ) type FoobarbazValidator struct { Foo string `json:\"foo\" validate:\"required\"` Bar string `json:\"bar\" validate:\"required\"` Baz string `json:\"baz\" validate:\"required\"` } // NewValidator コンストラクタ func NewValidator() *Validator { return &Validator{} } // Validate バリデーションを実行します． func (v *FoobarbazValidator) Validate() map[string]string { err := validator.New().Struct(v) var errorMessages = make(map[string]string) if err != nil { for _, err := range err.(validator.ValidationErrors) { switch err.Field() { // フィールドごとにマップ形式でバリデーションメッセージを構成します． case \"foo\": errorMessages[\"foo\"] = v.stringValidation(err) errorMessages[\"foo\"] = v.requiredValidation(err) case \"bar\": errorMessages[\"bar\"] = v.stringValidation(err) case \"baz\": errorMessages[\"baz\"] = v.stringValidation(err) errorMessages[\"baz\"] = v.requiredValidation(err) } } } return errorMessages } // stringValidation 文字列型指定のメッセージを返却します． func (v *FoobarbazValidator) stringValidation(err validator.FieldError) string { return fmt.Sprintf(\"%s は文字列のみ有効です\", err.Field()) } // requiredValidation 必須メッセージを返却します． func (v *FoobarbazValidator) requiredValidation(err validator.FieldError) string { return fmt.Sprintf(\"%s は必須です\", err.Field()) } package main import ( \"encoding/json\" \"fmt\" \"log\" \"github.com/foobarbaz_repository/validators\" ) func main() { v := NewFoobarbazValidator() // JSONを構造体にマッピングします． err := json.Unmarshal([]byte(`{\"foo\": \"test\", \"bar\": \"test\", \"baz\": \"test\"}`), v) if err != nil { log.Println(\"JSONエンコードに失敗しました。\") } // バリデーションを実行します． errorMessages := v.Validate() if len(errorMessages) > 0 { // マップをJSONに変換します． byteJson, _ := json.Marshal(errorMessages) fmt.Printf(\"%#v\\n\", byteJson) } // エンコード結果を出力します． fmt.Println(\"データに問題はありません．\") } 07. 外部パッケージの管理 コマンド ・go mod tidy インポートされているパッケージに合わせて，go.modファイルとgo.sumファイルを更新する． $ go mod tidy go.modファイル ・go.modファイルとは PHPにおけるcomposer.jsonファイルに相当する．インターネット上における自身のパッケージ名とGoバージョンを定義するために，全てのGoアプリケーションで必ず必要である．インストールしたい外部パッケージも定義できる． module github.com/hiroki-it/foo_repository go 1.16 ・インターネットからインポート パッケージ名とバージョンタグを用いて，インターネットからパッケージをインポートする．go mod tidyコマンドによってindirectコメントのついたパッケージが実装される．これは，使用しているパッケージではなく，インポートしているパッケージが依存しているパッケージである．なお，パッケージ名は，使用したいパッケージのgo.modファイルを参照すること． 参考：https://github.com/golang/go/wiki/Modules#should-i-commit-my-gosum-file-as-well-as-my-gomod-file module github.com/hiroki-it/repository go 1.16 require ( github.com/foo v1.3.0 github.com/bar v1.0.0 github.com/baz // indirect ) import \"github.com/bar\" func main() { // 何らかの処理 } ・ローカルPCからインポート ローカルPCでのみ使用する独自共有パッケージは，インターネット上での自身のリポジトリからインポートせずに，replace関数を使用してインポートする必要がある．独自共有の全パッケージでパッケージ名を置換する必要はなく，プロジェクトのルートパスについてのみ定義すればよい．パス実際，unknown revisionのエラーで，バージョンを見つけられない． 参考：https://qiita.com/hnishi/items/a9217249d7832ed2c035 module foo.com/hiroki-it/repository go 1.16 replace github.com/hiroki-it/foo_repository => / また，ルートディレクトリだけでなく，各パッケージにもgo.modファイルを配置する必要がある． foo_repository ├── cmd │ └── hello.go │ ├── go.mod ├── go.sum └── local-pkg ├── go.mod # 各パッケージにgo.modを配置する． └── module.go module foo.com/hiroki-it/foo_repository/local-pkg go 1.16 これらにより，ローカルのパッケージをインポートできるようになる． import \"local.packages/local-pkg\" func main() { // 何らかの処理 } go.sumファイル ・go.sumファイルとは PHPにおけるcomposer.lockファイルに相当する．go.modファイルによって実際にインストールされたパッケージが自動的に実装される．パッケージごとのチェックサムが記録されるため，前回のインストール時と比較して，ライブラリに変更があるかどうかを検知できる． "},"public/backend_go_framework_gin.html":{"url":"public/backend_go_framework_gin.html","title":"▶ Gin","keywords":"","body":"Gin はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ Context Bind ・処理 リクエストメッセージからデータを取得し，構造体に関連づける．Cotent-TypeヘッダーのMIMEタイプに応じて，バインド関数をコールし分ける． 参考：https://pkg.go.dev/github.com/gin-gonic/gin?utm_source=godoc#Context.Bind BindJSON ・処理 Content-TypeヘッダーのMIMEタイプがapplication/jsonであることが前提である．リクエストメッセージからJSONデータを取得し，構造体に関連づける． 参考：https://pkg.go.dev/github.com/gin-gonic/gin?utm_source=godoc#Context.BindJSON BindQuery ・処理 クエリパラメータからデータを取得し，構造体に関連づける． Get ・処理 同一のリクエストにてSet関数でセットされたマップ型データから，インターフェース型で値を取得する．値が存在しない場合は，第二返却値でfalseを返却する． 参考：https://pkg.go.dev/github.com/gin-gonic/gin#Context.Get ShouldBindQuery（= ShouldBindWith） ・処理 クエリパラメータからデータを取得し，指定したバインディングツールを使用して，構造体に関連づける． JSON ・処理 JSONデータとして，レスポンスを返信する．第二引数の引数型がインターフェースになっているため，様々なデータ型を渡せる． ＊実装例＊ マップ型データを渡す． c.JSON(200, gin.H{ \"id\": 1, \"name\": \"hiroki hasegawa\", }) 構造体型データを渡す． type Foo struct { id int json:\"id\" name string json:\"name\" } c.JSON(200, &Foo{ id: 1, name: \"hiroki hasegawa\", }) MustGet ・処理 同一のリクエストにてSet関数でセットされたマップ型データから，インターフェース型で値を取得する．値が存在しない場合は，ランタイムエラーとなる． 参考：https://pkg.go.dev/github.com/gin-gonic/gin#Context.MustGet Param ・処理 クエリパラメータからデータを取得する．この後，構造体に関連づける場合は，BindQuery関数を使用した方が良い． Set ・処理 当該のリクエストで利用できるマップ型データに，値を保存する． 参考：https://pkg.go.dev/github.com/gin-gonic/gin#Context.Set ・注意点 データ型を変換した値をSet関数で保存しないようにすることである．Set関数後にGet関数で取得される値は，元々のデータ型に関係なくインターフェース型に変換されてしまう．そのため，例えば，タイプID型として値を保存したとしても，Get関数で得られたインターフェース型データを改めて変換しないといけなくなってしまう． ＊実装例＊ package middlewares import ( \"strconv\" \"github.com/gin-gonic/gin\" ) // ConvertId パスパラメータのidのデータ型を変換します． func ConvertId() gin.HandlerFunc { return func(ctx *gin.Context) { id, err := strconv.Atoi(ctx.Param(\"id\")) if err != nil { _ = ctx.Error(err) return } ctx.Set(\"id\", id) ctx.Next() } } package controller type UserController struct { *interfaces.Controller userInteractor *interactor.UserInteractor } func (uc *UserController) GetUser(ctx *gin.Context) { // インターフェース型になってしまう． userId, ok := ctx.Get(\"id\") if !ok { uc.SendErrorJson(ctx, 400, []string{\"Parameters are not found.\"}) return } Util H マップ型の変数のエイリアスとして働く． type H map[string]interface{} c.JSON(200, gin.H{ \"id\": 1, \"name\": \"hiroki hasegawa\", }) c.JSON(400, gin.H{ \"errors\": []string{ \"Fooエラーメッセージ\", \"Barエラーメッセージ\", } }) Validator tag ・binding バリデーションのルールを定義する．標準のルールの一覧は，以下のリンクを参考にせよ． 参考：https://github.com/go-playground/validator/blob/65bb1236771df9bc1630c78a43b0bfea10fe7122/baked_in.go#L70 "},"public/backend_api_restful.html":{"url":"public/backend_api_restful.html","title":"▶ ︎RESTful APIの概念と実装","keywords":"","body":"RESTful APIの概念と実装 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. RESTとRESTfulとは REST ・RESTとは 分散型アプリケーションを構築する時に，それぞれアプリケーションを連携させるのに適したアーキテクチャスタイルをRESTという．また，アーキテクチャスタイルについては，オブジェクト指向に関するノートを参照せよ．RESTは，以下の特徴を持つ． ・RESTfulとRESTful APIとは RESTに基づいた設計をRESTfulという．RESTful設計が用いられたWebAPIをRESTful APIという．例えば，RESTful APIの場合，DBにおけるUserInfoのCRUDに対して，一つの『/UserInfo』というURIを対応づけている． RESTの４原則 ・Stateless クライアントに対してレスポンスを返信した後に，クライアントの情報を保持せずに破棄する仕組みのこと．擬似的にStatefulな通信を行う時は，キャッシュ，Cookie，セッションIDを用いて，クライアントの情報を保持する． Statelessプロトコル Statefulプロトコル HTTP SSH HTTPS TLS/SSL - SFTP ・Connectability ・Uniform Interface HTTPプロトコルを使用したリクエストを，『リソースに対する操作』とらえ，リクエストにHTTPメソッドを対応づけるようにする． ・Addressability エンドポイントによって，特定のリソースを操作できること． 02. Addressability エンドポイント ・エンドポイントとは 特定のリソースを操作するための固有のURIのこと．エンドポイント は，リソース1つごと，あるいはまとまりごとに割り振られる． ・HTTPメソッド，エンドポイント，ユースケースの対応関係 RESTfulAPIでは，全てのHTTPメソッドの内，主に以下の4つを使用して，データ処理の方法をリクエストする．それぞれが，APIのユースケースに対応する．ユースケースごとのメソッド名については，Laravelを参考にする． 参考：https://noumenon-th.net/programming/2020/01/30/laravel-crud/ HTTPメソッド エンドポイント ユースケース メソッド名の例 GET https://example.co.jp/users ・全データのインデックス取得・条件に基づくデータの取得 index https://example.co.jp/users/{id} IDに基づくデータの取得 show POST https://example.co.jp/users ・データの作成・PDFの作成・ファイルデータの送信・ログイン／ログアウト create，store PUT` https://example.co.jp/users/{id} データの更新（置換） update DELETE https://example.co.jp/users/{id} データの削除 delete，destroy ・POST送信 vs PUT送信 POST送信とPUT送信の重要な違いについてまとめる．データを作成するユースケースの時はPOST送信，または更新する時はPUT送信を使用する．ただしもっと正確には，ユースケースが『作成』or『更新』ではなく，『非冪等』or『冪等』で判断したほうが良い． 参考： https://stackoverflow.com/a/2691891/12771072 https://restfulapi.net/rest-put-vs-post/ POST送信 PUT送信 データ作成の冪等性 リクエスト1つにつき，1つのデータを作成（非冪等的） リクエスト数に限らず，1つのデータを作成する（冪等的）．古いデータを新しいデータに置換する行為に近い． リクエストパラメータの場所 メッセージボディにJSONデータなどを割り当てる． パスパラメータにidなど，またメッセージボディにJSONデータなどを割り当てる． パラメータの割り当て方法 ・パス，クエリストリングへの割り当て URIの構造のうち，パスまたはクエリストリングにパラメータを割り当てて送信する．それぞれ，パスパラメータまたはクエリパラメータという． GET https://example.co.jp:80/users/777?text1=a&text2=b 完全修飾ドメイン名 送信先のポート番号（80の場合は省略可） ルート パスパラメータ ？ クエリパラメータ（GET送信時のみ） https://example.co.jp 80 users {id} ? text1=a&text2=b ・使い分け（再掲） データの送信対象 パスパラメータ クエリパラメータ 単一条件で決まる検索処理 ◯ △ 複数条件で決まる検索処理 ✕ ◯ フィルタリング処理 ✕ ◯ ソーティング処理 ✕ ◯ ・メッセージボディへの割り当て JSON型データ内に定義し，メッセージボディにパラメータを割り当てて送信する． POST https://example.co.jp HTTP/2 # メッセージボディ { \"id\": 1, \"name\": \"foo\", } ・リクエストヘッダーへの割り当て リクエストヘッダーにパラメータを割り当てて送信する．送信時のヘッダー名は大文字でも小文字でもいずれでも問題ないが，内部的に小文字に変換されるため，小文字が推奨である．APIキーのヘッダー名の頭文字に『X』を付けるのは，独自ヘッダーの頭文字に『X』を付ける慣習があったためである．ただし，現在は非推奨である． 参考：https://developer.mozilla.org/ja/docs/Web/HTTP/Headers POST https://example.co.jp HTTP/2 # Authorizationヘッダー authorization: Bearer ${Token} # APIキーヘッダー x-api-key: ***** レスポンスのステータスコード ・使い分け コード 概要 説明 200 成功 正しいリクエストである． 401 認証エラー 誤ったリクエストである．認証プロセスで正しいトークンが発行されず，認可プロセスのリクエストでこの誤ったトークンを送信したことを表している．認可の失敗ではなく，認証の失敗であることに注意する． 403 認可エラーによるトークン所有者の認可スコープ外 誤ったリクエストである．APIに認証プロセスが存在し，トークンの発行が必要だとする．認証プロセスにて正しいトークンが発行されたが，認可プロセスにてトークンの所有者の認可スコープ外と判定されたことを表している． 送信元IPアドレスの閲覧禁止 誤ったリクエストである．APIに認証認可プロセスが存在せず，トークン発行と閲覧権限検証が不要だとする．送信元IPアドレスに閲覧権限がないと判定されてことを表している． 404 ページが見つからない 誤ったリクエストである．存在しないデータをリクエストしていることを表している． 409 競合エラー 誤ったリクエストである．UPDATE処理による新しいデータと現在のDBのデータの間で競合が起こっていることを表している．楽観的ロックによる排他制御の結果として使用する．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_database_operation.html 412 リソースアクセスエラー 誤ったリクエストである．リソースへのアクセスに失敗したことを表している． 422 バリデーションエラー 誤ったリクエストである．送信されたパラメータが誤っていることを示している． 500 サーバエラー サーバーの処理でランタイムエラーが起こっている．エラーの種類については，以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html 503 ビジネスロジックエラー エラーは起こらないが，ビジネス上ありえないデータをリクエストしていることを表す． ・リダイレクトとリライトの違い リダイレクトでは，リクエストされたURLをサーバ側で新しいURLに書き換えてブラウザに返信し，ブラウザがリクエストを再送信する．そのため，クライアント側は新しいURLで改めてリクエストを送信することになる．一方で，リライトでは，リクエストされたURLをサーバ側で異なるURLに書き換え，サーバがそのままリクエストを送信する．そのため，クライアント側は古いURLのままリクエストを送信することになる．その他の違いについては，以下を参考にせよ． 参考：https://blogs.iis.net/owscott/url-rewrite-vs-redirect-what-s-the-difference ・リライトとフォワードの違い リライトでは異なるサーバにリクエストを送信できるが，フォワードでは同一サーバ内の異なるファイルにアクセスすることしかできない． リソースアクセスのエンドポイントの作り方 ・動詞を使用しないこと すでにHTTPメソッド自体に動詞の意味合いが含まれるため，エンドポイントに動詞を含めないようにする．この時，アクセスするリソース名がわかりやすいような名詞を使用する． 参考： https://cloud.google.com/blog/products/api-management/restful-api-design-nouns-are-good-verbs-are-bad https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-design/#h-use-nouns-instead-of-verbs-in-endpoint-paths ただし慣例として，認証のエンドポイントが動詞（login，logout，register）になることは許容されている． 参考： https://stackoverflow.com/questions/7140074/restfully-design-login-or-register-resources https://www.developer.com/web-services/best-practices-restful-api ＊悪い実装例＊ GET https://example.co.jp/show-user/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 GET https://example.co.jp/users/hiroki_hasegawa ＊認証の場合＊ 動詞を許容するのであればloginやlogoutとし，名詞を採用するのであればsessionとする． GET https://example.co.jp/login GET https://example.co.jp/session ・短くすること ＊悪い実装例＊ ここで，service，api，といったキーワードは，なくても問題ない． GET https://example.co.jp/service/api/users/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 ・略称を使わないこと ＊悪い実装例＊ ここで，Usersを意味する『u』といった略称は，当時の設計者しかわからないため，不要である． GET https://example.co.jp/u/12345 ＊良い実装例＊ 略称を使わずに，『users』とする． GET https://example.co.jp/users/12345 ・小文字を使うこと ＊悪い実装例＊ GET https://example.co.jp/Users/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 ・ケバブケースを使うこと ＊悪い実装例＊ GET https://example.co.jp/users_id/12345 ＊良い実装例＊ スネークケースやキャメケースを使わずに，ケバブケースを使用する． GET https://example.co.jp/users-id/12345 ただ，そもそもケバブ方式も利用せずに，スラッシュで区切ってしまうのも手である GET https://example.co.jp/users/id/12345 ・複数形を使用すること ＊悪い実装例＊ Usersという集合の中に，Idが存在しているため，単数形は使わない． GET https://example.co.jp/user/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 ・システムの設計方法がバレないURIにすること ＊悪い実装例＊ 悪意のあるユーザに，脆弱性を狙われる可能性があるため，システムの設計方法がばれないアーキテクチャにすること．ミドルウェアにCGIプログラムが使用されていることや，phpを使用していることがばれてしまう． GET https://example.co.jp/cgi-bin/get_users.php ＊良い実装例＊ GET https://example.co.jp/users/12345 ・HTTPメソッドの名前を使用しないこと ＊悪い実装例＊ メソッドから，処理の目的はわかるので，URIに対応する動詞名を実装する必要はない． GET https://example.co.jp/users/get/12345 POST https://example.co.jp/users/create/12345 PUT https://example.co.jp/users/update/12345 DELETE https://example.co.jp/users/delete/12345 ＊良い実装例＊ GET https://example.co.jp/users/{id} POST https://example.co.jp/users PUT https://example.co.jp/users/{id} DELETE https://example.co.jp/users/{id} ・数字，バージョン番号を可能な限り使用しないこと ＊悪い実装例＊ ここで，alpha，v2，といったキーワードは，当時の設計者しかわからないため，あまり良くない．ただし，利便上，使う場合もある． GET https://example.co.jp/v2/users/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 URLにバージョンを表記しない代わりに，リクエストヘッダーのX-api-Versionにバージョン情報を格納する方法がより良い． X-Api-Version: 1 ・異なるHTTPメソッドの間でルールを統一すること ＊悪い実装例＊ GET送信とPOST送信の間で，IDパラメータのHTTPメソッドが統一されていない． GET https://example.co.jp/users/?id=12345 POST https://example.co.jp/users/12345/messages ＊良い実装例＊ 以下のように，異なるHTTPメソッドの間でも統一する． GET https://example.co.jp/users/12345 POST https://example.co.jp/users/12345/messages 03. リクエスト／レスポンスメッセージ メッセージとは アプリケーション層で生成されるデータを，メッセージという．リクエスト時にクライアント側で生成されるメッセージをリクエストメッセージ，レスポンス時にサーバ側で生成されるメッセージをレスポンスメッセージという． リクエストメッセージの構造 ・GET送信の場合 クエリパラメータに送信するデータを記述する方法．リクエストメッセージは，以下の要素に分類できる．以下では，Web APIのうち，特にRESTfulAPIに対して送信するためのリクエストメッセージの構造を説明する． GET https://example.co.jp/bar-form.php?text1=a&text2=b HTTP/2 # リクエストされたドメイン名 Host: example.co.jp Connection: keep-alive Upgrade-Insecure-Requests: 1 # ブラウザキャッシュの最大有効期限（リクエストヘッダーとレスポンスヘッダーの両方で定義可能） Cache-Control: max-age=31536000 # ブラウザのバージョン情報等 User-Agent: Mozzila/5.0 (Windows NT 10.0; Win64; x64) Ch # レスポンス返信してほしいMIMEタイプ Accept: text/html, application/xhtml+xml, application/xml; q=0 # レスポンスで返信してほしいエンコーディング形式 Accept-Encondig: gzip, deflate, br # レスポンスで返信してほしい言語 Accept-Language: ja, en-US; q=0.9, en; q=0.8 # 遷移元のページ Referer: https://foo.co.jp/ # 送信元IPアドレス # ※プロキシサーバ（ALBやCloudFrontなども含む）を経由している場合に，それら全てのIPアドレスも順に設定される X-Forwarded-For: , , ・POST送信の場合 クエリパラメータを，URLに記述せず，メッセージボディに記述してリクエストメッセージを送る方法．以下では，Web APIのうち，特にRESTfulAPIに対して送信するためのリクエストメッセージの構造を説明する．メッセージボディに情報が記述されるため，履歴では確認できない．また，SSLによって暗号化されるため，傍受できない．リクエストメッセージは，以下の要素に分類できる． POST https://example.co.jp/bar-form.php HTTP/2 # リクエストされたドメイン名 Host: example.co.jp Connection: keep-alive Content-Length: 15 # ブラウザキャッシュの最大有効期限（リクエストヘッダーとレスポンスヘッダーの両方で定義可能） Cache-Control: no-store # オリジン（プロトコル＋ドメイン＋ポート番号） Origin: https://example.co.jp Upgrade-Insecure-Requests: 1 # リクエストで送信するMIMEタイプ Content-Type: application/x-www-firm-urlencoded # ブラウザのバージョン情報等 User-Agent: Mozzila/5.0 (Windows NT 10.0; Win64; x64) Ap # レスポンス返信してほしいMIMEタイプ Accept: text/html, application/xhtml+xml, application/xml; q=0 # レスポンスで返信してほしいエンコーディング形式 Accept-Encondig: gzip, deflate, br # レスポンスで返信してほしい言語 Accept-Language: ja, en-US; q=0.9, en; q=0.8 # 遷移元のページ Referer: https://foo.co.jp/ # 各Cookieの値（二回目のリクエスト時に設定される） Cookie: sessionid=; csrftoken=; _gat=1 # 送信元IPアドレス # ※プロキシサーバ（ALBやCloudFrontなども含む）を経由している場合に，それら全てのIPアドレスも順に設定される X-Forwarded-For: , , # ボディ．（SSLによって暗号化されるため閲覧不可） text=a&text2=b ・例外として，ボディをもつGET送信の場合 GET送信ではあるが，ボディにクエリパラメータを記述して送信する方法がある． POSTMANで，GET送信にメッセージボディを含めることについて： https://github.com/postmanlabs/postman-app-support/issues/131 レスポンスメッセージの構造 ＊具体例＊ 200 OK # レスポンスで送信するMIMEタイプ Content-Type: text/html;charset=UTF-8 Transfer-Encoding: chunked Connection: close # Webサーバ（nginx，apache，AmazonS3などが表示される） Server: nginx Date: Sat, 26 Sep 2020 04:25:08 GMT # リファラポリシー（nginx，apache，などで実装可能） Referrer-Policy: no-referrer-when-downgrade x-amz-rid: ***** # セッションIDを含むCookie情報 Set-Cookie: session-id=*****; Domain=.amazon.co.jp; Expires=Sun, 26-Sep-2021 04:25:08 GMT; Path=/ Set-Cookie: session-id-time=*****; Domain=.amazon.co.jp; Expires=Sun, 26-Sep-2021 04:25:08 GMT; Path=/ Set-Cookie: i18n-prefs=JPY; Domain=.amazon.co.jp; Expires=Sun, 26-Sep-2021 04:25:08 GMT; Path=/ Set-Cookie: skin=noskin; path=/; domain=.amazon.co.jp Accept-CH: ect,rtt,downlink Accept-CH-Lifetime: 86400 X-UA-Compatible: IE=edge Content-Language: ja-JP # ブラウザキャッシュの最大有効期限（リクエストヘッダーとレスポンスヘッダーの両方で定義可能） Cache-Control: no-cache # ブラウザキャッシュの最大有効期限（レスポンスヘッダーのみで定義可能） Expires: Wed, 21 Oct 2015 07:28:00 GMT Pragma: no-cache X-XSS-Protection: 1; X-Content-Type-Options: nosniff Vary: Accept-Encoding,User-Agent,Content-Type,Accept-Encoding,X-Amzn-CDN-Cache,X-Amzn-AX-Treatment,User-Agent Strict-Transport-Security: max-age=*****; includeSubDomains; preload X-Frame-Options: SAMEORIGIN # CloudFrontのキャッシュにヒットしたかどうか X-Cache: Miss from cloudfront Via: 1.1 *****.cloudfront.net (CloudFront) X-Amz-Cf-Pop: SEA19-C2 X-Amz-Cf-Id: *****== # 言語のバージョン（※ php.ini にて，expose_php = Off と設定することで非表示にできる） X-Powered-By: PHP/7.3.22 # ボディ ここにサイトのHTMLのコード リクエストメッセージの送信方法 ・PHP URL, // HTTPメソッド CURLOPT_CUSTOMREQUEST => \"GET\", // SSL証明書の検証 CURLOPT_SSL_VERIFYPEER => false, // 文字列型で受信 CURLOPT_RETURNTRANSFER => true ] ); // リクエストの実行 $messageBody = (curl_exec($curl)) ? curl_exec($curl) : []; // curlセッションを閉じる curl_close($curl); リクエストコンテキスト ・リクエストコンテキストとは リクエストを受信した時に，これのデータ（ボディ，ヘッダー，など）や，セッションを操作できる仕組みのこと． 04. オブジェクトデータ オブジェクトデータ ・オブジェクトデータとは リクエスト（POST）／レスポンスにて，メッセージボディに割り当てて送信／返信するデータのこと． ・MIME type（Content type） POST／PUT送信において，ボディパラメータのデータ形式を表現する識別子のこと．リクエストヘッダー／レスポンスヘッダーのContent-Typeヘッダーに割り当てると，オブジェクトデータのデータ型を定義できる．GET送信には不要である． 参考：https://stackoverflow.com/questions/5661596/do-i-need-a-content-type-header-for-http-get-requests トップレベルタイプ サブレベルタイプ 意味 application octet-stream 任意のMIME type（指定なし）を示す． javascript json x-www-form-urlencoded POST送信のデータ zip text html HTMLテキスト css CSSテキスト plane プレーンテキスト image png jpeg gif ・データ型の指定方法 最も良い方法は，リクエストのContent-Typeヘッダーに，『application/json』を設定することである． POST https://example.co.jp/users/12345 # ヘッダー Content-Type: application/json 他に，URIでデータ型を記述する方法がある． POST https://example.co.jp/users/12345?format=json リクエスト（POST，PUT） 正常系レスポンスで返信するオブジェクトデータと同じ． 正常系レスポンスの場合 ・POST／PUTでは処理後データをレスポンス POST／PUTメソッドでは，処理後のデータを200レスポンスとして返信する．もし処理後のデータを返信しない場合，改めてGETリクエストを送信する必要があり，余分なAPIコールが必要になってしまう． 参考： https://developer.ntt.com/ja/blog/741a176b-372f-4666-b649-b677dd23e3f3 https://qiita.com/wim/items/dbb6def4e207f6048735 ・DELETEではメッセージのみをレスポンス DELETEメソッドでは，メッセージのみを200レスポンスとして返信する．空ボディ204レスポンスとして返信してもよい． 参考： https://stackoverflow.com/questions/25970523/restful-what-should-a-delete-response-body-contain/50792918 https://qiita.com/fukuma_biz/items/a9e8d18467fe3e04068e#4-delete---%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%81%AE%E5%89%8A%E9%99%A4 ・ステータスコードは不要 正常系レスポンスの場合，オブジェクトデータへのステータスコードの割り当ては不要である． { \"name\": \"Taro Yamada\" } ・フラットなデータ構造にすること JSONの場合，階層構造にすると，データ容量が増えてしまう． ＊具体例＊ { \"name\": \"Taro Yamada\", \"age\": 10, \"interest\": { \"sports\":[\"soccer\", \"baseball\"], \"subjects\": \"math\" } } そこで，できるだけデータ構造をフラットにする．ただし，見やすさによっては階層構造も許容される． 参考：https://www.amazon.co.jp/Web-API-The-Good-Parts/dp/4873116864 ＊具体例＊ { \"name\": \"Taro Yamada\", \"age\": 10, \"sports\":[\"soccer\", \"baseball\"], \"subjects\": \"math\" } あるいは，Content-Typeヘッダーに『application/hal+json』『application/vnd.api+json』『application/vnd.collection+json』といったよりJSONベースの強い制約のフォーマットを利用する． ・日付データの形式に気をつけること RFC3339（W3C-DTF）形式でオブジェクトデータに含めて送受信すること． ＊具体例＊ 2020-07-07T12:00:00+09:00 ただし，日付をリクエストパラメータで送受信する時，RFC3339（W3C-DTF）形式を正規表現で設定する必要があるので注意． ＊具体例＊ GET https://example.co.jp/users/12345?date=2020-07-07T12:00:00%2B09:00 異常系レスポンスの場合 { \"code\": 400 \"errors\": [ \"〇〇は必ず入力してください．\", \"□□は必ず入力してください．\" ] \"url\" : \"https://*****\" } 参考：https://qiita.com/suin/items/f7ac4de914e9f3f35884#%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%AC%E3%82%B9%E3%83%9D%E3%83%B3%E3%82%B9%E3%81%A7%E8%80%83%E6%85%AE%E3%81%97%E3%81%9F%E3%81%84%E3%81%93%E3%81%A8 種類 必要性 データ型 説明 エラーメッセージ 必須 文字列型 複数のエラーメッセージを返信できるように，配列として定義する． ステータスコード 任意 整数型 エラーの種類がわかるステータスコードを割り当てる． エラーコード（例外コード） 任意 文字列型 APIドキュメントのエラーの識別子として，エラコード（例外コード）を割り当てる． APIドキュメントのURL 任意 文字列型 外部に公開するAPIの場合に，エラーの解決策がわかるAPIドキュメントのURLを割り当てる． 05. Statelessプロトコルにおける擬似Stateful化 Cookie，Cookie情報（キー名／値） ・Cookie，Cookie情報とは クライアントからの次回のリクエスト時でも，Cookie情報（キー名／値のセット）を用いて，同一クライアントと認識できる仕組みをCookieという．HTTPはStatelessプロトコルであるが，Cookie情報により擬似的にStatefulな通信を行える． ・Cookie情報に関わるヘッダー 最初，サーバからのレスポンス時，Set-Cookieヘッダーを用いて送信される．反対に，クライアントからのリクエスト時，Cookie情報は，Cookieヘッダーを用いて送信される． HTTPメッセージの種類 ヘッダー名 属性 内容 レスポンスメッセージ Set-Cookie Name Cookie名と値 Expires Cookieの有効期限（日数） Max-Age Cookieの有効期限（秒数） Domain クライアントがリクエストする時のCookie送信先ドメイン名． Path クライアントがリクエストする時のCookie送信先ディレクトリ Secure クライアントからのリクエストでSSLプロトコルが使用されている時のみ，リクエストを送信できるようにする． HttpOnly クライアント側で，JavaScriptがCookieを使用できないようにする．XSS攻撃の対策になる． リクエストメッセージ Cookie セッションIDなどのCookie情報 クライアントから送信されてきたリクエストメッセージのCookieヘッダーの内容は，グローバル変数に格納されている． \"値\"] ・仕組み 最初，ブラウザはリクエストでデータを送信する． サーバは，レスポンスヘッダーのSet-CookieヘッダーにCookie情報を埋め込んで送信する． ブラウザは，そのCookie情報を保存する． 2回目以降のリクエストでは，ブラウザは，リクエストヘッダーのCookieヘッダーにCookie情報を埋め込んでサーバに送信する．サーバは，Cookie情報に紐づくクライアントのデータをReadする． セッション ・セッション，セッションIDとは 特定のサイトを訪問してから，離脱するまでの一連のユーザ操作を『セッション』という．この時，セッションIDを用いると，セッションの各リクエストの送信元を同一クライアントとして識別できる．HTTPはStatelessプロトコルであるが，セッションIDにより擬似的にStatefulな通信を行える．例えばセッションIDにより，ログイン後にページ遷移を行っても，ログイン情報を保持でき，同一ユーザからのリクエストとして認識できる．セッションIDは，Cookie情報の一つとして，CookieヘッダーとSet-Cookieヘッダーを使用して送受信される． # リクエストヘッダーの場合 Cookie: sessionid=; csrftoken=u32t4o3tb3gg43; _gat=1 # レスポンスヘッダーの場合 Set-Cookie: sessionId= セッション数はGoogleコンソールで確認できる．GoogleConsoleにおけるセッションについては，以下のリンクを参考にせよ． 参考：https://support.google.com/analytics/answer/6086069?hl=ja ・セッションIDの発行，セッションファイルの生成 セッションは，session_startメソッドを用いることで開始される．また同時に，クライアントにセッションIDを発行する．グローバル変数にセッションIDを代入することによって，セッションIDの記載されたセッションファイルを作成する．セッションIDに紐づくその他のデータはこのセッションファイルに書き込まれていく．セッションファイルの名前は，sess_*****ファイルとなっており，セッションファイル名を元にしてセッションIDに紐づくデータを参照する．もしクライアントに既にセッションIDが発行されている場合，セッションファイルを参照するようになる． ＊実装例＊ ・セッションファイルの保存場所 セッションファイルの保存場所は/etc/php.iniファイルで定義できる． # /etc/php.ini ### ファイル形式 session.save_handler = files ### 保存場所 session.save_path = \"/tmp\" セッションファイルは，サーバ外（PHP Redis，ElastiCache Redisなど）に保存することもできる．/etc/php-fpm.d/www.confファイルではなく，/etc/php.iniファイルにて保存先の指定が必要である．ElastiCache Redisについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws.html # /etc/php.ini ### Redis形式 session.save_handler = redis ### Amazon RedisのOrigin session.save_path = \"tcp://*****-redis.*****.ng.0001.apne1.cache.amazonaws.com:6379\" なお，PHP-FPMを使用している場合は，/etc/php-fpm.d/www.confファイルにて，セッションファイルの保存先を指定する必要がある． # /etc/php-fpm.d/www.conf ### Redis形式 php_value[session.save_handler] = redis ### Amazon RedisのOrigin php_value[session.save_path] = \"tcp://*****-redis.*****.ng.0001.apne1.cache.amazonaws.com:6379\" ・セッションの有効期限と初期化確率 セッションの有効期限を設定できる．これにより，画面遷移時にログイン情報を保持できる秒数を定義できる． # 24時間 session.gc_maxlifetime = 86400 ただし，有効期限が切れた後にセッションファイルを初期化するかどうかは確率によって定められている．確率は， 『gc_probability÷gc_divisor』 で計算される． 参考：https://www.php.net/manual/ja/session.configuration.php#ini.session.gc-divisor # 有効期限後に100%初期化されるようにする． session.gc_probability = 1 session.gc_divisor = 1 ・仕組み 最初，ブラウザはリクエストでデータを送信する．セッションIDを発行し，セッションIDごとにsess_*****ファイルを生成． サーバは，レスポンスヘッダ情報のCookieヘッダーを使用して，セッションIDを送信する． ブラウザは，そのセッションIDを保存する． 2回目以降のリクエストでは，ブラウザは，リクエストヘッダ情報のCookieヘッダーを使用して，セッションIDをサーバに送信する．サーバは，セッションIDに紐づくクライアントのデータをReadする． 06. API仕様書 OpenAPI仕様 ・OpenAPI仕様とは RESTful APIの仕様を実装により説明するためのフォーマットのこと．JSON型またはYAML型で実装できる．いくつかのフィールドから構成されている． 参考：https://spec.openapis.org/oas/v3.1.0#fixed-fields openapi: # openapiフィールド info: # infoフィールド servers: # serversフィールド paths: # pathsフィールド webhooks: # webhooksフィールド components: # componentsフィールド security: # securityフィールド tags: # tagsフィールド externalDocs: # externalDocsフィールド ・API Gatewayによるインポート API GatewayによるOpenAPI仕様のインポートについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws_apigateway_import.html ・openapiフィールド（必須） OpenAPI仕様のバージョンを定義する． ＊実装例＊ openapi: 3.0.0 ・infoフィールド（必須） API名，作成者名，メールアドレス，ライセンス，などを定義する． ＊実装例＊ info: title: Foo API # API名 description: The API for Foo. # APIの説明 termsOfService: https://www.foo.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.foo.com/support # 連絡先に関するURL email: support@foo.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン ・serversフィールド API自体のURL，などを定義する． ＊実装例＊ servers: - url: https://{env}.foo.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www ・pathsフィールド（必須） APIのエンドポイント，HTTPメソッド，ステータスコード，などを定義する． paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: # GETメソッドを指定する． tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # リクエスト #=========================== parameters: [] #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # path itemオブジェクト #=========================== post: # POSTメソッドを指定する． tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # リクエスト #=========================== parameters: [] requestBody: # メッセージボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type foo: # メッセージボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # スキーマとして，正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # スキーマとして，異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # リクエスト #=========================== parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string foo: # パスパラメータ例 userId=1 #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type foo: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type foo: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type foo: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # リクエスト #=========================== parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string foo: # パスパラメータ例 userId=1 #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # Content-Type foo: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # Content-Type foo: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # Content-Type foo: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． ・componentsフィールド（必須） スキーマなど，他の項目で共通して利用するものを定義する． components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type foo: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"APIキーの認可に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # Basic認証 basicAuth: description: Basic認証 type: http scheme: basic # Bearer認証 bearerAuth: description: Bearer認証 type: http scheme: bearer # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # ヘッダ名は『x-api-key』とする．小文字が推奨である． in: header ＊実装例＊ ・securityフィールド componentsフィールドで定義した認証方法を宣言する．ルートで宣言すると，全てのパスに適用できる． ＊実装例＊ security: - apiKeyAuth: [] ・tagsフィールド 各項目に付けるタグを定義する．同名のタグをつけると，自動的にまとめられる． ＊実装例＊ tags: - name: ユーザ情報取得エンドポイント description: | ・externalDocsフィールド APIを説明するドキュメントのリンクを定義する． ＊実装例＊ externalDocs: description: 補足情報はこちら url: https://foo.com スキーマ ・スキーマとは APIに対して送信されるリクエストメッセージのデータ，またはAPIから返信されるレスポンスメッセージのデータについて，データ型や必須データを，JSON型またはYAML型で実装しておいたもの．リクエスト／レスポンス時のデータのバリデーションに用いる． ・スキーマによるバリデーション データ型や必須データにより，リクエスト／レスポンスのデータのバリデーションを行う． 参考：https://spec.openapis.org/oas/v3.1.0#data-types ＊実装例＊ 例えば，APIがレスポンス時に以下のようなJSON型データを返信するとする． { \"id\": 1, \"name\": \"Taro Yamada\", \"age\": 10, \"sports\":[\"soccer\", \"baseball\"], \"subjects\": \"math\" } ここで，スキーマを以下のように定義しておき，APIからデータをレスポンスする時のバリデーションを行う． { \"$schema\": \"https://json-schema.org/draft-04/schema#\", \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"integer\", \"minimum\": 1 }, \"name\": { \"type\": \"string\" }, \"age\": { \"type\": \"integer\", \"minimum\": 0 }, \"sports\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } }, \"subjects\": { \"type\": \"string\" } }, \"required\": [\"id\"] } ・API Gatewayにおけるスキーマ設定 API Gatewayにて，バリデーションのためにスキーマを設定できる．詳しくは，以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws.html "},"public/frontend_and_backend_authentication_authorization.html":{"url":"public/frontend_and_backend_authentication_authorization.html","title":"▶ ︎認証と認可","keywords":"","body":"Authenticate（認証）とAuthorization（認可） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. HTTP認証 HTTP認証とは 認証時にHTTP通信の中で認証を行うこと．リクエストのauthorizationヘッダーとレスポンスのWWW-Authenticateヘッダーで認証スキームを指定する．認証スキームの種類には，『Basic認証』，『Digest認証』，『Bearer認証』などがある．認証情報の一時的な保存は，ブラウザのWebStoregeで行うため，認証解除（ログアウト）をサーバ側で完全に制御できない． 参考： https://www.iana.org/assignments/http-authschemes/http-authschemes.xhtml https://architecting.hateblo.jp/entry/2020/03/27/130535 https://developer.mozilla.org/ja/docs/Web/HTTP/Authentication#authentication_schemes Basic認証 ・Basic認証の仕組み 役割 説明 クライアント リクエスト送信元のアプリケーションのこと．文脈によっては，ブラウザがクライアントである場合とそうでない場合（例：OAuth認証）がある． ユーザ クライアントを使用している人物のこと． サーバ クライアントからリクエストを受信し，レスポンスを送信するアプリケーションのこと． 最初，クライアントは，認証後にアクセスできるページのリクエストをサーバに送信する． GET https://example.co.jp/foo-form HTTP/2 サーバは，これ拒否し，401ステータスで認証領域を設定し，レスポンスを送信する．これにより，認証領域の値をユーザに示して，ユーザ名とパスワードの入力を求めることができる．ユーザに表示するための認証領域には，任意の値を持たせることができ，サイト名が設定されることが多い． 401 Unauthorized WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" 『:』をBase64でエンコードした値をauthorizationヘッダーに割り当て，リクエストを送信する． POST https://example.co.jp/foo-form HTTP/2 authorization: Basic bG9naW46cGFzc3dvcmQ= サーバは，ユーザ名とパスワードを照合し，合致していれば，認証後ページのレスポンスを送信する．また，認証情報をブラウザのWebストレージに保存する． 200 OK WWW-Authenticate: Basic realm=\"\" 認証の解除時は，誤った認証情報をブラウザに意図的に送信させて認証を失敗させるようにする． 参考：https://stackoverflow.com/questions/4163122/http-basic-authentication-log-out POST https://example.co.jp/foo-form/logout HTTP/2 authorization: Basic サーバは，401ステータスでレスポンスを返信し，認証が解除される． 401 Unauthorized WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" Digest認証 ・Digest認証の仕組み 200 OK WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" POST https://example.co.jp/foo-form HTTP/2 authorization: Digest realm=\"\" nonce=\"\" algorithm=\"\" qoq=\"auth\" Bearer認証 ・Bearer認証とは 認証時にBearerトークンを使用する認証スキームのこと． ・Bearerトークン（署名なしトークン）とは 単なる文字列で定義されたアクセストークン．Bearer認証にて，トークンとして使用する．署名なしトークンとも呼ばれ，実際に認証された本人かどうかを判定する機能は無く，トークンを持っていればそれを本人として認可する．そのため，トークンの文字列が流出してしまわないよう，厳重に管理する必要がある．Bearerトークンを使用するBearer認証については，別項目の説明を参考にせよ． 参考：https://openid-foundation-japan.github.io/rfc6750.ja.html#anchor3 ・Bearer認証の仕組み 指定されたエンドポイントに対して，POSTリクエストを送信する．この時，Content-Typeヘッダーをapplication/x-www-form-urlencodedとする．必要なボディパラメータはAPIの提供元によって異なる．クライアントID，付与タイプ，などが必要なことが多い． 参考： https://developer.amazon.com/ja/docs/adm/request-access-token.html#request-format https://ja.developer.box.com/reference/post-oauth2-token/#request POST https://example.co.jp/foo HTTP/2 Content-Type: application/x-www-form-urlencoded # ボディ client_id=*****&grant_type=client_credentials&scope=messaging:push レスポンスボディにBearerトークンを含むレスポンスが返信される．他に，有効期限，権限のスコープ，指定可能な認証スキーマ，などが提供されることが多い． 参考： https://developer.amazon.com/ja/docs/adm/request-access-token.html#request-format https://ja.developer.box.com/reference/resources/access-token/ 200 OK X-Amzn-RequestId: d917ceac-2245-11e2-a270-0bc161cb589d Content-Type: application/json { \"access_token\":\"*****\", \"expires_in\":3600, \"scope\":\"messaging:push\", \"token_type\":\"Bearer\" } 発行されたBearerトークンを指定された認証スキーマでAuthorizationヘッダーに割り当て，リクエストを送信する．ここでは詳しく言及しないが，BearerトークンをForm認証のようにCookieヘッダーに割り当てることもある． 参考： https://stackoverflow.com/questions/34817617/should-jwt-be-stored-in-localstorage-or-cookie https://ja.developer.box.com/reference/post-oauth2-token/#response POST https://example.co.jp/foo HTTP/2 authorization: Bearer サーバは，Bearerトークンを照合し，合致していれば，認証後ページのレスポンスを送信する．無効なBearerトークンをブラックリストとしてRedis／DBで管理しておく．DBでブラックリストを管理すると，リクエストの度にDBアクセス処理が実行されることなってしまうため，Redisでこれを管理した方が良い． 200 OK WWW-Authenticate: Bearer realm=\"\" 認証の解除時は，Redis／DBでBearerトークンの状態を無効化する．またサーバは，401ステータスでレスポンスを返信し，認証が解除される． 参考： https://stackoverflow.com/questions/21978658/invalidating-json-web-tokens https://medium.com/devgorilla/how-to-log-out-when-using-jwt-a8c7823e8a6 401 Unauthorized WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" ・正常系／異常系レスポンス 参考：https://qiita.com/h_tyokinuhata/items/ab8e0337085997be04b1 成功の場合は，realm属性を空にしたレスポンスを返信する． 200 OK WWW-Authenticate: Bearer realm=\"\" 失敗の場合は，error属性にエラメッセージを割り当てたレスポンスを返信する． 400 Bad Request WWW-Authenticate: Bearer error=\"invalid_request\" 401 Unauthorized WWW-Authenticate: Bearer realm=\"token_required\" 403 Forbidden WWW-Authenticate: Bearer error=\"insufficient_scope\" ・Authorizationヘッダーのトークンのクライアント保持 不便ではあるが，AuthorizationヘッダーはCookieヘッダーとは異なり，ローカルPCに保存できない．その代わり，ブラウザの設定によって，ブラウザのWebStorageでも保持できる．Chromeでは，LocalStorage／SessionStorageに保持される．LocalStorageはSessionStorageと比べて保存期間が長いため，XSSの危険性がより高い．これらの確認方法については，以下のリンクを参考にせよ 参考： https://developer.chrome.com/docs/devtools/storage/localstorage/ https://developer.chrome.com/docs/devtools/storage/sessionstorage/ https://stackoverflow.com/questions/5523140/html5-local-storage-vs-session-storage OAuth認証 ・OAuth認証とは OAuthの項目を参考にせよ． 01-02. HTTP認証以外の認証方法 Form認証（Cookieベースの認証） ・Form認証とは 認証時にCookieヘッダーの値を使用する方法のこと．『`Cookieベースの認証』ともいう．Stateful化を行うため，HTTP認証には属していない．認証情報の一時的な保存は，サーバのセッションファイルで行うため，認証解除（ログアウト）をサーバ側で制御できる．Cookieヘッダーによる送受信では，CSRFの危険性がある． 参考： https://h50146.www5.hpe.com/products/software/security/icewall/iwsoftware/report/certification.html https://auth0.com/docs/sessions/cookies#cookie-based-authentication ・セッションIDを用いたForm認証の場合（セッションベース） セッションIDをCookieヘッダーに割り当て，リクエストを送信する． 最初，ユーザ作成の段階で，クライアントが認証情報をサーバに送信する．サーバは，認証情報をデータベースに保存する． POST https://example.co.jp/users HTTP/2 { \"email_address\": \"foo@gmail.com\", \"password\": \"foo\" } 次回の認証時に，再びユーザが認証情報を送信する． POST https://example.co.jp/foo-form HTTP/2 { \"email_address\": \"foo@gmail.com\", \"password\": \"foo\" } サーバは，データベースの認証情報を照合し，ログインを許可する．サーバは，セッションIDを生成し，セッションファイルに書き込む． # セッションファイル { sessionid: ***** } レスポンスのSet-Cookieヘッダーを使用して，セッションIDをクライアントに送信する． 200 OK Set-Cookie: sessionid= サーバは，セッションIDとユーザIDを紐づけてサーバ内に保存する．さらに次回のログイン時，クライアントは，リクエストのCookieヘッダーを使用して，セッションIDをクライアントに送信する．サーバは，保存されたセッションIDに紐づくユーザIDから，ユーザを特定し，ログインを許可する．これにより，改めて認証情報を送信せずに，素早くログインできるようになる． POST https://example.co.jp/foo-form HTTP/2 cookie: sessionid= 認証解除時，サーバでセッションファイルを削除する． 参考：https://blog.tokumaru.org/2013/02/purpose-and-implementation-of-the-logout-function.html ・トークンを用いたForm認証の場合（トークンベース） トークンをCookieヘッダーに割り当て，リクエストを送信する．この時のトークンの選択肢として，単なるランダムな文字列やJWTがある． 参考：https://scrapbox.io/fendo181/JWT(JSON_Web_Token)%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99%E3%82%8B%E3%80%82 ・Cookieヘッダーの値のクライアント保持 再利用のため，Cookieヘッダーに割り当てるための値（セッションID，トークン）は，ブラウザを通して，ローカルPCに有効期限に応じた間だけ保持できる．またはブラウザの設定によって，ブラウザのWebストレージでも保持できる．Chromeの場合は，Cookieストレージに保持される．確認方法については，以下のリンクを参考にせよ． 参考： https://developer.chrome.com/docs/devtools/storage/cookies/ https://qiita.com/cobachan/items/05fa537a4ffcb189d001 APIキー認証 ・APIキー認証とは 事前にAPIキーとなる文字列を配布し，認証フェースは行わずに認可フェーズのみでユーザを照合する方法のこと．API GatewayにおけるAPIキー認証については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws.html ・照合情報の送信方法 独自ヘッダーとして，x-api-keyヘッダーを定義する．これにAPIキーを割り当て，リクエストを送信する．リクエストヘッダへのパラメータの割り当てについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html GET https://example.co.jp/bar.php HTTP/2 x-api-key: Personal Access Tokenによる認証：PAT ・PATによる認証 クライアントがPersonal Access Token（個人用アクセストークン）の付与をリクエストし，認証フェースは行わずに認可フェーズのみでユーザを照合する方法のこと．AuthorizationヘッダーにPATを割りあてて，リクエストを送信する．作成時以降，アクセストークンを確認できなくなるため，クライアントがアクセストークンを管理する必要がある． 参考：https://www.contentful.com/help/personal-access-tokens/ GET https://example.co.jp/bar.php HTTP/2 authorization: サービス例 トークン名 説明 GitHub Personal access Token HTTPSを使用して，プライベートリポジトリにリクエストを送信するために必要．HTTPSを使用する場面として，アプリの拡張機能のGitHub連携，リポジトリのライブラリ化，などがある．参考：https://docs.github.com/ja/github/authenticating-to-github/creating-a-personal-access-token 01-03. 複数の認証の組み合わせ Two Step Verification（二段階認証） ・Two Step Verificationとは 認証時に段階的に二つの方法を設定し，クライアントを照合する方法のこと． 一段階目の認証例 二段階目の認証例 説明 備考 IDとパスワード IDとパスワード IDとパスワードによる方法の後，別のIDとパスワードによる方法を設定する． 秘密の質問 IDとパスワードによる方法の後，質問に対してあらかじめ設定した回答による方法を設定する． SMS IDとパスワードによる方法の後，SMS宛に送信した認証コードによる方法を設定する． 異なる要素のため，これは二要素認証でもある． 指紋 IDとパスワードによる方法の後，指紋の解析結果による方法を設定する． 異なる要素のため，これは二要素認証でもある． Two Factor Authorization（二要素認証） ・Two Factor Authorizationとは 二段階認証のうちで特に，認証時に異なる要素の方法を使用して，段階的にクライアントを照合すること方法のこと．後述するOAuth認証を組み込んでも良い． 一要素目の認証例 二要素目の認証例 IDとパスワード（知識） 事前登録された電話番号のSMSで受信したワンタイムパスワード（所持） 事前登録された電話番号のSMSで受信した認証コード（所持） OAuth認証（所持） 指紋（生体） 暗証番号（知識） キャッシュカード（所持） 02. 認可フェーズ 認証フェーズと認可フェーズ ・処理の違い 認証フェーズと認可フェーズでは，仕組みの中に，３つの役割が定義されている． クライアントが，HTTPリクエストにIDとパスワードを設定してリクエスト． IdP：Identity Providerが，IDを『認証』し，クライアント側にアクセストークンを発行． クライアントが，HTTPリクエストのヘッダーにアクセストークンを設定してリクエスト． アクセストークンが『認可』されれば，API側がデータをレスポンスする． 役割 説明 具体例 APIクライアント APIに対して，リクエストを送信したいサーバのこと． Ouath認証の仕組みにおけるクライアント． Identity Provider トークンを生成するサーバのこと． Ouath認証の仕組みにおける認可サーバ． APIサーバ クライアントに対して，リソースのレスポンスを送信するサーバのこと． Ouath認証の仕組みにおけるリソースサーバ． ・ステータスコードの違い 認証フェーズにて，誤ったトークンが発行されたことを表現したい場合，401ステータスを使用する．認可フェーズにて，正しいトークンが発行されたが，トークンの所有者に閲覧権限がないことを表現したい場合，403ステータスを使用する．ステータスコードについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html OAuthプロトコル，OAuth認証 ・OAuthプロトコル，OAuth認証とは 認証認可フェーズ全体の中で，認可フェーズにOAuthプロトコルを用いたクライアントの照合方法を『OAuth認証』と呼ぶ．認証フェーズと認可フェーズでは，３つの役割が定義されていることを説明したが，OAuthプロトコル2.0では，より具体的に４つの役割が定義されている． 役割 名称 説明 補足 APIクライアント クライアントアプリ リソースオーナに対するアクション機能を持つサーバのこと． OAuthの文脈では，ブラウザがクライアントと呼ばれないことに注意する．また，クライアントアプリとリソース間のデータ通信は，ブラウザを介したリダイレクトによって実現することに注意する． リソースオーナー クライアントを使用しているユーザのこと． Identity Provider 認可サーバ リソースサーバがリソースオーナーにアクセスできるトークンを生成するサーバのこと． 認可サーバがリダイレクト先のクライアントアプリのURLをレスポンスに割り当てられるように，クライアントアプリの開発者がURLを事前登録しておく必要がある．認可サーバを利用する開発者用に，コンソール画面が用意されていることが多い．参考：https://qiita.com/TakahikoKawasaki/items/8567c80528da43c7e844 APIサーバ リソースサーバ クライアントのアカウント情報を持っているサーバのこと． ユーザは，Facebookアカウントを使用してInstagramにログインしようとし，ブラウザはFacebookにリクエストを送信する．FacebookはInstagramにアカウント連携の承認ボタンをレスポンスとして返信する． ユーザが表示された承認ボタンを押し，ブラウザはFacebookにリクエストを送信する． アクセストークンを発行してもらうため，ブラウザはInstagram認可サーバにリクエストを送信する．Instagramは，アクセストークンを発行する．また，Facebookにリダイレクトできるように，LocationヘッダーにURLと認可レスポンスパラメータを割り当て，ブラウザにレスポンスを返信する．ブラウザはFacebookにリクエストを再送信し，Facebookは認可レスポンスパラメータを受け取る． 302 Found Location: https://example.com/foo.php?code=123&state=abc Facebookは，アクセストークンを割り当てたリクエストをInstagramのサーバに送信する． Instagramは，アクセストークンを認証し，データへのアクセスを許可する．また，Facebookにリダイレクトできるように，LocationヘッダーにURLを割り当て，ブラウザにレスポンスを返信する．ブラウザからFacebookにレスポンスがリダイレクトされる．ブラウザはFacebookにリクエストを再送信する． 参考： https://boxil.jp/mag/a3207/ https://qiita.com/TakahikoKawasaki/items/8567c80528da43c7e844 ・使用される認証スキーム OAuth認証では，認証スキーマとしてBearer認証が選ばれることが多く，AWSやGitHubは，独自の認証スキームを使用している．なお，認可サーバによって発行されたBearerトークンは，Authorizationヘッダー，リクエストボディ，クエリパラメータのいずれかに割り当てて送信できる． ・付与タイプ OAuth認証のトークンの付与方法には種類がある． 参考：https://oauth.net/2/grant-types/ 付与タイプ名 説明 使用例 Authorization Code Grant アプリケーションが他のAPIにアクセスする場合に使用する．推奨されている．参考：https://oauth.net/2/grant-types/authorization-code/ 他のSNSアプリとのアカウント連携 Client Credentials Grant 推奨されている．参考：https://oauth.net/2/grant-types/client-credentials/ Device Code 推奨されている．参考：https://oauth.net/2/grant-types/device-code/ Implicit Grant 非推奨されている．参考：https://oauth.net/2/grant-types/implicit/ Password Grant ユーザ名とパスワードを元に，トークンを付与する．非推奨されている．参考：・https://oauth.net/2/grant-types/password/・https://developer.okta.com/blog/2018/06/29/what-is-the-oauth2-password-grant#the-oauth-20-password-grant OpenID Connect ・OpenID Connectとは 要勉強． ・使用される認証スキーム 要勉強 03. JWT：JSON Web Token JWTとは 『ヘッダー』『ペイロード』『署名』のそれぞれのJSONデータをBase64urlによってエンコードし，ドットでつないだトークン．Bear認証やOauth認証のトークンとして使用できる．ランダムな文字列をこれら認証のトークンとするより，JWTを用いた方がより安全である． GET https://example.co.jp/bar.php HTTP/2 authorization: Bearer .. JWTをBearerトークンとして使用するBearer認証については，別項目の説明を参考にせよ． 参考： https://meetup-jp.toast.com/3511 https://dev.classmethod.jp/articles/json-signing-jws-jwt-usecase/ JWTの生成 ・JWT生成の全体像 JWTは以下のサイトから取得できる． 参考：https://jwt.io/ JWTの生成時に，例えばJavaScriptであれば，以下のような処理が実行されている． // .. const token = base64urlEncoding(header) + \".\" + base64urlEncoding(payload) + \".\" + base64urlEncoding(signature) ・ヘッダーのJSONデータの生成 ヘッダーは以下のJSONデータで定義される．署名のための暗号化アルゴリズムは，『HS256』『RS256』『ES256』『none』から選択できる． const header = { \"typ\" : \"JWT\" // JWTの使用 \"alg\" : \"HS256\", // 署名のための暗号化アルゴリズム } ・ペイロードのJSONデータの生成 ペイロードは以下のJSONデータで定義される．ペイロードには，実際に送信したいJSONを設定するようにする．必ず設定しなければならない『予約済みクレーム』と，ユーザ側が自由に定義できる『プライベートクレーム』がある． 予約済みクレーム名 役割 例 sub：Subject 一意な識別子を設定する． ユーザID iss：Issuer aud：Audience exp：Expiration Time JWTの有効期限を設定する． jti：JWT ID const payload = { \"sub\": \"foo\", \"aud\": \"foo\", \"iss\": \"https://example.com\", \"exp\": 1452565628, \"iat\": 1452565568 } ・署名のJSONデータの生成 例えばJavaScriptであれば，以下のような処理が実行されている． const signature = HMACSHA256( base64urlEncoding(header) + \".\" + base64urlEncoding(payload), secret ) JWTのクライアント保持 ・ 保持方法と安全度の比較 参考：https://qiita.com/Hiro-mi/items/18e00060a0f8654f49d6#%E6%97%A9%E8%A6%8B%E8%A1%A8 クライアント保持方法 組み合わせ おすすめ度 コメント localStorage △〜× XSSでJWTが盗まれる可能性がある． Cookieヘッダー プリフライトリクエスト △ Access-Control-Max-Ageの期間内だとCSRFでJWTが盗まれる可能性がある． Cookieヘッダー CSRFトークン ◯ SameSiteCookie ◯ SPAとAPIが同一オリジンの必要がある． "},"public/frontend_and_backend_json.html":{"url":"public/frontend_and_backend_json.html","title":"▶ ︎JSON","keywords":"","body":"JSON はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. データ記述言語 データ記述言語の種類 ・JSON：JavaScript Object Notation 一番外側を波括弧で囲う． { \"fruit\": [\"banana\", \"apple\"], \"account\": 200 } ・YAML：YAML Ain\"t a Markup Language { fruit: - \"banana\" - \"apple\" account: 200 } ・マークアップ言語 詳しくは以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_browser_rendering.html ・CSV：Comma Separated Vector データ解析の入力ファイルとしてよく使うやつ． 02-01. JS型オブジェクト，JSON，PHP型オブジェクト JS型オブジェクト ・定義方法 キーはクオーテーションで囲う必要が無い． ＊実装例＊ const object = { fruit: [\"banana\", \"apple\"], account: 200 }; class Foo { constructor(fruit, account) { this.fruit = fruit; this.account = account; } } JSON ・定義方法 キーを，シングルクオーテーションではなく，クオーテーションで囲う必要がある． ＊実装例＊ const json = { \"fruit\": [\"banana\", \"apple\"], \"account\": 200 }; ・キーと値の変更方法 ＊実装例＊ // どんなデータを含むJSONなのかわかりやすい方法 const json = { \"name\": null, \"age\": null, \"tel\": null } json.name = \"taro\"; json.age = 30; json.tel = \"090-0123-4567\"; ＊実装例＊ const json = {} // areaというキーの値を追加 json.prefecture = \"Tokyo\"; // もしくは， json[\"prefecture\"] = \"Tokyo\"; // 以下は．undefined になる．二段階の定義はできない． //// json.prefecture.area = \"Shibuya\"; ＊実装例＊ const json = { \"name\": \"taro\", \"age\": 30, \"tel\": \"090-0123-4567\" } // areaというキーの値を追加 json.prefecture = \"Tokyo\"; // もしくは， json[\"prefecture\"] = \"Tokyo\"; PHP型オブジェクト ・定義方法 ＊実装例＊ fruit = $fruit; $this->account = $account; } } 02-02. 相互パース（シリアライズ＋デシリアライズ） シリアライズ，デシリアライズとは ・バックエンドとフロントエンド間 データ送信のためにオブジェクト（JS型，PHP型）をJSONに変換する処理はシリアライズである．一方で，送信のためにJSONをオブジェクト（JS型，PHP型）に変換する処理はデシリアライズである． ・バックエンドとデータベース間 データ送信のためにオブジェクト（PHP型）をJSONに変換する処理はシリアライズである．一方で，送信のためにJSONをオブジェクト（PHP型）に変換する処理はデシリアライズである． フロントエンド ・シリアライズ：JS型からJSON JS型オブジェクトからJSONへの変換には，JSON.stringfyメソッドを使用する． ＊実装例＊ const object = { fruit: [\"banana\", \"apple\"], account: 200 }; // シリアライズ const json = JSON.stringify(object); console.log(json); // {\"fruit\":[\"banana\",\"apple\"],\"account\":200} ・デシリアライズ：JSONからJS型 JSONからJS型オブジェクトへの変換には，JSON.parseメソッドを使用する．レスポンスされたJSONはエスケープされていることに注意する． ＊実装例＊ const escapedJson = \"{\\\"fruit\\\":[\\\"banana\\\",\\\"apple\\\"],\\\"account\\\":200}\" console.log(escapedJson); // {\"fruit\":[\"banana\",\"apple\"],\"account\":200} // デシリアライズ const object = JSON.parse(escapedJson); console.log(object); // { fruit: [ 'banana', 'apple' ], account: 200 } ・相互パースメソッドをもつクラス ＊実装例＊ 以下でシリアライズとデシリアライズを行うクラスを示す． class StaffParser { // デシリアライズによるJS型データを自身に設定 constructor(properties) { this.id = properties.id; this.name = properties.name; } //-- デシリアライズ（JSONからJavaScriptへ） --// static deserializeStaff(json) { // JS型オブジェクトの定義方法 return new StaffParser({ id: json.id, name: json.name }); } //-- シリアライズ（JavaScriptからJSONへ） --// static serializeCriteria(criteria) { // JSONの定義 const json = { \"id\" : null, \"name\" : null } // ID if (criteria.id) { // JSONが生成される． json.id = _.trim(criteria.id); } // 氏名 if (criteria.name) { json.name = _.trim(criteria.name); } } } バックエンド ・デシリアライズ：JSONからPHP型 JSONからPHP型オブジェクトの変換には．json_decodeメソッドを使用する．第二引数がfalseの場合，object形式オブジェクトに変換する．リクエストで送信するJSONはエスケープする必要があることに注意する． // array(2) { // [0]=> // string(9) \"banana\" // [1]=> // string(9) \"apple\" // } // [\"account\"]=> // int(200) // } 第二引数がtrueの場合，連想配列形式に変換する． // array(2) { // [0]=> // string(9) \"banana\" // [1]=> // string(9) \"apple\" // } // [\"account\"]=> // int(200) // } ・シリアライズ：PHP型からJSON 03. JSONのクエリ言語 クエリ言語の種類 ・JMESPath ＊実装例＊ // ここに実装例 "},"public/frontend_and_backend_browser_rendering.html":{"url":"public/frontend_and_backend_browser_rendering.html","title":"▶ ︎ブラウザレンダリングの仕組み","keywords":"","body":"ブラウザレンダリングの仕組み はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ブラウザレンダリングの仕組み 構成する処理 以下の8つの処理からなる．クライアントの操作のたびにイベントが発火し，Scriptingプロセスが繰り返し実行される． Downloading Parse Scripting Rendering CalculateStyle Paint Rasterize Composite 01-02. マークアップ言語 ・マークアップ言語とは ハードウェアが読み込むファイルには，バイナリファイルとテキストファイルがある．このうち，テキストファイルをタグとデータによって構造的に表現し，ハードウェアが読み込める状態する言語のこと． ・マークアップ言語の歴史 Webページをテキストによって構成するための言語をマークアップ言語という．1970年，IBMが，タグによって，テキスト文章に構造や意味を持たせるGML言語を発表した． XML形式：Extensible Markup Language ・XML形式とは テキストファイルのうち，何らかのデータの構造を表現することに特化している． ・スキーマ言語とは マークアップ言語の特にXML形式において，タグの付け方は自由である．しかし，利用者間で共通のルールを設けた方が良い．ルールを定義するための言語をスキーマ言語という．スキーマ言語に，DTD：Document Type Definition（文書型定義）がある． ＊実装例＊ ]> HTML形式：HyperText Markup Language ・HTML形式とは テキストファイルのうち，Webページの構造を表現することに特化している． 01-03. JavaScript マークアップ言語へのJavaScriptの組み込み ・インラインスクリプト JavaScriptファイルを直接組み込む方法． document.write(\"JavaScriptを直接組み込んでいます。\") ・外部スクリプト 外部JavaScriptファイルを組み込む方法． CDNの仕組みを用いて，Web上からリソースを取得することもできる． ・scriptタグが複数ある場合 一つのページのHtml内で，scriptタグが複数に分散していても，Scriptingプロセスでは，一つにまとめて実行される．そのため，より上部のscriptタグの処理は，より下部のscriptに引き継がれる． 1．例えば，以下のソースコードがある． localNum見出し１ var globalNum = 10; 見出し２ globalNum = globalNum * 10; 見出し３ document.write(\"結果は\" + globalNum + \"です\"); var hoge = true; // sample.js // 無名関数の即時実行．定義と呼び出しを同時に行う． (function () { // 外側の変数（hoge）を参照できる． if(hoge) { console.log(\"外部ファイルを読み込みました\"); } var localNum = 20; function localMethod() { // 外側の変数（localNum）を参照できる． console.log(\"localNum\"); } // 定義したメソッドを実行 localMethod(); }()); 実行時には以下の様に，まとめて実行される．ここでは，htmlファイルで定義した関数の外にある変数は，グローバル変数になっている．一つのページを構成するHtmlを別ファイルとして分割していても，同じである． var globalNum = 10; localNum = localNum * 10; document.write(\"結果は\" + num + \"です\"); var hoge = true; // 無名関数の即時実行．定義と呼び出しを同時に行う． (function () { // 外側の変数（hoge）を参照できる． if(hoge) { console.log(\"外部ファイルを読み込みました\"); } var localNum = 20; function localMethod() { // 外側の変数（localNum）を参照できる． console.log(\"localNum\"); } // 定義したメソッドを実行 localMethod(); }()); 01-04. イベント駆動 イベント駆動 ・イベント駆動とは JavaScriptでは，画面上で何らかのイベントが発火し，これに紐づくイベントハンドラ関数がコールされることで，他の関数に処理が広がっていく．これをイベント駆動という． ・イベント発火，イベントハンドラ関数とは 画面上で何かの処理が起こると，Scriptingプロセスによって，特定の関数がコールされる． HTML形式におけるイベントハンドラ関数のコール ・onload 『画面のローディング』というイベントが発火すると，イベントハンドラ関数をコールする． ・onclick 『要素のクリック』というイベントが発火すると，イベントハンドラ関数をコールする． function methodA(){ console.log(\"イベントが発火しました\"); } JS形式におけるイベントハンドラ関数のコール ・document.getElementById() 指定したIDに対して，一つのイベントと一つのイベントハンドラ関数を紐づける． // 指定したIDで，クリックイベントが発火した時に，処理を行う． document.getElementById(\"btn\").onclick = function(){ console.log(\"イベントが発火しました\"); } ・document.addEventListener() 一つのイベントに対して，一つ以上のイベントハンドラ関数を紐づける．falseを設定することで，イベントバブリングを行わせない． // DOMContentLoadedイベントが発火した時に，処理を行う． document.addEventListener(\"DOMContentLoaded\", function(){ console.log(\"イベントが発火しました\"); }); // 一つ目 document.getElementById(\"btn\").addEventListener(\"click\", function(){ console.log(\"イベントが発火しました（１）\"); }, false); // 二つ目 document.getElementById(\"btn\").addEventListener(\"click\", function(){ console.log(\"イベントが発火しました（２）\"); }, false); 01-05. ブラウザのバージョン Polyfill ・Polyfillとは JavaScriptやHTMLの更新にブラウザが追いついていない場合に，それを補完するように実装されたライブラリのこと．『Polyfilla』に由来している． 02. Downloading処理 Downloading処理とは ・非同期的な読み込み まず，サーバサイドからリソース（Html，CSS，JS，画像）は，分割されながら，バイト形式でレスポンスされる．これは，メッセージボディに含まれている．これを優先度に基づいて読み込む処理．分割でレスポンスされたリソースを，随時読み込んでいく．そのため，各リソースの読み込みは非同期的に行われる．Downloading処理が終了したリソースから，次のParse処理に進んでいく． ・リソースの優先順位 HTML CSS JS 画像 Pre-Loading ・Pre-Loadingとは Downloading処理の優先順位を上げるように宣言する方法．優先度の高い分割リソースは，次のParse処理，Scripting処理も行われる．そのため，JSファイルのScripting処理が，以降のimageファイルのDownloading処理よりも早くに行われることがある． Title Hello World Lazy Loading（遅延読み込み） ・Lazy Loadingとは 条件に合致した要素を随時読み込む方法．条件の指定方法には，scroll/resizeイベントに基づく方法と，Intersection Observerによる要素の交差率に基づく方法がある．画像ファイルの遅延読み込みでは，読み込み前にダミー画像を表示させておき，遅延読み込み時にダミー画像パスを本来の画像パスに上書きする． ・scrollイベントとresizeイベントに基づく読み込み scrollイベントとresizeイベントを監視し、これらのイベントの発火をトリガーにして，画面内に新しく追加された要素を随時読み込む方法． ・Intersection Observerによる要素の交差率に基づく読み込み Intersection Observerによる要素の交差率を監視し，指定の交差率を超えた要素を随時読み込む方法．例えば，交差率の閾値を『0.5』と設定すると，ターゲットエレメントの交差率が『0.5』を超えた要素を随時読み込む． Eager Loading ・Eager Loadingとは 02-02. Parse処理 Parse処理とは Downloading処理によって読み込まれたリソースを翻訳するプロセス HTML形式テキストファイルの構造解析 ・構造解析の流れ Downloading処理で読みこまれたバイト形式ファイルは，文字コードに基づいて，一連の文字列に変換される．ここでは，以下のHTML形式ファイルとCSS形式ファイル（style.css）に変換されたとする． Critical Path Hello web performance students! Hello world! /* style.css */ body { font-size: 16px } p { font-weight: bold } span { color: red } p span { display: none } img { float: right } リソースの文字列からHTMLタグが認識され，トークンに変換される．各トークンは，一つのオブジェクトに変換される． HTMLパーサーは，オブジェクトをノードとして，DOMツリーを生成する．DOMツリーを生成する途中でscriptタグに到達すると，一旦，JSファイルを読み込んでScripting処理を終えてから，DOMツリーの生成を再開する． DOMのインターフェースについては，こちら． https://developer.mozilla.org/ja/docs/Web/API/Document_Object_Model 同時に，CSSパーサーは，headタグにあるlinkタグをもとにサーバにリクエストを行う．レスポンスされたCSSファイルに対してDownloading処理を行った後，オブジェクトをノードとして，CSSOMツリーを生成する． XML形式テキストファイルの構造解析 ・構造解析の流れ レンダリングエンジンは，最初に出現するルート要素を根（ルート），またすべての要素や属性を，そこから延びる枝葉として意味づけ，レンダリングツリーを生成する． ＊具体例＊ 引用：Real-time Generalization of Geodata in the WEB，https://www.researchgate.net/publication/228930844_Real-time_Generalization_of_Geodata_in_the_WEB 03. Scripting処理 Scripting処理とは JavaScriptエンジンによって，JavaScriptコードが機械語に翻訳され，実行される．この処理は，初回アクセス時だけでなく，イベントが発火した時にも実行される． JavaScriptエンジン ・JavaScriptエンジンとは JavaScriptのインタプリタのこと．JavaScriptエンジンは，レンダリングエンジンからHTMLファイルに組み込まれたJavaScriptのコードを受け取る．JavaScriptエンジンは，これを機械語に翻訳し，ハードウェアに対して，命令を実行する． ・機械語翻訳 JavaScriptエンジンは，ソースコードを，字句解析，構造解析，意味解釈，命令の実行，をコード一行ずつに対し，繰り返し行う．詳しくは，以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_software_centos.html 04. Rendering処理 Rendering処理とは レンダリングツリーが生成され，ブラウザ上のどこに何を描画するのかを計算する．CalculateStyle処理とLayout処理に分けられる． 04-02. CalculateStyle処理 CalculateStyle処理とは レンダリングエンジンは，DOMツリーのルートのノードから順にCSSOSツリーを適用し，Renderツリーを生成する． 04-03. Layout処理 Layout処理とは 上記で読み込まれたHTML形式テキストファイルには，ネストされた 2 つの div がある．1 つ目（親）のdivより，ノードの表示サイズをビューポートの幅の 50% に設定し、この親に含まれている 2 つ目（子）のdivより，その幅を親の50%、つまりビューポートの幅の25%になるようにレイアウトされる． 05. Paint処理 Paint処理とは DOMツリーの各ノードを，ブラウザ上に描画する． 05-02. Rasterize処理 Rasterize処理とは 05-03. CompositeLayers処理 CompositeLaysers処理とは 06. キャッシュ キャッシュとは 静的コンテンツ（HTML，JavaScript，CSS，画像）をデータを保存しておき，再利用することによって，処理速度を高める仕組みのこと． キャッシュの保存場所の種類 ・ブラウザにおけるキャッシュ クライアントのブラウザにおいて，レスポンスされた静的コンテンツがキャッシュとして保存される．Chromeの場合は，CacheStorageに保持される．確認方法については，以下のリンクを参考にせよ． 参考：https://developer.chrome.com/docs/devtools/storage/cache/ ・リバースProxyサーバにおけるキャッシュ リバースProxyサーバにおいて，レスポンスされた静的コンテンツがキャッシュとして保存される．AWSでは，CloudFrontにおけるキャッシュがこれに相当する． ・アプリケーションにおけるキャッシュ オブジェクトのプロパティにおいて，メソッド処理結果がキャッシュとして保存される．必要な場合に，これを取り出して再利用する．Laravelのキャッシュ機能については，以下のリンクを参考にせよ． 参考：https://readouble.com/laravel/8.x/ja/cache.html サーバ側でキャッシュすべきでないデータ リバースProxyサーバ／アプリケーションにおいて，キャッシュすべきでないデータを持つページがある． ページ 理由 Form認証ページ 無関係のユーザに認証済みのページが返信されてしまう． 緯度経度／フリーワードに基づく検索結果ページ パターン数が多く，全てのページを網羅することが現実的でない． ブラウザキャッシュ使用／不使用の検証 ・ETag値による検証 === （１）キャッシュの有効時間が切れるまで === クライアントのブラウザは，リクエストをサーバに送信する． サーバは，特定のアルゴリズムを使用してハッシュ値を生成し，これをコンテンツのETag値とする． サーバは，ETagヘッダーにETag値を設定し，コンテンツとともにレスポンスをクライアントに送信する． クライアントのブラウザは，コンテンツとETag値をキャッシュする． キャッシュの有効時間が切れるまで，ブラウザキャッシュを使用し続ける． === （２）キャッシュの有効時間が切れた後 === キャッシュの有効時間が切れる． クライアントのブラウザは，リクエストをサーバに送信する．この時，If-None-MatchヘッダーにキャッシュしておいたETag値を設定する． サーバは，送信されたETag値とコンテンツのETag値を比較検証する． === （３）検証により，ブラウザキャッシュを使用 === ETag値の比較検証の結果，一致する． サーバは，両方の値が一致する場合，304ステータスでレスポンスをクライアントに送信する． クライアントのブラウザは，キャッシュを使用する． === （４）検証により，ブラウザキャッシュを使用せず === ETag値の比較検証の結果，一致しない． サーバは，両方の値が一致しない場合，ETag値を生成し，これをコンテンツの新しいETag値とする． サーバは，ETagヘッダーにETag値を設定し，コンテンツとともにレスポンスをクライアントに送信する． クライアントのブラウザは，コンテンツとETag値をキャッシュする． ブラウザキャッシュ時間の定義 ・ブラウザキャッシュなし レスポンスヘッダーにて，Cache-Controlヘッダーにno-storeを設定する．この場合，ETag値が無効になり，ブラウザキャッシュを使用しなくなる． HTTP/1.1 200 # ～ 省略 ～ Cache-Control: no-store # ～ 省略 ～ # ボディ ここにサイトのHTMLのコード ・ブラウザキャッシュあり（有効時間あり） レスポンスヘッダーにて，Cache-Controlヘッダーにmax-age=31536000を設定する．Expireヘッダーに有効時間を設定しても良いが，Cache-Controlヘッダーの有効時間が優先される．この場合，有効時間を過ぎると，ETag値を比較検証するようになる． HTTP/1.1 200 # ～ 省略 ～ Cache-Control: max-age=31536000 # ～ 省略 ～ # ボディ ここにサイトのHTMLのコード ・ブラウザキャッシュあり（有効時間なし） レスポンスヘッダーにて，Cache-Controlヘッダーにmax-age=0を設定する．また，Expireヘッダーに期限切れの日時を設定する．この場合，毎回のリクエスト時にETag値を比較検証するようになる． HTTP/1.1 200 # ～ 省略 ～ Cache-Control: max-age=0 Expires: Sat, 01 Jan 2000 00:00:00 GMT # ～ 省略 ～ # ボディ ここにサイトのHTMLのコード "},"public/frontend_js_object_orientation_prototype.html":{"url":"public/frontend_js_object_orientation_prototype.html","title":"▶ ︎プロトタイプベース（1）","keywords":"","body":"プロトタイプベースのオブジェクト指向プログラミング（１） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 標準ビルトインオブジェクト 標準ビルトインオブジェクトとは JavaScriptの実行環境にあらかじめ組み込まれたオブジェクト． Object オブジェクトを生成するオブジェクト．他の全ての標準ビルトインオブジェクトの継承元になっているため，標準ビルトインオブジェクトは，Objectが持つメソッドとデータを使うことができる． ＊実装例＊ // new演算子を使ってインスタンスを生成 const obj = new Object(); Function ＊実装例＊ Array ・Array.prototype.entries() 配列からkeyとvalueを取得する． ＊実装例＊ const array = [\"foo\", \"bar\", \"baz\"]; // key，valueを取得できる． const iterator = array.entries(); // for-ofで展開 for (const value of iterator) { console.log(value); } // [ 0, 'foo' ] // [ 1, 'bar' ] // [ 2, 'baz' ] ・Array.prototype.map() ＊実装例＊ // ここに実装例 ・Array.prototype.filter() ＊実装例＊ // ここに実装例 ・Array.length 要素数を出力する． ＊実装例＊ const param = [\"foo\", \"bar\", \"baz\", \"qux\"]; console.log( param.length ); // 4 JSON ・JSON.parseメソッド JavaScriptからJSONにシリアライズする． ＊実装例＊ console.log( JSON.stringify({ x : 1, y : 5, z : \"test\" }) ); // JSON形式オブジェクト // \"{\"x\":5, \"y\":5 \"z\":\"test\"}\" ・stringifyメソッド JSONからJavaScriptにデシリアライズする． ＊実装例＊ console.log( JSON.parse({ \"x\" : 1, \"y\" : 5, \"z\" : \"test\" }) ); // JavaScriptオブジェクト // {x:5, y:5 z:\"test\"} 01-02. DOMオブジェクト Document ・getElementbyIdメソッド 指定したidのhtml要素を取得する． ＊実装例＊ Hello world! console.log(document.getElementById(\"myid\")); // Hello world! EventTarget ・addEventListeneメソッド 第一引数で，clickなどのイベントを設定し，第二引数でメソッド（無名関数でも可）を渡す． ＊実装例＊ 表示 const btn = document.getElementById(\"btn\"); btn.addEventListener(\"click\", function() { console.log(\"クリックされました！\"); }, false ); 02. オブジェクトの生成，初期化 リテラル表記の使用 オブジェクトをリテラル表記で生成する方法．キャメルケース（小文字から始める記法）を用いる． ・非省略形 ＊実装例＊ // リテラル表記 const example = { // 慣習的にアンダーバーでprivateを表す． _property: 0, alertValue: function(value) { alert(value); }, setValue(value) { this._property = value; }, getValue() { return this._property; } } ・省略形 リテラル表記において，methodA(): fucntion{} とするところを，methodA() {}と記述できる． // リテラル表記 const example = { // ~~ 省略 ~~ alertValue(value) { alert(value); }, // ~~ 省略 ~~ } コンストラクタ関数の使用 ・Objectコンストラクタ関数 キャメルケース（小文字から始める記法）を用いる．プロパティを生成するためには，値を格納する必要がある．関数宣言あるいは関数式で記述する．パスカルケース（大文字から始める記法）を用いる．ちなみに，オブジェクトのプロパティ値として生成された関数を，メソッドと呼ぶ． ＊実装例＊ const example = new Object({ // 慣習的にアンダーバーでprivateを表す． _property: 0, setValue(value) { this._property = value; }, getValue() { return this._property; } }) ・Functionコンストラクタ関数 ＊実装例＊ const Example = new Function(); ただし，公式からこのような記法は，非推奨とされている．以下の関数宣言，関数式，アロー関数による関数式省略，の記法が推奨される．特にアロー関数では，thisが宣言されたオブジェクト自身を指すため，保守性が高くおすすめである． ＊実装例＊ // 関数宣言 function Example() { // 慣習的にアンダーバーでprivateを表す． _property = 0; // プロパティ値として宣言した関数を，メソッドという． this.setValue = function(value) { this._property = value; }; this.getValue = function(){ return this._property; }; } // コール const Example = new Example(); // 関数式 const Example = function(value) { // 慣習的にアンダーバーでprivateを表す． _property = 0; this.setValue = function(value) { this._property = value; }; this.getValue = function() { return this._property; }; } // アロー関数による関数式の省略記法 const Example = (value) => { // 慣習的にアンダーバーでprivateを表す． _property = 0; this.setValue = function(value) { this._property = value; }; this.getValue = function() { return this._property; }; } リテラル表記とObjectコンストラクタ関数による生成とは異なり，コンストラクタ関数によって宣言されたオブジェクトは，暗示的にprototypeプロパティをもつ． ＊実装例＊ // リテラル表記による生成 const object1 = {}; // Objectコンストラクタ関数による生成 const object2 = new Object({}); // ユーザ宣言Functionコンストラクタ関数による生成 const Object3 = function(){}; // 出力結果 console.log( object1.prototype, // undefined object2.prototype, // undefined Object3.prototype // Object3 {} ); 糖衣構文のclassの使用 ・JavaScriptのクラスとは ES6から，糖衣構文のclassによって，オブジェクトを宣言できるようになった．クラス宣言あるいはクラス式で記述する．オブジェクトの生成時，constructor()でオブジェクトの初期化を行う．パスカルケース（大文字から始める記法）を用いる． ・クラス宣言記法 ＊実装例＊ // named exportによる出力 export class Example { // classでしか使えない． // Setterの代わりにコンストラクタでImmutableを実現． // データの宣言と格納が同時に行われる． constructor(value) { this.property = value; } getValue() { return this.property; } } // ファイルの読み込み import {Example} from \"./example.js\"; // 生成，初期化 const example = new Example(1); // メソッドのコール example.getValue(); ・クラス式記法 // named exportによる出力 export const Example = class { // classでしか使えない． // Setterの代わりにコンストラクタでImmutableを実現． // データの宣言と格納が同時に行われる． constructor(value) { this._property = value; } getValue() { return this._property; } } // ファイルの読み込み import {Example} from \"./example.js\"; // 生成，初期化 const example = new Example(1); // メソッドのコール example.getValue(); 02-02. オブジェクトの操作 プロトタイプチェーンによる継承 ・プロトタイプチェーンとは オブジェクトが暗示的に持つprototypeプロパティに，別のオブジェクトのメンバを追加することによって，そのオブジェクトのプロトタイプを継承することができる．オブジェクトからプロパティやメソッドをコールした時，そのオブジェクトにこれらが存在しなければ，継承元まで辿る仕組みを『プロトタイプチェーン』という．クラスベースのオブジェクト指向で用いられるクラスチェーンについては，別ノートを参照せよ． ・new Obejct()を用いた継承 ＊実装例＊ // 大元となるオブジェクトは個別ファイルで管理しておくのがベター． // コンストラクタ関数の関数式による宣言． const Example = function(value) { // 慣習的にアンダーバーでprivateを表す． _property = 0; this.setValue = function(value) { this._property = value; } this.getValue = function() { return this._property; }; } 別クラスで，以下のように継承する． ＊実装例＊ // 継承元のオブジェクトのファイルを読み込むことも忘れずに． // prototypeプロパティの継承先のオブジェクトを宣言． const SubExample = function(subValue) { // 慣習的にアンダーバーでprivateを表す． this.subProperty = subValue; this.setSubValue = function(subValue) { this.subProperty = subValue; } this.getSubValue = function() { return this.subProperty; }; } // new Example()を用いた継承． SubExample.prototype = new Example(); // SubExampleクラスにはgetValue()は無い． // 継承元まで辿り，Examlpeクラスからメソッドがコールされる（プロトタイプチェーン）． const result = SubExample.getValue() console.log(result); ・Object.create()を用いた継承とメンバ追加 ＊実装例＊ // 継承元のオブジェクトのファイルを読み込むことも忘れずに． // prototypeプロパティの継承先のオブジェクトを宣言． const SubExample = function() { // 慣習的にアンダーバーでprivateを表す． _property = 0; this.setSubValue = function(subValue) { this.subProperty = subValue; }; this.getSubValue = function() { return this.subProperty; }; }; // Object.create()を用いた継承． SubExample.prototype = Object.create(Example.prototype); // SubExampleクラスにはgetValue()は無い． // 継承元まで辿り，Examlpeクラスからメソッドがコールされる（プロトタイプチェーン）． const result = SubExample.getValue(); console.log(result); また，Object.create()を用いる場合，継承だけでなく，メンバを新しく追加することもできる． ＊実装例＊ // Object.create()による継承． SubExample.prototype = Object.create(Example.prototype, { // データを定義 subProperty: \"テスト\" // メソッドを定義 printSubValue: function() { return \"これは\" + this.subProperty + \"です．\"; } }); // SubExampleクラスにはprintSubValue()が追加された． const result = SubExample.printSubValue(); console.log(result); 02-03. thisの参照先 メソッドとしてコールする場合 メソッド内のthisは，exampleオブジェクトを指す． ＊実装例＊ const example = { // 慣習的にアンダーバーでprivateを表す． _property: 0, setValue(value) { this._property = value; }, getValue() { return this._property; } } // メソッド内のthisは，exampleオブジェクトを指す． example.setValue(1); example.getValue(); // 1 コンストラクタ関数としてコールする場合 ・関数宣言と関数式によるコンストラクタ関数内のthisの場合 コンストラクタ関数内のthisは，自身がコールされたオブジェクトを指す． ＊実装例＊ // 一番外側はWindowオブジェクト param = \"global param\"; // 関数宣言 function printParam(){ console.log(this.param); } // オブジェクト1 const object1 = { param: \"object1 param\", func: printParam } // オブジェクト2 const object2 = { param: \"object2 param\", func: printParam } /* コンストラクタ関数内のthisの場合 コンストラクタ関数内のthisは，自身がコールされたオブジェクトを指す． ここでは，object1とobject2 */ object1.printParam; // object1 param object2.printParam; // object2 param ・アロー関数によるコンストラクタ関数内のthisの場合 アロー関数内のthisの参照先には，十分な注意が必要である．今まで，JavaScriptでは，thisの参照先が文脈によって変わることに批判が集まっていた．そこで，参照先が文脈によって変わらない機能が追加された．thisは，自身が宣言されたオブジェクトを指す． ＊実装例＊ // 一番外側はWindowオブジェクト param = \"global param\"; // アロー関数による省略記法 const printParam = () => { console.log(this.param); }; // オブジェクト1 const object1 = { param: \"object1 param\", func: printParam }; // オブジェクト2 const object2 = { param: \"object2 param\", func: printParam } /* アロー関数内のthisの場合 thisは，自身が宣言されたオブジェクトを指す． ここでは，一番外側のWindowオブジェクトであり，object1とobject2ではない． 参照先は文脈によって変わらない． */ object1.printParam; // global param object2.printParam; // global param また，アロー関数がコールバック関数の引数となっている場合…（要勉強） "},"public/frontend_js_object_orientation_method_data.html":{"url":"public/frontend_js_object_orientation_method_data.html","title":"▶ ︎プロトタイプベース（2）","keywords":"","body":"プロトタイプベースのオブジェクト指向プログラミング（２） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 関数 関数オブジェクト ・関数オブジェクトとは オブジェクトでもある関数である． ・リテラル表記による関数オブジェクト // 定義 const object = { foo: \"bar\", age: 42, baz: {myProp: 12}, } ・コンストラクタ関数 関数宣言方式のFunctionコンストラクタを使用して，オブジェクトを定義する． // 関数宣言による定義 function car(make, model, year) { this.make = make; this.model = model; this.year = year; } // コール const mycar = new car(\"Eagle\", \"Talon TSi\", 1993); function命令 ・function命令とは オブジェクトではない関数である． ＊実装例＊ // 定義（コールする場所が前後しても無関係） function methodA(){ return \"A\"; } // コール function methodA(); ・名前がドルマークのもの JavaScriptでよく見かけるドルマーク．これは，関数の名前としてドルマークを使用しているだけである． ＊実装例＊ // 定義 function $(){ return \"A\"; } jQueryでは，ライブラリの読み込み宣言時に，「Jquery」という名前の代わりにドルマークを使用する仕様になってる．これと混乱しないように注意する． ＊実装例＊ // jQuery.get() と同じ $.get() { return \"A\"; } ・コールバック関数 const asyncFunc => (param, callback) { setTimeout(() => { // getDataメソッドは，数値を渡すとdataを取得してくれると仮定します． const data = getData(param); const err = data.getError(); // 第二引数のコールバック関数は，getDataメソッドとgetErrorメソッドの後に実行される． callback(err, data); }, 0); } const test = 1 // asyFuncメソッドの第一引数が，第二引数で設定したコールバック関数に渡される． // 渡されたコールバック関数は，getDataメソッドとgetErrorメソッドの後に実行されるため，errやdataを受け取れる asyncFunc(test, (err, data) => { if (err) { throw err; } console.log(data); }); 02. データ型 undefined，null ・undefined データを代入しない時に適用されるデータ型である． ＊実装例＊ // 変数b: 初期化されていない（値が代入されていない） const b; // 変数bの出力 console.log(b); // undefied ・null nullは，undefinedとは異なり，意図して代入しなければ適用されないデータ型である． ＊実装例＊ // 変数a: 意図をもってnullを入れている const a = null; console.log(a); // null ・undefinedの返却 undefinedを返却する場合，returnのみを記述する． ＊実装例＊ function hoge(){ return; // 空の『return文』です。空なので『undefined』を返します。 } const x = hoge(); // 変数『x』には関数『hoge』から返ってきた『undefined』が代入されます。 console.log(x); // 『undefined』が出力されます。 03. 変数 変数の種類 ・一覧表 項目 var let const 再宣言 可能 不可能 不可能 再代入 可能 可能 不可能 初期化（undefined化） 可能 可能 不可能 スコープ 関数スコープ ブロックスコープ ブロックスコープ ・const 基本的には，宣言にconstを用いる if (true) { // ブロック外からアクセス不可 const x = \"foo\"; // 再宣言不可 const x = \"bar\"; // ERROR // 再代入不可 x = \"baz\"; // ERROR } // ブロック内のconstにアクセス不可 console.log(x); // ERROR ・ let 繰り返し処理において再代入が必要であれば，constではなくletを用いる． if (true) { // ブロック外からアクセス不可 let x = \"foo\"; // 再宣言不可 let x = \"bar\"; // ERROR // 再代入可能 x = \"baz\"; } // ブロック内のletにアクセス不可 console.log(x); // ERROR また，try-catch構文では変数への代入が保証されていないため，letを使用して，あらかじめ初期化しておく必要がある． const asyncFunc = async () => { // 初期化するとundefinedになる． let response; try { response = await axios.get(\"/some/path1\") console.info(response); } catch (error) { console.error(error); } return response; } ・ var if (true) { // ブロック外からアクセス可 var x = \"hoge\"; // 再宣言 var x = \"fuga\"; // 再代入可能 x = \"fuga\"; } // ブロック内のvarにアクセス可能 console.log(x); // fuga 変数の巻き上げ ・巻き上げの対策 意図しない挙動を防ぐため，javascriptにおいて，変数の宣言と代入は，スコープの最初に行う． ・var 確認のためconsole.logメソッドを実行した場合，xを宣言していないため，「x is not defined 」エラーになりそうである．しかし実際は，宣言が既に済んでおり，xに値が代入されていないことを示す「undefined」となる． console.log(x); // undefined var x = \"hoge\"; // 宣言と代入 これは，スコープの範囲内で宣言と代入を実行した変数において，宣言処理がスコープの最初に行ったことになるという仕様のためである． // var x 宣言処理したことになる console.log(x); // undefined var x = \"hoge\"; // 宣言と代入により，実際は宣言処理を実装していなくとも，行なったことになる． ・let,const 宣言にlet，constを使用した場合，巻き上げは起こらない． console.log(x); // x is not defined let x = \"hoge\"; 04. 反復 for ... of ・for ... ofとは 配列を順序を保ったまま走査し，配列の値を取得する．オブジェクトに対してentiresメソッドを使用し，一度配列に変換すれば，オブジェクトでもfor ... ofを使用できる．for ... inを使用するより，こちらを使用した方が良い． ・配列の場合 const array = [\"foo\", \"bar\", \"baz\"]; for (const value of array) { console.log(value); } // foo // bar // baz 配列のentiresメソッドを使用すれば，インデックス番号を取得することもできる． const array = [\"foo\", \"bar\", \"baz\"]; for (const [key, value] of array.entries()) { console.log(key); } // 0 // 1 // 2 ・オブジェクトの場合 オブジェクトに対してentiresメソッドを実行し，一度連想配列に変換すれば，オブジェクトでもfor ... ofを使用できる． const object = { \"x\": \"foo\", \"y\": \"bar\", \"z\": \"baz\" }; for (const [key, value] of Object.entries(object)) { console.log(value); } // foo // bar // baz for ... in ・for ... inとは 配列／オブジェクト（連想配列）を順序を保たずに走査し，オブジェクト／配列のキー名を取得する． ・配列の場合 const array = [\"foo\", \"bar\", \"baz\"]; for (const key in array) { console.log(key); } // 0 // 1 // 2 ・オブジェクトの場合 const object = { \"x\": \"foo\", \"y\": \"bar\", \"z\": \"baz\" }; for (const key in object) { console.log(key); console.log(object[key]); } // x // y // z // foo // bar // baz continue ・continueとは 反復処理の現在のループをスキップし，次のループを開始する． const array = [\"foo\", \"bar\", \"baz\"]; for (const [key, value] of array.entries()) { // キーが偶数の組をスキップする． if(!(key % 2 == 0)){ continue; } console.log(value); } // foo // baz ・forEach関数を使用した代替法 反復処理のループをcontinueでスキップと同じ動作を，配列を扱う関数のコールバック関数で早期リターンで実現できる．continueを使用するより，こちらの方が良い． 参考：https://www.deep-rain.com/programming/javascript/778#continue PHPにも，forEach関数と同じように配列に対してコールバック関数を適用する関数（find，fliter，map，reduce，some）があり，用途に合わせて使い分ける． 参考：https://qiita.com/diescake/items/70d9b0cbd4e3d5cc6fce ちなみにPHPにも，forEach関数と同じような使い方をするarray_walk関数がある． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_logic_iteration.html const array = [\"foo\", \"bar\", \"baz\"]; array.forEach(function (value, key) { // キーが偶数の組をスキップする． if(!(key % 2 == 0)){ return; } console.log(value); }) // foo // baz "},"public/frontend_js_logic_validation.html":{"url":"public/frontend_js_logic_validation.html","title":"▶ ︎フロントエンド側の検証ロジック","keywords":"","body":"フロントエンド側の検証ロジック はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 検証 検証の必要性の有無 ・不要な場合 データベースから取得した後に直接表示する値の場合，データベースでNullにならないように制約をかけられる．そのため，値が想定通りの状態になっているかを改めて検証する必要はない． ・必要な場合 データベースからの値を直接表示する場合と異なり，新しく作られる値を用いる場合，その値が想定外の状態になっている可能性がある．そのため，値が想定通りの状態になっているかを検証する必要がある．検証パターンについては，後述の説明を参考にせよ． 検証パターンと検証メソッドの対応 〇：TRUE ✕：FALSE バックエンドの検証については以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_logic_validation.html typeof $var if($var) null object ✕ 0 number ✕ 1 number 〇 \"\"（空文字） string ✕ \"あ\" string 〇 NaN number ✕ undefined undefined ✕ "},"public/frontend_js_package.html":{"url":"public/frontend_js_package.html","title":"▶ ︎パッケージ","keywords":"","body":"JavaScriptパッケージ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. npmによるパッケージの管理 init ・package.jsonファイルの作成 プロジェクトのpackage.jsonファイルを作成する． $ npm init ・package.jsonファイルの構造 { # npmパッケージ名．全てのnpmパッケージの中で，一意の名前でなければならない． \"name\": \"tech-notebook-gitbook\", \"version\": \"1.0.0\", \"description\": \"tech-notebook-gitbook\", \"main\": \"index.js\", \"directories\": {}, # 本番環境と開発環境で依存するパッケージ名．パッケージ名は一意に識別できる． \"dependencies\": { \"gitbook-plugin-advanced-emoji\": \"^0.2.2\", \"gitbook-plugin-anchors\": \"^0.7.1\", \"gitbook-plugin-back-to-top-button\": \"^0.1.4\", \"gitbook-plugin-copy-code-button\": \"^0.0.2\", \"gitbook-plugin-ga\": \"^1.0.1\", \"gitbook-plugin-github-buttons\": \"^3.0.0\", \"gitbook-plugin-hide-published-with\": \"^1.0.3\", \"gitbook-plugin-intopic-toc\": \"^1.1.1\", # パッケージとして登録されていないもの『リポジトリURLから直接参照する．『git+』を忘れないこと． \"gitbook-plugin-prism\": \"git+https://github.com/hiroki-it/gitbook-plugin-prism.git\", \"gitbook-plugin-search-pro-fixed\": \"^1.0.1\", \"gitbook-plugin-sunlight-highlighter\": \"^0.4.3\", \"gitbook-plugin-toolbar\": \"^0.6.0\" }, # 開発環境のみ依存するパッケージ名． \"devDependencies\": {}, \"scripts\": {}, \"repository\": { \"type\": \"git\", \"url\": \"https://github.com/hiroki-it/tech-notebook-gitbook.git\" }, # 著者名 \"author\": { \"name\": \"Hiroki Hasegawa\", \"email\": \"hasegawafeedshop@gmail.com\", \"url\": \"https://github.com/hiroki-it\" }, \"license\": \"ISC\", \"bugs\": { \"url\": \"https://github.com/hiroki-it/tech-notebook-gitbook/issues\" }, \"homepage\": \"https://github.com/hiroki-it/tech-notebook-gitbook\" } install ・オプションなし インストールされていないパッケージをインストールする． $ npm install ・--force パッケージのインストール時に，ディレクトリの実行権限不足でインストールが停止することがある．これを無視してインストールを行う． $ npm install --force ・--save デフォルトで有効化されている．パッケージのインストール時に，依存するパッケージとして，dependenciesキーにパッケージ名とバージョンを書き込む． $ npm install --save update ・オプションなし インストールされていないパッケージをインストールする．また，バージョン定義をもとに更新可能なパッケージを更新する． $ npm update run ・オプションなし ユーザが定義したエイリアス名のコマンドを実行する． $ npm run あらかじめ，任意のエイリアス名をscriptsキー下に定義する．エイリアスの中で，実行するコマンドのセットを定義する．ちなみに，実行するコマンドの中で，再度runコマンドを定義することも可能である． { \"scripts\": { # \"\": \"\", \"dev\": \"npm run development\", \"development\": \"cross-env NODE_ENV=development node_modules/webpack/bin/webpack.js --progress --hide-modules --config=node_modules/laravel-mix/setup/webpack.config.js\", \"watch\": \"npm run development -- --watch\", \"watch-poll\": \"npm run watch -- --watch-poll\", \"hot\": \"cross-env NODE_ENV=development node_modules/webpack-dev-server/bin/webpack-dev-server.js --inline --hot --disable-host-check --config=node_modules/laravel-mix/setup/webpack.config.js\", \"prod\": \"npm run production\", \"production\": \"cross-env NODE_ENV=production node_modules/webpack/bin/webpack.js --no-progress --hide-modules --config=node_modules/laravel-mix/setup/webpack.config.js\" } } NODE_OPTIONS メモリ上限を設定する． $ export NODE_OPTIONS=\"--max-old-space-size=2048\" 02. モジュールバンドル モジュールバンドルとは 機能 ・読み込むパッケージをまとめる 参考：https://qiita.com/soarflat/items/28bf799f7e0335b68186 ＊例＊ 以下のようなHTMLファイルがあるとする． webpack tutorial モジュールバンドルは，scriptタグでのパッケージの読み込みをまとめる．これがブラウザにレンダリングされると，JavaScriptのファイルへのリクエスト数が減るため，ページの読み込みが早くなる． webpack tutorial "},"public/frontend_js_framework_vuejs.html":{"url":"public/frontend_js_framework_vuejs.html","title":"▶ ︎Vue.js","keywords":"","body":"Vue.js はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Vue.jsを用いたMVVMアーキテクチャ MVVMアーキテクチャ，双方向データバインディング ・一般的なMVVMアーキテクチャとは View層とModel層の間にViewModel層を置き，View層とViewModel層の間で双方向にデータをやり取り（双方向データバインディング）することによって，View層とModel層の間を疎結合にするための設計手法の一つ． ・ MVVMアーキテクチャにおける各層の責務 View層（xxx.html，/xxx.twig，xxx-component.vueのtemplateタグ部分） ViewModel層から渡されたデータを出力するだけ． ViewModel層（index.js，xxx-component.vueのscriptタグ部分） プレゼンテーションロジック（フォーマット整形，バリデーション，ページのローディング，エラーハンドリング，イベント発火など）や，ビジネスロジック（※控えめに）を記述する．scriptタグによって，JavaScriptが組み込まれている． Model層（store.jsまたはxxx.js) ビジネスロジックや，ajaxメソッドによるデータ送受信，を記述する． ・Vueを用いたMVVMアーキテクチャ，双方向データバインディング Vueは，アプリケーションの設計にMVVMアーキテクチャを用いることを前提として，双方向データバインディングを実現できるような機能を提供する． View層では，xxx.html，/xxx.twig，xxx-component.vueのtemplateタグ部分） ViewModel層では，index.js，xxx-component.vueのscriptタグ部分 Model層では，Vuex（store.js)やJavaScriptからなるモデル（xxx.js）を設置する． これの元，双方向データバインディングが実現される仕組みとして，View層でイベントが起こると，ViewModel層でこれにバインディングされたイベントハンドラ関数がコールされる． 親子コンポーネント間のデータ渡し ・親子コンポーネント間のデータ渡しの仕組み（Props Down, Events Up） まず，双方向データバインディングとは異なる概念なので，混乱しないように注意する．コンポーネント（xxx-component.vue）のscriptタグ部分（ViewModel層）の親子間では，propsと$emit()を用いて，データを渡す．この仕組みを，Props Down, Events Upという． MVVMアーキテクチャの実装例 (1) 【View層】テンプレート（xxx.html，xxx.twig） データが，テンプレートからJavaScriptファイルに渡される仕組みは，フレークワークを使わない場合と同じである．データがJavaScriptファイルに渡される状況としては，イベント発火時である． ＊実装例＊ 例えば，テンプレートの親コンポーネントタグでクリックイベントが発火した時，親コンポーネントから，イベントに紐づいたイベントハンドラ関数がコールされる． (1-2) 【ViewModel層】データの初期化を行うVueコンストラクタ関数（index.js） Vueコンストラクタ関数を用いて，インスタンス化することによって，ルートVueインスタンスが生成される．インスタンスの変数名vmはVIewModelの意味である．インスタンス化時，全てのコンポーネントのデータが初期化される．各コンポーネントで個別に状態を変化させたいものは，propsオプションではなく，dataオプションとして扱う． 参考：https://v1-jp.vuejs.org/guide/instance.html ＊実装例＊ // ルートVueインスタンス // 変数への格納を省略してもよい var vm = new Vue({ //　Vueインスタンスを使用するdivタグを設定. el: \"#app\", /* dataオプション ・Vueインスタンスのデータを保持する ・異なる場所にある同じコンポーネントは異なるVueインスタンスからなる． ・異なるVueインスタンスは異なる値をもつ必要があるため，メソッドとして定義． */ data: function () { return { isLoading: false, staffData: [], criteria: { id: null, name: null }, }; }, /* methodオプション ・Vueインスタンスのアクセサメソッドや状態変化メソッド ・イベントハンドラ関数，dataオプションのセッターを定義 */ method: { // イベントハンドラ関数 changeQuery(criteriaObj) { const keys = [ \"criteria\", \"limit\", ]; for (const key of keys) { if (key in criteriaObj) { this[key] = criteriaObj[key]; } } }, // dataオプションのセッター load(query) { // ここでのthisはdataオプションを指す． this.isLoading = true; this.staffData = []; // ajaxメソッドをラッピングしたメソッドをコール return Staff.find(query) /* done() ajaxメソッドによって返却されたJSONが引数になる． */ .done((data) => { /* サーバサイドからのJSONをデシリアライズ． dataオプションに設定． */ this.staffData = _.map( data.staffData, Staff.deserializeStaff ); }) }, }, /* watchオプション ・Vueインスタンス内の値の変化を監視する関数を定義． ・Vue-Routerを参照せよ． */ watch: {}, // テンプレートと親コンポーネントの対応になるようにする． component: { //『HTMLでのコンポーネントのタグ名：子コンポーネント』 \"v-foo-component-1\": require(\".../component/xxx-1.vue\"), \"v-foo-component-2\": require(\".../component/xxx-2.vue\"), \"v-foo-component-3\": require(\".../component/xxx-3.vue\") }, }) (2) 【View + ViewModel層】単一ファイルコンポーネントとしてのコンポーネント（xxx-component.vue） コンポーネントは，View層としてのtemplateタグ，ViewModel層としてのscriptタグとstyleタグを用いて，単一ファイルコンポーネントとする． ＊実装例＊ 例えば，親コンポーネントの子コンポーネントタグでクリックイベントが発火した時，子コンポーネントから，イベントに紐づいたイベントハンドラ関数がコールされる． //============= // ViewModel層 //============= // 親コンポーネント以降では，Vueインスタンスを生成しないようにする． module.exports = { /* propsオプション ・親コンポーネントまたはajaxメソッドからpropsオブジェクトのプロパティに値が格納される． */ props: { \"criteria\": { type: Object, required: true, }, \"foo\": { type: Object, required: true, } }, /* dataオプション ・異なる場所にある同じコンポーネントは異なるVueインスタンスからなる． ・異なるVueインスタンスは異なる値をもつ必要があるため，メソッドとして定義する． */ data: function () { return { a: \"a\", b: \"b\", c: \"c\", d: \"d\", }; }, // イベントハンドラ関数，dataオプションのセッター method: { updateCriteria(key, value) { /* ・コンポーネント（v-foo-component-1）と紐づく処理 ・changeイベントの発火と，これのイベントハンドラ関数に引数を渡す． */ this.$emit( \"change\", {\"criteria\": localCriteria} ); }, // ajaxメソッドから送信されてきたデータを用いて，propsを更新 updateProps(key, value) { }, // 『HTMLでのコンポーネントのタグ名：　JSでのコンポーネントのオブジェクト名』 component: { // 子コンポーネントと孫コンポーネントの対応関係 \"v-foo-component-4\": require(\"./xxx/xxx/xxx-4\"), \"v-foo-component-5\": require(\"./xxx/xxx/xxx-5\"), }, } } (3) 【Model層】オブジェクトとしてのVuex（store.js） Vuexについては，以降の説明を参照せよ． (3-2) 【Model層】オブジェクトとしてのJavaScript（xxx.js） クラス宣言で実装する． ＊実装例＊ class Foo { /* ・コンポーネントからデータを受信． ・プロパティの宣言と，同時に格納． */ constructor(properties) { this.isOk = properties.isOk; } // コンストラクタによって宣言されているので，アクセスできる． isOk() { // bool値を返却するとする． return this.isOk; } } 01-02. View層とViewModel層の間での双方向データバインディングの方法 イベントハンドリング ・v-on:とは View層（templateタグ部分）のイベントを，ViewModel層（scriptタグ部分）のイベントハンドラ関数（methods:内にあるメソッド）やインラインJSステートメントにバインディングし，イベントが発火した時点でイベントハンドラ関数をコールする．コンポーネントのscriptタグ部分（ViewModel層）の親子間データ渡しである「Props Down, Events Up」とは異なる概念なので注意する． v-on:{イベント名}=\"{イベントハンドラ関数（methods: 内にあるメソッド）}\" または，省略して， @:{イベント名}=\"\" で記述する． ・v-on:submit=\"\"，buttonタグ View層のフォーム送信イベントが起きた時点で，ViewModel層にバインディングされたイベントハンドラ関数をコールする．例えば，親コンポーネントでは，子コンポーネントによって発火させられるsearchイベントに対して，result()というイベントハンドラ関数を紐づけておく． ＊実装例＊ index.jsのmethods:内には，イベントハンドラ関数としてresult()を定義する． ＊実装例＊ // 変数への格納を省略してもよい var vm = new Vue({ //　Vueインスタンスを使用するdivタグを設定. el: \"#app\", // イベントハンドラ関数 method: { result() { // 何らかの処理 } } }) 『検索ボタンを押す』というsubmitイベントの発火によって，formタグでイベントに紐づけられているイベントハンドラ関数（search()）がコールされる． イベントハンドラ関数内のemit()が，親コンポーネントのsearchイベントを発火させる．これに紐づくイベントハンドラ関数（result()） がコールされる． ＊実装例＊ 検索する // 変数への格納を省略してもよい var vm = new Vue({ // イベントハンドラ関数を定義 methods: { search() { // 親コンポーネントのsearchイベントを発火させる． this.$emit(\"search\") }, } }) ・v-on:click=\"\" View層でクリックイベントが起きた時点で発火し，ViewModel層でバインディングされたイベントハンドラ関数をコールする． ・v-on:change=\"\" View層でinputタグやselectタグで，値の入力後にマウスフォーカスがタグから外れた時点で発火し，ViewModel層でバインディングされたイベントハンドラ関数をコールする ・v-on:input=\"\" View層でinputタグで，一文字でも値が入力された時点で発火し，ViewModel層バインディングされたイベントハンドラ関数をコールする．v-on:changeとは，イベントが発火するタイミングが異なるため，共存することが可能である． 条件付きレンダリング ・v-show／v-ifとは 条件分岐を行うタグであり，v-showまたはv-ifを使用して，プロパティ名を指定する．（v-xxx=\"\"）で記述する．親テンプレートから渡されたprops内のプロパティ名がもつ値がTRUEの時に表示し，FALSEの時に非表示にする．もし頻繁に表示と非表示の切り替えを行うようなら，v-ifの方が，描画コストが重たくなるリスクが高くなる為，v-show推奨である． タグ 使い分け v-if 単発の切り替えがメインの場合 v-show 表示/非表示の切替回数が多い場合 属性データバインディング ・v-bindとは ※要勉強 フォーム入力データバインディング ・v-modelとは 実装方法は，v-on:input=\"\"と同じである．例えば，以下の二つは同じである． その他のディレクティブ ・v-cloakとは ※要勉強 01-03. コンポーネント コンポーネントの登録方法 ・グローバル登録 ＊実装例＊ Vue.component(\"v-foo-component\", { template: require(\"./xxx/xxx/xxx\") }); // 変数への格納を省略してもよい var vm = new Vue({ el: \"#app\" }) ・ローカル登録 ＊実装例＊ var vFooComponent = { // テンプレートと親コンポーネントの対応関係 template: require(\"./xxx/xxx/xxx\"), }; // 変数への格納を省略してもよい var vm = new Vue({ el: \"#app\", components: { // 親コンポーネントにオブジェクト名をつける． \"v-foo-component\": vFooComponent } }) ただし，コンポーネントのオブジェクト名の定義は，以下のように省略することができる． ＊実装例＊ // 変数への格納を省略してもよい var vm = new Vue({ el: \"#app\", components: { // テンプレートと親コンポーネントの対応関係 \"v-foo-component\": require(\"./xxx/xxx/xxx\"), } }) 02. Vue-Routerライブラリによるルーティング Vue-Router ・Vue-Routerとは ルーティングライブラリの一つ．コンポーネントに対してルーティングを行い，/{ルート}/パラメータ}に応じて，コールするコンポーネントを動的に切り替えることができる． GET http://www.example.co.jp:80/{ルート}/{パスパラメータ}?text1=a&text2=b HTTP/2 ＊実装例＊ // Vue-Routerライブラリを読み込む． const vueRouter = require(\"vue-router\").default; // VueRouterインスタンスを作成する． const router = new VueRouter({ routes: [ {path: \"/\", component: Home}, {path: \"/foo\", component: Foo} ] }) // 外部ファイルが，VueRouterインスタンスを読み込めるようにしておく． module.exports = router; そして，Vue-Routerの機能を利用するために，routerオプションをルートコンポーネントに注入する必要がある． import router from \"./router\" // 変数への格納を省略してもよい var vm = new Vue({ // routerオプション router, // watchオプション watch: { // スタック内で履歴の移動が起こった時に，対応付けた無名関数を実行． \"$route\": function (to, from) { if (to.fullPath !== from.fullPath) { // 何らかの処理． } }, } }) ・$router（Routerインスタンス） Webアプリケーション全体に1つ存在し，全体的なRouter機能を管理しているインスタンス．スタック型で履歴を保持し，履歴を行き来することで，ページ遷移を行う． メソッド 説明 push queryオブジェクトを引数とする．履歴スタック内に新しい履歴を追加し，現在をその履歴とする．また，ブラウザの戻る操作で，履歴スタック内の一つ前の履歴に移動する． 参考：https://router.vuejs.org/guide/essentials/navigation.html ＊実装例＊ // users/?foo=xyz が履歴スタックに追加される． this.$router.push({ path : \"/users\", query: { foo : \"xyz\" }}); ・$route（Routeオブジェクト） 現在のアクティブなルートをもつオブジェクト プロパティ データ型 説明 注意 path string 現在のルートの文字列． query Object クエリパラメータのキー名と値を保持するオブジェクト．/foo?user=1というクエリパラメータの場合，$route.query.user==1となる． もしクエリーがない場合は，空オブジェクト fullPath string URL全体の文字列． その他のRouterライブラリ JQueryにはJQueryRouter，ReactにはReact-Routerがある． 03. Vuexライブラリによるデータの状態変化の管理 Vuex ・Vuexとは Vuejsでライブラリの一つで，MVVMアーキテクチャのモデルに相当する機能を提供し，グローバルで参照できる．異なるコンポーネントで共通したデータを扱いたくとも，双方向データバインディングでは，親子コンポーネント間でしか，データを受け渡しできない．しかし，Vuexストア内で，データの状態の変化を管理することによって，親子関係なく，全てのコンポーネント間でデータを受け渡しできるようになる． ※Vuexからなるモデルはどうあるべきか，について要勉強 Vuex.Store()によるVuexストアの実装 外部のコンポーネントは，各オプションにアクセスできる． ・getters:{} データから状態を取得するメソッドをいくつか持つ．クラスベースオブジェクト指向でいうところの，Getterメソッドに相当する． ※MVVMにおいて，モデルにゲッターを持たせてはいけないというルールについては，要勉強． ・state:{} データの状態の変化をいくつか管理する．クラスベースオブジェクト指向でいうところの，データ（プロパティ）に相当する． ・mutations:{} データに状態（state）を設定するメソッドをいくつか持つ．保守性の観点から，mutations:{}におくメソッド間は同期的に実行されるようにしておかなければならない．クラスベースオブジェクト指向でいうところの，Setterメソッドに相当する． ・actions:{} 定義されたmutations{}のメソッドを間接的にコールするためのメソッドをいくつか持つ．また，JQueryのajaxメソッド をコールし，サーバー側からレスポンスされたデータをmutations:{}へ渡す．クラスベースオブジェクト指向でいうところの，Setterメソッドに相当する． ＊実装例＊ // Vuexライブラリを読み込む． const vuex = require(\"vuex\") // 外部ファイルが，このStoreインスタンスを読み込めるようにする． module.exports = new Vuex.Store({ /* getters ・データから状態を取得するメソッドをいくつか持つ ・クラスベースオブジェクト指向のGetterメソッドに相当. */ getters: { staffData(state) { return state.staffData; }, }, /* state ・状態の変化を管理したいデータをいくつかもつ． ・クラスベースオブジェクト指向のプロパティに相当． */ state: { // stateには多くを設定せず，Vueインスタンスのdataオプションに設定しておく． staffData: [], }, /* mutations ・データの状態（state）を変化させるメソッドをいくつかもつ． ・クラスベースオブジェクト指向のSetterメソッドに相当． */ mutations: { // Vuexのstateを第一引数，外部からセットしたい値を第二引数 mutate(state, staffData) { exArray.forEach( /* ・矢印はアロー関数を表し，無名関数の即コールを省略することができる． ・引数で渡されたexArrayの要素を，stateのexArrayに格納する． */ (element) => { state.exArray.push(element); } /* ※アロー関数を用いなければ，以下のように記述できる． function(element) { state.exArray.push(element); } */ ); }, }, /* actions ・mutations{}のメソッドを間接的にコールするためのメソッドをいくつか持つ． ・contextオブジェクトからcommit機能を取り出す必要がある．（※省略記法あり） ・クラスベースオブジェクト指向のSetterメソッドに相当． */ actions: { // 省略記法（Argument destructuring) mutate({commit}) { commit(\"mutate\"); } } }) コンポーネントからVuexへのアクセス 例えば，子コンポーネントのファイル（templateタグをもつファイル）の下部に，以下を記述することで，Vuex.Store()とデータを受け渡しできるようになる． ・computed: {} イベントハンドラ関数として，mapGettersヘルパーとmapStateヘルパーを設定する． ・methods: {} イベントハンドラ関数として，mapMutationsヘルパーとmapActionsヘルパーを設定する． ・mapGettersヘルパー コンポーネントのcomputed:{}に，Vuex.Store()のgetters: {}をマッピングし，コールできるようにする． ・mapStateヘルパー コンポーネントのcomputed:{}に，Vuex.Store()のstate: {}をマッピングし，コールできるようにする． ・mapMutationsヘルパー コンポーネントのmethods: {}に，Vuex.Store()のmutations: {}```をマッピングし，コールできるようにする． ・mapActionsヘルパー コンポーネントのmethods: {}に，Vuex.Store()のactions:{}をマッピングし，コールできるようにする． ＊実装例＊ ... // Vuex.Store()を読み込む． const store = require(\"./_store\") // Vuex.Store()のgetters，mutations，actionsをマッピングできるように読み込む． const mapGetters = require(\"vuex\").mapGetters; const mapActions = require(\"vuex\").mapActions; const mapMutaions = require(\"vuex\").mapMutaions; module.exports = { // イベントハンドラ関数を定義（※データを状態の変更を保持したくないもの） computed: { /* mapGettersヘルパー． StoreのGetterをローカルのcomputed:{}にマッピングし，コールできるように． */ ...mapGetters([ \"x-Function\" ]) }, // イベントハンドラ関数を定義（※データを状態の変更を保持したいもの） methods: { // mapMutationsヘルパー ...mapMutations([ \"y-Function\" ]), // mapActionsヘルパー ...mapActions([ \"z-Function\" ]), } } 04. ライフサイクル ライフサイクルフック ・ライフサイクルフックとは Vueインスタンスの生成から破棄までの間に実行される関数のこと．全ての関数を使用する必要はない． 参考：https://jp.vuejs.org/v2/api/index.html#%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3-%E3%83%A9%E3%82%A4%E3%83%95%E3%82%B5%E3%82%A4%E3%82%AF%E3%83%AB%E3%83%95%E3%83%83%E3%82%AF 順番 フック名 タイミング 1 beforeCreate Vueインスタンスの生成前 2 created Vueインスタンスの生成後 3 beforeMount Vueインスタンスがマウントされる前 4 mounted Vueインスタンスがマウントされた後 5 beforeUpdate データ更新時の再レンダリング前 6 updated データ更新時の再レンダリング後 7 beforeDestroy Vueインスタンスが削除される前（$destroyメソッド実行前） 8 destroyed Vueインスタンスが削除された後（$destroyメソッド実行後） ・マウントとは ブラウザ上のリアルDOMの要素を，Vue.jsの処理によって生成される仮想DOMの要素で置き換えること． 参考：https://jp.vuejs.org/v2/guide/render-function.html#%E3%83%8E%E3%83%BC%E3%83%89%E3%80%81%E3%83%84%E3%83%AA%E3%83%BC%E3%80%81%E3%81%8A%E3%82%88%E3%81%B3%E4%BB%AE%E6%83%B3-DOM ・beforeCreate Vueインスタンスの生成前に実行される． ＊検証例＊ beforeCreateフックの動作を検証する．dataオプションは，Vueインスタンス生成後に有効になるため，beforeCreateフックでコールできず，undefinedになる． {{ name }} new Vue({ data(){ return{ hoge:\"Hiroki\" } }, beforeCreate () { console.log(this.name) } } # 結果 undefined ・created フックの中で特によく使う．Vueインスタンスの生成後に実行される．マウント前に必要な処理を実装する． ＊実装例＊ 非同期通信によるデータを取得，マウント時に必要なデータの準備，など ＊検証例＊ createdフックの動作を検証する．dataオプションは，Vueインスタンス生成後に設定されるため，createdフックでコールでき，処理結果が表示される． {{ name }} // 変数への格納を省略してもよい var vm = new Vue({ data() { return{ name:\"Hiroki\" } }, created() { console.log(this.name) } } # 結果 \"Hiroki\" ・beforeMount Vueインスタンスがマウントされる前に実行される． ＊検証例＊ beforeMountフックの動作を検証する．dataオプションからname変数への展開は，マウントによって実行される．そのため，beforeMountフックの段階では要素自体が生成されておらず，何も表示されない． {{ name }} // 変数への格納を省略してもよい var vm = new Vue({ data() { return{ name: \"\" } }, beforeMount() { this.name = \"Hiroki\" } } # 結果 要素が生成されていないため，何も表示されない． ・mounted フックの中で特によく使う．Vueインスタンスがマウントされた後に実行される．要素を操作する処理を実装する．まず，Vueインスタンスにelオプションが設定されているかを識別し，これに応じて処理の流れが分岐する．SSRの場合には使用できない． ＊実装例＊ Vue.js以外の外部ライブラリの読み込み，検索実行時のイベントハンドラ関数，ページング実行時のイベントハンドラ関数，など ＊検証例＊ beforeMountフックの動作を検証する．dataオプションからname変数への展開は，elementへのマウント中に実行される．そのため，mountedメソッドが実行され，空文字が上書きされる． {{ name }} // 変数への格納を省略してもよい var vm = new Vue({ data() { return{ name: \"\" } }, mounted() { this.name = \"Hiroki\" } } # 結果 \"Hiroki\" ただし，全ての子コンポーネントでマウントが完了したことを待つために，nextTickメソッドを使用する必要がある． {{ name }} // 変数への格納を省略してもよい var vm = new Vue({ data() { return{ name: \"\" } }, mounted() { this.$nextTick(function () { this.name = \"Hiroki\" }) } } ・beforeUpdate データが更新される時の再レンダリング前に実行される．再レンダリング前に要素を操作する処理を実装する． ＊実装例＊ WindowオブジェクトやDocumentオブジェクトのメソッドによる要素の取得，など ＊検証例＊ {{ name }} // 変数への格納を省略してもよい var vm = new Vue({ data() { return{ name: \"\" } }, mounted() { this.$nextTick(function () { this.name = \"Hiroki\" }) }, beforeUpdate(){ console.log(this.name) } } # 結果 \"Hiroki\" ・updated データが更新される時の再レンダリング後に実行される．再レンダリング後に要素を操作する処理を実装する． {{ name }} // 変数への格納を省略してもよい var vm = new Vue({ data() { return{ name: \"\" } }, mounted() { this.$nextTick(function () { this.name = \"Hiroki\" }) }, beforeUpdate(){ console.log(this.name) } } # 結果 \"Hiroki\" ・beforeDestroy Vueインスタンスが削除される前に実行する．インスタンスを削除する前に無効化しておく必要のある処理を実装する．SSRの場合には使用できない． ・destroyed Vueインスタンスが削除された後に実行する．インスタンスを削除した後のTearDown処理を実装する．SSRの場合には使用できない． "},"public/frontend_js_framework_nuxtjs.html":{"url":"public/frontend_js_framework_nuxtjs.html","title":"▶ ︎Nuxt.js","keywords":"","body":"Nuxt.js はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ コマンド serverモード ・serverモードとは アプリケーションをSSRとして稼働させる． 参考：https://ja.nuxtjs.org/docs/2.x/get-started/commands#target-server ・dev ローカル環境として使用するため，アプリケーションをビルドし，Nodeサーバを起動する．Webpackは使用されないため，静的ファイルの圧縮や画像ファイル名のハッシュ化は実行されない． $ nuxt dev ・build 本番環境として使用するため，Nodeサーバの起動前にアプリケーションのビルドを実行する．devコマンドとは異なり，ビルド時にWebpackによる最適化が実行される．これにより，JavaScriptとCSSはminifyされる．minifyにより，不要な改行やインデントが削除され，パッケージの読み込みURLはまとめられ，圧縮される．画像名はハッシュ化される． $ nuxt build ・start 本番環境として使用するため，ビルド完了後にNodeサーバを起動する．SSRモードのために使用する． $ nuxt start staticモード ・staticモードとは アプリケーションをSSGとして稼働させる． 参考：https://ja.nuxtjs.org/docs/2.x/get-started/commands#target-static ・dev ローカル環境として使用するため，アプリケーションをビルドし，Nodeサーバを起動する．Webpackは使用されないため，静的ファイルの圧縮や画像ファイル名のハッシュ化は実行されない． $ nuxt dev ・build Node.jsを使用してテストフレームワークを動かすために使用する．devコマンドとは異なり，ビルド時にWebpackによる最適化が実行される．これにより，JavaScriptとCSSはminifyされる．minifyにより，不要な改行やインデントが削除され，パッケージの読み込みURLはまとめられ，圧縮される．画像名はハッシュ化される． $ nuxt build ・generate JavaScriptから静的ファイルを生成する．静的ファイルをビデータベースに格納したデータ（例：画像ファイルパス）を元にビルドすることも可能である．SSGモードのために使用する． $ nuxt generate ・start 静的ホスティングサイトを起動する． $ nuxt start ビルド時のWebpackオプション serverモードとstaticモードにおいて，buildコマンド時に使用されるWebpackの最適化方法を指定できる．` https://ja.nuxtjs.org/docs/2.x/get-started/commands#webpack-%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%82%92%E6%A4%9C%E6%9F%BB 設定ファイル envファイル # API側のURL（フロントエンドからのリクエスト向け） API_URL=http://web:80/ # API側のURL（外部サーバからのリクエスト向け） API_URL_BROWSER=http://localhost:8500/ # API側のOauth認証の情報 OAUTH_CLIENT_ID= OAUTH_CLIENT_SECRET= # GoogleMapのURL GOOGLE_MAP_QUERY_URL=https://www.google.com/maps/search/?api=1&query= # ホームパス HOME_PATH=/ nuxt.config.jsファイル ・概要 Nuxtが標準で用意している設定を上書きできる． 参考：https://ja.nuxtjs.org/docs/2.x/directory-structure/nuxt-config#nuxtconfigjs import { Configuration } from '@nuxt/types' const nuxtConfig: Configuration = { } ・hardSource ビルド時のキャッシュを有効化する．ビルドの完了が早くなる． 参考：https://nuxtjs.org/docs/2.x/configuration-glossary/configuration-build#hardsource import { Configuration } from '@nuxt/types' const nuxtConfig: Configuration = { build: { hardSource: true, }, } ・quiet ビルド時にログを最小限にする．CICDツールでログが確認できなくなるため，無効化しておいた方が良い． 参考：https://ja.nuxtjs.org/docs/2.x/configuration-glossary/configuration-build#quiet import { Configuration } from '@nuxt/types' const nuxtConfig: Configuration = { build: { quiet: false, }, } "},"public/frontend_js_debug.html":{"url":"public/frontend_js_debug.html","title":"▶ ︎デバッグのコツ","keywords":"","body":"フロントエンドのデバッグの豆知識 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. JavaScript デバッグに使えるメソッド ・Console API メソッド名 出力内容 console.clearメソッド コンソール画面をクリアにする console.countメソッド 実行する度にカウントアップして回数を出力する console.dirメソッド オブジェクトが持つプロパティの一覧をリストで出力する console.errorメソッド エラー情報として出力する（他に、info() / warn()もあり） console.groupメソッド インデントを付けて出力することで階層構造を持たせる（groupEnd()で終了する） console.logメソッド 任意の値を出力する console.tableメソッド 配列やオブジェクトなどの構造をテーブル表にして出力する console.timeメソッド time()〜timeEnd()までの間にある処理を計測する console.traceメソッド 呼び出し元を出力する． "},"public/backend_database_operation.html":{"url":"public/backend_database_operation.html","title":"▶ ︎データベースの操作","keywords":"","body":"データベースの操作 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. RDB（関係データベース）とは RDBMS（関係データベース管理システム）の仕組み RDBは，データ同士がテーブル状に関係をもつデータ格納形式である．データはストレージに保存する． RDBMSとRDBの種類 ・MariaDB MariaDBデータベースを管理できるRDBMS ・MySQL MySQLデータベースを管理できるRDBMS ・PostgreSQL PostgreSQLデータベースを管理できるRDBMS RDBSにおけるデータベースエンジン RDBMSがデータベースに対してデータのCRUDの処理を行うために必要なソフトウェアのこと． ・InnoDB 01-02. NoSQL（非関係データベース）とは NoSQLは，データ同士が関係を持たないデータ格納形式である．データをメインメモリに保存する． NoSQLの種類 01-04. テーブル設計 ER図：Entity Relation Diagram 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_object_orientation_analysis_design_programming.html 正規化 ・正規化とは 繰り返し要素のある表を『正規形』，その逆を『非正規形』という．非正規形の表から，他と連動するカラムを独立させ，正規形の表に変更することを『正規化』という． ・方法 ＊具体例＊ まず，主キーが受注Noと商品IDの2つであることを確認．これらの主キーは，複合主キーではないとする． エクセルで表を作成 エクセルで作られた以下の表があると仮定． 第一正規化（繰り返し要素の排除） レコードを1つずつに分割． 第二正規化（主キーの関数従属性を排除） 主キーと特定のカラムが連動する（関数従属性がある）場合，カラムを左表として独立させる．今回，主キーが2つあるので，まず受注Noから関数従属性を排除していく．受注Noと他3カラムが連動しており，左表として独立させる．主キーと連動していたカラムを除いたものを右表とする．また，主キーが重複するローを削除する． 次に，商品IDの関数従属性を排除していく．商品IDと他2カラムに関数従属性があり，左表として独立させる．主キーと連動していたカラムを除いたものを右表とする．また，主キーが重複するローを削除する．これで，主キーの関数従属性の排除は終了． 第三正規化（主キー以外のカラムの関数従属性を排除） 次に主キー以外のカラムの関係従属性を排除していく．上記で独立させた3つの表のうち，一番左の表で，顧客IDと顧客名に関数従属性があるので，顧客IDを新しい主キーに設定し，左表として独立させる．主キーと連動していたカラムを除いたものを右表とする． まとめ 主キーの関係従属性の排除によって，受注表，商品表，数量表に分割できた．また，主キー以外の関係従属性の排除によって，顧客IDを新しい主キーとした顧客表に分割できた． ＊具体例＊ エクセルで表を作成 以下のような表の場合，行を分割し，異なる表と見なす． 第一正規化（繰り返し要素の排除） データの追加／削除 データを追加するあるいは削除する場合，カラムではなく，レコードの増減を行う．カラムの増減の処理には時間がかかる．一方で，レコードの増減の処理には時間がかからない． ＊具体例＊ 賞与を年1回から，2回・3回と変える場合，主キーを繰り返し，新しく賞与区分と金額区分を作る． テーブル命名規則 ・テーブル名は複数形 例えば，foosとする． カラム命名規則 ・プレフィクスは単数形テーブル名 例えば，foo_id，foo_name，foo_typeとする．ただし，子テーブルの外部キーと紐づくカラムがある場合，そのカラムのプレフィクスは，子テーブル名の単数形とする．例えば，bar_idとする．例外として，ActiveRecordパターンのフレームワーク（Laravelなど）では使用しない方がよいかもしれない．これらのフレームワークでは，単数形テーブル名のプレフィクスがないカラム名を想定して機能が備わっていることがある．この場合，DBとの連携で毎回カラム名を明示する必要があったり，標準ではないカラム名を使用することによる不具合が発生したり，不便なことが多かったりするため，おすすめしない． foo_id bar_id foo_name foo_type 1 1 foo 2 02. ACID ACIDとは トランザクションを実現するため必要な機能を略して『ACID』という． 参考： http://tooljp.com/jyosho/docs/ACID/ACID.html https://atmarkit.itmedia.co.jp/ait/articles/1801/31/news011.html Atomicity（不可分性） ・Atomicityとは トランザクションに含まれる全ての処理が成功することと，またはいずれかが失敗した場合には何も実行されていない状態に戻ることを保証する性質のこと．コミットメント制御によって実装される． Consistency（整合性） ・Consistencyとは トランザクションの実行前後であっても，データは常にDBのルールに則っている性質のこと．カラムの制約によって実装される． Isolation（独立性） ・Isolationとは トランザクションはお互いに独立し，影響を与え合わない性質のこと．排他制御によって実装される． Durability（永続性） ・Durabilityとは トランザクションの完了後は，たとえシステム障害があったとしても，データは失われない性質のこと．障害回復制御によって実装される． 02-02. コミットメント制御 RDBの書き込み系の操作 ・CREATE／UPDATE/DELETE処理の流れ ・RDBの操作と実際のメソッドの対応関係 RDBの書き込み系の操作 PDOでのメソッド名 ラッピング システム障害からの回復 更新前ログの記録 ↓ ↓ ↓ ↓ ↓ トランザクション開始 beginTransaction() execute()開始 ↓ ↓ ↓ ⬆︎ ・C／U／Dの処理・トランザクション終了 ・insert()・update()・delete() flush() ⬆︎　Roll back：rollBack() ↓ ↓ ↓ ⬆︎ Commitによる更新後ログの書き込み． commit()開始 ↓ ↓ ↓ ↓ ⬇︎ ↓ ↓ ↓ ⬇︎　Roll forward ↓ ↓ ↓ ⬇︎ Check Pointによる更新後ログのDB反映 commit()終了 execute()終了 ・PDOによるRDBの書き込み系の操作 PDOでは書き込み処理にexecメソッド，読み出し処理にqueryメソッドを使用する． ＊実装例＊ setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION); // トランザクションを開始． $db->beginTransaction(); // いくつかのSQLが実行される．※もし失敗した場合，ERRMODE_EXCEPTIONを実行． $db->exec(\"INSERT INTO movie(title, price) VALUES(\"ハリポタ\", 2000)\") $db->exec(\"INSERT INTO movie(title, price) VALUES(\"シスター\", 2000)\") // トランザクション内の一連のステートメントが成功したら，ログファイルにコミット． $db->commit(); } catch{ // 例外が発生したらロールバックし，エラーメッセージを出力． $db->rollBack(); print \"失敗しました．：{$e->getMessage()}\" } ・DoctrineによるRDBの書き込み系の操作 詳しくは，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_framework_symfony.html コミットによるログファイルへの更新前ログへの書き込み ・コミット トランザクション内の一連のステートメントを，ログファイルの更新前ログとして書き込む． ・二相コミット コミットを以下の二つの段階に分けて行うこと．ACIDのうち，原子性と一貫性を実装している． 他のサイトに更新可能かどうかを確認． 全サイトからの合意が得られた場合に更新を確定． チェックポイントにおけるデータファイルへの書き込み トランザクションの終了後，DBMSは，処理速度を高めるために，ログファイルの更新後ログをいったんメモリ上で管理する． そして，チェックポイントで，ログファイルの更新後ログをディスク上のデータファイルに反映させる．この時，チェックポイントは，自動実行または手動実行で作成する． 02-03. 障害回復制御 システム障害からの回復 データベースサーバのソフトウェア障害のこと．例えば，DBMSやOSのトラブル等によりシステム全体が停止する． ・ロールバック 障害によって，トランザクション内の一連のステートメントがすべて実行されなかった場合に，ログファイルの更新前ログを用いて，トランザクションの開始前の状態に戻す． ・ロールフォワード 障害によって，トランザクションの終了後に一連のステートメントの更新結果がディスクに反映されなかった場合に，ログファイルの更新後ログを用いて，ディスク上のデータファイルに更新結果を反映させる． ＊具体例＊ 『a』の値を更新するステートメントを含むトランザクションの後に，システムが異常終了した場合，ログファイルの更新後ログ『a = 5』を用いて，ディスク上のデータファイルに更新結果を反映させる．（ロールフォワード） 『b』の値を更新するステートメントを含むトランザクションの途中に，システムが異常終了した場合，ログファイルの更新前ログ『b = 1』を用いて，障害発生前の状態に戻す．（ロールバック） 媒体障害からの回復 データベースサーバのハードウェア障害のこと．例えば，ハードディスクの障害がある．ディスクを初期化／交換した後，バックアップファイルからデータベースを修復し，ログファイルの更新後ログ『a = 5』『b = 1』を用いて，修復できる限りロールフォワードを行う． ＊具体例＊ バックアップファイルの実際のコード -- -------------------------------------------------------- -- Host: xxxxx -- Server version: 10.1.38-MariaDB - mariadb.org binary distribution -- Server OS: Win64 -- HeidiSQL Version: 10.2.0.5611 -- -------------------------------------------------------- /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; /*!40101 SET NAMES utf8 */; /*!50503 SET NAMES utf8mb4 */; /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */; /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE=\"NO_AUTO_VALUE_ON_ZERO\" */; # データベース作成 -- Dumping database structure for kizukeba_pronami_php CREATE DATABASE IF NOT EXISTS `kizukeba_pronami_php` /*!40100 DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci */; USE `kizukeba_pronami_php`; # テーブルのデータ型を指定 -- Dumping structure for table kizukeba_pronami_php.mst_staff CREATE TABLE IF NOT EXISTS `mst_staff` ( `code` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(15) COLLATE utf8_unicode_ci NOT NULL, `password` varchar(32) COLLATE utf8_unicode_ci NOT NULL, PRIMARY KEY (`code`) ) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci; # レコードを作成 -- Dumping data for table kizukeba_pronami_php.mst_staff: ~8 rows (approximately) /*!40000 ALTER TABLE `mst_staff` DISABLE KEYS */; INSERT INTO `mst_staff` (`code`, `name`, `password`) VALUES (1, \"秦基博\", \"xxxxxxx\"), (2, \"藤原基央\", \"xxxxxxx\"); /*!40000 ALTER TABLE `mst_staff` ENABLE KEYS */; /*!40101 SET SQL_MODE=IFNULL(@OLD_SQL_MODE, \"\") */; /*!40014 SET FOREIGN_KEY_CHECKS=IF(@OLD_FOREIGN_KEY_CHECKS IS NULL, 1, @OLD_FOREIGN_KEY_CHECKS) */; /*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */; 02-04. 排他制御 UPDATE処理競合問題 ・UPDATE処理競合問題とは アプリケーションのレコードのUPDATE処理が，レコードの取得と更新からなるとする．システムのユーザAとBがおり，ユーザBがUPDATE処理時に取得しなければならないレコードの状態は，ユーザAがUPDATE処理を終えた後のものである．しかし，ユーザAがレコードを取得してから更新を終えるまでの間に，ユーザBが同じくレコードを取得してしまうことがある．結果として，ユーザBのUPDATE処理によって，ユーザAの処理が上書きされ，無かったことになってしまう． 参考：https://qiita.com/NagaokaKenichi/items/73040df85b7bd4e9ecfc ユーザAとユーザBのUPDATE処理が並行したとしても，ユーザAの処理が無かったことにならないよう保証する方法として，『排他制御』がある． 排他制御 ・種類 参考：https://qiita.com/momotaro98/items/5e37eefc62d726a30aee 種類 説明 共有／占有ロック DBによるロック機能． 楽観的／悲観的ロック アプリケーションまたはDBによるロック機能． ・UPDATE処理競合問題の許容 UPDATE処理競合問題を許容し，排他制御を使用しない選択肢もある． 共有／占有ロック ・共有ロック DBにおいて，CRUDのREAD処理以外の処理を実行不可能にする．レコードのREAD処理を実行する時に，他者によってUPDATE処理されたくない場合に用いる．「共有」の名の通り，共有ロックされているレコードに対して，他の人も共有ロックを行うことができる．MySQLでは，『SELECT ... LOCK IN SHARE MODE』を使用する． 参考：https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html ・占有ロック DBにおいて，CRUDの全ての処理を実行不可能にする．レコードのUPDATE処理を実行する時に，他者によってUPDATE／READ処理の両方を実行させない場合に用いる．MySQLでは，『SELECT ... FOR UPDATE』を使用する． 参考：https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html ・デッドロック現象 複数のトランザクションが，互いに他者が使いたいレコードをロックしてしまい，お互いのロック解除を待ち続ける状態のこと．もう一方のレコードのロックが解除されないと，自身のレコードのロックを解除できない時，トランザクションが停止する． 共有ロックの実行 占有ロックの実行 共有ロックされたレコード 〇 ✕ 占有ロックされたレコード ✕ ✕ 楽観的／悲観的ロック ・楽観的ロック DBのレコードにはバージョンに関するカラム値（最終更新日時など）が存在しているとする．UPDATE処理のためにユーザAがDBのレコードを取得した時に，バージョン値を一時的に保持しておく．続けて更新する直前に，DBからバージョンの値を改めて取得する．保持しておいたバージョン値とDBの値を比較し，DBの値の方がより新しいバージョンだった場合，UPDATE処理が失敗するようにする．競合によるエラーを表す409ステータスをレスポンスとして返信するとよい． 参考： https://e-words.jp/w/%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF-%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF.html https://medium-company.com/%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%A8%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%AE%E9%81%95%E3%81%84/ ・悲観的ロック ユーザAがDBのレコードを取得した時点でロックを起動し，ユーザBはレコードの取得すらできなくする．ユーザAが更新を終えてロックが解除され，そこで初めてユーザBはレコードを取得できるようになる．アプリケーションで悲観的ロックを実装することは難易度が高く，基本的にはDBが提供するロック機能を用いる． 参考： https://e-words.jp/w/%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF-%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF.html https://medium-company.com/%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%A8%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%AE%E9%81%95%E3%81%84/ ・ORMの楽観的ロックについて ORMが楽観的ロックの機能を持っている場合がある．PHPのORMであるDoctrineのロック機能については，以下のリンクを参考にせよ． 参考： https://www.doctrine-project.org/projects/doctrine-orm/en/2.9/reference/transactions-and-concurrency.html#locking-support https://qiita.com/tatsurou313/items/053cffdfe940a89d7f5a#or-%E3%83%9E%E3%83%83%E3%83%91%E3%83%BC%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%A5%BD%E8%A6%B3%E7%9A%84%E3%83%AD%E3%83%83%E3%82%AF%E3%81%AE%E5%AE%9F%E8%A3%85%E6%9C%89%E7%84%A1 ロックの粒度 DB ＞ テーブル ＞ レコード ＞ カラム の順に，粒度は大きい．ロックの粒度が細かければ，トランザクションの同時実行性が高くなって効率は向上する（複数の人がDBに対して作業できる）．しかし，ロックの粒度を細かくすればするほど，それだけベース管理システムのCPU負荷は大きくなる． "},"public/backend_database_mysql.html":{"url":"public/backend_database_mysql.html","title":"▶ ︎SQL","keywords":"","body":"MySQL はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. データベース MySQLの準備 ・CentOSにインストール mysqlコマンドのみをインストールしたい場合 $ dnf install -y mysql mysqlコマンド，データベースサーバ機能，をインストールしたい場合はこちら $ dnf install -y mysql-server ・DBに接続 DBに接続する．pオプションの値にはスペースが不要であることに注意する． $ mysql -u -p -h パラメータ ・パラメータの表示 データベースに登録されているグローバルパラメータとセッションパラメータを表示する． -- セッション／グローバルパラメータを表示 SHOW SESSION VARIABLES; SHOW GLOBAL VARIABLES; -- OSとDBのタイムゾーンに関するパラメータを表示 SHOW SESSION VARIABLES LIKE \"%time_zone\"; SHOW GLOBAL VARIABLES LIKE \"%time_zone\"; ・パラメータの設定 -- グローバルパラメータの場合 SET GLOBAL time_zone = \"Asia/Tokyo\"; -- セッションパラメータの場合 SET time_zone = \"Asia/Tokyo\"; 02. テーブル CREATE TABLE句 ・使い方 ＊実装例＊ -- 注文テーブル作成 CREATE TABLE order_data ( -- プライマリキー制約 order_id INT(10) PRIMARY KEY COMMENT \"注文ID\", -- Not Null制約 order_kbn INT(3) NOT NULL COMMENT \"注文区分\", system_create_date_time DATETIME NOT NULL COMMENT \"システム登録日時\", system_update_date_time DATETIME NOT NULL COMMENT \"システム更新日時\", delete_flg INT(1) DEFAULT 0 NOT NULL COMMENT \"0：通常，1：削除済\", -- 複合プライマリキー制約（これを指定する場合，上記のプライマリキー制約の記述は不要） PRIMARY KEY(order_id, order_kbn) -- 参照制約キー FOREIGN KEY order_kbn REFERENCES order_kbn_data ) CREATE VIEW句 ・使い方 ビューとはある表の特定のカラムや指定した条件に合致するレコードなどを取り出した仮想の表．また，複数の表を結合したビューを作成できる．ビューを作成することによりユーザに必要最小限のカラムやレコードのみにアクセスさせる事ができ，また結合条件を指定しなくても既に結合された表にアクセスできる． ⇒よくわからん… ＊実装例＊ CREATE VIEW { テーブル名 } AS SELECT * FROM { テーブル名 }; プライマリキー ・プライマリキーとは テーブルの中で，レコードを一意に識別できる値を『プライマリキー』の値と呼ぶ．一意に識別できるものあれば，何をプライマリキーとして使用しても問題なく，基本的に以下が使用される． 種類 説明 補足 MySQLのAuto Increment機能によって増加する番号カラム プライマリキー制約を課したカラムのAuto Increment機能を有効化しておく．CREATE処理でドメインモデルを作成する時に，『0』または『null』をモデルのID値として割り当てる．これにより，処理によって新しいレコードが追加される時に，現在の最新番号に＋１した番号が割り当てられるようになる．これはプライマリキー制約を満たす．参考：https://dev.mysql.com/doc/refman/8.0/en/example-auto-increment.html ・ドメインモデルとDBがより密結合になり，Active Recordパターンと相性がよい．MySQLの環境変数として『NO_AUTO_VALUE_ON_ZERO』を設定すると，『0』の割り当てによる自動連番が拒否されるようになる． UUID（例：3cc807ab-8e31-3071-aee4-f8f03781cb91） CREATE処理でモデルを作成する時に，アプケーションで生成したUUID値をドメインモデルのID値として割り当てる．UUID値が重複することは基本的に起こり得ないため，プライマリキー制約を満たす．UUID値の生成関数は言語の標準ライブラリとして用意されている． ・ドメインモデルとDBがより疎結合にでき，Repositoryパターンと相性がよい．UUID値は文字列として管理されるため，DBアクセス処理の負荷が高まってしまう．プライマリキーを使用してソートできない． ・複合プライマリキー プライマリキーは複数設定することができ，複合プライマリキーの場合，片方のフィールドの値が異なれば，異なるプライマリキーとして見なされる． ＊例＊ ユーザIDと期間開始日付を複合プライマリキーとすると，一人のユーザが複数の期間をもつことを表現できる． user_id period_start_date period_end_date fee_yen 1 2019-04-03 2019-05-03 200 1 2019-10-07 2019-11-07 400 2 2019-10-11 2019-11-11 200 ・採番テーブル 各テーブルのプライマリキーを統合的に管理するテーブルを採番テーブルという．各テーブルのプライマリキーは採番テーブルを元に割り当てられるため，連番ではなく飛び飛びになる． 参考：http://blog.livedoor.jp/sasata299/archives/51280681.html あらかじめ，最初のレコードのみ手動で挿入しておく． # 採番テーブルの作成する． CREATE TABLE id_sequence (id BIGINT NOT NULL); # 最初のレコードを手動で挿入する． INSERT INTO id_sequence VALUES (0); CREATE処理時には，事前に，採番テーブルに新しくプライマリキーを作成する．INSERT文のプライマリキーに『0』や『null』を割り当てるのではなく，採番テーブルから取得したIDを割り当てるようにする． # 新しくプライマリキーを作成する． UPDATE id_sequence SET id = LAST_INSERT_ID(id + 1); # プライマリキーを取得する． SELECT LAST_INSERT_ID(); 制約 ・制約とは DBにおいて，アプリケーションのCRUD処理に対するバリデーションのルールを定義する．しかし，必ずしも制約を使用する必要はなく，代わりのロジックをアプリケーション側で実装してもよい．その制約を，DBとアプリケーションのいずれの責務とするかを考え，使用するか否かを判断する． ・プライマリキー制約 プライマリキーとするカラムにはプライマリキー制約を課すようにする．プライマリキー制約によって，Unique制約とNot Null制約の両方が課される． ・Not Null制約 レコードに挿入される値のデータ型を指定しておくことによって，データ型不一致やNullのための例外処理を実装しなくてもよくなる． ・外部キー制約 親テーブルのカラムを参照する子テーブルのカラムを『外部キー』といい，この時に子テーブルに課す制約を『外部キー制約』という．子テーブルにおける外部キー制約によって，親子テーブル間に以下の整合性ルールが課される． 親テーブルの参照元カラムに存在しない値は，子テーブルに登録できない． 子テーブルの外部キーが参照する値が，親テーブルの参照元カラムに存在する場合，参照元カラムは削除できない． ＊例＊ 会社情報テーブル（親テーブル）と個人情報テーブル（子テーブル）があるとする．子テーブルの会社IDカラムを外部キーとして，親テーブルの会社IDカラムを参照する．親テーブルの参照元カラムに存在しないIDは，子テーブルの外部キーに登録できない．また，親テーブルの参照元カラムは外部キーに参照されているため，参照元カラムは削除できない． stored procedure ・stored procedureとは あらかじめ一連のSQL文をデータベースに格納しておき，Call文で呼び出す方式． ・使い方 ＊実装例＊ SELECT文のstored procedureを作成するとする． -- PROCEDUREを作成し，データベースへ格納しておく． CREATE PROCEDURE SelectContact AS SELECT { カラム名 } FROM { テーブル名 } -- PROCEDUREを実行 EXEC SelectContact エクスポート，インポート ・テーブルのエクスポート DBからテーブルをエクスポートする．エクスポートしたいテーブルの数だけ，テーブル名を連ねる $ mysqldump --force -u \"{ アカウント }\" -p -h \"{ DBのホスト }\" \"{ DB名 }\" \"{ テーブル名1 }\" \"{ テーブル名2 }\" > table.sql ・テーブルのインポート DBにテーブルをインポートする．forceオプションで，エラーが出ても強制的にインポート． $ mysql --force -u \"{ アカウント }\" -p -h \"{ DBのホスト }\" \"{ DB名 }\" データ型 ・数値型 整数値がどのくらい増えるかによって，3つを使い分ける．符号なし（Unsigned）を有効化した場合，マイナス値を使用しなくなった分，使用可能なプラス値が増える． データ型 値 符号なし（Unsigned）を有効化した場合 TINYINT -128~ +127 0~ +255 INT 2147483648~ +2147483647 0~ +4294967295 BIGINT -9223372036854775808~ +9223372036854775807 0~ +18446744073709551615 ・文字列型 文字数がどのくらい増えるかによって，3つを使い分ければ良い． データ型 最大バイト数 VARCHAR(M) 255 TEXT 65535 MEDIUMTEXT 16777215 Collation（照合順序） ・文字列型の照合順序とは 文字列型のカラムに関して，WHERE句の比較における値の特定，ORDER BY句における並び替えの昇順降順，JOIN句における結合，GROUP BYにおけるグループ化のルールを定義する．カラム／テーブル／DB単位で設定でき，比較するカラム同士では同じ照合順序が設定されている必要がある． 参考：https://johobase.com/sqlserver-where-collate/ ・種類 寿司とビールの絵文字が区別されないことを『寿司ビール問題』という．大文字Aと小文字aを区別しないことは，CI：Case Insensitiveと表現され，照合順序名にも特徴としてCIの文字が含まれている． 照合順序名 A／a ／:beer: は／ぱ／ば や／ゃ utf8mb4_unicode_ci = = = = utf8mb4_unicode_520_ci = ≠ = = utf8mb4_general_ci = = ≠ ≠ utf8mb4_bin ≠ ≠ ≠ ≠ 03. ユーザの管理 CREATE ・ユーザ作成 CREATE USER \"{ ユーザ名 }\" IDENTIFIED BY \"{ パスワード }\"; ・ユーザ一覧 ここで表示される特権と．ALL特権は異なる． SELECT * FROM mysql.user; DROP ・ユーザ削除 -- ユーザ別のホスト名の確認 SELECT * FROM mysql.user; -- ホストが「%」だった場合 DROP USER { ユーザ名 }@`%`; GRANT ・全ての操作権限を付与 データベース名は，シングルクオーテーションで囲う必要が無い．全権限を付与する場合，PRIVILEGESは省略できるが，厳密には省略しないようほうがよい． -- 全てのデータベースに関する権限を付与 GRANT ALL PRIVILEGES ON *.* TO \"{ ユーザ名 }\"; -- Amazon AuroraまたはRDSの場合はこちら GRANT ALL PRIVILEGES ON `%`.* TO \"{ ユーザー名 }\"; -- Amazon Auroraも同じく -- 特定のデータベースに関する全権限を付与 GRANT ALL PRIVILEGES ON {DB名}.* TO \"{ ユーザ名 }\"; ・一部の操作権限を付与 特定のデータベースに関する読み出し権限のみ付与する． GRANT SELECT ON {DB名}.* TO \"{ ユーザ名 }\"; ・権限の振り方 ユーザの種類 権限 admin アプリケーション GRANT ALL PRIVILEGES ON {DB名}.* TO '{ ユーザー名 }' 読み出し／書き込みユーザ GRANT ALL PRIVILEGES ON {DB名}.* TO '{ ユーザー名 }' 読み出しユーザ GRANT SELECT ON {DB名}.* TO '{ ユーザ名 }'; ・ユーザ権限一覧 ユーザに付与されている権限を表示する． SHOW GRANTS FOR \"{ ユーザ名 }\"; 作成しただけで権限を何も付与してないユーザの場合，「データベースサーバ内の全データベースに関して，全権限なし」を表すUSAGEとして表示される． GRANT USAGE ON *.* TO \"{ ユーザー名 }\"; 特定のデータベースの操作権限を与えると，上記に加えて，付与したGRANT権限も表示されるようになる． REVOKE ・全権限削除 全権限を削除し，GRANT権限をUSAGEに戻す． -- Amazon AuroraまたはRDSの場合 REVOKE ALL PRIVILEGES ON `%`.* FROM \"{ ユーザ名 }\"; REVOKE ALL PRIVILEGES ON { DB名 }.* FROM \"{ ユーザ名 }\"; ・ユーザ名変更 RENAME USER \"{ 古いユーザ名 }\" TO \"{ 新しいユーザ名 }\"; 04. レコードの読み出し：READ はじめに ・句の処理の順番 FROM ---> JOIN ---> WHERE ---> GROUP BY ---> HAVING ---> SELECT ---> ORDER BY SELECT句 ・なし 指定したカラムを取得する．MySQLでは，取得結果に標準の並び順が存在しないため，プライマリキーの昇順で取得したい場合は，ORDER BY句を使用して，明示的に並び替えるようにする． 参考：https://www.quora.com/What-is-the-default-order-of-records-for-a-SELECT-statement-in-MySQL SELECT * FROM { テーブル名 }; ・SUM関数 指定したカラムで，『フィールド』の合計を取得する． SELECT SUM({ カラム名 }) FROM { テーブル名 }; ・AVG関数 指定したカラムで，『フィールド』の平均値を取得する． SELECT AVG({ カラム名 }) FROM { テーブル名 }; ・MIN関数 指定したカラムで，『フィールド』の最小値を取得する． SELECT MIN({ カラム名 }) FROM { テーブル名 }; ・MAX関数 指定したカラムで，『フィールド』の最大値を取得する． SELECT MAX({ カラム名 }) FROM { テーブル名 }; ・COUNT関数 指定したカラムで，『フィールド』の個数を取得する． SELECT { カラム名 } COUNT(*) FROM { テーブル名 }; ※消去法の小技：集合関数を入れ子状にはできない ＊実装例＊ 集合関数を集合関数の中に入れ子状にすることはできない． -- SELECT AVG(SUM({ カラム名 })) FROM { テーブル名 }; 指定したカラムで，値無しも含む『フィールド』を取得する． SELECT { カラム名 } COUNT(*) FROM { テーブル名 }; 指定したカラムで，値無しを除いた『フィールド』を取得する． SELECT { カラム名 } COUNT(*); ・LAST_INSERT_ID関数 任意のテーブルに最後に挿入されたIDを読み出す．テーブル名を指定する必要はない． SELECT LAST_INSERT_ID(); ・MD5関数 文字列をハッシュ化 SELECT MD5(\"xxxxx\"); CASE句 カラム1がtrueだったら，カラム2を取得する．falseであったら，カラム3を取得する． SELECT CASE WHEN { エイリアス }.{ カラム名1 } = 1 THEN { エイリアス }.{ カラム名2 } ELSE { エイリアス }.{ カラム名3 } END AS name FROM { テーブル名 } AS { エイリアス }; FROM句 ・JOIN句の種類 ・LEFT JOIN（左外部結合） 『users』テーブルと『items』テーブルの商品IDが一致しているデータと，元となる『users』テーブルにしか存在しないデータが，セットで取得される． ・INNER JOIN（内部結合） 基本情報技術者試験では，内部結合（A∩B）しか出題されない． ・内部結合にWHEREを用いる場合 2つのWHERE文が，ANDで結びつけられている時，まず一つ目のWHEREを満たすレコードを取得した後，取得したレコードの中から，二つ目のWHEREを満たすレコードを取得する． ＊実装例＊ -- 『カラム』だけでなく，どの『表』なの物なのかも指定 SELECT { テーブル名1 }.{ カラム名1 }, -- 複数の表を指定 FROM { テーブル名1 }, { テーブル名2 }, -- まず，1つ目のフィールドと2つ目のフィールドが同じレコードを取得する．． WHERE -- 次に，上記で取得したレコードのうち，次の条件も満たすレコードのみを取得する．． { レコード名1 } = { レコード名2 } AND { レコード名2 } = { レコード名3 } ・内部結合にINNER JOIN ONを用いる場合 ＊実装例＊ -- 『カラム』だけでなく，どの『表』なの物なのかも指定 SELECT { テーブル名1 }.{ カラム名1 }, -- 複数の表を指定 FROM { テーブル名1 } -- 2つ目の表の『レコード』と照合 INNER JOIN { テーブル名2 } ON { テーブル名1 }.{ カラム名1 } = { テーブル名2 }.{ カラム名2 } -- 3つ目の表の『レコード』と照合 INNER JOIN { テーブル名3 } ON { テーブル名1 }.{ カラム名1 } = { テーブル名3 }.{ カラム名3 } ORDER BY句 ・使い方 ＊実装例＊ $order) { switch ($key) { case \"id\": return sprintf(\"ss.id %s\", $order); } } } // IN句順の場合 return sprintf(\"FIELD(ss.id, %s)\", $idList); }); $sql = IN句，ANY句の違い ・IN句の使い方 指定した値と同じ『フィールド』を取得する． ＊実装例＊ 指定したカラムで，指定した値の『フィールド』を取得する． SELECT * FROM { テーブル名 } WHERE { カラム名 } in (xxx, xxx,...); 指定したカラムで，指定した値以外の『フィールド』を取得する． SELECT * FROM { テーブル名 } WHERE { カラム名 } not in ({ レコード名1 }, { レコード名2 },...); 指定したカラムで，SELECTで読み出した値以外の『フィールド』を取得する． SELECT * FROM { テーブル名 } WHERE { カラム名 } not in ( -- SELECT { カラム名 } FROM { テーブル名 } WHERE { レコード名 } >= 160 ); 【IN句を使用しなかった場合】 SELECT * FROM fruit WHERE name = \"みかん\" OR name = \"りんご\"; 【IN句を使用した場合】 SELECT * FROM fruit WHERE name IN(\"みかん\", \"りんご\"); ・ANY句の使い方 書き方が異なるだけで，inと同じ出力 SELECT * FROM { テーブル名 } WHERE { カラム名 } = ANY(xxx, xxx, xxx); GROUP BY句 ・使い方 カラムをグループ化し，集合関数を使用して，フィールドの値を計算する． ＊実装例＊ 指定したカラムをグループ化し，フィールドの値の平均値を算出する． SELECT { カラム名1 }, AVG({ カラム名2 }) FROM { テーブル名 } GROUP BY { カラム名1 }; HAVING句 ・使い方 各句の処理の順番から考慮して，GROUP BYでグループ化した結果から，HAVINGで『フィールド』を取得する．．SELECTにおける集計関数が，HAVINGにおける集計関数の結果を指定していることに注意せよ． ＊実装例＊ -- HAVINGによる集計結果を指定して出力． SELECT { カラム名1 }, COUNT({ カラム名2 }) FROM { テーブル名 } GROUP BY -- グループ化した結果を集計し，２個以上の『フィールド』を取得する． { カラム名1 } HAVING COUNT(*) >= 2; ※以下の場合，GROUP BY + HAVINGを使っても，WHEREを使っても，同じ出力結果になる． SELECT { カラム名 } FROM { テーブル名 } GROUP BY { カラム名 } HAVING { レコード名 }; SELECT { カラム名 } FROM { テーブル名 } WHERE { レコード名 } GROUP BY { カラム名 }; WILDCARD句 ・使い方 ＊実装例＊ SELECT * FROM { テーブル名 } WHERE { カラム名 } LIKE \"%営業\"; SELECT * FROM { テーブル名 } WHERE { カラム名 } LIKE \"_営業\"; BETWEEN句 ・使い方 ＊実装例＊ 指定したカラムで，1以上10以下の『フィールド』を取得する． SELECT * FROM { テーブル名 } BETWEEN 1 AND 10; SET句 ・使い方 ＊実装例＊ SET @A = { パラメータ値 }; SET @B = { パラメータ値 }; UPDATE { テーブル名 } SET { カラム名 } = @A, WHERE { カラム名 } = @B; サブクエリ ・使い方 掛け算と同様に，括弧内から先に処理を行う． ＊実装例＊ -- Main-query SELECT * FROM { テーブル名 } WHERE { カラム名 } != ( -- Sub-query SELECT max({ カラム名 }) FROM { テーブル名 } ); インデックス ・インデックスとは テーブルから特定のカラムだけを抜き出し，検索しやすいように並び替え，名前を付けて保存しておいたもの．インデックスとして保存されたカラムから特定のレコードを直接取得できるため，SQLの実行時間がカラム数に依存しなくなる．インデックスを使用しない場合，SQLの実行時に全てカラムを取得するため，実行時間がテーブルのカラム数に依存してしまう． ・クラスタインデックス プライマリキーあるいはユニークキーのカラムを抜き出して並び替えたインデックスのこと． ・セカンダリインデックス プライマリキーあるいはユニークキーではないカラムを抜き出して並び替えたインデックスのこと． ・複合インデックス 複数のカラムをひとまとめに抜き出して並び替えたインデックスのこと．対象としたカラムごとに異なる値のレコード数が計測され，この数が少ない（一意の値の多い）カラムが検出される．そして，カラムのレコードの昇順で並び替えられ，インデックスとして保存される． ＊例＊ 以下のようなテーブルがあり，nameカラムとaddressカラムをインデックスとして抜き出すとする． id name address old 1 Suzuki Tokyo 24 2 Yamada Osaka 18 3 Takahashi Nagoya 18 4 Honda Tokyo 16 5 Endou Tokyo 24 抜き出されたカラムごとに異なる値のレコード数が計測され，nameカラムはaddressカラムよりも一意のレコードが多いため，nameカラムの昇順（アルファベット順）に並び替えられ，インデックスとして保存される． name address Endou Tokyo Honda Tokyo Suzuki Tokyo Takahashi Nagoya Yamada Osaka EXPLAIN句 ・使い方 設定したSELECT句が仮に実行された場合に，いずれのテーブルのいずれのカラムを取得することになるか（実行計画）を表示する．また，想定実行時間も検出できるため，スロークエリの検出に役立つ． 参考：https://dev.mysql.com/doc/refman/5.7/en/explain-output.html EXPLAIN SELECT * FROM t1, t2 WHERE t1.c1 = 1 AND t1.c2 = t2.c3 *************************** 1. row *************************** id: 1 select_type: SIMPLE table: t1 type: ref possible_keys: index_t1_on_c1_and_c2 key: index_t1_on_c1_and_c2 key_len: 5 ref: const rows: 10 Extra: Using where; Using index *************************** 2. row *************************** id: 1 select_type: SIMPLE table: t2 type: ref possible_keys: index_t2_on_c3 key: index_t2_on_c3 key_len: 5 ref: sample.t1.c2 rows: 1 Extra: Using index ・select_type SQLの種類が表示される．サブクエリを含まないSQLはSIMPLEとなり，サブクエリを含むと，サブクエリの種類に応じて，PRIMARY，SUBQUERY，DEPENDENT SUBQUERY，UNCACHEABLE SUBQUERY，DERIVED，のいずれかが表示される． ・table 設定したSELECT句がアクセスするテーブル名が表示される． ・type 設定したSELECT句がテーブルにアクセスする時に，どの程度の数のカラムを検索するのかが表示される．検索するカラムが多いSQLほど，想定実行時間が長くなる． 種類 条件 検索するカラム数 補足 ALL ・インデックスを使用していない． 全てのカラム 全てのカラムを検索するため，実行時間が最も長く，改善する必要がある． index ・インデックスを使用していない． 全てのインデックスのカラム range ・セカンダリインデックスを使用している．・WHERE句に重複したレコード値，IN句，BETWEEN句を使用している． 特定の複数カラム ref ・セカンダリインデックスを使用している．・WHERE句に重複しないレコード値 特定の複数カラム eq_ref ・クラスタインデックスを使用している． 一つのカラム 一つのカラムしかfetchしないため，JOIN句を使用したアクセスの中で，実行時間が最も短い． const ・クラスタインデックスを使用している．・JOIN句を使用していない． 一つのカラム 一つのカラムしかfetchしないため，実行時間が最も短い． ・possible_keys インデックスとして設定されたカラムのうちで，実際に利用可能なものの一覧が表示される． Tips ・各データベース容量の確認 SELECT table_schema, sum(data_length) / 1024 / 1024 AS mb FROM information_schema.tables GROUP BY table_schema ORDER BY sum(data_length + index_length) DESC; ・カラムの検索 SELECT table_name, column_name FROM information_schema.columns WHERE column_name = { 検索したいカラム名 } AND table_schema = { 検索対象のデータベース名 } ・最適なインデックスの検出 04-02. 読み出されたレコードの取得 FETCH ・FETCHとは 読み出したレコードをに一度に全て取得してしまうと，サーバ側のメモリを圧迫してしまう．そこで，少しずつ取得する． ・FETCHのメソッド名に関する注意点 注意点として，FETCH関数は，ベンダーによって名前が異なっていることがある．そのため，同じ名前でも同じ分だけレコードを取得するとは限らない． PDOの場合 ・prepareメソッド プリペアードステートメントを使用してSQLを定義する．プリアードステートメントによるSQLインジェクションの防御については，以下のリンクを参考にせよ． ・fetchメソッド 読み出された全てのレコードのうち，最初のレコードの全てのカラムを取得し，一次元の連想配列で返却する． ・fetchAllメソッド 読み出された全てのレコードの，全てのカラムを取得し，二次元の連想配列で返却する． ＊実装例＊ prepare($sql); // プリペアードステートメントを定義． $stmt->execute(); // 実行． // 全てのレコードを取得する． $data = $stmt->fetchAll(); // 出力 print_r($data); // カラム名と値の連想配列として取得できる． // Array // ( // [0] => Array // ( // [id] => 1 // [name] => のび太 // [gender] => man // [type] => human // ) // [1] => Array // ( // [id] => 2 // [name] => ドラえもん // [gender] => man // [type] => robot // ) // ) ・fetchColumnメソッド 読み出された全てのレコードのうち，最初のレコードの一番左のカラムのみを取得し，混合型で返却する．主に，COUNT関数の場合に用いる ＊実装例＊ prepare($sql); // プリペアードステートメントを定義． $stmt->execute(); // 実行． // レコードを取得する． $data = $stmt->fetchColumn(); // 出力 print_r($data); // 10 (件) Doctrineの場合 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_package.html Javaの場合 PHPとは異なり，変数定義に『$』は用いないことに注意． ＊実装例＊ // SELECT文を定義して実行． String sql = \"SELECT * FROM doraemon_characters\"; ResultSet result statement.executeQuery(); // 全てのレコードを取得する． while(result.next()){ System.out.println(result.getInt(\"id\")); System.out.println(result.getString(\"name\")); System.out.println(result.getString(\"gender\")); System.out.println(result.getString(\"typeL\")); } // カラム名と値の連想配列として取得できる． // ここに出力結果コードを書く． 05. レコードの書き込み ：CREATE，UPDATE，DELETE PDOの場合 ・INSERT 」などの特殊文字をエスケープ（無害化） $staff_name = htmlspecialchars($staff_name, ENT_QUOTES, \"UTF-8\"); $staff_pass = htmlspecialchars($staff_pass, ENT_QUOTES, \"UTF-8\"); // データベースと接続（イコールの間にスペースを入れるとエラーになる） $dsn = \"mysql:dbname=kizukeba_pronami_php; host=kizukebapronamiphp charaset=UTF-8\"; $user = \"root\"; $password = \"\"; $dbh = new PDO($dsn, $user, $password); $dbh->setAttribute(PDO::ATTR_ERRMODE,PDO::ERRMODE_EXCEPTION); // 列名と値を指定してINSERT $sql=\"INSERT INTO mst_staff (name,password) VALUES (?,?)\"; $stmt = $dbh->prepare($sql); // 配列に値を格納（格納する値の順番と，SQLでの引数の順番は，合わせる必要がある） $data[] = $staff_name; $data[] = $staff_pass; // SQLを実行 $stmt->execute($data); // データベースとの接続を切断 $dbh = null; ・UPDATE ・DELETE 06. その他 マイグレーション ・マイグレーションとは DBに保存されているデータを保持したまま，テーブルの作成やカラムの変更などを行うための機能のこと．マイグレーションファイルと呼ばれるスクリプトファイルを作成し，テーブルの新規作成やカラムの追加はこのスクリプトファイルに記述していく． 運用手順 誰かが以下のMigrationファイルをmaster別名にPush Migrationファイルをローカル環境にPull データベース更新バッチを実行し，ローカル環境のデータベーススキーマとレコードを更新 ＊実装例＊ レコードの突き合わせ処理アルゴリズム ・突き合わせ処理とは ビジネスの基盤となるマスタデータ（商品データ，取引先データなど）と，日々更新されるトランザクションデータ（販売履歴，入金履歴など）を突き合わせ，新しいデータを作成する処理のこと． ・アルゴリズム ・具体例 とある生命保険会社では，顧客の保険契約データを契約マスタテーブルで，またそれとは別に，保険契約データの変更点（異動事由）を異動トランザクションテーブルで，管理している．毎日，契約マスタテーブルと異動トランザクションテーブルにおける前日レコードを突き合わせ，各契約の異動事由に応じて，変更後契約データとして，新契約マスタテーブルに挿入する． 前処理として，契約マスタデータと異動トランザクションデータに共通する識別子が同じ順番で並んでいる必要がある． 契約マスタデータの1行目と，異動トランザクションデータの1行目の識別子を突き合わせる．『契約マスタデータ = 異動トランザクションデータ』の時，異動トランザクションデータを基に契約マスタデータを更新し，それを新しいデータとして変更後契約マスタデータに挿入する． 契約マスタデータの2行目と，異動トランザクションデータの2行目の識別子を突き合わせる．『マスタデータ マスタデータの3行目と，固定したままのトランザクションデータの2行目の識別子を突き合わせる．『マスタデータ = トランザクションデータ』の時，トランザクションデータを基にマスタデータを更新し，それを変更後データとして変更後マスタテーブルに挿入する． 『契約マスタデータ 最終的に，変更後マスタテーブルは以下の通りになる． "},"public/infrastructure_network_structure.html":{"url":"public/infrastructure_network_structure.html","title":"▶ ︎ネットワーク構造","keywords":"","body":"ネットワークの構造 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ネットワークの全体像 インターネット，WAN，LAN ネットワークには，『インターネット』『WAN』『LAN』がある．家庭内LAN，学内LAN，企業内LAN，企業WANなど，さまざまなネットワークがあり，インターネットは，それぞれのネットワークを互いに接続しているネットワークである． WAN，LANの具体例 例えば，LANとしてEthernet，WANとしてデジタル専用線を用いる． WANの種類と歴史 グローバルネットワークとプライベートネットワーク ルータを境に，プライベートネットワークとグローバルネットワークに分けられる．ややこしいが，ルータにはグローバルIPアドレスが割り当てられている． 02. プライベートネットワークへのデータ送信 データ通信方法の種類 ・回線交換方式 少数対少数でデータ通信を行うため，送信時に，送信者と受信者の宛先情報は必要ない． ・パケット交換方式 通信するデータをパケット化する．多数対多数でデータ通信を行うため，送信時に，送信者と受信者の宛先情報が必要になる． URLとメールアドレス ・構造 URLとメールアドレスは完全修飾ドメイン名を持つ． また，完全修飾ドメイン名は，ドメイン名の子関係にあるサブドメイン名を持つことができる．ホスト名（以下では省略されている）と，ドメイン名の間につける． ・完全修飾ドメイン名によるサーバ指定 完全修飾ドメイン名は，所属ネットワークを指すドメイン名と，そのネットワークにおける具体的なサーバを指すホスト名からなる．ただし，サーバのホスト名が『www』である場合，クライアントはURLの指定時にホスト名を省略できる．例えば，『www.example.co.jp』という完全修飾ドメイン名をURLで指定する場合，『example.co.jp』としてもよい． セグメント ・セグメントの種類 プライベートネットワークは，外部公開用ネットワーク，非武装地帯，内部ネットワークに分類される． ・非武装地帯のサーバの種類 攻撃の影響が内部ネットワークに広がる可能性を防ぐために，外部から直接リクエストを受ける．そのため，『DNSサーバ』『プロキシサーバ』『Webサーバ』『メールサーバ』は，非武装地帯に設置される． ・内部ネットワークのサーバの種類 外部から直接リクエストを受けない．そのため，『DBサーバ』は，内部ネットワークに設置される． 03. Webシステムを構成する主要な3層構造 Webシステムとは Webサーバ，Appサーバ，DBサーバによるネットワークの仕組みをWebシステムという．ソフトウェアとハードウェアのノートも参照せよ． Webサーバ ・Webサーバの役割 ミドルウェア（Apache，Nginxなど）がインストールされている．また，Web兼Appサーバのミドルウェアとして機能する（NGINX Unit）がインストールされていることもある． Webサーバ → Appサーバ → DBサーバ 静的コンテンツ 静的レス ー ー 静的コンテンツ＋動的コンテンツ 静的レス 動的レス データ管理 ブラウザから静的コンテンツのみのリクエストがあった場合，静的コンテンツをレスポンスする．また，静的コンテンツと動的コンテンツの両方のリクエストがあった場合に，アプリケーションサーバに動的コンテンツのリクエストを行う．アプリケーションサーバからレスポンスを受け取り，ブラウザにレスポンスを行う． Appサーバ ・Appサーバの役割 ミドルウェア（PHPならPHP-FPM，JavaならTomcat）がインストールされている． Webサーバ → Appサーバ → DBサーバ 静的コンテンツ 静的レス ー ー 静的コンテンツ＋動的コンテンツ 静的レス 動的レス データ管理 Webサーバから動的コンテンツのリクエストがあった場合に，プログラミング言語を言語プロセッサで翻訳し，DBサーバにリクエストを行う．DBサーバからのレスポンスを受け取り，Webサーバに動的なコンテンツのレスポンスを行う． DB管理システムをもつDBサーバ ・DBサーバの役割 DB管理システムがインストールされている．DBの情報が保存されている． サーバの処理能力向上 ・垂直スケーリング（スケールアップ ⇔ スケールダウン） サーバ自体のスペックをより高くすることで，サーバ当たりの処理能力を向上させる．その逆は，スケールダウン．設定で，仮想サーバのスペックを上げることも，これに該当する． ・水平スケーリング（スケールアウト ⇔ スケールイン） サーバの台数を増やすことで，サーバ全体の処理能力を向上させる．その逆は，スケールイン． 03-02. Webシステムの構成方法 Dualシステム 同じ処理を行う2つのシステムからなるシステム構成のこと．随時，処理結果を照合する．いずれかが故障した場合，異常が発生したシステムを切り離し，残る片方で処理を続けることによって，故障を乗り切る． Duplexシステム オンライン処理を行う主系システムと，バッチ処理を行う従系システムからなるシステム構成のこと．主系システムが故障した場合，主系システムのオンライン処理を従系システムに引き継ぎ，処理を続けることによって，故障を乗り切る． 従系システムの待機方法には２つの種類がある． ・ホットスタンバイ ・コールドスタンバイ システムの稼働率 並列システムの場合，両方の非稼働率をかけて，全体から引く． ＊具体例＊ １－(1－0.81) × (1－0.64) = 0.9316 04. フォワード／リバースプロキシサーバ 役割 ・代理リクエスト機能（セキュリティのノートも参照） 代理でリクエストを送るフォワードプロキシサーバと，レスポンスを送るリバースプロキシサーバに分類できる． ・キャッシュ機能 リバースプロキシサーバに，Webページのコンテンツをキャッシュとして保存することによって，Webサーバのアクセス負荷を抑える．ちなみに，ブラウザもキャッシュ機能を持っている． 設置場所 ・物理サーバの場合 フォワードプロキシサーバはプロバイダの会社に，リバースプロキシサーバはリクエスト先の社内ネットワークに設置されている． ・クラウド上の場合 クラウドの場合も，サーバが仮想的に構築される違いだけで，設置場所は同じである． リバースプロキシサーバの実現方法 ・Nginx Webサーバとしてではなく，リバースプロキシサーバとして使用し，代理リクエストやキャッシュを行わせることが可能． 04-02. プロキシサーバ，DNSサーバによる名前解決 （1）完全修飾ドメイン名に対応するIPアドレスのレスポンス ・仕組み クライアントPCは，完全修飾ドメイン名を，フォワードプロキシサーバ（キャッシュDNSサーバ）にリクエスト． フォワードプロキシサーバは，完全修飾ドメイン名を，リバースプロキシサーバに代理リクエスト． リバースプロキシサーバは，完全修飾ドメイン名を，DNSサーバ（ネームサーバ）に代理リクエスト． DNSサーバは，完全修飾ドメインにマッピングされるIPv4アドレスを取得し，リバースプロキシサーバにレスポンス． | 完全修飾ドメイン名 | ⇄ | IPv4アドレス | | :--------------------------: | :--: | :-------------------: | | http://www.example.com | | 203.142.205.139 | リバースプロキシサーバは，IPv4アドレスを，フォワードプロキシサーバに代理レスポンス．（※NATによるIPv4アドレスのネットワーク間変換が起こる） フォワードプロキシサーバは，IPv4アドレスを，クライアントPCに代理レスポンス． ・プロキシサーバ（キャッシュDNSサーバ）におけるDNSキャッシュ ルートサーバは世界に13機しか存在しておらず，世界中の名前解決のリクエストを全て処理することは現実的に不可能である．そこで，IPアドレスとドメイン名の関係をキャッシュするプロキシサーバ（キャッシュDNSサーバ）が使用されている．基本的には，プロキシサーバとDNSサーバは区別される．ただし，Amazon Route53のように，プロキシサーバとDNSサーバの機能を両立しているものもある． （2）IPアドレスに対応するWebページのレスポンス ・仕組み クライアントPCは，レスポンスされたIPv4アドレスを基に，Webページを，リバースプロキシサーバにリクエスト． リバースプロキシサーバは，Webページを，Webサーバに代理リクエスト． Webサーバは，Webページを，リバースプロキシサーバにレスポンス． リバースプロキシサーバは，Webページを，クライアントPCに代理レスポンス． 06. ネットワーク速度の指標 一覧 レスポンスタイム リクエストを送信してから，サーバが処理を実行し，レスポンスが返信されるまでに要する時間のこと． レイテンシー リクエストを送信してから，レスポンスが返信されるまで要する時間のこと．サーバの処理時間は含まない． Connection Time（接続時間） リクエストを送信する前に，サーバとのTCP接続の確立に要する時間のこと． リクエストとレスポンスの送受信の前後に行われるTCP接続の確立を「スリーウェイハンドシェイク」という． Bandwidth（帯域幅） 一度に送受信できるデータの最大容量のこと． スループット（伝送速度） 単位時間当たりの送信できる最大のデータ容量のこと． 他からの影響を受けた実際のスループットを「実効スループット」という． スループット（伝送速度） ・伝送とは サーバからクライアントPCにデータを送信すること．相互の送信は，通信と呼ぶ． ・スループットとは 単位時間当たりの送信できる最大のデータ容量のこと．実際には，スループットは，『プロバイダ』，『光回線』，『自宅の有線／無線』の三つに影響されるため，スループットで期待されるデータ容量を満たせないことが多い．実際のスループットを「実効スループット」という． ・伝送秒数の求め方 (伝送秒数) = データ容量(bit) ÷ スループット(bit/s) × 伝送効率 ・トラフィックとは とあるネットワーク地点でのスループットのこと． 総務省のデータで，日本のブロードバンド大手5社の総トラフィックを年次でグラフ化したものがある． "},"public/infrastructure_network_osi_tcp.html":{"url":"public/infrastructure_network_osi_tcp.html","title":"▶ ︎OSI参照モデル／TCP階層モデル","keywords":"","body":"OSI参照モデル／TCP階層モデル はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. OSI参照モデルとTCP階層モデル データがパケットになるまで アプリケーション層でデータが作成される． トランスポート層でTCPヘッダが追加される． インターネット層でIPヘッダが追加される． ネットワークインターフェース層でEthernetヘッダが追加される． パケットとして送信される． OSI参照モデル ・各概念層のヘッダ情報追加 TCP階層モデル ・プロトコルの分類と扱われる階層 TCP/IPモデルで用いられるプロトコルのうち，最も代表的な「TCP」と「IP」から名前をとって「TCP/IP」と名付けられた．プロトコルとしての暗号化技術である『セキュアプロトコル』は，赤色で示してある． 02-02. 通信機器におけるヘッダ情報認識 各概念層と通信機器の間の対応関係 プライベートネットワークにクライアントPCがある． クライアントPCにて，WebブラウザのアプリケーションのプロセスがTCPアプリケーション層（OSIアプリケーション層＋プレゼンテーション層＋セッション層）で稼働している．ここで，パケットが作成される． パケットは，クライアントPCのTCPトランスポート層（OSIトランスポート層），TCPインターネット層（OSIネットワーク層），TCPネットワークインターフェース層（OSIデータリンク層＋OSI物理層）を経る．各層で，パケットにヘッダー情報が追加される． PCからルータにパケットが送信される． ルータはTCPインターネット層（OSIネットワーク層）に属するため，より上層に一度戻ることになる． グローバルネットワークを経て，送信先のプライベートネットワークのルータに到達する． ルータからサーバにパケットが送信される． パケットは，サーバのCPネットワークインターフェース層（OSIデータリンク層＋OSI物理層），TCPインターネット層（OSIネットワーク層），TCPトランスポート層（OSIトランスポート層），を経る． サーバにて，アプリケーションのプロセスが特定のポート番でリッスンしている．アプリケーションによってパケットが処理される． ・ネットワーク層 ・データリンク層 ・物理層 NIC：Network Interface Card（例：LANアダプタ，LANボード，LANカード），リピータ，LANケーブル 各概念層のヘッダ情報認識 送信元で作成されたパケットは，非カプセル化されながら，通信機器に認識される． 参考：https://ja.wikipedia.org/wiki/%E3%83%AB%E3%83%BC%E3%82%BF%E3%83%BC 03. TCPアプリケーション層 アプリケーション層とは 各アプリケーションがプロセスとして稼働しており，それぞれがデータ（メッセージ）を作成する．各プロセスは特定のポート番号をリッスンする． 参考：https://netdekagaku.com/netstat-command/ ちなみに，指定したポート番号でリッスンしているプロセスを特定できる． $ sudo lsof -i: 03-02. メールデータの作成 メールデータの送受信 ・仕組み クライアント（メール送信可能なアプリケーション）から送信されたメールは，送信側のメールサーバに送信される． 送信側のメールサーバは，メールを受信側のメールサーバに転送する． 受信側のアプリケーションは，各々が指定したプロトコルに応じて，受信側のメールサーバからメールデータを取得する． 参考：https://xtech.nikkei.com/it/pc/article/basic/20120312/1043605/ ・送信側のメールサーバのモック メールデータの送信機能を開発するときに，送信テストを行う必要があり，この内容は公開したくない．そこで，送信側のメールサーバのモックを提供するサービスを利用する．この送信側メールサーバモックは，クライアントから送信されたメールのテストデータを受信側のメールサーバに転送しないため，安全に送信テストを実行できる．Mailtrapがおすすめである． 参考：https://mailtrap.io/ SMTP：Simple Mail Transfer Protocol ・SMTPとは メールデータを送信するためのプロトコルのこと． ・SMTP-AUTH：SMTP AUTHentication SMTPに認証を組み込んだ仕組みのこと．クライアント（メール送信可能なアプリケーション）からメールサーバにメールデータをSMTP送信する時，メールサーバがクライアントに対して認証を実行する． POP3：Post Official Protocol version 3 ・POP3とは メールサーバに届いたメールを，受信機器にダウンロードし，受信機器で閲覧するプロトコル．メールの既読未読状況は，他の受信機器と共有される． IMAP4：Internet Message Access Protocol version 4 ・IMAP4とは メールサーバに届いたメールを，受信機器にダウンロードせず，メールサーバに置いたまま閲覧するプロトコル．メールの既読未読状況は，他の受信機器と共有されない． ＊具体例＊ GmailでPOPかIMAPを設定可能 APOP：Authenticated POP ・APOPとは メール受信の際に，チャレンジレスポンス方式の認証を行うことで平文の認証情報がネットワークに流れるのを防止するプロトコル 04. TCPトランスポート層 トランスポート層とは ・全体像 クライアントからのリクエスト時に，ネットワーク層から渡されたパケットのポート番号情報を元に，アプリケーション層の特定のプロセスにパケットを渡す．また反対に，レスポンス時にアプリケーション層のプロセスから出力されたパケットに情報を付加し，ネットワーク層に渡す．この時，各アプリケーションはプロセスとして稼働していることに留意する． ・クライアントからのリクエスト時（図の 「→」 ） まず，ネットワーク層でプライベートIPアドレスを用いて，リクエスト先のパソコンを識別する．その後，トランスポート層で，ポート番号を元にして，アプリケーション層のプロセスにパケットを送信する． ＊具体例＊ ローカル環境のnginxプロセスのリッスンするポート番号を8080と設定した場合，リクエスト時に以下のようにポート番号を指定すると，nginxプロセスにリクエストを送信できる． GET http://localhost:8080/ ・クライアントへのレスポンス時（図の 「←」 ） アプリケーション層から送信されてきたパケットの通過したポート番号をヘッダ情報として追加する．これを，ネットワーク層へ送信する． ・ソケット，ソケット接続とは トランスポート層に存在し，受信した通信をアプリケーション層の各プロセスに振り分ける受け口をソケットという．送信元のサーバが送信先に対して，『192.168.1.1:50001（送信元IPアドレス:送信ポート）』『10.0.0.1:80（宛先IPアドレス:宛先ポート）』といったように，IPアドレスとポート番号の組合せで指定する．オリジンとは似て非なるものなので注意．サーバ間のソケット間のネットワーク接続をソケット接続という． ポート番号 ・ポート番号とは アプリケーションのプロセスへのパケット送受信に，プロセスを区別するために各プロセスに割り当てられる番号．アプリケーションには，それぞれポート番号が割り当てられており，トランスポート層で，ポート番号を元にして，特定のプロセスにパケットを送信する． ・Well known ポート番号（0 ～ 1023） IANA：Internet Assigned Numbers Authority（インターネット割当番号公社）によって管理されているポート番号．Webサーバがリクエストを受信する時，またレスポンスを送信する時に使用される．ホストOSとゲスト（仮想サーバ）との通信では，80番（HTTP）の受信に関する様々な設定が必要になる． ・登録済みポート番号（1024 ～ 49151） IANAが登録申請を受けて公開しているポート番号．企業が作成した独自のアプリなどに対して割り当てられる．クライアントがリクエストを送信する時，またレスポンスを受信する時に使用される． ・動的／非公式ポート番号（49152 ～ 65535） 自由に使用できるポート番号．クライアントがリクエストを送信する時，またレスポンスを受信する時に使用される． ・ポートフォワーディング（ポート転送） サーバ内の特定のポート番号のアプリケーションに対して，パケットが送信されてきた時，これを異なるポート番号のアプリケーションに転送すること．SSHプロトコルと組み合わせたSSHポートフォワーディングについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_encryption_technology.html ポートスキャナ ・ポートスキャナとは ポートスキャナを用いることによって，各ポート番号にアクセスし，応答があるかどうかや，どのようなソフトウェアが応答するかを調べ，一覧表示することができる． 05. TCPインターネット層 インターネット層とは IPパケットのヘッダ情報を用いて，宛先認識する． PC-Aは，構成したIPパケットをEthernetに乗せて，ルータAに送信． ルータAは，IPパケットをデジタル専用線に乗せて，ルータBに送信． ルータBは，構成したIPパケットをEthernetに乗せて，Webサーバに送信． IPv4アドレスの種類 ・プライベートIPアドレス LAN内で使用される．異なるプライベートネットワーク間では，同じIPv4アドレスが存在する．プライベートIPアドレスは，『10.0.0.0 ～ 10.255.255.255』，『172.16.0.0 ～ 172.31.255.255』，『192.168.0.0 ～ 192.168.255.255』で表される． ・グローバルIPアドレス プロバイダが提供するIPv4アドレスである．パブリックネットワーク内に同じIPv4アドレスは存在せず，Network Information Centerへの使用申請が必要．プライベートIPアドレスの番号でなければ，グローバルIPアドレスである．NATはグローバルIPアドレスを持っており，プライベートネットワークとプライベートネットワーク間の双方向への通信時に，プライベートIPアドレスと相互変換する． プライベート／グローバルIPアドレスとbitとの関係 例えば，プライベートIPアドレスの４つのオクテット（第一オクテットから第四オクテットまで）が１Byteの容量をもち，IPアドレス全体で４Byteの容量をもつ．ちなみに，172から始まるIPアドレスは，クラスBである．　 プライベート／グローバルIPアドレスのネットワーク部とホスト部 ・クラスによるホスト部とネットワーク部の定義 IPアドレスをクラスとして分類し，各クラスでIPアドレスのネットワーク部とホスト部を定義する方法．設定したIPアドレスの属するクラスによって，使用できるIPアドレスの範囲が決まってしまう．ホスト部とネットワーク部の定義方法が4種類しかないため，IPアドレスのパターン数（最大パソコン数）が多すぎたり，少なすぎたりしてしまう． 使用可能なIPアドレスの範囲 クラス ネットワーク部のオクテット ホスト部のオクテット 二進数で見た時（n：ネ，h：ホ） IPアドレスのパターン数（最大パソコン数） 備考 0.0.0.0 〜 127.255.255.255 A 第一のみ 第二から第四 0nnnnnnn.hhhhhhhh.hhhhhhhh.hhhhhhhh 2^24（16777216）個 128.0.0.0 〜 191.255.255.255 B 第一から第二 第三から第四 10nnnnnn.nnnnnnnn.hhhhhhhh.hhhhhhhh 2^16（65536）個 よく使う 192.0.0.0 〜 223.255.255.255 C 第一から第三 第四のみ 110nnnnn.nnnnnnnn.nnnnnnnn.hhhhhhhh 2^8（256）個 224.0.0.0 〜 239.255.255.255 D - - 1110xxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx - 240.0.0.0 〜 255.255.255.255 E - - 1111xxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx - ・サブネットマスクよるネットワーク部とホスト部の定義 『1』あるいは『0』で，IPアドレスのネットワーク部とホスト部を定義し，IPアドレスの後ろに記述する方法（＊具体例＊192.168.42.23/24）．設定したIPアドレスに対して，使用可能なIPアドレスの範囲を自由に定義することができる．ネットワーク部を『1』，ホスト部を『0』で表現する．サブネットマスクの表記方法には，二進数形式，IPアドレス形式，1の個数で表すCIDR形式による表現方法がある． 二進数形式 IPアドレス形式 CIDR形式 IPアドレスのパターン数（最大PC数） 備考 /10000000.00000000.00000000.00000000 /128.0.0.0 /1 /11000000.00000000.00000000.00000000 /192.0.0.0 /2 ... ... ... /11111111.00000000.00000000.00000000 /255.0.0.0 /8 2^24（16777216）個 ... ... ... /11111111.11111110.00000000.00000000 /255.254.0.0 /15 /11111111.11111111.00000000.00000000 /255.255.0.0 /16 2^16（65536）個 よく使う範囲 ... ... /11111111.11111111.11111110.00000000 /255.255.254.0 /23 /11111111.11111111.11111111.00000000 /255.255.255.0 /24 2^8（256）個 ... ... ... /11111111.11111111.11111111.11111110 /255.255.255.254 /31 /11111111.11111111.11111111.11111111 /255.255.255.255 /32 1個 よく使う範囲 ＊具体例＊ プライベートIPアドレスが192.168.0.0（11000000.10101000.00000000.00000000）で，使いたいIPアドレスのパターン数が65536個，または16777216個の場合に，サブネットマスクの表記，使用可能なIPアドレスの範囲は以下のようになる． 使いたいIPアドレスのパターン数 二進数形式による表記 IPアドレス形式 CIDR形式 使用可能なIPアドレスの範囲 16777216個 192.168.0.0/11111111.00000000.00000000.00000000 192.168.0.0/255.0.0.0 192.168.0.0/24 ⇒ 192.168.0.1 〜 192.168.0.254 65536個 192.168.0.0/11111111.11111111.00000000.00000000 192.168.0.0/255.255.0.0 192.168.0.0/16 ⇒ 192.168.0.1 〜 192.168.255.254 1個 192.168.0.0/11111111.11111111.11111111.11111111 192.168.0.0/255.255.255.255 192.168.0.0/32 ⇒ 192.168.0.0 DNSサーバとhostsファイルの役割 ・完全修飾ドメイン名とグローバルIPアドレスのマッピング 例えば，外部WebサーバのグローバルIPアドレスが『203.142.205.139』であると知っている場合，URLのプロトコル部分以下を『203.142.205.139』としてリクエストすれば，外部Webサーバが提供するウェブサイトにアクセスできる．しかし，グローバルIPアドレスは数字の羅列であるため，人間には覚えにくい．そこで，グローバルIPアドレスの代わりに，完全修飾ドメイン名をURLの一部として用いる． ・hostsファイル DNSサーバよりも先に参照されるマッピングファイル．WebサーバのIPアドレスがDNSサーバに登録されていない時，またDNSサーバが不具合の時に，DNSサーバの代わりとして用いる． 05-02. ルータ NAT（静的NAT）：Network Address TranslationによるIPアドレスv4の変換 一つのグローバルIPアドレスに対して，一つのプライベートIPアドレスを紐づけられる．グローバルIPアドレスを持ち，グローバルネットワークとプライベートネットワークの双方向への通信時に，IPアドレスを変換できる． ・リクエスト時のルータにおける変換 プライベートネットワークから出る時に，パケットのヘッダ情報における『送信元』のプライベートIPアドレスをグローバルIPアドレスに変換する． ＊例＊ 例えば，GoogleでWebページを見ながら，Gmailアプリを起動している場合，リクエストにおけるパケット情報として… 送信元プライベートIPアドレス ⇄ 送信元グローバルIPアドレス 192.168.1.1 200.1.1.1 『送信元プライベートIPアドレス』『送信先グローバルIPアドレス』『メールサーバの待ち受けポート番号110（POP3）』を指定して，メールサーバにリクエスト． GET http://www.example.co.jp:110/ 『送信元プライベートIPアドレス』『送信先グローバルIPアドレス』『Webサーバの待ち受けポート番号80（HTTP）』を指定して，Webサーバにリクエスト．ただし．80は，省略可能． GET http://www.example.co.jp:80/ 『送信元プライベートIPアドレス』『送信先グローバルIPアドレス』『DNSサーバの待ち受けポート番号53（DNS）』を指定して，DNSサーバにリクエスト GET http://www.example.co.jp:53/ これらの『送信元プライベートIPアドレス』が，NATルータで，グローバルIPアドレスに変換される． ・レスポンス時の変換 プライベートネットワークに入る時に，パケットのヘッダ情報における『宛先』のグローバルIPアドレスをプライベートIPアドレスに変換する． NAPT（動的NAT）：Network Address Port TranslationによるIPアドレスとポート番号の変換 一つのグローバルIPアドレスに対して，複数のプライベートIPアドレスを紐づけられる．グローバルネットワークとプライベートネットワークの双方向への通信時に，IPアドレスを変換できる． ・リクエスト時の変換 プライベートネットワークから出る時に，パケットのヘッダ情報における『送信元』のプライベートIPアドレスをグローバルIPアドレスに変換する．ただし，異なるプライベートIPアドレスが同じグローバルIPに変換されてしまうため，これを識別するために，ポート番号を複数の異なるポート番号に変換し，グローバルIPアドレスに付け加える． ＊具体例＊ 送信元プライベートIPアドレス 変換前ポート番号 ⇄ 送信元グローバルIPアドレス 変換後ポート番号 192.168.2.1 50011 130.X.X.X:50011 50011 192.168.3.1 50011 130.X.X.X:50012 50012 ・レスポンス時の変換 プライベートネットワークに入る時に，付け加えられたポート番号を元に，パケットのヘッダ情報における『宛先』のグローバルIPアドレスを，異なるプライベートIPアドレスに変換し分ける． "},"public/infrastructure_network_cyber_attacks.html":{"url":"public/infrastructure_network_cyber_attacks.html","title":"▶ ︎サイバー攻撃","keywords":"","body":"サイバー攻撃 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. サイバー攻撃からの防御方法 防御方法の種類 ファイアウォール ・Proxyサーバによるアプリケーションゲートウェイ型ファイアウォール Proxyサーバ上で，SSLサーバ証明書の認証，セキュリティ系のソフトウェアの稼働，を行い，ファイアウォールとして用いる．Proxyサーバセキュリティ精度を重視する場合はこちら． ・パケットフィルタリング型ファイアウォール パケットのヘッダ情報に記載された送信元IPアドレスやポート番号などによって，パケットを許可するべきかどうかを決定する．速度を重視する場合はこちら．ファイアウォールとWebサーバの間には，NATルータやNAPTルータが設置されている．これらによる送信元プライベートIPアドレスから送信元グローバルIPアドレスへの変換についても参照せよ． ＊具体例＊ Win10における設定画面 Detection Systemとは ・Detection Systemとは ネットワーク上を流れるトラフィックを監視し，不正アクセスと思われるパケットを検出した時に，管理者に通知するシステム．あくまで通知するだけで，攻撃を防御することはしない． IPS：Intrusion Prevention Systemとは ・IPSとは ネットワーク上を流れるトラフィックを監視し，不正アクセスと思われるパケットを検出した時に，管理者に通知し，さらにパケットの侵入を防ぐシステム． WAF：Web Application Firewallとは ・WAFとは Webアプリケーション自体を保護するシステム． 02. Malware の種類と特徴 Malware の語源 『malicious（悪意のある）＋software（ソフトウェア）』 Macroウイルス ・Macroウイルスとは Wordなどのワープロアプリや，Excelなどの表計算アプリに感染 Worm ・Wormとは 自己複製し，1つのコンピュータから，4つの経路（ネットワーク，メール，共有フォルダ，USB）を辿って，他のコンピュータに感染を広げていく．パソコンがグローバルIPで直接インターネットに接続していると感染しやすい．ワームを防ぐためには，パソコンにプライベートIPアドレスを設定し，NATやNAPTなどを介して，インターネットに接続させる必要がある． ＊具体例＊ 共有フォルダ経由での感染拡大 トロイの木馬 ・トロイの木馬とは ＊具体例＊ Google play で，過去にアプリとして忍び込んでいたトロイの木馬 感染方法がギリシャ神話上のトロイの木馬に似ていることに由来する．有用なプログラムであるように見せかけて，パソコン利用者に実行させることで感染．裏で不正な処理を行う． ※トロイの木馬はギリシャ神話に登場する．ギリシャ軍は難攻不落のトロイ城を陥落させるため，中に精鋭部隊を忍び込ませた木馬をトロイ城の近くに置いて帰った．戦利品だと勘違いしたトロイ軍は，城内に木馬を持ち帰った．夜中，木馬の中に隠れた精鋭部隊が自軍の兵士をトロイ城に引き入れ，城を制圧した． Spyware ・Spywareとは パソコン利用者の個人情報を収集し，外部に送信する． Bot ・Botとは あらかじめBot化させておいたパソコンを踏み台として，攻撃者の命令通りに動かす． ・パソコンがボット化するまでのプロセス ・スマホがボット化するまでのプロセス ・Bot の使われ方 まず，攻撃対象のネットワーク内にあるパソコンをBot化させる．攻撃者は，Bot化したパソコンを踏み台としてサーバーを攻撃させるように，C&Cサーバーに命令を出す． 03. サイバー攻撃／その対策 CSRF：Cross-Site Request Forgeries ・CSRFとは ユーザがとあるフォームからログイン後，セッションIDを保持したまま悪意のあるサイトにアクセスしたとする．悪意のあるサイトのサーバは，ユーザのセッションIDを使用して，元々ログインしていたサイトのサーバを攻撃する．サーバは，正しいフォームからのリクエストと誤認してしまい，攻撃を許容してしまう． 参考：https://www.ipa.go.jp/security/vuln/websecurity-HTML-1_6.html ・【対策】ワンタイムトークン 認証時に，セッションIDだけでなく，ワンタイムトークンも併用する．認証フォームがリクエストされた時，サーバ側では，ワンタイムトークンを発行し，これをSet-Cookieヘッダーのcsrftokenパラメータ（フレームワークによっては，これに相当するパラメータ）や独自ヘッダーに割り当てて，レスポンスを返信する． 200 OK Set-Cookie: csrftoken= # 独自ヘッダー X-CSRF-TOKEN: ブラウザではレスポンスヘッダーからワンタイムトークンを取り出し，認証フォームのinputタグのhidden属性に割り当てる．加えて，metaタグにトークンを割り当てることもある． \"> \"> 認証のためのPOSTリクエスト時に，リクエストボディや独自ヘッダーにトークンを割り当て，リクエストを送信する．どちらを使用するかは，バックエンド側の仕様によって異なる． POST https://example.co.jp/bar-form.php HTTP/2 # 独自ヘッダー x-csrf-token: { _token= } サーバ側では，POSTリクエストによって送信されたトークンとワンタイムトークンを比較し，認証を実行する．認証完了後のセッションでは，新たなPOSTリクエスト時にそのワンタイムトークンが使い回し，GETリクエスト時には使用しない． 参考： https://terasolunaorg.github.io/guideline/5.2.0.RELEASE/ja/Security/CSRF.html#spring-securitycsrf https://qiita.com/Nsystem/questions/1bd6d30748957e1b6700 https://qiita.com/mpyw/items/0595f07736cfa5b1f50c#%E3%83%88%E3%83%BC%E3%82%AF%E3%83%B3%E3%81%AE%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95 ・【対策】CORS XSSの説明を参考にせよ セッションID固定化 ・セッションID固定化とは 参考：https://www.ipa.go.jp/security/vuln/websecurity-HTML-1_4.html Directory traversal ・Directory traversalとは traversalは，横断する（ディレクトリの構造を乗り越える）の意味．パス名を使ってファイルを指定し，管理者の意図していないファイルを不正に閲覧またはダウンロードする． DoS攻撃：Denial of Service ・DoS攻撃，DDos攻撃とは アクセスが集中することでWebサーバーがパンクすることを利用し，悪意を持ってWebサーバーに大量のデータを送りつける手法．リクエストの送信元が一つの場合はDos攻撃，複数の場合はDDos攻撃という． ・【対策】POSTリクエストのリクエスト数制限 php.iniファイルにて，一度に受信できるPOSTリクエストの上限値を設定できる． max_input_vars = 1000 ・【対策】同一送信元のリクエスト制限 同じ送信元からの一分間あたりのリクエスト数を制限する．例えば，WAF，API Gatewayの機能を使用する． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws.html SQL Injection ・SQL Injectionとは データベースのSQLクエリのパラメータとなる入力に，不正な文字列を入力して不正なSQLクエリを実行させ，データベースの情報を抜き取る手法．ただし，近年は減少傾向にある． ・【対策】特殊な文字の無効化 データベースのSQLクエリのパラメータとなる入力では，『シングルクオーテーション』や『バックスラッシュ』などはSQLで特別な意味を持つ．そのため，これらのパラメータが割り当てられているリクエストメッセージを拒否する．例えば，WAFの機能を使用する． 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/aws-managed-rule-groups-list.html ・【対策】プレースホルダー プリペアードステートメントのSQL中にパラメータを設定し，値をパラメータに渡した上で，SQLとして発行する方法．処理速度が速い．また，パラメータに誤ってSQLが渡されても，これを実行できなくなるため，SQLインジェクションの対策になる．プレースホルダーについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_php_package.html XSS：Cross Site Scripting ・XSSとは WebアプリケーションによるHTML出力のエスケープ処理の欠陥を悪用し，利用者のWebブラウザで悪意のあるスクリプトを実行させる ． ・【対策】CORS：Cross-Origin Resource Sharing（オリジン間リソース共有） 異なるドメインで表示されるページからのリクエストを許可する仕組みのこと．標準では，異なるドメインで表示されるページからのリクエストは拒否されるようになっている．異なるドメインで表示されるページからのリクエストを許可したい場合は，ページからのリクエストメッセージとサーバからのレスポンスメッセージの両方で対応が必要である． 参考：https://developer.mozilla.org/ja/docs/Glossary/Origin ＊実装例＊ まず，リクエストメッセージのOriginヘッダーに送信元オリジンを設定する．加えて，Cookieヘッダーを持つリクエストメッセージを送信したい場合は，JavaScriptの実装でwithCredentialsにtrueを割り当てる．JavaScriptのライブラリによってオプション名が異なるため注意する． 参考：https://qiita.com/tomoyukilabs/items/81698edd5812ff6acb34#%E3%82%B7%E3%83%B3%E3%83%97%E3%83%AB%E3%81%AB%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%82%92%E8%A8%B1%E5%8F%AF%E3%81%97%E3%81%9F%E3%81%84%E5%A0%B4%E5%90%88 GET https://foo.com/bar HTTP/2 # 送信元オリジン Origin: https://example.com import axios from 'axios' const client = axios.create({ baseURL: \"https://foo.co.jp\", withCredentials: true, // オプションの有効化 }) return new Promise((resolve, reject) => { client.get('/bar') .then((data) => { resolve(data) }) .catch((err) => { reject(err) }) }) 次に，レスポンスメッセージのAccess-Control-Allow-Originヘッダーに，許可された送信元オリジンを割り当てて返信する．Cookieヘッダーを持つリクエストメッセージを許可する場合，同じくレスポンスメッセージのAccess-Control-Allow-Credentialsヘッダーにtrueを割り当てる．その他，許可するHTTPメソッドやHTTPヘッダーを定義できる．例えば，許可されていないHTTPメソッドを使用して，異なるオリジンにリクエストを送信すると，405ステータスでエラーレスポンスが返信される． 参考： https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Access-Control-Allow-Credentials https://stackoverflow.com/questions/24687313/what-exactly-does-the-access-control-allow-credentials-header-do 200 OK # 許可された送信元オリジン Access-Control-Allow-Origin: https://example.co.jp # リクエストメッセージがCookieヘッダーを持つことを許可する場合 Access-Control-Allow-Credentials: true # 許可するHTTPメソッド Access-Control-Allow-Methods: GET,POST,HEAD,OPTIONS # その他，許可するHTTPヘッダー Access-Control-Allow-Headers: Content-Type ちなみに，Cookieヘッダーを持つリクエストメッセージを許可しない場合に限り，全てのオリジンやヘッダーを許可することができる． 200 OK # 全てのオリジンを許可 Access-Control-Allow-Origin: * Access-Control-Allow-Headers: * ・【対策】Set-CookieヘッダーのDomain属性 リクエストメッセージがCookieヘッダーを持つことを許可した場合に，サブドメインのオリジンにもCookieヘッダーの送信を許可するかどうかを制御できる．サブドメインレスポンスメッセージのSet-Cookieヘッダーにて，Domain属性にドメインが割り当てなかった場合は，ページを表示するサーバのドメインにのみCookieヘッダーを持つリクエストを許可でき，サブドメインへの送信を拒否できる．一方で，ドメインが割り当てた場合は，そのページからサブドメインに対しても，Cookieヘッダーを持つリクエストを許可できる．ドメインではなく，オリジンであることに注意する． 参考： https://zenn.dev/agektmr/articles/f8dcd345a88c97 https://azisava.sakura.ne.jp/programming/0017.html#sec4-1 ＊実装例＊ Domain属性にexample.co.jpが割り当てられていたとする．最初にドットがついているドメイン（.example.co.jp）でも，同じ値として認識される．この場合，example.co.jpに加えて，サブドメイン（foo.example.co.jp）に対しても，Cookieヘッダーを持つリクエストを送信できる． 200 OK Set-Cookie: domain=example.co.jp POST http://foo.example.co.jp/bar-form.php HTTP/2 # 送信元オリジン Origin: http://example.co.jp Cookie: sessionid=; csrftoken= ・【対策】Set-CookieヘッダーのHttpOnly属性 これを有効化した場合，Set-CookieヘッダーにHttpOnly属性が割り当てられるようになる．JavaScriptからCookieヘッダーにアクセスできなくできる． 200 OK Set-Cookie: HttpOnly ・【対策】Set-CookieヘッダーのsameSite属性 種類 説明 None 異なるドメインから送信された全てのリクエストがCookieヘッダーを持つことを許可する． Lax 異なるドメインから送信された一部のリクエストがCookieヘッダーを持つことを許可する． Strict 異なるドメインから送信された全てのリクエストがCookieヘッダーを持つことを拒否する． 異なるドメインからのリクエストがCookieヘッダーを持つことを許可／拒否する．ここでリクエストを制御しているのは，オリジンではなく，ドメインであることに注意する． 参考：https://zenn.dev/agektmr/articles/f8dcd345a88c97 200 OK Set-Cookie: SameSite=None ・【対策】Set-CookieヘッダーのSecure属性 これを有効化した場合，Set-CookieヘッダーにSecure属性が割り当てられるようになる．HTTPSプロトコルを使用した場合のみ，リクエストメッセージにCookieヘッダーを割り当てられるようになる． 200 OK Set-Cookie: Secure パスワードリスト攻撃 ・パスワードリスト攻撃とは 漏洩したパスワードを用いて，正面から正々堂々とアクセスする手法． Brute-force攻撃とReverse Brute-force攻撃 ・Brute-force攻撃とReverse Brute-force攻撃とは Brute-forceは力ずくの意味．IDを固定して，パスワードを総当たりで試す手法．例えば，5桁数字のパスワードなら，9の5乗通りの組み合わせを試す．一方で，Reverse Brute-forceは，パスワードを固定して，IDを総当たりで試す手法． ・パスワードのパターン数 レインボー攻撃 ・レインボー攻撃とは レインボーテーブルの文字列とハッシュ値の対応関係を元にして，ハッシュ化された暗号からパスワードを推測する手法． ・【対策】BCryptによるハッシュ化 BCryptを使用して，Blowfish方式に基づく暗号化を実行する．Blowfish方式では，同じパスワードの文字列であっても異なるハッシュ値が生成されるため，レインボー攻撃を防げる．Blowfish方式で生成されたハッシュ値は，異なるルールで生成された複数のハッシュ値の組み合わせである． 参考： https://medium-company.com/%E3%82%B9%E3%83%88%E3%83%AC%E3%83%83%E3%83%81%E3%83%B3%E3%82%B0/ https://medium-company.com/bcrypt/ # + + + $2y$10$1QVmWNzk.TsaZQLQ/zeI9OAZL02AWP.VdFPPyAc9hSc2Cp4yOXKtG 文字列 説明 $2y$（4文字） 暗号化アルゴリズムのバージョンを表す．他に，2，2a，2b，2xがある． $10$（4文字） ストレッチング（ハッシュ化の反復）の回数を表す．10とした場合は，2^10回反復でハッシュ化を実行する． 1QVmWNzk.TsaZQLQ/zeI9O（22文字） ソルト（ランダムな文字列）を表す． AZL02AWP.VdFPPyAc9hSc2Cp4yOXKtG（31文字） パスワードそのもののハッシュ値を表す． 04. その他のサイバー攻撃 ソーシャルエンジニアリング ・ソーシャルエンジニアリングとは 技術的な手法ではなく，物理的な手法（盗み見，盗み聞き，成りすまし，詐欺など）によってパスワードを取得し，アクセスする手法． 踏み台攻撃 ・踏み台攻撃とは 対象のインターネット内のパソコンに攻撃プログラムを仕込んで置き，攻撃者からの命令でサーバを攻撃させる手法（※ボットを用いた攻撃など） ・パソコンがボット化するまでのプロセス（再掲） ・スマホがボット化するまでのプロセス（再掲） ・Bot の使われ方（再掲） DNS Cache Poisoning ・DNS Cache Poisoningとは キャッシュDNSサーバーがもつIPアドレスを偽のIPアドレスに変え，偽のWebサイトに強制的にアクセスさせる手法． Back Door ・Back Doorとは 例えば，Webサイトのカード決済画面やサーバに潜ませることによって，カード情報を第三者に送信する手法． "},"public/infrastructure_network_encryption_technology.html":{"url":"public/infrastructure_network_encryption_technology.html","title":"▶ ︎通信データの暗号化技術","keywords":"","body":"通信データの暗号化技術 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 通信データを暗号化する目的 盗聴（通信データの盗み取り）を防ぐため 『共通鍵暗号方式』や『公開鍵暗号方式』によって実現される．暗号アルゴリズムに基づく暗号方式を用いてデータを暗号化することによって，通信データの盗聴を防ぐ． 改竄（通信データの書き換え）を防ぐため 『デジタル署名』や『ハッシュ関数』によって実現される．相手に送ったデータと相手が受け取ったデータが同じかどうかを確認することによって，通信データの改竄を防ぐ． 成りすましを防ぐため 『デジタル署名』によって実現される．正しい相手であることを証明することによって，成りすましを防ぐ． 01-02. 暗号アルゴリズム 通信データの暗号化のほとんどは，『共通鍵暗号方式』や『公開鍵暗号方式』によって実現される．それらの方式は，以下のアルゴリズムによって実装される． 共通鍵暗号アルゴリズム 共通鍵暗号方式を実装するためのアルゴリズム ・DES 暗号：Data Encryption Standard ・AES 暗号：Advanced Encryption Standard 公開鍵暗号アルゴリズム 公開鍵暗号方式を実装するためのアルゴリズム ・RSA 暗号：Rivest-Shamir-Adleman cryptosystem 01-03. 暗号アルゴリズムに基づく暗号方式 暗号方式の種類一覧 共通鍵暗号方式 公開鍵暗号方式 暗号化アルゴリズム 共通鍵暗号アルゴリズム 公開鍵暗号アルゴリズム アルゴリズムの種類 RC4、DES、3DES、AES RSA、ElGamal 暗号化に要する時間 より短い より長い 生成される暗号鍵 共通鍵 秘密鍵、公開鍵 鍵の配布方法 メール（盗聴に気を付ける） メール、PKI 鍵の再利用 再利用するべきではない 再利用してもよい 共通鍵暗号方式 ・共通鍵暗号方式とは サーバから受信者（クライアント）にあらかじめ秘密鍵を渡しておく．鍵の受け渡しを工夫しないと，共通鍵が盗聴される可能性がある（鍵配送問題）． ＊具体例＊ エクセルのファイルロック 長所：処理が速い 短所：鍵の配布が大変 ・共通鍵の再利用の可否 各受信者（クライアント）は，サーバから，受信者ごとに生成された共通鍵をもらう．鍵の再利用をするべきではない． 公開鍵暗号方式 ・公開鍵暗号方式とは 公開鍵暗号方式でも記載の通り，共通鍵暗号方式の鍵配送問題を解決すべく開発された．『RSA暗号』などによって実装される．受信者（クライアント）の公開鍵で暗号化した場合，受信者の秘密鍵でのみ復号可能．すなわち，第三者に復号（解読）されることはないと判断可能． ＊サーバが行うこと＊ サーバは，受信者（クライアント）から公開鍵をもらう． 公開鍵を用いて，情報を暗号化する． ＊受信者（クライアント）が行うこと＊ 受信者（クライアント）は，秘密鍵で情報を復号する． ・公開鍵の再利用の可否 各受信者（クライアント）は，サーバから，異なるサーバで再利用される公開鍵をもらう．ただし，サーバごとに異なる秘密鍵と公開鍵を用いてもよい． ハイブリッド暗号方式 共通鍵暗号方式と公開鍵暗号方式を組み合わせた暗号方式．両方の方式の長所と短所を補う． 02. 暗号化方式に基づくセキュアプロトコル セキュアプロトコルの種類と扱われる階層 プロトコルとしての暗号化技術である『セキュアプロトコル』は，赤色で示してある． セキュアプロトコルで扱われる通信データ ・通信データの種類 Webコンテンツデータ，メールデータ，その他 ・通信データの作成，ヘッダ情報追加，カプセル化 パケット交換方式におけるパケットのヘッダ情報は，パソコンの各概念層のプロトコルによって追加されていく． 02-02. アプリケーション層におけるメールデータの暗号化技術 S/MIME：Secure MIME ・S/MINEとは 暗号化ダイジェスト（デジタル署名）を含むデジタル証明書をメールに添付することによって，公開鍵の成りすましを防ぐセキュリティ技術． ・S/MIMEにおけるデジタル証明書 デジタル証明書をS/MIMEに用いる場合，特にS/MIME証明書という．詳しくは，暗号ダイジェスト（デジタル署名）を参照． 02-03. アプリケーション層におけるリモート接続／操作やファイル転送の暗号化技術 SSH：Secure Shell ・SSHとは 公開鍵暗号方式に基づくセキュアプロトコル．アプリケーション層で，公開鍵暗号方式と，公開鍵認証方式やパスワード認証方式の技術を用いて，サーバのリモート接続／操作を行う．物理Webサーバであっても，仮想Webサーバであっても，SSHによるリモート接続／操作の仕組みは同じである． ・SSH接続／操作する側に必要なソフトウェア 『OpenSSH』，『TeraTerm』，『Putty』がある． ・SSH接続／操作される側に必要なソフトウェア 『OpenSSH』，『Apache MINA/SSHD』 ・SSHポートフォワーディング（SSHポート転送） ローカルサーバと踏み台サーバのSSH接続と，ポートフォワーディングを組み合わせることによって，外部ネットワークのプライベートネットワーク内リモートサーバのアプリケーションに間接的に通信を行う方法．ポートフォワーディングについては，ネットワークのノートを参照． ＊具体例＊ 踏み台サーバ（例：EC2）を用いて，ローカルサーバ（例：自身のパソコン）の20000番ポートが割り当てられたアプリケーションと，リモートサーバ（例：Aurora）の3306番が割り当てられたアプリケーションをマッピングできるようになる．DBMSクライアントソフトでは，リモートにあるDBサーバに接続するために，この仕組みがよく用いられる． # ローカルの20000番ポートが割り当てられたアプリケーションに対する通信を，RDSの3306番ポートのアプリケーションに転送． [local pc] $ ssh -L20000:xxxx.rds.amazonaws.com:3306 username@fumidai.com ＊具体例＊ このリモートサーバが仮想サーバ／コンテナの場合もあり，ホストOSと仮想サーバ／コンテナの接続でもSSHポートフォワーディングが用いられている．ホスト外部のパソコンから，ホストOS上の仮想サーバ／コンテナに接続したい場合，SSHポートフォワーディングを用いることによって，ホストOSを踏み台とした仮想サーバ／コンテナへの接続が行えるようになる． SCP：Secure Copy Protocol ・SCPとは SSHを介して，ファイル転送を行う．SSHの機能をより拡張したプロトコルである． クライアントは，リモート接続先のサーバにファイル送信を命令する． サーバは，Shellを用いてSCPプログラムを起動し，クライアントにファイルを送信する． ・ファイルを要求する側に必要なソフトウェア 『WinSCP』，『Filezilla』 ・ファイルを送信する側に必要なソフトウェア SFTP：SSH File Transfer Protocol ・SFTPとは SSHを介して，ファイル転送を行う．SSHとFTPを組み合わせたプロトコルではなく，SSHの機能をより拡張したものである． ・ファイル要求側のクライアントソフトウェア 『WinSCP』，『Filezilla』 ・ファイル送信側のクライアントソフトウェア 02-04. トランスポート層におけるヘッダ情報の暗号化技術 SSL/TLS：Secure Sockets Layer / Transport Layer Security ・SSL/TLSとは ハイブリッド暗号方式に基づくセキュアプロトコル．トランスポート層で，パケットのヘッダ情報の暗号化を担う．具体的には，HTTPプロトコルで，GET送信のヘッダ部分，またPOST送信のヘッダ部分とボディ部分を暗号化する． ＊具体例＊ Chromeでは，HTTPSにおいて，SSLサーバ証明書に不備がある（例えば，オレオレ証明書を用いている）と，以下のような警告が表示される．SSLサーバ証明書については，公開鍵基盤の説明を参照せよ． ・SSL/TLSにおけるデジタル証明書とドメイン認証 デジタル証明書をSSLに用いる場合，特にSSLサーバ証明書という．提供される秘密鍵と組み合わせて，ドメインの認証に用いられる．詳しくは，暗号ダイジェスト（デジタル署名）を参照． VPN：Virtual Private Network（仮想プライベートネットワーク） ・VPNとは 異なるネットワーク間で安全な通信を行うための仕組み．IPsecやSSL/TLSによって実現される． ・インターネットVPNでのSSL/TLS通信の利用 VPNゲートウェイとのSSL/TLS通信によって，インターネットVPNを実現できる． 02-05. 暗号ダイジェスト（デジタル署名）について 暗号ダイジェスト（デジタル署名）を用いた暗号化技術 ・暗号ダイジェスト（デジタル署名）とは 『公開鍵暗号方式とは逆の仕組み（※つまり，公開鍵暗号方式ではない）』と『ハッシュ関数』を利用した暗号化．『成りすまし』と『改竄』を防ぐことができる． ＊サーバが行うこと＊ サーバは，受信者（クライアント）にあらかじめ公開鍵を配布しておく． 平文をハッシュ化し，ダイジェストにする． ダイジェストを秘密鍵で暗号化し，暗号ダイジェスト（デジタル署名）を作成する． 『平文』，『暗号ダイジェスト（デジタル署名）』を送信する． ＊受信者（クライアント）が行うこと＊ 受信者（クライアント）は，『平文』と『暗号ダイジェスト（デジタル署名）』を受信する． 平文をハッシュ化し，ダイジェストにする． 上記２つのダイジェストが同一なら，『成りすまし』と『改竄』が行われていないと判断 ・暗号ダイジェスト（デジタル署名）のメリット 1．改竄を防ぐことができる サーバから送られた『平文』と『暗号ダイジェスト』のどちらかが，通信の途中で改竄された場合，これらのダイジェストが同じになることは確率的にありえない．したがって，確かに改竄されていないと判断可能． 2．成りすましを防ぐことができる 特定の秘密鍵を持つのは，特定のサーバだけ．したがって，確かにサーバによって暗号化されたものだと判断可能． ・暗号ダイジェスト（デジタル署名）のデメリット ★★公開鍵の成りすましを防ぐことができない★★ 二者間だけのやり取りでは，あらかじめ受信者に渡される公開鍵が偽の送信者のものであっても，確かめる術がない．これを保障する仕組みに，PKI（公開鍵基盤）がある． 暗号ダイジェスト（デジタル署名）と公開鍵暗号方式を用いた暗号化技術 『成りすまし』と『改竄』を防げるデジタル署名に，『盗聴』を防げる公開鍵暗号方式を組み込んだ暗号化技術． ハッシュ関数によるハッシュ化 何かのデータを入力すると，規則性のない一定の桁数の値を出力する演算手法． PKI：Public Key Infrastructure（公開鍵基盤）による公開鍵の検証 ・ドメインの正当性の検証 秘密鍵とデジタル証明書はドメインの正当性（偽サイトではないこと）を担保するものである．デジタル署名に用いた秘密鍵に対応する公開鍵は，成りすました人物による偽の公開鍵である可能性がある．第三者機関の認証局によって，公開鍵を検証するインフラのことを，公開鍵基盤という． ・公開鍵の検証の仕組み 多くの場合，サーバの提供会社が中間認証局をもっている．中間認証局とルート認証局の関係については，認証局そのもののなりすましの防止策を参照． ＊具体例＊ サーバ提供者 自社の中間認証局名 ルート認証局名 AWS Amazon Trust Services Starfield社 GCP Google Trust Services ＊サーバが行うこと＊ サーバは，公開鍵と秘密鍵を作り，認証局に公開鍵とデジタル署名を提出． 認証局から，暗号ダイジェスト（デジタル署名）を含むデジタル証明書（S/MIME証明書，SSLサーバ証明書）を発行してもらう．デジタル証明書が，公開鍵の本人証明になる．デジタル証明書は，S/MIMEで用いる場合には，『S/MIME証明書』，SSL/TLSで用いる場合には，『SSLサーバ証明書』という． 受信者（クライアント）にメール，暗号ダイジェスト（デジタル署名）を含むデジタル証明書を送信． ＊受信者（クライアント）が行うこと＊ 受信者（クライアント）は，暗号ダイジェスト（デジタル署名）を含むデジタル証明書（S/MIME証明書，SSLサーバ証明書）を受信． 認証局からもらった公開鍵を用いて，デジタル証明書の暗号ダイジェスト（デジタル署名）部分を復号し，ハッシュ値が同じなら，認証局そのものが成りすましでないと判断する． ・認証局そのものの成りすましの防止策 デジタル証明書（S/MIME証明書，SSLサーバ証明書）を発行する認証局そのものが，成りすましの可能性がある．そこで，認証局をランク付けし，ルート認証局が下位ランクの認証局に権限を与えることで，下位の認証局の信頼性を持たせている．なお，ルート認証局は専門機関から厳しい審査を受けているため，ルート認証局自体がなりすましである可能性は非常に低い． 02-06. ネットワーク層におけるヘッダ情報の暗号化技術 IPsec：Internet Protocol Security ・IPSecとは 共通鍵暗号方式に基づくセキュアプロトコル．ネットワーク層で，パケットのヘッダ情報の暗号化を担う．インターネットVPNの実現のために用いられる．盗聴を防ぐことができる． ・IPsecによるパケットのカプセル化 VPN：Virtual Private Network（仮想プライベートネットワーク） ・VPNとは 異なるネットワーク間で安全な通信を行うための仕組み．使用されているセキュアプロトコルに基づいて，『PPTP-VPN』，『SSL/TLS-VPN』，『IPsec-VPN』がある． ・PPTP-VPNの例 『PPTP』 ・SSL/TLS-VPNの例 『OpenVPN』 ・IPsec-VPNの例 『L2TP/IPSec』 03. その他のセキュリティ技術 メール受信におけるセキュリティ ・OP25B（Outbound Port 25 Blocking） ・SPF（Sender Policy Framework） パスワードの保存方法 平文で保存しておくと，流出した時に勝手に使用されてしまうため，ハッシュ値で保存するべきである． 生体認証 Web beacon webページに，サーバに対してHTTPリクエストを送信するプログラムを設置し，送信されたリクエストを集計するアクセス解析方法．例えば，1x1の小さなGif「画像」などを設置する． Penetration テスト 既知のサイバー攻撃を意図的に行い，システムの脆弱性を確認するテストのこと． ＊具体例＊ 株式会社LACによるPenetration テストサービス "},"public/infrastructure_software.html":{"url":"public/infrastructure_software.html","title":"▶ ︎ソフトウェアの種類","keywords":"","body":"ソフトウェアの種類 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ソフトウェアとは ユーザの操作による命令の流れ ユーザの操作による命令が，ソフトウェアを介して，ハードウェアに伝わるまで，を以下に示す． ソフトウェアの種類 1. 応用ソフトウェア 2. ミドルウェア 3. 基本ソフトウェア（広義のOS） 4. Firmware 5. デバイスドライバ 02. 応用ソフトウェア 応用ソフトウェア（アプリケーション）の一覧 ネイティブアプリ Webアプリとクラウドアプリ ハイブリッドアプリ 利用可能な通信状況 On／Off On On／Off ネイティブアプリケーション 端末のシステムによって稼働するアプリのこと．一度ダウンロードしてしまえば，インターネットに繋がっていなくとも，使用できる． ＊具体例＊ Office，BookLiveのアプリ版 Webアプリケーションとクラウドアプリケーション ・Webアプリケーション Webサーバ上でWebシステムをレンダリングすることによって稼働するアプリのこと．URLをWebサーバにリクエストすることで利用でき，随時，Webサーバとデータ通信を行う．全ての人が無料で利用できるものと，お金を払った人だけが利用できるものがある． ＊具体例＊ Googleアプリ，Amazon，BookLiveのブラウザ版，サイボウズ ・クラウドアプリケーション Webサーバ上のシステムによって稼働するアプリのうち，クラウドサービスを提供するもののこと． ＊具体例＊ Google Drive，Dropbox ハイブリッドアプリケーション 端末でWebviewを稼働させ，WebシステムのレンダリングなどをWebview上で行うアプリのこと． ＊具体例＊ クックパッド 03. ミドルウェア Webサーバのミドルウェア ・Apache Apacheのノートを参照． ・Nginx Nginxのノートを参照． ・Node.js Appサーバのミドルウェア ・Apacheの拡張モジュール mod_phpという拡張モジュールを読み込むことによって，Apacheを，WebサーバだけでなくAppサーバのミドルウェアとしても機能させることができる． ・PHP-FPM：PHP FastCGI Process Manager WebサーバのNginxと組み合わせて使用できるミドルウェア． ・NGINX Unit WebサーバのNginxと組み合わせて使用できるミドルウェア． ・CGIプログラム：Common Gateway Interface DBサーバのミドルウェア ・MySQL ・MariaDB ※詳しくは，データベースのノートを参照せよ． 04. 基本ソフトウェア（広義のOS） 基本ソフトウェアの種類 ・Unix系OS Unixを源流として派生したOS．現在では主に，Linux系統（緑色），BSD系統（黄色），SystemV系統（青色）の三つに分けられる． ※ちなみに，MacOSはBSD系統 ・WindowsOS MS-DOSを源流として派生したOS．今では，全ての派生がWindows 10に集約された． 基本ソフトウェア ・基本ソフトウェアの構成 ・ユーティリティ 基本ソフトウェアのノートを参照． ・言語プロセッサ 基本ソフトウェアのノートを参照． ・制御プログラム（カーネル） 基本ソフトウェアのノートを参照． 04-02. Unix系OS Linux系統 ・OSとバージョンの確認コマンド OSとバージョンが/etc/issueファイルに記載されている． $ cat /etc/issue Debian GNU/Linux 10 \\n \\l 現在，Linux系統のOSは，さらに3つの系統に分けられる． ・RedHat系統 RedHat，CentOS，Fedora ・Debian系統 Debian，Ubuntu， ・Slackware系統 Slackware BSD系統｜MacOS ・環境変数の確認 環境変数を確認する．全ての項目は，実際に実行して確認すること． $ export -p export EDITOR=vim export HOME=/Users/h.hasegawa export LANG=en_US.UTF-8 export SHELL=/bin/zsh export USER=h.hasegawa export VISUAL=vim ... 05. デバイスドライバ デバイスドライバとは 要勉強 06. Firmware Firmwareとは システムソフトウェア（ミドルウェア ＋ 基本ソフトウェア）とハードウェアの間の段階にあるソフトウェア．ROMに組み込まれている． BIOS：Basic Input/Output System UEFI：United Extensible Firmware Interface Windows 8以降で採用されている新しいFirmware 07. OSS：Open Source Software OSSとは 以下の条件を満たすソフトウェアをOSSと呼ぶ．応用ソフトウェアから基本ソフトウェアまで，様々なものがある． 利用者は，無償あるいは有償で自由に再配布できる． 利用者は，ソースコードを入手できる． 利用者は，コードを自由に変更できる．また，変更後に提供する場合，異なるライセンスを追加できる． 差分情報の配布を認める場合には，同一性の保持を要求してもかまわない． ⇒ よくわからない 提供者は，特定の個人やグループを差別できない． 提供者は，特定の分野を差別できない． 提供者は，全く同じOSSの再配布において，ライセンスを追加できない． 提供者は，特定の製品でのみ有効なライセンスを追加できない． 提供者は，他のソフトウェアを制限するライセンスを追加できない． 提供者は，技術的に偏りのあるライセンスを追加できない． OSSの種類 引用：https://openstandia.jp/oss_info/ ・OS CentOS，Linux，Unix，Ubuntu ・データベース MySQL，MariaDB ・プログラミング言語 言うまでもない． ・フレームワーク 言うまでもない． ・OR Mapper 言うまでもない． ・バージョン管理 Git，Subversion ・Webサーバ Apache ・業務システム Redmine ・インフラ構築 Chef，Puppet ・クラウド構築 Docker "},"public/infrastructure_software_middleware_nginx.html":{"url":"public/infrastructure_software_middleware_nginx.html","title":"▶ ︎Nginx","keywords":"","body":"Nginx はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Tips コマンドリファレンス ・nginx 参考：https://httpd.apache.org/docs/trunk/ja/programs/apachectl.html よく使うコマンド ・起動／停止 $ sudo systemctl start nginx $ sudo systemctl stop nginx ・設定ファイルのバリデーション $ sudo service nginx configtest # もしくはこちら $ sudo nginx -t ・設定ファイルの反映と安全な再起動 $ sudo systemctl reload nginx ・読み込まれた設定ファイルと設定値の一覧 読み込まれている全ての設定ファイル（includeディレクティブの対象も含む）の内容を展開して表示する． $ sudo nginx -T 02. Nginxの用途 Webサーバ／コンテナのミドルウェアとして ・PHP-FPMとの組み合わせ 静的ファイルのリクエストが送信されてきた場合，Nginxはそのままレスポンスを返信する．動的ファイルのリクエストが送信されてきた場合，Nginxは，FastCGIプロトコルを介して，PHP-FPMにリクエストをリダイレクトする． # 設定ファイルのバリデーション $ php-fpm -t ＊実装例＊ #------------------------------------- # HTTPリクエスト #------------------------------------- server { listen 80; server_name example.com; root /var/www/example/public; index index.php index.html; include /etc/nginx/default/xxx.conf; #『/』で始まる全てのリクエストの場合 location / { try_files $uri $uri/ /index.php?$query_string; } #-------------------------------------------------- # FastCGIを用いたAppサーバ／コンテナへの転送，受信 # OSによって，fastcgi_paramsファイルの必要な設定が異なる #-------------------------------------------------- location ~ \\.php$ { # リダイレクト先のTCPソケット fastcgi_pass 127.0.0.1:9000; # もしくは，Unixソケット # fastcgi_pass unix:/run/php-fpm/www.sock; # リダイレクト先のURL（rootディレクティブ値+パスパラメータ） fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # 設定ファイルからデフォルト値を読み込む include fastcgi_params; } } ・www.confファイルについて php.iniファイルによって読み込まれる/etc/php-fpm.d/www.confファイルは，PHP-FPMに関する設定が定義されたファイルである．php.iniよりも優先されるので，設定項目が重複している場合は，こちらを変更する． ＊実装例＊ [www] # プロセスのユーザ名，グループ名 user = nginx group = nginx # Unixソケットのパス listen = /run/php-fpm/www.sock # PHP-FPMと組み合わせるミドルウェアを指定（apacheと組み合わせることも可能） listen.owner = nginx listen.group = nginx # コメントアウト推奨 ;listen.acl_users = apache,nginx # TCPソケットのIPアドレス listen.allowed_clients = 127.0.0.1 pm = dynamic pm.max_children = 50 pm.start_servers = 5 pm.min_spare_servers = 5 pm.max_spare_servers = 35 # ログファイルの場所 slowlog = /var/log/php-fpm/www-slow.log php_admin_value[error_log] = /var/log/php-fpm/www-error.log php_admin_flag[log_errors] = on # セッションの保存方法．ここではredisのキーとして保存（デフォルト値はfiles） php_value[session.save_handler] = redis # セッションの保存場所（デフォルト値は，/var/lib/php/session） php_value[session.save_path] = \"tcp://xxxxx.r9ecnn.ng.0001.apne1.cache.amazonaws.com:6379\" # php_value[soap.wsdl_cache_dir] = /var/lib/php/wsdlcache ・/etc/nginx/fastcgi_paramsファイル nginx.confファイルによって読み込まれる/etc/nginx/fastcgi_paramsファイルは，PHP-FPMに関する変数が定義されたファイルである．OSやそのバージョンによっては，変数のデフォルト値が書き換えられていることがある．実際にサーバ／コンテナ内に接続し，上書き設定が必要なものと不要なものを判断する必要がある．以下は，Debian 10のデフォルト値である． ＊実装例＊ #-------------------------------------- # FastCGIを用いたAppサーバ／コンテナへの転送，受信 # OSによって，fastcgi_paramsファイルの必要な設定が異なる #-------------------------------------- fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; fastcgi_param DOCUMENT_ROOT $document_root; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param REQUEST_SCHEME $scheme; fastcgi_param HTTPS $https if_not_empty; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; # PHPだけで必要な設定 fastcgi_param REDIRECT_STATUS 200; ロードバランサ－のミドルウェアとして HTTPプロトコルで受信したリクエストを，HTTPSプロトコルに変換して転送する． ＊実装例＊ #------------------------------------- # HTTPリクエスト #------------------------------------- server { server_name example.com; listen 80; return 301 https://$host$request_uri; } #------------------------------------- # HTTPSリクエスト #------------------------------------- server { server_name example.com; listen 443 ssl http2; index index.php index.html; #------------------------------------- # SSL #------------------------------------- ssl on; ssl_certificate /etc/nginx/ssl/server.crt; ssl_certificate_key /etc/nginx/ssl/server.key; add_header Strict-Transport-Security \"max-age=86400\"; location / { proxy_pass http://app1; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Port $remote_port; } } リバースProxyのミドルウェアとして 前提として，ロードバランサ－から転送されたHTTPリクエストを受信するとする．静的コンテンツのリクエストは，リバースProxy（Nginx）でレスポンスを返信する．Webサーバは，必ずリバースProxyを経由して，動的リクエストを受信する． ＊実装例＊ #------------------------------------- # HTTPリクエスト #------------------------------------- server { server_name example.com; listen 80; return 301 https://$host$request_uri; #------------------------------------- # 静的ファイルであればNginxでレスポンス #------------------------------------- location ~ ^/(images|javascript|js|css|flash|media|static)/ { root /var/www/example/static; expires 30d; } #------------------------------------- # 動的ファイルであればWebサーバに転送 #------------------------------------- location / { proxy_pass http://127.0.0.1:8080; } } 03-01. Core機能 ブロック ・events 参考：https://nginx.org/en/docs/ngx_core_module.html#events ＊実装例＊ events { worker_connections 1024; } ディレクティブ ・user 本設定ファイルの実行ユーザとグループを設定する．グループ名を入力しなかった場合，ユーザ名と同じものが自動的に設定される． user www www; ・error_log error_log logs/error.log; ・include 共通化された設定ファイルを読み込む．アスタリスクによるワイルドカードに対応している． include /etc/nginx/conf.d/*.conf; ・pid pid logs/nginx.pid; ・worker_connections workerプロセスが同時に処理可能なコネクションの最大数を設定する． 参考：https://nginx.org/en/docs/ngx_core_module.html#worker_connections worker_connections 1024; ・worker_processes worker_processes 5; ・worker_rlimit_nofile worker_rlimit_nofile 8192; 設定ファイルの種類 ・/etc/nginx/conf.d/*.confファイル デフォルトの設定が定義されているいくつかのファイル．基本的には読み込むようにする．ただし，nginx.confファイルの設定が上書きされてしまわないかを注意する． include /etc/nginx/conf.d/*.conf; ・/etc/nginx/mime.typesファイル リクエストのContent-TypeのMIMEタイプとファイル拡張子の間の対応関係が定義されているファイル． include /etc/nginx/mime.types; ・/usr/share/nginx/modules/*.confファイル モジュールの読み込み処理が定義されているファイル． include /usr/share/nginx/modules/*.conf; 例えば，mod-http-image-filter.confファイルの内容は以下の通り． load_module \"/usr/lib64/nginx/modules/ngx_http_image_filter_module.so\"; 03-02. http_core_module ブロック ・http 全てのWebサーバに共通する処理を設定する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#http http { # Nginxのバージョンを表示するかどうか server_tokens off; # MIMEタイプを設定 include /etc/nginx/mime.types; default_type application/octet-stream; # ログのフォーマット log_format main \"$remote_addr - $remote_user [$time_local] \"$request\" \" \"$status $body_bytes_sent \"$http_referer\" \" \"\"$http_user_agent\" \"$http_x_forwarded_for\"\"; access_log /var/log/nginx/access.log main; # sendfileシステムコールを使用するかどうか sendfile on; # ヘッダーとファイルをまとめてレスポンスするかどうか tcp_nopush on; # keepaliveを維持する時間 keepalive_timeout 65; default_type application/octet-stream; include /etc/nginx/mime.types; include /etc/nginx/conf.d/*.conf; server { # ～ 省略 ～ } } ・location 個別のWebサーバ／コンテナにおける特定のURLの処理を設定する． https://nginx.org/en/docs/http/ngx_http_core_module.html#location ＊実装例＊ 各設定の優先順位に沿った以下の順番で実装した方が良い． # 1. ドキュメントルートを指定したリクエストの場合 location = / { } # 2. 『/images/』で始まるリクエストの場合 location ^~ /images/ { } # 3と4. 末尾が、『gif，jpg，jpegの形式』 のリクエストの場合 # バックスラッシュでドットをエスケープし，任意の文字ではなく『ドット文字』として認識できるようにする． location ~* \\.(gif|jpg|jpeg)$ { } # 5-1. 『/docs/』で始まる全てのリクエストの場合 location /docs/ { } # 5-2. 『/』で始まる全てのリクエストの場合 location / { } ルートの一致条件は，以下の通りである． 優先順位 prefix ルートの一致条件 ルートの具体例 1 = 指定したルートに一致する場合． http://example.com/ 2 ^~ 指定したルートで始まる場合． http://example.com/images/foo.gif 3 ~ 正規表現（大文字・小文字を区別する）． http://example.com/images/FOO.jpg 4 ~* 正規表現（大文字・小文字を区別しない）． http://example.com/images/foo.jpg 5 なし 指定したルートで始まる場合． ・http://example.com/foo.html・http://example.com/docs/foo.html ・server 個別のWebサーバ／コンテナの処理を設定する． 参考https://nginx.org/en/docs/http/ngx_http_core_module.html#server ＊実装例＊ server { # 80番ポートで受信 listen 80; # ホスト名 server_name example.com; root /var/www/example; index index.php index.html; location / { try_files $uri $uri/ /index.php?$query_string; } location ~ \\.php$ { fastcgi_pass unix:/run/php-fpm/www.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } ・リダイレクトとリライトの違い 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html ディレクティブ ・default_type Content-Typeヘッダーの値がmime.typesファイルにないMIME typeであった場合に適用するMIME typeを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#default_type ＊実装例＊ # application/octet-stream：任意のMIME type（指定なし）と見なして送信 default_type application/octet-stream ・listen HTTPリクエストを80番ポートでリクエストを受信する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#listen ＊実装例＊ listen 80; HTTPSリクエストを443番ポートでリクエストを受信する． ＊実装例＊ listen 443 ssl; ・sendfile クライアントへのレスポンス時に，ファイル送信のためにLinuxのsendfileシステムコールを使用するかどうかを設定する．ファイル返信処理をOS内で行うため，処理が速くなる．使用しない場合，Nginxがレスポンス時に自身でファイル返信処理を行う． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#sendfile ＊実装例＊ sendfile on; ・server_name パブリックIPアドレスに紐づくドメイン名を設定する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#server_name server_name example.com; パブリックIPアドレスを直接記述してもよい． server_name 192.168.0.0; ・ssl NginxでHTTPSプロトコルを受信する場合，sslプロトコルを有効にする必要がある． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#ssl ＊実装例＊ ssl on; ・ssl_certificate PEM証明書のパスを設定する． ＊実装例＊ ssl_certificate /etc/nginx/ssl/server.crt; ・ssl_certificate_key PEM秘密鍵のパスを設定する． ＊実装例＊ ssl_certificate_key /etc/nginx/ssl/server.key; ・tcp_nopush 上述のLinuxのsendfileシステムコールを使用する場合に，適用できる．クライアントへのレスポンス時，ヘッダーとファイルを，一つのパケットにまとめて返信するかどうかを設定する． ＊実装例＊ tcp_nopush on; ・try_files 指定されたパスのファイルを順に探してアクセスする．また，最後のパラメータで内部リダイレクトする．最後のパラメータでは，異なるパスまたはステータスコードを指定できる．もし，nginxとアプリケーションを別々のサーバ／コンテナで稼働させている場合，try_filesディレクティブがファイル探索の対象とする場所は，あくまでnginxの稼働するサーバ／コンテナ内になることに注意する．内部リダイレクトによって，nginx内でリクエストが再処理される．異なるパスに内部リダイレクトしていた場合は，パスに合ったlocationブロックで改めて処理される．内部リダイレクトは，URLを書き換えてリダイレクトせずに処理を続行する『リライト』とは異なることに注意する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#try_files location / { try_files file ... uri; } location / { try_files file ... =code; } ＊実装例＊ location / { # 1. 『/foo.html』のパスでサーバ／コンテナからファイルをレスポンス # 2. 『/foo.html/』のパスでサーバ／コンテナからファイルをレスポンス # 3. 『/index.php?query_string』のパスで内部リダイレクト try_files $uri $uri/ /index.php?query_string; } # 内部リダイレクト後は，『/index.php?foo=bar』のため，以下で処理される． location ~ \\.php$ { # php-fpmに転送される． fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } ヘルスチェックの受信 ・nginxによるレスポンス Webサーバ／コンテナのみヘルスチェックを受信する．ヘルスチェック用のserverブロックで，gifファイルのレスポンスを返信するようにlocationブロックを定義する．Nginxでアクセスログを出力する必要はないため，locationブロックではaccess_logを無効化する． ＊実装例＊ server { listen 80 default_server; listen [::]:80 default_server; root /var/www/example; index index.php index.html; location /healthcheck { empty_gif; access_log off; break; } } ・アプリケーションによるレスポンス Webサーバ／コンテナとアプリケーションの両方でヘルスチェックを受信する．アプリケーション側に200ステータスのレスポンスを返信するエンドポイントを実装したうえで，ヘルスチェック用のserverブロックで，アプリケーションにルーティングするようにlocationブロックを定義する．Nginxでアクセスログを出力する必要はないため，locationブロックではaccess_logを無効化する． ＊実装例＊ server { listen 80 default_server; listen [::]:80 default_server; root /var/www/example; index index.php index.html; location /healthcheck { try_files $uri $uri/ /index.php?$query_string; access_log off; } } 03-03. http_index_module ディレクティブ ・index リクエストのURLがトレイリングスラッシュで終わる全ての場合に，指定されたファイルをURLの末尾に追加する． 参考：https://nginx.org/en/docs/http/ngx_http_index_module.html ＊実装例＊ index index.php; 03-04. http_headers_module ディレクティブ ・add_header レスポンスヘッダーを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_headers_module.html#add_header ＊実装例＊ # Referrer-Policyヘッダーに値を設定する add_header Referrer-Policy \"no-referrer-when-downgrade\"; 03-05. http_upstream_module ブロック ・upstream 参考：https://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream ＊実装例＊ upstream big_server_com { server 127.0.0.3:8000 weight=5; server 127.0.0.3:8001 weight=5; server 192.168.0.1:8000; server 192.168.0.1:8001; } 03-06. http_fast_cgi_module ディレクティブ ・fastcgi_params FastCGIプロトコルを使用してAppサーバ／コンテナにリクエストを転送する場合に，転送先で使用する変数とその値を設定する． 参考：https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_param ＊実装例＊ fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; ・fastcgi_pass FastCGIプロトコルを使用してAppサーバ／コンテナにリクエストを転送する場合に，転送先のアドレスとポートを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_pass ＊実装例＊ fastcgi_pass 127.0.0.1:9000; 03-07. http_proxy_module ディレクティブ ・proxy_pass HTTPプロトコルを使用してAppサーバ／コンテナにリクエストを転送する場合に，転送先のアドレスとポートを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass ＊実装例＊ proxy_pass http://127.0.0.1:8080/; "},"public/infrastructure_software_middleware_apache.html":{"url":"public/infrastructure_software_middleware_apache.html","title":"▶ ︎Apache","keywords":"","body":"Apache はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Tips コマンドリファレンス ・httpd 参考：https://httpd.apache.org/docs/trunk/ja/programs/httpd.html ・apachectl 参考：https://httpd.apache.org/docs/trunk/ja/programs/apachectl.html よく使うコマンド ・ディレクティブの実装場所の一覧 特定のディレクティブを実装するべき設定ファイルを一覧で表示する． $ sudo httpd -L ・設定ファイルのバリデーション # systemctlコマンドでは実行不可能 $ sudo service httpd configtest $ sudo apachectl configtest $ sudo apachectl -t ・コンパイル済みモジュールの一覧 コンパイル済みのモジュールを一覧で表示する．表示されているからといって，読み込まれているとは限らない． $ sudo httpd -l ・読み込み済みモジュールの一覧 コンパイル済みのモジュールのうちで，実際に読み込まれているモジュールを表示する． $ sudo httpd -M ・読み込み済みconfファイルの一覧 読み込まれたconfファイルを一覧で表示する．この結果から，使われていないconfファイルもを検出できる． $ sudo httpd -t -D DUMP_CONFIG 2>/dev/null | grep \"# In\" | awk \"{print $4}\" ・読み込まれるVirtualHost設定の一覧 $ sudo httpd -S ・強制的な起動／停止／再起動 # 起動 $ sudo systemctl start httpd # 停止 $ sudo systemctl stop httpd # 再起動 $ sudo systemctl restart httpd ・安全な再起動 Apacheを段階的に再起動する．安全に再起動できる． $ sudo apachectl graceful 02. Apacheの用途 Webサーバのミドルウェアとして 03. Coreにおける設定ディレクティブ ServerRoot ・ServerRootとは 他の設定ディレクティブで，相対パスが設定されている場合に適用される．そのルートディレクトリを定義する． ＊実装例＊ 通常であれば，etcディレクトリ以下にconfファイルが配置される． ServerRoot /etc/httpd CentOSのEPELリポジトリ経由でインストールした場合，Apacheのインストール後に，optディレクトリ以下にconfファイルが設置される． ServerRoot /opt/rh/httpd24/root/etc/httpd VirtualHost ・VirtualHostとは ディレクティブを囲うディレクティブの一つ．特定のホスト名やIPアドレスにリクエストがあった時に実行するディレクティブを定義する．VirtualHostという名前の通り，1 つのサーバ上で，仮想的に複数のドメインを扱うような処理も定義できる．複数のVirtualHostを設定した場合，一つ目がデフォルト設定として認識される． ＊実装例＊ Listen 80 NameVirtualHost *:80 # Defaultサーバとして扱う． DocumentRoot /www/foo ServerName www.example.com DocumentRoot /www/bar ServerName www.example.org ・IPベースVirtualHost 各ドメインに異なるIPアドレスを割り振るバーチャルホスト． ・名前ベースVirtualHost 全てのドメインに同じIPアドレスを割り振るバーチャルホスト． DocumentRoot ・DocumentRootとは ドキュメントのルートディレクトリを定義する．ドキュメントルートに『index.html』というファイルを置くと，ファイル名を指定しなくとも，ルートディレクトリ内のindex.htmlファイルが，エントリーポイントとして自動的に認識されて表示される． ＊実装例＊ DocumentRoot /www/foo: ServerName www.example.com index.html以外の名前をエントリーポイントにする場合，ファイル名を指定する必要がある． ＊実装例＊ DocumentRoot /www/foo:/start-up.html ServerName www.example.com Directory ・Directoryとは ディレクティブを囲うディレクティブの一つ．指定したディレクトリ内にリクエストがあった時に実行するディレクティブを定義する． ＊実装例＊ DirectoryIndex index.php AllowOverride All User，Group ・Userとは httpdプロセスのユーザ名を定義する．httpdプロセスによって作成されたファイルの所有者名は，このディレクティブで定義したものになる． ＊実装例＊ User apache ・Groupとは httpdプロセスのグループ名を定義する．httpdプロセスによって作成されたファイルのグループ名は，このディレクティブで定義したものになる． ＊実装例＊ Group apache KeepAlive，MaxKeepAliveRequests，KeepAliveTimeout ・KeepAliveとは HTTPプロトコルのリクエストのクライアントに対して，セッションIDを付与するかどうか，を定義する． ＊実装例＊ KeepAlive On ・KeepAliveTimeout セッションIDを付与中のクライアントにおいて，再びリクエストを送信するまでに何秒間空いたら，セッションIDを破棄するか，を定義する． ＊実装例＊ # KeepAliveがOnの時のみ KeepAliveTimeout 5 ・MaxKeepAliveRequests セッションIDを付与中のクライアントにおいて，リクエストのファイルの最大数を定義する． ＊実装例＊ # KeepAliveがOnの時のみ MaxKeepAliveRequests 1000 04. mod_soにおける設定ディレクティブ LoadModule ・LoadModule モジュールを読み込み，設定ディレクティブを宣言できるようにする． ＊実装例＊ 相対パスを指定し，ServerRootを適用させる．これにより，httpdディレクトリのmodulesディレクトリが参照される． # ServerRoot が /opt/rh/httpd24/root/etc/httpd だとする． LoadModule dir_module modules/mod_dir.so 04-02. mod_dirにおける設定ディレクティブ DirectoryIndex ・DirectoryIndexとは Directoryディレクティブによってリクエストされたディレクトリのインデックスファイルをレスポンスする． ＊実装例＊ DirectoryIndex index.html index.php ＊実装例＊ DirectoryIndex index.html DirectoryIndex index.php AllowOverride ・AllowOverrideとは 別に用意した.htaccessファイルにて，有効化するディレクティブを定義する． ＊実装例＊ DirectoryIndex index.php AllowOverride All ・All 別に用意した.htaccessファイルにて，実装可能なディレクティブを全て有効化する． ＊実装例＊ AllowOverride All ・None 別に用意した.htaccessファイルにて，実装可能なディレクティブを全て無効化する． ＊実装例＊ AllowOverride None ・Indexes 別に用意した.htaccessファイルにて，DirectoryIndexディレクティブを有効化する． ＊実装例＊ AllowOverride Indexes 04-03. mod_writeにおける設定ディレクティブ RewriteCond ・RewriteCondとは 条件分岐と，それによる処理を定義する． ＊実装例＊ RewriteCond %変数名 条件 ＊実装例＊ RewriteCond %{HTTP:X-Forwarded-Port} !^443$ RewriteRule ・リダイレクトとリライトの違い 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html ・RewriteRuleとは 条件分岐による処理を定義する． RewriteRule URL書換＆転送の記述 ＊実装例＊ リクエストをHTTPSプロトコルに変換して，リダイレクトする． RewriteRule ^(.*)?$ https://%{HTTP_HOST}$1 [R=301,L] 04-04. mod_setenvifにおける設定ディレクティブ SetEnvIf ・SetEnvIfとは 条件分岐と環境変数の設定を定義する． # クエリパラメータが以下の拡張子の場合に， SetEnvIf Request_URI \"\\.(gif|jpe?g|png|js|css)$\" object-is-ignore ・nolog ログを出力しない場合を設定できる． 04-05. mod_log_configにおける設定ディレクティブ LogFormat ・LogFormatとは アクセスログファイルの書式を定義する． ・アクセスログ形式と出力内容 アクセスログの出力先ログファイルとフォーマットを合わせて定義する． ＊実装例＊ # common形式 CustomLog logs/access_log common LogFormat \"%h %l %u %t \"%r\" %>s %b\" common # combine形式 CustomLog logs/access_log combined LogFormat \"%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"\" combined 以下のようなログになる． # common形式 118.86.194.71 - - [17/Aug/2011:23:04:03 +0900] \"GET /home/name/category/web HTTP/1.1\" 200 11815 # combine形式 118.86.194.71 - - [17/Aug/2011:23:04:03 +0900] \"GET /home/name/category/web HTTP/1.1\" 200 11815 \"http://naoberry.com/home/name/\" \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.112 Safari/535.1\" ・ログの変数一覧 変数 値 例 %h リモートホスト 118.86.194.71 %l リモートログ名（基本”-“になる） - %u リモートユーザ（Basic認証のユーザ） - %t リクエスト受付時刻 [17/Aug/2011:23:04:03 +0900] %r リクエストの最初の行 GET /home/name/category/web HTTP/1.1 %s ステータス 200 %b レスポンスのバイト数 11815 %{Referer}i リファラ http://naoberry.com/home/name/ %{User-Agent}i ユーザエージェント Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.112 Safari/535.1 ErrorLog ・ErrorLogとは エラーログファイルの書式を定義する． ・エラーログ形式と出力内容 エラーログの出力先を定義する． ＊実装例＊ ErrorLog /var/log/httpd/error_log LogLevel ・LogLevelとは どのレベルまでログを出力するかを定義する． ログレベル 意味 設定の目安 emerg サーバが稼動できないほどの重大なエラー alert critよりも重大なエラー crit 重大なエラー error エラー warn 警告 本番環境 notice 通知メッセージ info サーバ情報 ステージング環境 debug デバック用の情報 04-06. mod_sslにおける設定ディレクティブ SSLCertificateFile ・SSLCertificateFileとは PKIにおける公開鍵の検証に必要なSSLサーバ証明書のディレクトリを定義する．本番環境ではAWSのACM証明書を用いることが多いため，基本的な用途としては，ローカル開発でのオレオレ証明書読み込みのために用いる． ＊実装例＊ SSLCertificateFile /etc/httpd/conf.d/server.crt SSLCertificateKeyFile ・SSLCertificateKeyFileとは PKIにおける公開鍵の検証に必要な秘密鍵のディレクトリを定義する． ＊実装例＊ SSLCertificateKeyFile /etc/httpd/conf.d/server.key 04-07. mod_headersにおける設定ディレクティブ Header ・Headerとは レスポンスヘッダーを定義する．set，append，add，unset，echoオプションを設定できる．標準では2xxと3xxのステータスコードのみで設定が適用される．オプションとして，alwaysを設定することで，全てのステータスコードでヘッダーを設定する． ・set レスポンスヘッダーを追加する． ＊実装例＊ Referrer-Policyヘッダーを追加し，値をno-referrer-when-downgradeとする．ちなみに，Chrome85以降のReferrer-Policyヘッダー初期値の仕様変更については，以下を参考にせよ． 参考：https://www.chromestatus.com/feature/6251880185331712 Header set Referrer-Policy \"no-referrer-when-downgrade\" Header set Referrer-Policy \"no-referrer-when-downgrade\" always ・unset レスポンスヘッダーを削除する． ＊実装例＊ Referrer-Policyヘッダーを削除する Header unset Referrer-Policy \"no-referrer-when-downgrade Header unset Referrer-Policy \"no-referrer-when-downgrade\" always 05. htaccess 影響範囲 ・ルートディレクトリの場合 全てのファイルに対して，ディレクティブが適用される． ・それ以外のディレクトリの場合 設置したディレクトリ以下の階層のファイルに対して適用される． "},"public/infrastructure_software_centos.html":{"url":"public/infrastructure_software_centos.html","title":"▶ ︎CentOSの構成","keywords":"","body":"CentOSの構成 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 基本ソフトウェア（広義のOS） 基本ソフトウェアの構成 02. ユーティリティ ユーティリティの種類 ・Unixの場合 今回，以下に紹介するものをまとめる． ファイルシステム系 プロセス管理系 ネットワーク系 テキスト処理系 環境変数系 ハードウェア系 mkdir batch nslookup tail export df ls ps curl vim printenv free cp kill netstat grep timedatectl - find systemctl route history - - chmod cron ssh - - - rm - - - - - chown - - - - - ln - - - - - od - - - - - tar ・Windowsの場合 Windowsは，GUIでユーティリティを使用する．よく使うものを記載する． システム系 ストレージデバイス管理系 ファイル管理系 その他 マネージャ デフラグメントツール ファイル圧縮プログラム スクリーンセーバー クリップボード アンインストーラー - ファイアウォール レジストリクリーナ - - - アンチウイルス - - - ユーティリティのバイナリファイル ・バイナリファイルの配置場所 バイナリファイルのディレクトリ バイナリファイルの種類 /bin Unixユーティリティのバイナリファイルの多く． /usr/bin 管理ユーティリティによってインストールされるバイナリファイルの多く． /usr/local/bin Unix外のソフトウェアによってインストールされたバイナリファイル．最初は空になっている． /sbin Unixユーティリティのバイナリファイルうち，sudo権限が必要なもの． /usr/sbin 管理ユーティリティによってインストールされたバイナリファイルのうち，sudo権限が必要なもの． /usr/local/sbin Unix外のソフトウェアによってインストールされたバイナリファイルのうち，sudo権限が必要なもの．最初は空になっている． # バイナリファイルが全ての場所で見つからないエラー $ which python3 which: no python3 in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin) # バイナリファイルの場所 $ which python3 /usr/bin/python3 pipeline ・pipelineとは 「|」の縦棒記号のこと．複数のプログラムの入出力を繋ぐことができる． ・grepとの組み合わせ コマンドの出力結果をgrepコマンドに渡し，フィルタリングを行う． ＊コマンド例＊ 検索されたファイル内で，さらに文字列を検索する． $ find /* \\ -type f | xargs grep \"\" ・killとの組み合わせ コマンドの出力結果に対して，killコマンドを行う． ＊コマンド例＊ フィルタリングされたプロセスを削除する． $ sudo pgrep \\ -f | sudo xargs kill -9 ・awkとの組み合わせ コマンドの出力結果に対して，awkコマンドを行う． ＊コマンド例＊ 検索されたファイルの容量を合計する． $ find ./* -name \"*.js\" -type f -printf \"%s\\n\" | awk \"{ sum += $1; } END { print sum; }\" $ find ./* -name \"*.css\" -type f -printf \"%s\\n\" | awk \"{ sum += $1; } END { print sum; }\" $ find ./* -name \"*.png\" -type f -printf \"%s\\n\" | awk \"{ sum += $1; } END { print sum; }\" ・sortとの組み合わせ コマンドの出力結果に対して，並び順を変更する． ＊コマンド例＊ 表示された環境変数をAZ昇順に並び替える． $ printenv | sort -f 標準入出力 ・標準入出力とは 種類 説明 stddin（標準入力） キーボードからのコマンドに対して，データを入力するためのインターフェースのこと． stdout（標準出力） コマンドからターミナルに対して，エラー以外のデータを出力するためのインターフェースのこと． stderr（標準エラー出力） コマンドからターミナルに対して，エラーデータを出力するためのインターフェースのこと． ・標準出力に出力 コマンド処理の後に，「>&1」を追加すると，処理の結果を，標準出力に出力できる． ＊コマンド例＊ $ echo \"stdout\" >&1 ・標準エラー出力に出力 コマンド処理の後に，「>&2」を追加すると，処理の結果を，標準エラー出力に出力できる． ＊コマンド例＊ $ echo \"stderr\" >&2 02-02. シェルスクリプト／Makefile シェルスクリプト ・シェルスクリプトとは ユーティリティの処理を手続き的に実装したファイル．最初の「#!」をシェバンという． ＊実装例＊ #!/bin/bash echo \"foo\" echo \"bar\" echo \"baz\" Makefile ・Makefileとは ユーティリティの処理を手続き的に実装したファイル．ターゲットごとに処理を実装する．複数のターゲット名を割り当てられる． foo: echo \"foo\" bar: echo \"bar\" baz qux: # 複数のターゲット名 echo \"baz\" ・ターゲット間依存関係 特定のターゲットの実行前に，他のターゲットを実行しておきたい場合，依存関係を定義できる．これは複数定義できる． foo: echo \"foo\" bar: foo # fooを事前に実行する． echo \"bar\" baz: foo baz # foo，bazを事前に実行する． echo \"baz\" シェルスクリプトの実行方法 ・source 現在開かれているインタラクティブで処理を実行する．そのため，シェルスクリプト内で定義した変数は，シェルスクリプトの実行後も維持される． $ source hello.sh ・bash 新しくインタラクティブを開き，処理を実行する．そのため，シェルスクリプト内で定義した変数は，シェルスクリプトの実行後に破棄される． $ bash hello.sh ・ドット $ . hello.sh ・パス指定 相対パスもしくは絶対パスでシェルスクリプトを指定する．実行するファイルをカレントディレクトリに置くことはできない． $ ./hello.sh Makefileの実行方法とオプション ・make Makefileが置かれた階層で，makeコマンドの引数としてターゲット名や環境変数を渡せる．Makefile内で環境変数のデフォルト値を定義できる． $ make = ＊実装例＊ $ make foo FOO=foo FOO=default foo: echo ${FOO} ロジック ・ヒアドキュメント ヒアドキュメントで作成したシェルスクリプトには，各行にechoが追加される． #!/bin/bash cat \"echo.sh\" #!/bin/bash hoge fuga EOF #!/bin/bash echo hoge echo fuga ・for ＊実装例＊ #!/bin/bash for i in 1 2 3 4 5 do echo \"$i\" done ・switch-case 変数に代入された値によって，処理を分ける．全ての場合以外をアスタリスクで定義する． ＊実装例＊ #!/bin/bash case \"$ENV\" in \"test\") VAR=\"XXXXX\" ;; \"stg\") VAR=\"YYYYY\" ;; \"prd\") VAR=\"ZZZZZ\" ;; *) echo \"The parameter ${ENV} is invalid.\" exit 1 ;; esac 02-03. ファイルシステム系 chmod：change mode ・ ファイルの権限を変更する．よく使用されるパーミッションのパターンは次の通り． $ chmod 600 ・-R ディレクトリ内のファイルに対して，再帰的に権限を付与する． $ chmod -R 600 ・100番刻みの規則性 所有者以外に全権限が与えられない． 数字 所有者 グループ その他 特徴 500 r-x --- --- 所有者以外に全権限なし 600 rw- --- --- 所有者以外に全権限なし 700 rwx --- --- 所有者以外に全権限なし ・111番刻みの規則性 全てのパターンで同じ権限になる． 数字 所有者 グループ その他 特徴 555 r-x r-x r-x 全てにWrite権限なし 666 rw- rw- rw- 全てにExecut権限なし 777 rwx rwx rwx 全てに全権限あり ・その他でよく使う番号 数字 所有者 グループ その他 特徴 644 rw- r-- r-- 所有者以外にWrite，Execute権限なし 755 rwx r-x r-x 所有者以外にWrite権限なし cp ・-Rp ディレクトリの属性情報も含めて，ディレクトリ構造とファイルを再帰的にコピー． $ cp -Rp // // # 隠しファイルも含めて，ディレクトリの中身を他のディレクトリ内にコピー # 「アスタリスク」でなく「ドット」にする $ cp -Rp // / ・-p 『ファイル名.YYYYmmdd』の形式でバックアップファイルを作成 $ cp -p .`date +\"%Y%m%d\"` echo ・オプション無し 定義されたシェル変数を出力する．変数名には$マークを付ける．ダブルクオートはあってもなくてもよい． $ = $ echo $ $ echo \"$\" file ・オプション無し ファイルの改行コードを確認する． # LFの場合（何も表示されない） $ file foo.txt foo.txt: ASCII text # CRLFの場合 $ file foo.txt foo.txt: ASCII text, with CRLF line terminators # CRの場合 $ file foo.txt foo.txt: ASCII text, with CR line terminators find ・-type ファイルを検索するためのユーティリティ．アスタリスクを付けなくとも，自動的にワイルドカードが働く． $ find /* -type f | xargs grep \"\" # パーミッションエラーなどのログを破棄して検索． $ find /* -type f | xargs grep \"\" 2> /dev/null ・-name 名前が .conf で終わるファイルを全て検索する． $ find /* -name \"*.conf\" -type f 名前が dir で終わるディレクトリを全て検索する． $ find /* -name \"*dir\" -type d ルートディレクトリ以下で， という文字をもち，ファイル名が .conf で終わるファイルを全て検索する． $ find /* -name \"*.conf\" -type f | xargs grep \"\" ln ・シンボリックリンクとは ファイルやディレクトリのショートカットのこと．シンボリックリンクに対する処理は，リンク元のファイルやディレクトリに転送される． ・-s カレントディレクトリに，シンボリックリンクを作成する．リンクの元になるディレクトリやファイルのパスを指定する． $ ln -s ls ・-l，-a 隠しファイルや隠しディレクトリも含めて，全ての詳細を表示する． $ ls -l -a mkdir ・-p 複数階層のディレクトリを作成する． $ mkdir -p // rm ・-R ディレクトリ自体と中のファイルを再帰的に削除する． $ rm -R od：octal dump ・オプション無し ファイルを8進数の機械語で出力する． $ od ・-Ad，-tx ファイルを16進数の機械語で出力する． $ od -Ad -tx set ・オプション無し 現在設定されているシェル変数を一覧で表示する． $ set ・-n シェルスクリプトの構文解析を行う． $ set -n ・-e 一連の処理の途中で0以外の終了ステータスが出力された場合，全ての処理を終了する． $ set -e ・-x 一連の処理をデバッグ情報として出力する． $ set -x ・-u 一連の処理の中で，未定義の変数が存在した場合，全ての処理を終了する． $ set -u ・-o pipefail パイプライン（|）内の一連の処理の途中で，エラーが発生した場合，その終了ステータスを出力し，全ての処理を終了する． $ set -o pipefail tar ・-x 圧縮ファイルを解凍する． $ tar -xf foo.tar.gz ・-f 圧縮ファイル名を指定する．これを付けない場合，テープドライブが指定される． $ tar -xf foo.tar.gz ・-v 解凍中のディレクトリ／ファイルの生成ログを表示する． $ tar -xvf foo.tar.gz ./ ./opt/ ./opt/foo/ ./opt/foo/bar/ ./opt/foo/bar/install.sh ./opt/foo/bar/baz/ ./opt/foo/bar/baz/init.sh ・-g gzip拡張子の圧縮ファイルを解凍する．ただし，標準で有効になっているため，オプションは付けないくても問題ない． $ tar -zxf foo.tar.gz unlink ・オプション無し カレントディレクトリのシンボリックリンクを削除する． $ unlink 02-04. ネットワーク系 curl ・-o（小文字） インストール後のファイル名を定義する．これを指定しない場合，-Oオプションを有効化する必要がある． $ curl -o http://example.com/foo ・-O（大文字） インストール後のファイル名はそのままでインストールする．これを指定しない場合，-oオプションを有効化する必要がある． ・-L 指定したURLでリダイレクトが行われても，リダイレクト後のURLからファイルをインストールする． $ curl -L http://example.com/foo ssh：secure shell ・-l，-p，，-i，-T 事前に，秘密鍵の権限は「600」にしておく．tty（擬似ターミナル）を使用する場合は，-Tオプションをつける． $ ssh -l @ -p 22 -i -T ・-l，-p，，-i，-T，-vvv # -vvv：ログを出力する $ ssh -l @ -p 22 -i -T -vvv ・設定ファイル（~/.ssh/config） 設定が面倒なsshコマンドのオプションの引数を，~/.ssh/configファイルに記述しておく． # サーバ１ Host User Port 22 HostName IdentityFile # サーバ２ Host User Port 22 HostName IdentityFile これにより，コマンド実行時の値渡しを省略できる．tty（擬似ターミナル）を使用する場合は，-Tオプションをつける． # 秘密鍵の権限は，事前に「600」にしておく $ ssh -T 02-05. プロセス系 ps： process status ・aux 稼働しているプロセスの詳細情報を表示するためのユーティリティ． # 稼働しているプロセスのうち，詳細情報に「xxx」を含むものを表示する． $ ps aux | grep \"\" systemctl：system control（旧service） ・systemctlとは デーモンを起動するsystemdを制御するためのユーティリティ． ・list-unit-files デーモンのUnitを一覧で確認する． $ systemctl list-unit-files --type=service crond.service enabled # enable：自動起動する supervisord.service disabled # disable：自動起動しない systemd-reboot.service static # enable：他サービス依存 ・enable マシン起動時にデーモンが自動起動するように設定する． $ systemctl enable # 例：Cron，Apache $ systemctl enable crond.service $ systemctl enable httpd.service ・disable マシン起動時にデーモンが自動起動しないように設定する． $ systemctl disable # 例：Cron，Apache $ systemctl disable crond.service $ systemctl disable httpd.service ・systemd：system daemon のUnitの種類 各デーモンを，/usr/lib/systemd/systemや/etc/systemd/system下でUnit別に管理し，Unitごとに起動する．Unitは拡張子の違いで判別する． Unitの拡張子 意味 デーモン例 mount ファイルのマウントに関するデーモン． service プロセス起動停止に関するデーモン． httpd：http daemon socket ソケットとプロセスの紐づけに関するデーモン kill ・-9 指定したPIDのプロセスを削除する． $ kill -9 指定したコマンドによるプロセスを全て削除する． $ sudo pgrep -f | sudo xargs kill -9 cron ・cronとは 指定したスケジュールに従って，指定されたプログラムを定期実行する常駐プログラム． ・cronファイル ファイル名ディレクトリ名 利用者 主な用途 /etc/crontab root 毎時，毎日，毎月，毎週の自動タスクのメイン設定ファイル /etc/cron.hourly root 毎時実行される自動タスク設定ファイルを置くディレクトリ /etc/cron.daily root 毎日実行される自動タスク設定ファイルを置くディレクトリ /etc/cron.monthly root 毎月実行される自動タスク設定ファイルを置くディレクトリ /etc/cron.weekly root 毎週実行される自動タスク設定ファイルを置くディレクトリ ＊実装例＊ あらかじめ，各ディレクトリにcronファイルを配置しておく． cronとして登録するファイルを作成する．run-partsコマンドで，指定した時間に，各cronディレクトリ内のcronファイルを一括で実行するように記述しておく． # 設定 SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=\"hasegawafeedshop@gmail.com\" LANG=ja_JP.UTF-8 LC_ALL=ja_JP.UTF-8 CONTENT_TYPE=text/plain; charset=UTF-8 # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed # run-parts 1 * * * * root run-parts /etc/cron.hourly # 毎時・1分 5 2 * * * root run-parts /etc/cron.daily # 毎日・2時5分 20 2 * * 0 root run-parts /etc/cron.weekly # 毎週日曜日・2時20分 40 2 1 * * root run-parts /etc/cron.monthly # 毎月一日・2時40分 @reboot make clean html # cron起動時に一度だけ ・cron.dファイル 複数のcronファイルで全ての一つのディレクトリで管理する場合に用いる． ディレクトリ名 利用者 主な用途 /etc/cron.d root 上記以外の自動タスク設定ファイルを置くディレクトリ ・supervisorとの組み合わせ ユーザーが，OS上のプロセスを制御できるようにするためのプログラム． # インストール $ pip3 install supervisor # /etc/supervisor/supervisord.conf に設定ファイルを置いて起動． $ /usr/local/bin/supervisord 以下に設定ファイルの例を示す． ＊実装例＊ [supervisord] # 実行ユーザ user=root # フォアグラウンドで起動 nodaemon=true # ログ logfile=/var/log/supervisord.log # Pid pidfile=/var/tmp/supervisord.pid [program:crond] # 実行コマンド command=/usr/sbin/crond -n # プログラムの自動起動 autostart=true # プログラム停止後の再起動 autorestart=true # コマンドの実行ログ stdout_logfile=/var/log/command.log stderr_logfile=/var/log/command-error.log # コマンドの実行ユーザ user=root # コマンドの実行ディレクトリ directory=/var/www/tech-notebook crontab ・crontabとは cronデーモンの動作が定義されたcrontabファイルを操作するためのユーティリティ． ・オプション無し 作成したcronファイルを登録する．cron.dファイルは操作できない． $ crontab ・登録されたcronファイルの処理を確認 $ crontab -l # crontabコマンドで登録されたcronファイルの処理 1 * * * * rm foo ・cronファイルの登録手順 ＊実装例＊ １. 拡張子は自由で，時刻とコマンドが実装されたファイルを用意する．この時，最後に改行がないとエラー（premature EOF）になるため，改行を追加する． 参考： # cron-hourly.txt # 毎時・1分 1 * * * * root run-parts /etc/cron.hourly # cron-daily.txt # 毎日・2時5分 5 2 * * * root run-parts /etc/cron.daily # cron-monthly.txt # 毎週日曜日・2時20分 20 2 * * 0 root run-parts /etc/cron.weekly # cron-weekly.txt # 毎月一日・2時40分 40 2 1 * * root run-parts /etc/cron.monthly # cron起動時に一度だけ @reboot make clean html ２. このファイルをcrontabコマンドで登録する．cronファイルの実体はないことと，ファイルの内容を変更した場合は登録し直さなければいけないことに注意する． $ crontab /foo/cron-hourly.txt ３. 登録されている処理を確認する． $ crontab -l 1 * * * * root run-parts /etc/cron.hourly ４. ログに表示されているかを確認． $ cd /var/log $ tail -f cron ５. 改行コードを確認．改行コードが表示されない場合はLFであり，問題ない． $ file /foo/cron-hourly.txt foo.txt: ASCII text crond ・crondとは cronデーモンを起動するためのプログラム ・-n フォアグラウンドプロセスとしてcronを起動 $ crond -n 02-06. テキスト処理系 vim：Vi Imitaion，Vi Improved ・オプション無し vim上でファイルを開く． $ vim history ・オプション無し 履歴1000件の中からコマンドを検索する． $ history | grep tr #!/bin/bash cat ./src.txt | tr \"\\n\" \",\" > ./dst.txt 02-07. 環境変数系 export ・オプション無し 基本的な手順としては，シェル変数を設定し，これを環境変数に追加する． # シェル変数を設定 $ PATH=$PATH: # 環境変数に追加 $ export PATH シェル変数の設定と，環境変数への追加は，以下の通り同時に記述できる． # 環状変数として，指定したバイナリファイル（bin）のあるディレクトリへの絶対パスを追加． # バイナリファイルを入力すると，絶対パス $ export PATH=$PATH: # 不要なパスを削除したい場合はこちら # 環状変数として，指定したバイナリファイル（bin）のあるディレクトリへの絶対パスを上書き $ export PATH=/sbin:/bin:/usr/sbin:/usr/bin ・.bashrcへの追記 exportの結果は，OSの再起動で初期化されてしまう．そのため，再起動時に自動的に実行されるよう，/home/centos/.bashrcに追記しておく． # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific environment PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\" # xxxバイナリファイルのパスを追加 を追加 printenv ・オプション無し 全ての環境変数を表示する． $ printenv また，特定の環境変数を表示する． $ printenv VAR timedatactl ・set-timezone # タイムゾーンを日本時間に変更 $ timedatectl set-timezone Asia/Tokyo # タイムゾーンが変更されたかを確認 $ date 02-08. ハードウェア系 top ・オプション無し 各プロセスの稼働情報（ユーザ名，CPU，メモリ）を確認する． CPU使用率昇順に並べる $ top ・-a メモリ使用率昇順に並べる． $ top -a free ・-m，-total 物理メモリ，スワップ領域，の使用状況をメガバイトで確認する． # m：Mega Bytes # t: -total $ free -m -total df ・-h，-m，-t ストレージの使用状況をメガバイトで確認する． # h：--human-readable # t: -total $ df -h -m -t mkswap，swapon，swapoff ・スワッピング方式 物理メモリのアドレス空間管理の方法の一つ．ハードウェアのノートを参照． ・スワップ領域の作成方法 # 指定したディレクトリをスワップ領域として使用 $ mkswap /swap_volume # スワップ領域を有効化 # 優先度のプログラムが，メモリからディレクトリに，一時的に退避されるようになる $ swapon /swap_volume # スワップ領域の使用状況を確認 $ swapon -s # スワップ領域を無効化 $ swapoff /swap_volume 03. 管理ユーティリティ 管理ユーティリティの種類 ・管理ユーティリティの対象 様々なレベルを対象にした管理ユーティリティがある． ・ライブラリ管理ユーティリティ ユーティリティ名 対象プログラミング言語 composer.phar：Composer PHP pip：Package Installer for Python Python npm：Node Package Manager Node.js maven：Apache Maven Java gem：Ruby Gems Ruby ・パッケージ管理ユーティリティ ユーティリティ名 対象OS 依存関係のインストール可否 Rpm：Red Hat Package Manager RedHat系 ✕ Yum：Yellow dog Updater ModifiedDNF：Dandified Yum RedHat系 〇 Apt：Advanced Packaging Tool Debian系 〇 Apk：Alpine Linux package management Alpine Linux 〇 ・言語バージョン管理ユーティリティ ユーティリティ名 対象プログラミング言語 phpenv PHP pyenv Python rbenv Ruby 03-02. ライブラリ管理ユーティリティ pip ・install 指定したライブラリをインストールする． # /usr/local 以下にインストール $ pip install --user # requirements.txt を元にライブラリをインストール $ pip install -r requirements.txt # 指定したディレクトリにライブラリをインストール pip install -r requirements.txt　--prefix=/usr/local ・freeze pipでインストールされたパッケージを元に，要件ファイルを作成する． $ pip freeze > requirements.txt ・show pipでインストールしたパッケージ情報を表示する． $ pip show sphinx Name: Sphinx Version: 3.2.1 Summary: Python documentation generator Home-page: http://sphinx-doc.org/ Author: Georg Brandl Author-email: georg@python.org License: BSD # インストール場所 Location: /usr/local/lib/python3.8/site-packages # このパッケージの依存対象 Requires: sphinxcontrib-applehelp, imagesize, docutils, sphinxcontrib-serializinghtml, snowballstemmer, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-jsmath, setuptools, packaging, Pygments, babel, alabaster, sphinxcontrib-qthelp, requests, Jinja2 # このパッケージを依存対象としているパッケージ Required-by: sphinxcontrib.sqltable, sphinx-rtd-theme, recommonmark npm ・入手方法 # リポジトリの作成 $ curl -sL https://rpm.nodesource.com/setup_.x | bash - # nodejsのインストールにnpmも含まれる $ yum install nodejs ・init package.jsonを生成する． $ npm init ・install ディレクトリにパッケージをインストール # ローカルディレクトリにパッケージをインストール $ npm install # グローバルディレクトリにインストール（あまり使わない） $ npm install -g 03-03. パッケージ管理ユーティリティ rpm ・-ivh パッケージをインストールまたは更新する．一度に複数のオプションを組み合わせて記述する．インストール時にパッケージ間の依存関係を解決できないので注意． # パッケージをインストール # -ivh：--install -v --hash $ rpm -ivh # パッケージを更新 # -Uvh：--upgrade -v --hash $ rpm -Uvh ・-qa インストールされた全てのパッケージの中で，指定した文字を名前に含むものを表示する． # -qa： $ rpm -qa | grep ・-ql 指定したパッケージ名で，関連する全てのファイルの場所を表示する． # -ql： $ rpm -ql ・-qi 指定したパッケージ名で，インストール日などの情報を表示する． # -qi： $ rpm -qi yum，dnf ・install，reinstall rpmと同様の使い方ができる．また，インストール時にパッケージ間の依存関係を解決できる． # パッケージをインストール $ yum install -y # 再インストールする時は，reinstallとすること $ yum reinstall -y ・list インストールされた全てのパッケージを表示する． # 指定した文字を名前に含むものを表示． $ yum list | grep ・EPELリポジトリ，Remiリポジトリ CentOS公式リポジトリはパッケージのバージョンが古いことがある．そこで，--enablerepoオプションを使用すると，CentOS公式リポジトリではなく，最新バージョンを扱う外部リポジトリ（EPEL，Remi）から，パッケージをインストールできる．外部リポジトリ間で依存関係にあるため，両方のリポジトリをインストールする必要がある． CentOSのEPELリポジトリをインストール．インストール時の設定ファイルは，/etc/yu.repos.d/* に配置される． # CentOS7系の場合 $ yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm # CentOS8系の場合 $ dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm # こちらでもよい $ yum install -y epel-release でもよい CentOSのRemiリポジトリをインストール．RemiバージョンはCentOSバージョンを要確認．インストール時の設定ファイルは，/etc/yu.repos.d/*に配置される． # CentOS7系の場合 $ yum install -y https://rpms.remirepo.net/enterprise/remi-release-7.rpm # CentOS8系の場合 $ dnf install -y https://rpms.remirepo.net/enterprise/remi-release-8.rpm 設定ファイルへは，インストール先のリンクなどが自動的に書き込まれる． [epel] name=Extra Packages for Enterprise Linux 6 - $basearch #baseurl=http://download.fedoraproject.org/pub/epel/6/$basearch mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-6&arch=$basearch failovermethod=priority enabled=0 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 [epel-debuginfo] name=Extra Packages for Enterprise Linux 6 - $basearch - Debug #baseurl=http://download.fedoraproject.org/pub/epel/6/$basearch/debug mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-6&arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=1 [epel-source] name=Extra Packages for Enterprise Linux 6 - $basearch - Source #baseurl=http://download.fedoraproject.org/pub/epel/6/SRPMS mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-6&arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=1 Remiリポジトリの有効化オプションを永続的に使用できるようにする． # CentOS7の場合 $ yum install -y yum-utils # 永続的に有効化 $ yum-config-manager --enable remi-php74 # CentOS8の場合（dnf moduleコマンドを使用） $ dnf module enable php:remi-7.4 remiリポジトリを指定して，php，php-mbstring，php-mcryptをインストールする．Remiリポジトリを経由してインストールしたソフトウェアは/opt/remi/*に配置される． # CentOS7の場合 # 一時的に有効化できるオプションを利用して，明示的にremiを指定 $ yum install --enablerepo=remi,remi-php74 -y php php-mbstring php-mcrypt # CentOS8の場合 # リポジトリの認識に失敗することがあるのでオプションなし $ dnf install -y php php-mbstring php-mcrypt 再インストールする時は，reinstallとすること． # CentOS7の場合 # 一時的に有効化できるオプションを利用して，明示的にremiを指定 $ yum reinstall --enablerepo=remi,remi-php74 -y php php-mbstring php-mcrypt # CentOS8の場合 # リポジトリの認識に失敗することがあるのでオプションなし $ dnf reinstall -y php php-mbstring php-mcrypt 03-04. 言語バージョン管理ユーティリティ pyenv ・which # pythonのインストールディレクトリを確認 $ pyenv which python /.pyenv/versions/3.8.0/bin/python 04. 言語プロセッサ 言語プロセッサの例 ・アセンブラ 後述の説明を参考にせよ． ・コンパイラ 後述の説明を参考にせよ． ・インタプリタ 後述の説明を参考にせよ． 言語の種類 プログラム言語のソースコードは，言語プロセッサによって機械語に変換された後，CPUによって読み込まれる．そして，ソースコードに書かれた様々な処理が実行される． ・コンパイラ型言語 C#など．コンパイラという言語プロセッサによって，コンパイラ方式で翻訳される言語． ・インタプリタ型言語 PHP，Ruby，JavaScript，Python，など．インタプリタという言語プロセッサによって，インタプリタ方式で翻訳される言語をインタプリタ型言語という． ・Java仮想マシン型言語 Scala，Groovy，Kotlin，など．Java仮想マシンによって，中間言語方式で翻訳される． 実行のエントリポイント ・動的型付け型言語の場合 動的型付け言語では，エントリポイントが指定プログラムの先頭行と決まっており，そこから枝分かれ状に処理が実行されていく．PHPでは，index.phpファイルがエントリポイントと決められている．その他のファイルにはエントリポイントは存在しない． handle($request); $response->send(); $kernel->terminate($request, $response); ・静的型付け型言語の場合 静的型付け言語では，エントリポイントが決まっておらず，自身で定義する必要がある．Javaでは，「public static void main(String[] args)メソッドを定義した場所がエントリポイントになる． import java.util.*; public class Age { // エントリポイントとなるメソッド public static void main(String[] args) { // 定数を定義． final int age = 20; System.out.println(\"私の年齢は\" + age); // 定数は再定義できないので，エラーになる． age = 31; System.out.println(\"…いや，本当の年齢は\" + age); } } 04-02. コンパイラ型言語の機械語翻訳 コンパイラ方式 ・機械語翻訳と実行のタイミング コードを，バイナリ形式のオブジェクトコードとして，まとめて機械語に翻訳した後，CPUに対して命令が実行される． ・ビルド（コンパイル＋リンク） コンパイルによって，ソースコードは機械語からなるオブジェクトコードに変換される．その後，各オブジェクトコードはリンクされ．exeファイルとなる．この一連のプロセスを『ビルド』という．また，ビルドによって生成されたファイルを『アーティファクト（成果物）』という． ・仕組み（じ，こ，い，さい，せい，リンク，実行） Lexical analysis（字句解析） ソースコードの文字列を言語の最小単位（トークン）の列に分解． 以下に，トークンの分類方法の例を示す． Syntax analysis（構文解析） トークンの列をツリー構造に変換． Semantics analysis（意味解析） ツリー構造を基に，ソースコードに論理的な誤りがないか解析． Code optimization（コード最適化） ソースコードの冗長な部分を削除または編集．機械語をより短くするこができる． Code generation（コード生成） 最適化されたコードをバイナリ形式のオブジェクトコードに変換． リンク オブジェクトコードをリンクする． 命令の実行 リンクされたオブジェクトコードを基に，命令が実行される． makeによるビルド 1. パッケージをインストール # パッケージを公式からインストールと解答 $ wget $ tar # ビルド用ディレクトリの作成． $ mkdir build $ cd build 2. ビルドのルールを定義 configureファイルを元に，ルールが定義されたMakefileを作成する． # configureへのパスに注意． $ ../configure --prefix=\"\" 3. ビルド （コンパイル＋リンク） パッケージのソースコードからexeファイルをビルドする． # -j で使用するコア数を宣言し，処理の速度を上げられる． $ make -j4 任意で，exeファイルのテストを行える． $ make check 4. exeファイルの実行 生成されたソースコードのファイルを，指定したディレクトリにコピー． # installと命令するが，実際はコピー．sudoを付ける． $ sudo make install 元となったソースコードやオブジェクトコードを削除． $ make clean 04-03. インタプリタ型言語の機械語翻訳 インタプリタ方式 ・機械語翻訳と実行のタイミング コードを，一行ずつ機械語に変換し，その都度，CPUに対して命令が実行される． コマンドラインでそのまま入力し，機械語翻訳と実行を行うことができる． #=========== # PHPの場合 #=========== # PHPなので，処理終わりにセミコロンが必要 $ php -r \"\" # Hello Worldを出力 $ php -r \"echo \"Hello World\";\" # phpinfoを出力 $ php -r \"phpinfo();\" # （おまけ）phpinfoの出力をテキストファイルに保存 $ php -r \"phpinfo();\" > phpinfo.txt # php.iniの読み込み状況を出力 $ php --ini ・仕組み（じ，こ，い，実行） Lexical analysis（字句解析） ソースコードの文字列を言語の最小単位（トークン）の列に分解． 以下に，トークンの分類方法の例を示す． Syntax analysis（構文解析） トークンの列をツリー構造に変換．ソースコードから構造体を構築することを構文解析といい，htmlを構文解析してDOMツリーを構築する処理とは別物なので注意． Semantics analysis（意味解析） ツリー構造を基に，ソースコードに論理的な誤りがないか解析． 命令の実行 意味解析の結果を基に，命令が実行される． １から４をコード行ごとに繰り返す ・補足：JSの機械語翻訳について Webサーバを仮想的に構築する時，PHPの言語プロセッサが同時に組み込まれるため，PHPのソースコードの変更はブラウザに反映される．しかし，JavaScriptの言語プロセッサは組み込まれない．そのため，JavaScriptのインタプリタは別に手動で起動する必要がある． 04-04. Java仮想マシン型言語の機械語翻訳 中間言語方式 ・中間言語方式の機械語翻訳の流れ JavaまたはJVM型言語のソースコードを，Javaバイトコードを含むクラスファイルに変換する． JVM：Java Virtual Machine内で，インタプリタによって，クラスデータを機械語に翻訳する． 結果的に，OS（制御プログラム？）に依存せずに，命令を実行できる．（C言語） ・C言語とJavaのOSへの依存度比較 JVM言語 ソースコード 05. 制御プログラム（カーネル） 制御プログラム（カーネル）の例 カーネル，マイクロカーネル，モノリシックカーネル 通信管理 ・SELinux：Security Enhanced Linux Linuxに標準で導入されているミドルウェア．ただし，アプリケーションと他のソフトウェアの通信を遮断してしまうことがあるため，基本的には無効にしておく． SELinuxの状態を確認 $ getenforce # 有効の場合 Enforcing /etc/sellnux/configを修正する． # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # OSを再起動 OSを再起動しないと設定が反映されない． ジョブ管理 クライアントは，マスタスケジュールに対して，ジョブを実行するための命令を与える． マスタスケジュラ，ジョブスケジュラ ジョブとは，プロセスのセットのこと．マスタスケジュラは，ジョブスケジュラにジョブの実行を命令する．データをコンピュータに入力し，複数の処理が実行され，結果が出力されるまでの一連の処理のこと．『Task』と『Job』の定義は曖昧なので，『process』と『set of processes』を使うべきとのこと． 引用：https://stackoverflow.com/questions/3073948/job-task-and-process-whats-the-difference/31212568 複数のジョブ（プログラムやバッチ）の起動と終了を制御したり，ジョブの実行と終了を監視報告するソフトウェア．ややこしいことに，タスクスケジューラとも呼ぶ． ・Reader ジョブ待ち行列に登録 ・Initiator ジョブステップに分解 ・Terminator 出力待ち行列に登録 ・Writer 優先度順に出力の処理フローを実行 Initiatorによるジョブのジョブステップへの分解 Initiatorによって，ジョブはジョブステップに分解される． タスク管理 タスクとは，スレッドに似たような，単一のプロセスのこと．Initiatorによるジョブステップから，タスク管理によって，タスクが生成される．タスクが生成されると実行可能状態になる．ディスパッチャによって実行可能状態から実行状態になる． ・優先順方式 各タスクに優先度を設定し，優先度の高いタスクから順に，ディスパッチしていく方式． ・到着順方式 待ち行列に登録されたタスクから順に，ディスパッチしていく方式． ＊具体例＊ 以下の様に，タスクがCPUに割り当てられていく． ・Round robin 方式 Round robinは，『総当たり』の意味．一定時間（タイムクウォンタム）ごとに，実行状態にあるタスクが強制的に待ち行列に登録される．交代するように，他のタスクがディスパッチされる． ＊具体例＊ 生成されたタスクの到着時刻と処理時間は以下のとおりである．強制的なディスパッチは，『20秒』ごとに起こるとする． タスクAが0秒に待ち行列へ登録される． 20秒間，タスクAは実行状態へ割り当てられる． 20秒時点で，タスクAは実行状態から待ち行列に追加される．同時に，待ち行列の先頭にいるタスクBは，実行可能状態から実行状態にディスパッチされる． 40秒時点で，タスクCは実行状態から待ち行列に追加される．同時に，待ち行列の先頭にいるタスクAは，実行可能状態から実行状態にディスパッチされる． 入出力管理 アプリケーションから低速な周辺機器へデータを出力する時，まず，CPUはスプーラにデータを出力する．Spoolerは，全てのデータをまとめて出力するのではなく，一時的に補助記憶装置（Spool）にためておきながら，少しずつ出力する（Spooling）． "},"public/infrastructure_software_machine_language_and_radix.html":{"url":"public/infrastructure_software_machine_language_and_radix.html","title":"▶ ︎機械語と進数","keywords":"","body":"機械語と進数 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 機械語と2進数の関係 機械語とは あらゆる情報を『0』と『1』の2進数を機械語として，CPUに対して，命令が実行される． 様々な進数とbitの関係 しかし，人間が扱う上では8進数あるいは16進数に変換して表現することが適している．2進数1ケタが『1 bit』と定義されている．8進数の1ケタは2進数の3ケタ（＝3 bit）に相当し，16進数の1ケタは2進数の4ケタ（4 bit）に相当する． なぜ８bitを1Byteとするのか？（半角英数字とbitの関係） ８bitを一区切りとして，１Byteと表現する．これは，半角英数字一文字が８bitのデータ量をもつからである． Byte単位 1000 Byte = 1k Byte 一般的なCPUが扱える情報の種数 CPUでは，各データは2進法によって区別されている．CPUは4 ，8，16，32-bitバージョンと進歩し，2008年の後半からは 64-bitバージョンのCPUが普及し始めた．1-bitは2種類の情報を表すことができるため，32-bitのCPUでは2^32，64-bitでは2^64の種類の情報を扱う事ができる． 01-02. 機械語命令の種類 設定命令 ・実行アドレスをレジスタに設定する場合 ・実行アドレスが指す語の内容をレジスタに設定する場合 ・レジスタの内容を実行アドレスに格納する場合 シフト命令（※別節を参照せよ） 計算命令 レジスタから取り出した値を別の値と足し，その結果を元のレジスタに設定すること． 論理演算命令（※3章を参照せよ） 01-03. シフト命令 論理左シフト 最上位に正負を表す『符号bit』を設定せずに，シフトを行う． ２進数の場合… 左に１bitシフトすると『2倍』 左に１bitシフトし，元の値を足すを『3倍』 左に２bitシフトすると『4倍』 左に２bitシフトし，元の値を足すと『5倍』 左に２bitシフトし，元の値を足して『5倍』．さらに２bitシフトすると『10倍』 左に３bitシフトすると『8倍』 ・正の数の場合 ＊具体例＊ 00011100 ・負の数の場合 ＊具体例＊ 11100100 論理右シフト 最上位に正負を表す『符号bit』を設定せずに，シフトを行う． ２進数の場合… 右に１bitシフトすると『1/2』 右に２bitシフトすると『1/4』 右に３bitシフトすると『1/8』 ・正の数の場合 ＊具体例＊ 00011100 ・負の数の場合（計算はできない） ＊具体例＊ 11100100 負の数で論理右シフトを行う場合，間違った計算が行われてしまう．こういう場合，算術シフトが用いられる． 算術左シフト 最上位に正負を表す『符号bit』を設定し，シフトを行う． ２進数の場合… 左に１bitシフトすると『2倍』 左に１bitシフトし，元の値を足すを『3倍』 左に２bitシフトすると『4倍』 左に２bitシフトし，元の値を足すと『5倍』 左に２bitシフトし，元の値を足して『5倍』．さらに２bitシフトすると『10倍』 左に３bitシフトすると『8倍』 ・正の数の場合 ＊具体例＊ 00011100 ・負の数の場合 ＊具体例＊ 00011100 算術右シフト ２進数の場合… 最上位に正負を表す『符号bit』を設定し，シフトを行う． 右に１bitシフトすると『1/2』 右に２bitシフトすると『1/4』 右に３bitシフトすると『1/8』 ・正の数の場合 ＊具体例＊ 00011100 ・負の数の場合 01-04. 機械語命令の実行手順 実行手順 16進数が2進数に変換され，記号へ値が割り当てられる．（ビット分割） 記号の値を基に，実行アドレスの計算方法が選択され，実行される．（実行アドレスの計算） 実行アドレスを基に，機械語命令が実行され，値がレジスタやメモリに書き留められる．（機械語命令のトレース） （１）ビット分割 ＊具体例＊ 命令：20B3h ・16進数の2進数への変換 ・記号への値の割り当て （２）実効アドレスの計算 ・実行アドレスの計算方法の選択 『X＝2』，『I = 1』より，表の網掛けの計算式を選択． ・実効アドレスの計算の実行 ここに，レジスタ番号と内容の表を張る． (実効アドレス) = [adr + [X] ] = [1000h + [レジスタ2] ]（※配列のように，レジスタ2の値を参照） = [1000h + 0002h] = [1002h] = 1003h （３）機械語命令のトレース 01-05. 構文解析における数式の認識方法 逆ポーランド表記法（後置表記法） 演算子（＋，－，×，÷など）を被演算子（数値や変数，また計算の結果）の後ろに書くことで数式を表現する方法．ちなみに，人間が使っている表記方法は，『中置記法』という． ＊具体例＊ Y = ( A + B ) × ( C － ( D ÷ E ) ) 括弧は先に計算するので塊と見なす． ( A + B ) ⇒ AB+ 括弧は先に計算するので塊と見なす． ( D ÷ E ) ⇒ DE ÷ 括弧は先に計算するので塊と見なす． ( AB + ) × ( C － DE ÷ ) ⇒ ( AB + ) ( CDE ÷ －) × 括弧を外しても，塊はそのまま． 　　( AB + ) ( CDE ÷ －) × ⇒ AB+CDE÷－× 左辺と右辺をそれぞれ塊と見なす． 　　Y = AB+CDE÷－× ⇒ YAB+CDE÷－×= 01-06. CPUにおける小数の処理方法 固定小数点数 『この位置に小数点がある』な前提で数字を扱うことによって，小数点を含む数値を表現する方法． CPUは，数値に対し，特定の位置に小数点を打つ． 浮動小数点数 指数表記を用いることによって，小数点を含む数値を表現する方法． ・正規化した数式から浮動小数点数への変換 ・浮動小数点数から正規化した数式への変換 指数部と仮数部を調節して，できるだけ仮数部の上位桁に0が入らないようにして，誤差を少なくすること．例えば，ある計算の結果が0.012345×10^－3だった場合，仮数部を0.1～1の範囲に収めるために0.12345×10^－4に変更する． 01-07. 誤差 『誤差』：実際の数値とCPUが表現できる数値の間に生じるズレのこと． 無限小数 桁溢れ誤差 ＊具体例＊ 初代ドラクエ 初代のドラゴンクエストの経験値の上限は「65535」だった．これは，経験値が16bit（2 Byte）で表されており，桁溢れが起きることを防ぐために65535以上は計算しないようになっていた． 情報落ち 打切り誤差 円周率は，途中で計算を打ち切る． 桁落ち 丸め誤差 02. N 進数 ➔ 10進数（重み掛けを行う） 16進数 ➔ 10進数 ・整数 ＊具体例＊『CA125』 『(16^0 × 5) + (16^1 × 2) + (16^2 × 1) + (16^3 × A) + (16^4 × C) 』というように，下の位から，順に16^Nをかけていく．（AとCは，10進数に変換して『10』と『12』） (1×5) + (16×2) + (256×1) + (4096×10) + (65536×12) ＝ 827685 ・少数 2進数 ➔ 10進数 ・整数 『1101101』 『(2^0 × 1) + (2^1 × 0) + (2^2 × 1) + (2^3 × 1) + (2^4 × 0) + (2^5 × 1) + (2^6 × 1)』というように，下の位から，順に2^Nをかけていく． ・少数 02-02. 10進数 ➔ N 進数（Nで割り続ける） 10進数 ➔ 16進数 ・整数 ＊具体例＊『27』 27を16で割り続ける． 16進数で10～15は，A～Fで表記されるため，11をBで表記． 余りを並べ，答えは『1B』 ・少数 ＊具体例＊『0.1015625』 1.『0.1015625』に16をかけ，整数部分を取り出す．（0.1015625 × 16 = 1.625．『1』を取り出し，16進数に変換して『1』） 2．計算結果の少数部分に16をさらにかける．少数部分が0になるまで，これを繰り返す．（0.625 × 16 = 10.0より，『10』を取り出し，16進数に変換して『A』） 3．少数部分が0になったので，取り出した数を順に並べ，答えは『0.1A』 10進数 ➔ 2進数 ・整数 ＊具体例＊『109』 ・少数 02-03. X 進数 ➔ 10進数 ➔ Y 進数 一度，10進数に変換してから，任意の進数に変換する． 16進数 ➔ 2進数 ・整数 ＊具体例＊『20B3』 2，0，B，3を10進数に変換して，『(16^0 × 3) + (16^1 × 11) + (16^2 × 0) + (16^3 × 2) = 8371』 10と15を2進数に変換して，『0010』，『0000』，『1011』，『0011』 よって，AFは10進法に変換して『0010000010110011』 02-04. X 進数 ➔ 10 進数 ➔ Y 進数 ➔ 10 進数 16進数 ➔ 2進数 ・少数 ＊具体例＊ 2A.4C 整数部分の2Aを10進数に変換して， 42を2進数に変換して，『101010』．また，余り計算の時，余り１を2^Nに直しておく． 整数の場合，下位の桁から，『(2^0 × 0) + (2^1 × 1) + (2^2 × 0) + (2^3 × 1) + (2^4 × 0) + (2^5 × 1) + (2^6 × 0) + (2^7 × 0) + (2^8 × 0) 』 =『2^5＋2^3＋2^1』 （※16進数からの変換の場合，101010は，00101010として扱うことに注意） 76を2進数に変換して，『1001100』．また，余り計算の時，余り１を2^Nに直しておく． 少数部分の場合，上位の桁から，『(2^－1 × 0) + (2^－2 × 1) + (2^－3 × 0) + (2^－4 × 0) + (2^－5 × 1) + (2^－6 × 1) + (2^－7 × 0) + (2^－8 × 0) 』 =『 2^－2＋2^－5＋2^－6 』 （※16進数からの変換の場合，1001100は，01001100として扱うことに注意） したがって，『2^5＋2^3＋2^1＋2^－2＋2^－5＋2^－6』 03. 論理回路 論理式 以下のベン図では，集合Aと集合Bは入力が『1』の場合，外側は入力が『0』の場合を表している．演算方法を思い出すときには，ベン図を思い出せ． 否定回路（NOT回路），NOT演算，ベン図 丸い記号が否定を表す． 論理積回路（AND回路），AND演算，ベン図 ２つのbitを比較して，どちらも『1』なら『1』を出力． 否定論理積回路（NAND回路），NAND演算，ベン図 ２つのbitを比較して，どちらも『1』なら『0』を出力．ベン図では両方が『1』以外の場合を指しているが，回路の出力をうまく説明できない…． 論理和回路（OR回路），OR演算，ベン図 ２つのbitを比較して，どちらかが『1』なら『1』を出力． 排他的論理和回路（EOR回路／XOR回路），EOR演算，ベン図 ２つのbitを比較して，どちらかだけが『1』なら『1』を出力． 否定論理和回路（NOR回路），NOR演算，ベン図 ２つのbitを比較して，どちらも『0』なら『1』を出力． フリップフロップ回路 わかりやすい動画解説：https://www.youtube.com/watch?v=4vAGaWyGanU SRAMの電子回路に用いられている（6章を参照）．Set側に初期値『1』が入力される．入力を『0』に変えても，両方の出力結果は変わらず，安定している． Reset側に『1』を入力すると，両方の出力結果は変化する． 03-02. 論理演算命令 論理積 ＊例題＊ 16進数の『F』は，2進数で『0000 0000 0000 1111』で表される．よって，000Fを用いてAND演算した場合，下位4桁を変化させずに取り出すことができる． 1100 1101 1111 1000 0000 0000 0000 1111 ーーーーーーーーーーー 0000 0000 0000 1000 引用：https://ameblo.jp/kou05/entry-10883110086.html ＊例題＊ 16進数の『7F』は，2進数で『0000 0000 0111 1111』で表される．よって，7Fを用いてAND演算した場合，下位7桁を変化させずに取り出すことができる． 1100 1101 1111 1000 0000 0000 0111 1111 ーーーーーーーーーーー 0000 0000 0111 1000 ＊例題＊ 否定論理積 論理和 排他的論理和 否定論理和 ＊例題＊ XとYの否定論理積 X NAND Yは，NOT(X AND Y)として定義される．X OR YをNANDだけを使って表した論理式はどれか． ⇒X＝0，Y＝0のときにX OR Yが『0』になることから，『0』になる選択肢を探す． ・((X NAND Y) NAND X) NAND Y ((0 NAND 0)NAND 0)NAND 0 ＝(1 NAND 0) NAND 0 ＝1 NAND 0 ＝1 ・(X NAND X) NAND (Y NAND Y) (0 NAND 0)NAND(0 NAND 0) ＝1 NAND 1 ＝0 ・(X NAND Y) NAND (X NAND Y) (0 NAND 0)NAND(0 NAND 0) ＝1 NAND 1 ＝0 ・X NAND (Y NAND (X NAND Y)) 0 NAND(0 NAND(0 NAND 0)) ＝0 NAND (0 NAND 1) ＝0 NAND 1 ＝1 "},"public/infrastructure_cloud_computing.html":{"url":"public/infrastructure_cloud_computing.html","title":"▶ ︎クラウドコンピューティング","keywords":"","body":"クラウドコンピューティング はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. オンプレミスとクラウドコンピューティングの種類 オンプレミスとは ベンダーは関わらず，ユーザの設備によって，システムを運用すること． クラウドコンピューティングとは インターネットを経由して，ベンダーのサーバに自身のデータを保存し，利用すること．ベンダーが，システムを稼働させるために必要なソフトウェアとハードウェアをどこまで提供するかによって，サービスの名称が異なる． 02. オンプレミスの具体例 03. クラウドコンピューティングの具体例 IaaS：Infrastructure as a Service ＊具体例＊ アプリケーション名 提供 Amazon Web Service Amazon Google Cloud Platform Google Microsoft Azure Microsoft IBM Cloud IBM PaaS：Platform as a Service ＊具体例＊ アプリケーション名 提供 Google App Engine Google Windows Azure Microsoft GitHub Pages GitHub FaaS：Platform as a Service ユーザ側は関数プログラムの実装のみを行い，それ以外はベンダー側に管理してもらうサービスのこと． ＊具体例＊ Lambda SaaS：Software as a Service 従来はパッケージとして提供していたアプリケーションを，Webアプリケーションとして提供するサービスのこと． ＊具体例＊ Google Apps（Google Map，Google Cloud，Google Calender など） "},"public/infrastructure_cloud_computing_aws.html":{"url":"public/infrastructure_cloud_computing_aws.html","title":"▶ ︎Amazon Web Service","keywords":"","body":"Amazon Web Service はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ALB：Application Load Balancing ALBとは クラウドリバースプロキシサーバ，かつクラウドロードバランサーとして働く．リクエストを代理で受信し，インスタンスへのアクセスをバランスよく分配することによって，サーバへの負荷を緩和する． 設定項目 ・主要項目 設定項目 説明 補足 リスナー ALBに割り振るポート番号お，受信するプロトコルを設定する．リバースプロキシかつロードバランサ－として，これらの通信をターゲットグループにルーティングする． セキュリティポリシー リクエストの送信者が使用するSSL/TLSプロトコルや暗号化方式のバージョンに合わせて，ALBが受信できるこれらのバージョンを設定する． ・リクエストの送信者には，ブラウザ，APIにリクエストを送信する外部サービス，転送元のAWSリソース（CloudFrontなど），などを含む．・参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/create-https-listener.html#describe-ssl-policies ルール リクエストのルーティングのロジックを設定する． ターゲットグループ ルーティング時に使用するプロトコルと，ルーティング先のアプリケーションに割り当てられたポート番号を指定する． ターゲットグループ内のターゲットのうち，トラフィックはヘルスチェックがOKになっているターゲットにルーティングされる． ヘルスチェック ターゲットグループに属するプロトコルとアプリケーションのポート番号を指定して，定期的にリクエストを送信する． ・ターゲットグループの詳細 ターゲットの指定方法 補足 インスタンス ターゲットが，EC2でなければならない． IPアドレス ターゲットのパブリックIPアドレスが，静的でなければならない． Lambda ターゲットが，Lambdaでなければならない． ルール ・ルールの設定例 ユースケース ポート IF THEN リクエストがポート80を指定した時に，443にリダイレクトしたい． 80 それ以外の場合はルーティングされないリクエスト リダイレクト先：https://#{host}:443/#{path}?#{query}ステータスコード：HTTP_301 リクエストがポート443を指定した時に，ターゲットグループに転送したい． 443 それ以外の場合はルーティングされないリクエスト 特定のターゲットグループ Webサーバ，アプリケーションにおける対応 ・問題 ALBからEC2へのルーティングをHTTPプロトコルとした場合，アプリケーション側で，HTTPSプロトコルを用いた処理ができなくなる．そこで，クライアントからALBに対するリクエストのプロトコルがHTTPSだった場合，Webサーバまたはアプリケーションにおいて，ルーティングのプロトコルをHTTPSと見なすように対処する． ・Webサーバにおける対処方法 ALBを経由したリクエストの場合，リクエストヘッダーにX-Forwarded-Protoヘッダーが付与される．これには，ALBに対するリクエストのプロトコルの種類が，文字列で代入されている．これが『HTTPS』だった場合，WebサーバへのリクエストをHTTPSであるとみなすように対処する．これにより，アプリケーションへのリクエストのプロトコルがHTTPSとなる（こちらを行った場合は，以降のアプリケーション側の対応不要）． ＊実装例＊ SetEnvIf X-Forwarded-Proto https HTTPS=on ・アプリケーションにおける対処方法 ALBを経由したリクエストの場合，リクエストヘッダーにHTTP_X_FORWARDED_PROTOヘッダーが付与される．これには，ALBに対するリクエストのプロトコルの種類が．文字列で代入されている．これが『HTTPS』だった場合，アプリケーションへのリクエストをHTTPSであるとみなすように，index.phpに追加実装を行う． ＊実装例＊ その他の留意事項 ・割り当てられるプライベートIPアドレス範囲 ALBに割り当てられるIPアドレス範囲には，VPCのものが適用される．そのため，EC2のSecurity Groupでは，VPCのIPアドレス範囲を許可するように設定する必要がある． ・ALBのセキュリティグループ Route53から転送されるパブリックIPアドレスを受信できるようにしておく必要がある．パブリックネットワークに公開するWebサイトであれば，IPアドレスは全ての範囲（0.0.0.0/0と::/0）にする．社内向けのWebサイトであれば，社内のプライベートIPアドレスのみ（n.n.n.n/32）を許可するようにする． 02. Amplify Amplifyとは サーバレスアプリケーションを構築するためのクラウドインフラストラクチャのフレームワーク．SSGの場合，静的ファイルをデプロイしさえすれば，アプリケーションとしての要件が全て整う．SPAの場合，サーバレスのバックエンドを自動構築してくれ，フロントエンドをデプロイしさえすれば，要件が全て整う．これのAWSリソースはCloudFormationによって構築されるが，Amplify経由でしか設定を変更できず，各AWSリリースのコンソール画面を見ても，非表示になっている．ただし，Route53の設定は表示されており，Amplifyが追加したレコードをユーザが編集できるようになっている． 参考：https://d1.awsstatic.com/webinars/jp/pdf/services/20200520_AWSBlackBelt_Amplify_A.pdf 役割 使用されているAWSリソース 認証 Gognito 静的サイトホスティング CloudFront，S3 API API Gateway，AppSync GraphQL バックエンドロジック Lambda DB DynamoDB ストレージ S3 全文検索 Elastic Search リアルタイム通知 AppSync，IoT Core 設定項目 項目 説明 補足 本番稼働ブランチ 基点ブランチを設定する． Amplifyを本番運用しない場合は，developブランチを設定すればよい． Branch autodetection ブランチの自動検出を有効化する． ワイルドカードを組み込む場合，アスタリスクを二つ割り当てないと，ブランチが検知されないことがある． 手動ビルド＆デプロイ ・開発環境で擬似再現 サーバレスアプリケーションを開発環境で再現する． $ amplify mock api ・開発環境から直接ビルド&デプロイ 開発／ステージング／本番環境に切り替える必要がある． # アプリケーションの設定 $ amplify add hosting # ビルド&デプロイ $ amplify publish 自動ビルド&デプロイ ・連携可能なバージョン管理システム 参考：https://docs.aws.amazon.com/ja_jp/amplify/latest/userguide/getting-started.html#step-1-connect-repository ・対応するリポジトリ構造 種類 ビルド開始ディレクトリ 非モノリポジトリ リポジトリ名からなるディレクトリ モノリポジトリ モノリポジトリの各アプリケーションディレクトリ ・amplify.ymlファイル リポジトリのルートにamplify.ymlファイルを配置する．Next.jsではSSG／SSRの両モードでビルド＆デプロイが可能である．package.jsonファイルで使用されるnextコマンドに応じて，SSGまたはSSRのいずれかのインフラが構築され，デプロイされる．SSGの場合，裏側ではS3，CloudFront，Route53などが構築され，静的ホスティングが実行される．SSRの場合，フロントエンドだけでなくバックエンドの稼働環境が必要になるため，LambdaやCogniteが構築される． 参考： https://docs.aws.amazon.com/ja_jp/amplify/latest/userguide/build-settings.html https://docs.aws.amazon.com/ja_jp/amplify/latest/userguide/server-side-rendering-amplify.html#deploy-nextjs-app version: 1 #===================== # 環境変数 #===================== env: variables: key: # 環境変数のハードコーディング #===================== # バックエンドのCI/CD #===================== backend: phases: preBuild: commands: - # コマンド build: commands: - # コマンド postBuild: commands: - # コマンド #===================== # フロントエンドのCI/CD #===================== frontend: phases: preBuild: commands: - npm install # 環境変数として登録したエンコード値をデコード - echo $ENV | base64 -di > .env - cat .env build: commands: - nuxt generate --fail-on-error - ls -la ./dist artifacts: # デプロイ対象のディレクトリ files: # 全てのディレクトリ - \"**/*\" discard-paths: yes # ビルドのアーティファクトを配置するディレクトリ baseDirectory: dist # キャッシュとして保存するディレクトリ cache: paths: - node_modules/**/* #===================== # テスト #===================== test: phases: preTest: commands: - # コマンド test: commands: - # コマンド postTest: commands: - # コマンド artifacts: # デプロイ対象のディレクトリ files: # 全てのディレクトリ - \"**/*\" configFilePath: *location* # ビルドのアーティファクトのディレクトリ baseDirectory: *location* 03. API Gateway API Gatewayとは 異なるクライアントからのリクエストを受信して差分を吸収し，適切なAPIに振り分けられる． 設定項目 ・一覧 API Gatewayは，メソッドリクエスト，統合リクエスト，統合レスポンス，メソッドレスポンス，から構成される． 設定項目 説明 補足 リソース エンドポイント，HTTPメソッド，転送先，などを設定する． 構築したAWSリソースのパスが，API Gatewayのエンドポイントになる． ステージ API Gatewayをデプロイする環境を定義する． オーソライザー LambdaまたはCognitoによるオーソライザーを使用して，認可プロセスを定義する． ゲートウェイのレスポンス モデル リクエスト／レスポンスのスキーマを設定する．これらのバリデーションのために使用できる． OpenAPI仕様におけるスキーマについては，以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html リソースポリシー ポリシーを使用して，API Gatewayにセキュリティを定義づける． ドキュメント ダッシュボード APIの設定 使用量プラン 有料サービスとしてAPIを公開し，料金体系に応じてリクエスト量を制限するために使用する．APIキーにリクエスト量のレートを設定する． 有料サービスとして使用しないAPIの場合は，レートを設定する必要はない． APIキー APIキー認証を設定する． ・その他のアクセス制御の方法として，以下がある．参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/apigateway-control-access-to-api.html・APIキー認証については，以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_and_backend_authentication_authorization.html クライアント証明書 SSLサーバ証明書をAPI Gatewayに割り当てる． APIが，API Gatewayから転送されたリクエストであること識別できるようになる． CloudWatchログの設定 API GatewayがCloudWatchログにアクセスできるよう，ロールを設定する． 一つのAWS環境につき，一つのロールを設定すればよい． リソース ・リソースの詳細 順番 処理 説明 補足 1 メソッドリクエスト クライアントから送信されたデータのうち，実際に転送するデータのフィルタリングを行う． 2 統合リクエスト メソッドリクエストから転送された各データを，マッピングテンプレートのJSONに紐づける． 3 統合レスポンス 統合リクエストでプロキシ統合を使用する場合，統合レスポンスを使用できなくなる． 4 メソッドレスポンス レスポンスが成功した場合，クライアントに送信するステータスコードを設定する． ・メソッドリクエストの詳細 設定項目 説明 補足 認可 定義したLambdaまたはCognitoによるオーソライザーを有効化する． リクエストの検証 『URLクエリ文字列パラメータ』『HTTPリクエストヘッダー』『リクエスト本文』のバリデーションを有効化する． APIキーの必要性 リクエストヘッダーにおけるAPIキーのバリデーションを行う．リクエストのヘッダーに『x-api-key』を含み，これにAPIキーが割り当てられていることを強制する． ヘッダー名は大文字でも小文字でも問題ないが，小文字が推奨．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html URLクエリ文字列パラメータ リクエストされたURLのクエリパラメータのバリデーションを行う． HTTPリクエストヘッダー リクエストヘッダーのバリデーションを行う． リクエスト本文 リクエストボディのバリデーションを行う． SDK設定 ・統合リクエストの詳細 設定項目 説明 補足 統合タイプ リクエストの転送先を設定する． URLパスパラメータ メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのパスパラメータに紐づける．または紐づけずに，新しいデータを転送しても良い． URLクエリ文字列パラメータ メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのクエリパラメータに紐づける．または紐づけずに，新しいデータを転送しても良い． HTTPヘッダー メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのヘッダーに紐づける．または紐づけずに，新しいデータを転送しても良い． 値はシングルクオートで囲う必要がある． マッピングテンプレート メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのメッセージボディに紐づける．または紐づけずに，新しいデータを転送しても良い． ・テスト 設定項目 設定例 補足 クエリ文字 ヘッダー X-API-Token: test 波括弧，スペース，クオーテーションは不要． リクエスト本文 {test:\"test\"} 改行タグやスペースが入り込まないようにする． ・OpenAPI仕様のインポート 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws_apigateway_import.html ・CORSの有効化 CORSを有効化し，異なるオリジンによって表示されたページからのリクエストを許可する．以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/how-to-cors.html プライベート統合 ・プライベート統合とは API GatewayとVPCリンクの間で，リクエスト／レスポンスのJSONデータを自動的にマッピングする機能のこと． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-private-integration.html また，VPCリンクの設定によって，VPCエンドポイントサービスが構築される．VPCエンドポイントサービスについては，VPCエンドポイントサービスの説明を参考にせよ． 設定項目 説明 統合タイプ VPCリンクを選択する． プロキシ統合の使用 VPCリンクとのプロキシ統合を有効化する． メソッド HTTPメソッドを設定する． VPCリンク VPCリンク名を設定する． エンドポイントURL NLBのDNS名をドメイン名として，転送先のURLを設定する． デフォルトタイムアウトの使用 ・メソッドリクエストと統合リクエストのマッピング Lambdaプロキシ統合 ・Lambdaプロキシ統合とは API GatewayとLambdaの間で，リクエスト／レスポンスのJSONデータを自動的にマッピングする機能のこと．プロキシ統合を使用すると，Lambdaに送信されたリクエストはハンドラ関数のeventオブジェクトに代入される．プロキシ統合を使用しない場合，LambdaとAPI Gatewayの間のマッピングを手動で行う必要がある． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-lambda-integrations.html 設定項目 説明 統合タイプ Lambda関数を選択する． Lambdaプロキシ統合の使用 Lambdaとのプロキシ統合を有効化する． Lambdaリージョン 実行したLambda関数のリージョンを設定する． Lambda関数 実行したLambda関数の名前を設定する． 実行ロール 実行したいLambda関数へのアクセス権限がアタッチされたロールのARNを設定する．ただし，Lambda側にAPI Gatewayへのアクセス権限をアタッチしてもよい． 認証情報のキャッシュ デフォルトタイムアウトの使用 ・リクエスト時のマッピング API Gateway側でプロキシ統合を有効化すると，API Gatewayを経由したクライアントからのリクエストは，ハンドラ関数のeventオブジェクトのJSONデータにマッピングされる． { \"resource\": \"Resource path\", \"path\": \"Path parameter\", \"httpMethod\": \"Incoming request\"s method name\", \"headers\": {String containing incoming request headers}, \"multiValueHeaders\": {List of strings containing incoming request headers}, \"queryStringParameters\": {query string parameters }, \"multiValueQueryStringParameters\": {List of query string parameters}, \"pathParameters\": {path parameters}, \"stageVariables\": {Applicable stage variables}, \"requestContext\": {Request context, including authorizer-returned key-value pairs}, \"body\": \"A JSON string of the request payload.\", \"isBase64Encoded\": \"A boolean flag to indicate if the applicable request payload is Base64-encoded\" } ・レスポンス時のマッピング API Gatewayは，Lambdaからのレスポンスを，以下のJSONデータにマッピングする．これ以外の構造のJSONデータを送信すると，API Gatewayで『Internal Server Error』のエラーが起こる． { \"isBase64Encoded\": true|false, \"statusCode\": httpStatusCode, \"headers\": { \"headerName\": \"headerValue\", ... }, \"multiValueHeaders\": { \"headerName\": [\"headerValue\", \"headerValue2\", ...], ... }, \"body\": \"Hello Lambda\" } API Gatewayは上記のJSONデータを受信した後，bodyのみ値をレスポンスのメッセージボディに持たせ，クライアントに送信する． \"Hello Lambda\" ステージ ・設定 設定項目 説明 キャッシュ設定 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-caching.html デフォルトのメソッドスロットリング １秒当たりのリクエスト数制限を設定する．参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-request-throttling.html WAF 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/apigateway-control-access-aws-waf.html クライアント証明書 関連付けるWAFを設定する． ・ログ／分散トレース 設定項目 説明 CloudWatch設定 CloudWatchログにAPI Gatewayの実行ログを送信するかどうかを設定する．参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-logging.html カスタムアクセスのログ記録 CloudWatchログにAPI Gatewayのアクセスログを送信するかどうかを設定する．参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-logging.html X-Ray分散トレース 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/apigateway-xray.html ・ステージ変数 デプロイされるステージ固有の環境変数を設定できる．Lambda関数名，エンドポイントURL，パラメータマッピング，マッピングテンプレートで値を出力できる．以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/aws-api-gateway-stage-variables-reference.html ・SDKの生成 ・Canary 設定項目 説明 ステージのリクエストディストリビューション Canaryのデプロイ Canaryステージ変数 キャッシュ APIの設定 ・エンドポイントタイプ 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html 種類 説明 リージョン API Gatewayのエンドポイントへのリクエストを，リージョン内の物理サーバで受け付ける． プライベート API Gatewayのエンドポイントへのリクエストを，VPC内からのみ受け付ける． エッジ最適化 API Gatewayのエンドポイントへのリクエストを，CloudFrontのエッジサーバで受け付ける． 04. Auto Scaling Auto Scalingとは アプリケーションのメトリクスの閾値を基準として，自動水平スケーリングを自動的に実行する． 設定項目 ・起動設定 スケーリングの対象となるAWSリソースを定義する． ・スケーリンググループ スケーリングのグループ構成を定義する．各グループで最大最小必要数を設定できる． ・スケーリングポリシー スケーリングの方法を定義する． 種類 説明 補足 シンプルスケーリング 特定のメトリクスに単一の閾値を設定し，それに応じてスケーリングを行う． ステップスケーリング 特定のメトリクスに段階的な閾値を設定し，それに応じて段階的にスケーリングを実行する． （例）CPU平均使用率に段階的な閾値を設定する．・40%の時にインスタンスが１つスケールアウト・70%の時にインスタンスを２つスケールアウト・90%の時にインスタンスを３つスケールアウト ターゲット追跡スケーリング 特定のメトリクス（CPU平均使用率やMemory平均使用率）にターゲット値を設定し，それに収束するように自動的にスケールインとスケールアウトを実行する． ターゲット値を設定できるリソースの例・ECSサービスのタスク数・RDSクラスターのAuroraのリードレプリカ数・Lambdaのスクリプト同時実行数 05. Certificate Manager 設定項目 設定項目 説明 ドメイン名 認証をリクエストするドメイン名を設定する． 検証の方法 DNS検証かEmail検証かを設定する． 認証局 認証局であるATSによって認証されたSSLサーバ証明書を管理できる． 自社の中間認証局名 ルート認証局名 ATS：Amazon Trust Services Starfield社 ドメインの承認方法 ・DNS検証 CNAMEレコードランダムトークンを用いて，ドメイン名の所有者であることを証明する方法．ACMによって生成されたCNAMEレコードランダムトークンが提供されるので，これをRoute53に設定しておけば，ACMがこれを検証し，証明書を発行してくれる． 証明書 ・セキュリティポリシー 許可するプロトコルを定義したルールこと．SSL/TLSプロトコルを許可しており，対応できるバージョンが異なるため，ブラウザがそのバージョンのSSL/TLSプロトコルを使用できるかを認識しておく必要がある． Policy-2016-08 Policy-TLS-1-1 Policy-TLS-1-2 Protocol-TLSv1 〇 ✕ ✕ Protocol-TLSv1.1 〇 〇 ✕ Protocol-TLSv1.2 〇 〇 〇 ・SSLサーバ証明書の種類 DNS検証またはEメール検証によって，ドメイン名の所有者であることが証明されると，発行される．証明書は，PKIによる公開鍵検証に用いられる． 証明書の種類 説明 ワイルドカード証明書 証明するドメイン名にワイルドカードを用いたもの． ・SSLサーバ証明書の設置場所パターン AWSの使用上，ACM証明書を設置できないAWSリソースに対しては，外部の証明書を手に入れて設置する．HTTPSによるSSLプロトコルを受け付けるネットワークの最終地点のことを，SSLターミネーションという． パターン（Route53には必ず設置） SSLターミネーション（HTTPSの最終地点） 補足 Route53 → ALB(+ACM証明書) → EC2 ALB Route53 → CloudFront(+ACM証明書) → ALB(+ACM証明書) → EC2 ALB CloudFrontはバージニア北部で，またALBは東京リージョンで，証明書を構築する必要がある．CloudFrontに送信されたHTTPSリクエストをALBにルーティングするために，両方に関連付ける証明書で承認するドメインは，一致させる必要がある． Route53 → CloudFront(+ACM証明書) → EC2 CloudFront Route53 → CloudFront(+ACM証明書) → S3 CloudFront Route53 → ALB(+ACM証明書) → EC2(+外部証明書) EC2 Route53 → NLB → EC2(+外部証明書) EC2 Route53 → EC2(+外部証明書) EC2 Route53 → Lightsail(+ACM証明書) Lightsail 証明書の確認方法 ・ブラウザからの確認 Chromeを例に挙げると，SSLサーバ証明書はURLの鍵マークから確認できる． ＊例＊ CircleCIのサイトは，SSLサーバ証明書のためにACMを使用している． 06. Chatbot Chatbotとは SNSを経由して，CloudWatchからの通知をチャットアプリに転送するAWSリソース． 設定項目 ・slack通知の場合 クライアントをSlackとした場合の設定を以下に示す． 設定項目 説明 Slackチャンネル 通知の転送先のSlackチャンネルを設定する． アクセス許可 SNSを介して，CloudWatchにアクセスするためのロールを設定する． SNSトピック CloudWatchへのアクセス時経由する，SNSトピックを設定する． ・サポート対象のイベント AWSリソースのイベントを，EventBridge（CloudWatchイベント）を用いて，Chatbotに転送できるが，全てのAWSリソースをサポートしているわけではない．サポート対象のAWSリソースは以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/chatbot/latest/adminguide/related-services.html#cloudwatchevents ・インシデント ４大シグナルを含む，システム的に良くない事象のこと． ・オンコール インシデントを通知するようにし，通知を受けて対応すること． 08. CloudFront CloudFrontとは クラウドリバースプロキシサーバとして働く．VPCの外側（パブリックネットワーク）に設置されている．オリジンサーバ（コンテンツ提供元）をS3とした場合，動的コンテンツへのリクエストをEC2に振り分ける．また，静的コンテンツへのリクエストをCacheし，その上でS3へ振り分ける．次回以降の静的コンテンツのリンクエストは，CloudFrontがレンスポンスを行う． 設定項目 ・一覧 設定項目 説明 Distributions Reports & analytics Distributions ・Distributionsの詳細 参考になったサイト 設定項目 説明 補足 General Origin and Origin Groups コンテンツを提供するAWSリソースを設定する． Behavior オリジンにリクエストが行われた時のCloudFrontの挙動を設定する． ErrorPage 指定したオリジンから，指定したファイルのレスポンスを返信する． Restriction Invalidation CloudFrontに保存されているCacheを削除できる． ・Generalの詳細 設定項目 説明 補足 Price Class 使用するエッジロケーションを設定する． Asiaが含まれているものを選択． AWS WAF CloudFrontに紐づけるWAFを設定する． CNAME CloudFrontのデフォルトドメイン名（xxxxx.cloudfront.net.）に紐づけるRoute53レコード名を設定する． ・Route53からルーティングする場合は必須．・複数のレコード名を設定できる． SSL Certificate HTTPSプロトコルでオリジンに転送する場合に設定する． 上述のCNAMEを設定した場合，SSL証明書が別途必要になる．また，Certificate Managerを使用する場合，この証明書は『バージニア北部』で申請する必要がある． Security Policy リクエストの送信者が使用するSSL/TLSプロトコルや暗号化方式のバージョンに合わせて，CloudFrontが受信できるこれらのバージョンを設定する． ・リクエストの送信者には，ブラウザ，APIにリクエストを送信する外部サービス，転送元のAWSリソース，などを含む．・参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/secure-connections-supported-viewer-protocols-ciphers.html Default Root Object オリジンのドキュメントルートを設定する． ・何も設定しない場合，ドキュメントルートは指定されず，Behaviorで明示的にルーティングする必要がある．・index.htmlを設定すると，『/』でリクエストした時に，オリジンのルートディレクトリにあるindex,htmlファイルがドキュメントルートになる． Standard Logging CloudFrontのアクセスログをS3に生成するかどうかを設定する． ・Origin and Origin Groupsの詳細 設定項目 説明 補足 Origin Domain Name CloudFrontをリバースプロキシとして，AWSリソースのエンドポイントやDNSにルーティングする． ・例えば，S3のエンドポイント，ALBのDNS名を設定する．・別アカウントのAWSリソースのDNS名であってもよい． Origin Path オリジンのルートディレクトリを設定する． ・何も設定しないと，デフォルトは『/』のなる．Behaviorでは，『/』の後にパスが追加される．・『/var/www/app』を設定すると，Behaviorで設定したパスが『/var/www/app/xxxxx』のように追加される． Origin Access Identity リクエストの転送先となるAWSリソースでアクセス権限のアタッチが必要な場合に設定する．転送先のAWSリソースでは，アクセスポリシーをアタッチする． CloudFrontがS3に対して読み出しを行うために必要． Origin Protocol Policy リクエストの転送先となるAWSリソースに対して，HTTPとHTTPSのいずれのプロトコルで転送するかを設定する． ・ALBで必要．ALBのリスナーのプロトコルに合わせて設定する．・HTTP Only：HTTPで転送・HTTPS Only：HTTPSで転送・Match Viewer：両方で転送 HTTPポート 転送時に指定するオリジンのHTTPのポート番号 HTTPSポート 転送時に指定するオリジンのHTTPSのポート番号 ・Behaviorの詳細 何に基づいたCacheを行うかについては，★マークの項目で制御できる．★マークで，各項目の全て値が，過去のリクエストに合致した時のみ，そのリクエストと過去のものが同一であると見なす仕組みになっている．キャッシュ判定時のパターンを減らし，HIT率を改善するために，★マークで可能な限り『None』を選択した方が良い．最終的に，対象のファイルがCloudFrontのCacheの対象となっているかは，レスポンスのヘッダーに含まれる『X-Cache:』が『Hit from cloudfront』，『Miss from cloudfront』のどちらで，Cacheの使用の有無を判断できる．その他の改善方法は，以下リンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/cache-hit-ratio.html#cache-hit-ratio-query-string-parameters 設定項目 説明 補足 Precedence 処理の優先順位． 最初に構築したBehaviorが『Default (*)』となり，これは後から変更できないため，主要なBehaviorをまず最初に設定する． Path Pattern Behaviorを行うファイルパスを設定する． Origin or Origin Group Behaviorを行うオリジンを設定する． Viewer Protocol Policy HTTP／HTTPSのどちらを受信するか，またどのように変換して転送するかを設定 ・HTTP and HTTPS：両方受信し，そのまま転送・Redirect HTTP to HTTPS：両方受信し，HTTPSで転送・HTTPS Only：HTTPSのみ受信し，HTTPSで転送 Allowed HTTP Methods リクエストのHTTPメソッドのうち，オリジンへの転送を許可するものを設定 ・パスパターンが静的ファイルへのリクエストの場合，GETのみ許可．・パスパターンが動的ファイルへのリクエストの場合，全てのメソッドを許可． ★Cache Based on Selected Request Headers（★については表上部参考） リクエストヘッダーのうち，オリジンへの転送を許可し，またCacheの対象とするものを設定する． ・各ヘッダー転送の全拒否，一部許可，全許可を設定できる．・全拒否：全てのヘッダーの転送を拒否し，Cacheの対象としない．動的になりやすい値をもつヘッダー（Accept-Datetimeなど）を一切使用せずに，それ以外のクエリ文字やCookieでCacheを判定するようになるため，同一と見なすリクエストが増え，HIT率改善につながる．・一部転送：指定したヘッダーのみ転送を許可し，Cacheの対象とする．・全許可：全てのヘッダーがCacheの対象となる．しかし，日付に関するヘッダーなどの動的な値をCacheの対象としてしまうと．同一と見なすリクエストがほとんどなくなり，HITしなくなる．そのため，この設定でCacheは実質無効となり，『対象としない』に等しい． Whitelist Header Cache Based on Selected Request Headers を参考にせよ． ・Accept-xxxxx：アプリケーションにレスポンスして欲しいデータの種類（データ型など）を指定．・ CloudFront-Is-xxxxx-Viewer：デバイスタイプのBool値が格納されている． Object Caching CloudFrontにコンテンツのCacheを保存しておく秒数を設定する． ・Origin Cache ヘッダーを選択した場合，アプリケーションからのレスポンスヘッダーのCache-Controlの値が適用される．・カスタマイズを選択した場合，ブラウザのTTLとは別に設定できる． TTL CloudFrontにCacheを保存しておく秒数を詳細に設定する． ・Min，Max，Default，の全てを0秒とすると，Cacheを無効化できる．・『Cache Based on Selected Request Headers = All』としている場合，Cacheが実質無効となるため，最小TTLはゼロでなければならない． ★Farward Cookies（★については表上部参考） Cookie情報のキー名のうち，オリジンへの転送を許可し，Cacheの対象とするものを設定する． ・Cookie情報キー名転送の全拒否，一部許可，全許可を設定できる．・全拒否：全てのCookieの転送を拒否し，Cacheの対象としない．Cookieはユーザごとに一意になることが多く，動的であるが，それ以外のヘッダーやクエリ文字でCacheを判定するようになるため，同一と見なすリクエストが増え，HIT率改善につながる．・リクエストのヘッダーに含まれるCookie情報（キー名／値）が変動していると，CloudFrontに保存されたCacheがHITしない．CloudFrontはキー名／値を保持するため，変化しやすいキー名／値は，オリジンに転送しないように設定する．例えば，GoogleAnalyticsのキー名（_ga）の値は，ブラウザによって異なるため，１ユーザがブラウザを変えるたびに，異なるCacheが生成されることになる．そのため，ユーザを一意に判定することが難しくなってしまう．GoogleAnalyticsのキーはブラウザからAjaxでGoogleに送信されるもので，オリジンにとっても基本的に不要である．・セッションIDはCookieヘッダーに設定されているため，フォーム送信に関わるパスパターンでは，セッションIDのキー名を許可する必要がある． ★Query String Forwarding and Caching（★については表上部参考） クエリストリングのうち，オリジンへの転送を許可し，Cacheの対象とするものを設定する． ・クエリストリング転送とCacheの，全拒否，一部許可，全許可を選択できる．全拒否にすると，Webサイトにクエリストリングをリクエストできなくなるので注意．・異なるクエリパラメータを，別々のCacheとして保存するかどうかを設定できる． Restrict Viewer Access リクエストの送信元を制限するかどうかを設定できる． セキュリティグループで制御できるため，ここでは設定しなくてよい． Compress Objects Automatically レスポンス時にgzipを圧縮するかどうかを設定 ・クライアントからのリクエストヘッダーのAccept-Encodingにgzipが設定されている場合，レスポンス時に，gzip形式で圧縮して送信するかどうかを設定する．設定しない場合，圧縮せずにレスポンスを送信する．・クライアント側のダウンロード速度向上のため，基本的には有効化する． ・Invalidation TTL秒によるCacheの自動削除を待たずに，手動でCacheを削除できる．全てのファイルのCacheを削除したい場合は『/*』，特定のファイルのCacheを削除したい場合は『/』，を指定する．CloudFrontに関するエラーページが表示された場合，不具合を修正した後でもCacheが残っていると，エラーページが表示されてしまうため，作業後には必ずCacheを削除する． ・オリジンに対するリクエストメッセージの構造 CloudFrontからオリジンに送信されるリクエストメッセージの構造例を以下に示す． GET /foo/ # リクエストされたドメイン名 Host: foo.com User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1 Authorization: Bearer X-Amz-Cf-Id: XXXXX Via: 2.0 77c20654dd474081d033f27ad1b56e1e.cloudfront.net (CloudFront) # 各Cookieの値（二回目のリクエスト時に設定される） Cookie: sessionid=; __ulfpc=; _ga=; _gid= # 送信元IPアドレス # ※プロキシサーバ（ALBやCloudFrontなども含む）を経由している場合，それら全てのIPアドレスも順に設定される X-Forwarded-For: , , Accept-Language: ja,en;q=0.9 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate, br pragma: no-cache cache-control: no-cache upgrade-insecure-requests: 1 sec-fetch-site: none sec-fetch-mode: navigate sec-fetch-user: ?1 sec-fetch-dest: document # デバイスタイプ CloudFront-Is-Mobile-Viewer: true CloudFront-Is-Tablet-Viewer: false CloudFront-Is-SmartTV-Viewer: false CloudFront-Is-Desktop-Viewer: false # リクエストの送信元の国名 CloudFront-Viewer-Country: JP # リクエストのプロトコル CloudFront-Forwarded-Proto: https ・CloudFrontとオリジン間のHTTPS通信 CloudFrontとオリジン間でHTTPS通信を行う場合，両方にドメイン証明書を割り当てる必要がある．割り当てたとしても，以下の条件を満たさないとHTTPS通信を行うことはできない．CLoudFronからオリジンにHostヘッダーを転送しない設定の場合，オリジンが返却する証明書に『Origin Domain Name』と一致するドメイン名が含まれている必要がある．一方で，Hostヘッダーを転送しない場合，オリジンが返却する証明書に『Origin Domain Name』と一致するドメイン名が含まれているか，またはオリジンが返却する証明書に，Hostヘッダーの値と一致するドメイン名が含まれている必要がある． ・キャッシュの時間の決まり方 キャッシュの時間は，リクエストヘッダー（Cache-Control，Expires）の値とCloudFrontの設定（最大最小デフォルトTTL）の組み合わせによって決まる．ちなみに，CloudFrontの最大最小デフォルトTTLを全て０秒にすると，キャッシュを完全に無効化できる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#ExpirationDownloadDist Reports & analytics ・Cache statistics リクエストに関連する様々なデータを，日付別に集計したものを確認できる． ・Popular objects リクエストに関連する様々なデータを，オブジェクト別に集計したものを確認できる． エッジロケーションとエッジサーバ ・Point Of Presence CloudFrontは世界中に設置される『Point Of Presence（エッジロケーション＋中間層キャッシュ）』にデプロイされる． 参考：https://aws.amazon.com/jp/cloudfront/features/?whats-new-cloudfront.sort-by=item.additionalFields.postDateTime&whats-new-cloudfront.sort-order=desc ・エッジロケーションにおける全エッジサーバのIPアドレス CloudFrontには，エッジロケーションの数だけエッジサーバがあり，各サーバにIPアドレスが割り当てられている．以下のコマンドで，全てのエッジサーバのIPアドレスを確認できる． $ curl https://ip-ranges.amazonaws.com/ip-ranges.json | jq \".prefixes[] | select(.service==\"CLOUDFRONT\") | .ip_prefix\" もしくは，以下のリンクを直接参考し，『\"service\": \"CLOUDFRONT\"』となっている部分を探す． 参考：https://ip-ranges.amazonaws.com/ip-ranges.json ・エッジロケーションの使用中サーバのIPアドレス CloudFrontには，エッジロケーションがあり，各ロケーションにサーバがある．以下のコマンドで，エッジロケーションにある使用中サーバのIPアドレスを確認できる． $ nslookup .cloudfront.net カスタムエラーページ ・カスタムエラーページとは オリジンに該当のファイルが存在しない場合，オリジンはCloudFrontに以下の403ステータスのレスポンスを返信する．カスタムエラーページを設定しない場合，CloudFrontはこの403ステータスをそのままレスポンスしてしまうため，オリジンに配置したカスタムエラーページを404ステータスでレスポンスするように設定する． This XML file does not appear to have any style information associated with it. The document tree is shown below. AccessDenied Access Denied ***** ***** ・設定方法 オリジンからカスタムエラーページをレスポンスするパスパターンを定義する．Lamnda@Edgeを使用したCloudFrontの場合は，Lambda@Edgeを経由して，カスタムエラーページをレスポンスする必要がある． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/HTTPStatusCodes.html 07. CloudTrail CloudTrailとは IAMユーザによる操作や，ロールのアタッチの履歴を記録し，ログファイルとしてS3に転送する．CloudWatchと連携することもできる． 08. CloudWatch 監視と可観測性 ・監視の種類 監視は以下の種類に大別される． 種類 説明 外部監視 アプリケーション外部からの死活監視．アプリケーションにリクエストを送信し，レスポンスに関して，あらゆる情報を監視する． 内部監視 アプリケーション内部からの死活監視．アプリケーションのレスポンスからはわからないあらゆる情報を監視する． 合成監視 プログラムを使用して，実際のユーザを模したリクエストをアプリケーションに送信し，外部監視と内部監視を実行する． ・可観測性 メトリクス，ログ，分散トレースの３要素からなる開発運用手法のこと．NewRelicやDatadogが可観測性を実現できる．また，AWSではCloudWatch（メトリクス＋ログ）とX-Ray（分散トレース）を両方利用すると，これらの要素を満たせたことになり，可観測性を実現できる． 種類 説明 補足 メトリクス ログ 分散トレース マイクロサービスの各コンポーネントでイベントが発生した時，一連のイベントを因果関係として繋げたデータセットのこと． ・４大シグナル 種類 説明 レイテンシー 以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_internet.html トラフィック 以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_internet.html エラー 以下の２種類に分類できる．・明示的エラー：400/500系のレスポンス・暗黙的エラー：SLOに満たない200/300系のレスポンス，API仕様に合っていないレスポンス サチュレーション システムの利用率の飽和度のこと．例えば，以下の飽和度がある．60～70%で，警告ラインを設けておく必要がある．・CPU利用率・メモリ利用率・ストレージ利用率 ・SLI，SLO，エラーバジェット 項目 説明 SLI：Service Level Indicator（サービスレベル指標） サービスレベルの指標とするメトリクスのこと．・サーバ稼働率・データベース稼働率・レイテンシー・レスポンスタイム・レスポンスのステータスコード率・スループットなどが採用される． SLO：Service Level Objective（サービスレベル目標） SLIとして採用した指標の目標値のこと．99.9%の成功率を目標とすることが多い．・サーバ稼働率（日当たり0.1%のダウンタイム）・データベース稼働率（日当たり0.1%のダウンタイム）・レイテンシー（日当たり0.1%までのレイテンシー）・レスポンスのステータスコード率（日当たり99.9%の200ステータスコード・スループット（日当たり0.1%のスループット低下） エラーバジェット SLOが未達の場合は，新規リリースよりもSLOの達成を優先する． CloudWatchメトリクス ・CloudWatchメトリクスとは 使用しているAWSリソースの状態をメトリクス化し，内部監視できる． ・名前空間，メトリクス，ディメンションとは データ収集の対象とする領域のこと． CloudWatchメトリクス上では，以下のように確認できる． ・SLIに関連するメトリクス 指標 関連するメトリクス 補足 サーバ稼働率 ECS・RunningTaskCount ターゲット追跡スケーリングポリシーのECSサービスメトリクスも参考にせよ． データベース稼働率 RDS：・CPUUtilization・FreeableMemory レイテンシー API Gateway：・Latency・IntegrationLatency レスポンスのステータスコード率 ALB：・HTTPCode_ELB_4XX_Count・HTTPCode_ELB_5XX_Count・HTTPCode_TARGET_4XX_Count・HTTPCode_TARGET_5XX_Count・RejectedConnectionCount・HealthyHostCount・TargetConnectionErrorCount・TargetTLSNegotiationErrorCountAPI Gateway：・4XXError・5XXError ・パフォーマンスに関するメトリクス 種類 名前 補足 RDS パフォーマンスインサイト RDSのパフォーマンスに関するメトリクスを収集し，SQLレベルで監視できるようになる．パラメータグループのperformance_schemaを有効化する必要がある．対応するエンジンバージョンとインスタンスタイプについては，以下のリンクを参考にせよ．参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_PerfInsights.Overview.Engines.htm ECS／EKS Container インサイト ECS／EKSのパフォーマンスに関するメトリクスを収集し，ECS／EKSのクラスター，サービス，タスク，インスタンス，単位で監視できるようになる．また，コンテナ間の繋がりをコンテナマップで視覚化できるようになる．ECS／EKSのアカウント設定でContainerインサイトを有効化する必要がある． Lambda Lambdaインサイト Lambdaのパフォーマンスに関するメトリクスを収集できるようになる． CloudWatch Synthetics ・CloudWatch Syntheticsとは 合成監視を行えるようになる． CloudWatchログ ・設定項目 クラウドログサーバとして働く．様々なAWSリソースで生成されたログファイルを収集できる． 設定項目 説明 補足 ロググループ ログストリームをグループ化して収集するかどうかを設定する． 基本的に，ログファイルはグループ化せずに，一つのロググループには一つのログストリームしか含まれないようにする． メトリクスフィルター 紐づくロググループで，出現を監視する文字列を設定する． サブスクリプションフィルター Logsインサイト クエリを使用してログを抽出する． ・メトリクスフィルターの詳細 設定項目 説明 補足 フィルターパターン 紐づくロググループで，メトリクス値増加のトリガーとする文字列を設定する． 大文字と小文字を区別するため，網羅的に設定する必要がある． 名前空間 紐づくロググループが属する名前空間を設定する．CloudWatchログが，設定した名前空間に対して，値を発行する． メトリクス 紐づくロググループが属する名前空間内のメトリクスを設定する．CloudWatchログが，設定したメトリクスに対して，値を発行する． メトリクス値 フィルターパターンで文字列が検出された時に，メトリクスに対して発行する値のこと． 例えば『検出数』を発行する場合は，『１』を設定する． ・フィルターパターンのテンプレート # OR条件で大文字小文字を考慮し，『XXXXX:』を検出 ?\"WARNING:\" ?\"Warning:\" ?\"ERROR:\" ?\"Error:\" ?\"CRITICAL:\" ?\"Critical:\" ?\"EMERGENCY:\" ?\"Emergency:\" ?\"ALERT:\" ?\"Alert:\" # OR条件で大文字小文字を考慮し，『XXXXX message』を検出 ?\"WARNING message\" ?\"Warning message\" ?\"ERROR message\" ?\"Error message\" ?\"CRITICAL message\" ?\"Critical message\" ?\"EMERGENCY message\" ?\"Emergency message\" ?\"ALERT message\" ?\"Alert message\" ・Logインサイト 汎用的なクエリを示す． # 小文字と大文字を区別せずに，ExceptionまたはErrorを含むログを検索する． fields @timestamp, @message, @logStream | filter @message like /(?i)(Exception|Error)/ | sort @timestamp desc | limit 100 CloudWatchエージェント ・CloudWatchエージェントとは インスタンス内で稼働する常駐システムのこと．インスタンス内のデータを収集し，CloudWatchに対して送信する． ・CloudWatchエージェントの設定 セクションの種類 説明 補足 agentセクション CloudWatchエージェント全体を設定する． ・ウィザードを使用した場合，このセクションの設定はスキップされる．・実装しなかった場合，デフォルト値が適用される． metricsセクション ・ウィザードを使用した場合，このセクションの設定はスキップされる．・実装しなかった場合，何も設定されない． logsセクション CloudWatchエージェントは，/opt/aws/amazon-cloudwatch-agent/bin/config.jsonファイルの定義を元に，実行される．設定ファイルは分割できる．設定後，amazon-cloudwatch-agent-ctlコマンドで設定ファイルを読み込ませる．CloudWatchエージェントを使用して，CloudWatchにログファイルを送信するだけであれば，設定ファイル（/opt/aws/amazon-cloudwatch-agent/bin/config.json）にはlogセッションのみの実装で良い．run_as_userには，プロセスのユーザ名（例：cwagent）を設定する． ＊実装例＊ { \"agent\": { \"run_as_user\": \"cwagent\" }, \"logs\": { \"logs_collected\": { \"files\": { \"collect_list\": [ { \"file_path\": \"/var/log/nginx/error.log\", \"log_group_name\": \"/foo-www/var/log/nginx/error_log\", \"log_stream_name\": \"{instance_id}\" }, { \"file_path\": \"/var/log/php-fpm/error.log\", \"log_group_name\": \"/foo-www/var/log/php-fpm/error_log\", \"log_stream_name\": \"{instance_id}\" } ] } } } } ・ログ送信権限 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html ・操作コマンド ＊コマンド例＊ # EC2内にある設定ファイルを，CloudWatchエージェントに読み込ませる（再起動を含む） $ /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \\ -a fetch-config \\ -m ec2 \\ -s \\ -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json # プロセスのステータスを確認 $ /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \\ -m ec2 \\ -a status # 設定ファイルが読み込まれたかを確認 ### CloudWatchエージェントのプロセスのログファイル $ tail -f /opt/aws/amazon-cloudwatch-agent/logs/amazon-cloudwatch-agent.log ### 設定ファイルの構文チェックのログファイル $ tail -f /opt/aws/amazon-cloudwatch-agent/logs/configuration-validation.log ### OS起動時にデーモンが稼働するように設定されているかを確認 $ systemctl list-unit-files --type=service CloudWatchログエージェント ・CloudWatchログエージェントとは（非推奨） インスタンス内で稼働する常駐システムのこと．インスタンス内のデータを収集し，CloudWatchログに対して送信する．2020/10/05現在は非推奨で，CloudWatchエージェントへの設定の移行が推奨されている． ・CloudWatchログエージェントの設定 confファイルを，インスタンス内のetcディレクトリ下に設置する．OS，ミドルウェア，アプリケーション，の各層でログを収集するのがよい． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/logs/AgentReference.html#agent-configuration-file ＊実装例＊ ############################# # /var/awslogs/awslogs.conf ############################# # ------------------------------------------ # CentOS CloudWatch Logs # ------------------------------------------ [/var/log/messages] # タイムスタンプ #（例）Jan 1 00:00:00 datetime_format = %b %d %H:%M:%S #（例）2020-01-01 00:00:00 # datetime_format = %Y-%m-%d %H:%M:%S # 収集したいログファイル．ここでは，CentOSのログを指定する． file = /var/log/messages # 文字コードutf_8として送信する．文字コードが合わないと，CloudWatchログの画面上で文字化けする． encoding = utf_8 # 要勉強 buffer_duration = 5000 initial_position = start_of_file # インスタンスID log_stream_name = {instance_id} # AWS上で管理するロググループ名 log_group_name = /var/log/messages # ------------------------------------------ # Nginx CloudWatch Logs # ------------------------------------------ [/var/log/nginx/error.log] file = /var/log/nginx/error.log buffer_duration = 5000 log_stream_name = {instance_id} initial_position = start_of_file log_group_name = /var/log/nginx/error_log.production # ------------------------------------------ # Application CloudWatch Logs # ------------------------------------------ [/var/www/project/app/storage/logs/laravel.log] file = /var/www/project/app/storage/logs/laravel.log buffer_duration = 5000 log_stream_name = {instance_id} initial_position = start_of_file log_group_name = /var/www/project/app/storage/logs/laravel_log.production ############################# # /var/awslogs/awscli.conf ############################# [plugins] cwlogs = cwlogs [default] region = ap-northeast-1 ・操作コマンド 設定後，awslogsコマンドでプロセスを起動する． ＊コマンド例＊ # CloudWatchエージェントの再起動 # 注意: restartだとCloudWatchに反映されない時がある． $ service awslogs restart # もしくは $ service awslogs stop $ service awslogs start # ログが新しく生成されないと変更が適用されないことがあるため，ログファイルに適当な文字列行を増やしてみる． CLI ・メトリクス収集量を確認 ＊コマンド例＊ 全てのロググループに対して，一日当たりのメトリクス収集量をstart-timeからend-timeの間で取得する．--dimensionsオプションを使用して，特定のディメンション（ロググループ）に対して集計を実行することもできる．（ただ，やってみたけどうまくいかず） 参考：https://docs.aws.amazon.com/cli/latest/reference/cloudwatch/get-metric-statistics.html $ aws cloudwatch get-metric-statistics \\ --namespace AWS/Logs \\ --metric-name IncomingBytes \\ --start-time 2021-08-01T00:00:00 \\ --end-time 2021-08-31T23:59:59 \\ --period 86400 --statistics Sum | jq -r \".Datapoints[] | [.Timestamp, .Sum] | @csv\" | sort ・CloudWatchアラームの状態変更 ＊コマンド例＊ CloudWatchアラームの状態を変更する． $ aws cloudwatch set-alarm-state \\ --alarm-name \"prd-foo-alarm\" \\ --state-value ALARM \\ --state-reason \"アラーム!!\" 09. Code系サービス CodePipeline ・CodePipelineとは CodeCommit，CodeBuild，CodeDeployを連携させて，AWSに対するCI/CD環境を構築する．CodeCommitは，他のソースコード管理サービスで代用できる． ・CodeCommitとは ソースコードをバージョン管理する． ・CodeBuildとは ビルドフェーズとテストフェーズを実行する． ・CodeDeployとは デプロイフェーズを実行する． CodeBuild ・buildspec.ymlファイル CodeBuildの設定を行う．ルートディレクトリの直下に配置しておく． 参考：https://docs.aws.amazon.com/ja_jp/codebuild/latest/userguide/build-spec-ref.html version: 0.2 phases: install: runtime-versions: docker: 18 preBuild: commands: # ECRにログイン - $(aws ecr get-login --no-include-email --region ${AWS_DEFAULT_REGION}) # イメージタグはGitHubコミットのハッシュ値を使用 - IMAGE_TAG=$CODEBUILD_RESOLVED_SOURCE_VERSION # ECRのURLをCodeBuildの環境変数から作成 - REPOSITORY_URI=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${IMAGE_REPO_NAME} build: commands: # タグ付けしてイメージをビルド - docker build -t REPOSITORY_URI:$IMAGE_TAG -f Dockerfile . postBuild: commands: # ECRにイメージをプッシュ - docker push $REPOSITORY_URI:$IMAGE_TAG # ECRにあるデプロイ対象のイメージの情報（imageDetail.json） - printf \"{\"Version\":\"1.0\",\"ImageURI\":\"%s\"}\" $REPOSITORY_URI:$IMAGE_TAG > imageDetail.json # デプロイ対象とするビルドのアーティファクト artifacts: files: imageDetail.json ・ビルド時に作成すべきデプロイ設定ファイル デプロイ対象となるイメージを定義するために，標準デプロイアクションの場合にはimagedefinitions.jsonファイル，またはBlue/Greenデプロイメントの場合にはimageDetail.jsonファイルを用意する必要がある．これはリポジトリに事前に配置するのではなく，ビルド時に自動的に作成するようにした方がよい． 参考：https://docs.aws.amazon.com/ja_jp/codepipeline/latest/userguide/file-reference.html CodeDeployによるBlue/Greenデプロイメント ・Blue/Greenデプロイメントとは 以下の手順でデプロイを行う． ECRのイメージを更新 タスク定義の新しいリビジョンを構築． サービスを更新． CodeDeployによって，タスク定義を基に，現行の本番環境（Prodブルー）のタスクとは別に，テスト環境（Testグリーン）が構築される．ロードバランサーの接続先を，本番環境（Prodブルー）のターゲットグループ（Primaryターゲットグループ）に加えて，テスト環境（Testグリーン）にも向ける． 社内からテスト環境（Testグリーン）のALBに，特定のポート番号でアクセスし，動作を確認する． 動作確認で問題なければ，Console画面からの入力で，ロードバランサーの接続先をテスト環境（Testグリーン）のみに設定する． テスト環境（Testグリーン）が新しい本番環境としてユーザに公開される． 元々の本番環境（Prodブルー）は削除される． ・appspec.ymlファイル CodeDeployの設定を行う．ルートディレクトリの直下に配置しておく．仕様として，複数のコンテナをデプロイできない．タスク定義名をとすると，自動補完してくれる． 参考：https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-resources.html version: 0.0 Resources: - TargetService: # 使用するAWSリソース Type: AWS::ECS::Service Properties: # 使用するタスク定義 TaskDefinition: \"\" # 使用するロードバランサー LoadBalancerInfo: ContainerName: \"\" ContainerPort: \"80\" PlatformVersion: \"1.4.0\" ・taskdef.jsonファイル デプロイされるタスク定義を実装し，ルートディレクトリの直下に配置する．CodeDeployは，CodeBuildから渡されたimageDetail.jsonファイルを検知し，ECRからイメージを取得する．この時，taskdef.jsonファイルのイメージ名をとしておくと，ECRから取得したイメージ名を使用して，自動補完してくれる． { \"family\": \"\", \"requiresCompatibilities\": [ \"FARGATE\" ], \"networkMode\": \"awsvpc\", \"taskRoleArn\": \"\", \"executionRoleArn\": \"\", \"cpu\": \"512\", \"memory\": \"1024\", \"containerDefinitions\": [ { \"name\": \"\", \"image\": \"\", \"essential\": true, \"portMappings\": [ { \"containerPort\": 80, \"hostPort\": 80, \"protocol\": \"tcp\" } ], \"secrets\": [ { \"name\": \"DB_HOST\", \"valueFrom\": \"/ecs/DB_HOST\" }, { \"name\": \"DB_DATABASE\", \"valueFrom\": \"/ecs/DB_DATABASE\" }, { \"name\": \"DB_PASSWORD\", \"valueFrom\": \"/ecs/DB_PASSWORD\" }, { \"name\": \"DB_USERNAME\", \"valueFrom\": \"/ecs/DB_USERNAME\" }, { \"name\": \"REDIS_HOST\", \"valueFrom\": \"/ecs/REDIS_HOST\" }, { \"name\": \"REDIS_PASSWORD\", \"valueFrom\": \"/ecs/REDIS_PASSWORD\" }, { \"name\": \"REDIS_PORT\", \"valueFrom\": \"/ecs/REDIS_PORT\" } ], \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"\", # スタックトレースのログを紐付けられるように，日付で区切るようにする． \"awslogs-datetime-format\": \"\\\\[%Y-%m-%d %H:%M:%S\\\\]\", \"awslogs-region\": \"\", \"awslogs-stream-prefix\": \"\" } } } ] } CodeDeployによるインプレースデプロイメント 10. EBS：Elastic Block Storage EBSとは クラウド内蔵ストレージとして働く． 設定項目 ・ストレージの種類とボリュームタイプ ストレージの種類 ボリューム名 SSD 汎用SSD SSD プロビジョンド IOPS SSD HDD スループット最適化 HDD HDD Cold HDD ・最小ボリューム 踏み台サーバを構築する時，できるだけ最小限のボリュームを選択し，ストレージ合計を抑える必要がある． OS 仮想メモリ ボリュームサイズ Amazon Linux t2.micro 8 CentOS t2.micro 10 11. EC2：Elastic Computer Cloud EC2とは クラウドサーバとして働く．注意点があるものだけまとめる．ベストプラクティスについては，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/ec2-best-practices.html 設定項目 ・一覧 設定項目 説明 補足 AMI：Amazonマシンイメージ OSを選択する． ベンダー公式のものを選択すること．（例：CentOSのAMI一覧 https://wiki.centos.org/Cloud/AWS） インスタンスの詳細設定 EC2インスタンスの設定する． ・インスタンス自動割り当てパブリックにて，EC2に動的パブリックIPを割り当てる．EC2インスタンス構築後に有効にできない．・終了保護は必ず有効にすること． ストレージの追加 EBSボリュームを設定する． 一般的なアプリケーションであれば，20～30GiBでよい．踏み台サーバの場合，最低限で良いため，OSの下限までサイズを下げる．（例：AmazonLinuxの下限は8GiB，CentOSは10GiB） キーペア EC2の秘密鍵に対応した公開鍵をインストールできる． キーペアに割り当てられるフィンガープリント値を調べることで，公開鍵と秘密鍵の対応関係を調べることができる． インスタンスのダウンタイム ・ダウンタイムの発生条件 以下の条件の時にEC2にダウンタイムが発生する．EC2を冗長化している場合は，ユーザに影響を与えずに対処できる．ダウンタイムが発生する方のインスタンスを事前にALBのターゲットグループから解除しておき，停止したインスタンスが起動した後に，ターゲットグループに再登録する． 変更する項目 ダウンタイムの有無 補足 インスタンスタイプ あり インスタンスタイプを変更するためにはEC2を停止する必要がある．そのため，ダウンタイムが発生する． ホスト物理サーバのリタイアメント あり AWSから定期的にリタイアメントに関する警告メールが届く．ルートデバイスタイプが『EBS』の場合，ホスト物理サーバの引っ越しを行うためにEC2の停止と起動が必要である．そのため，ダウンタイムが発生する．なお，再起動では引っ越しできない． スペック ・インスタンスタイプ 『世代』と『大きさ』からなる名前で構成される．世代の数字が上がるにつれて，より小さな世代と同じ大きさであっても，パフォーマンスと低コストになる．AMIのOSのバージョンによっては，新しく登場したインスタンスタイプを適用できないことがあるため注意する．例えば，CentOS 6系のAMIでは，t3.smallを選択できない． 参考：https://aws.amazon.com/marketplace/pp/prodview-gkh3rqhqbgzme?ref=cns_srchrow 種類 世代 t2，t3，t3a，t4g，a1 大きさ nano，small，medium，large，xlarge，2xlarge ・ストレージ EBSの説明を参考にせよ． ・CPUバーストモード バーストモードのインスタンスタイプの場合，一定水準のベースラインCPU使用率を提供しつつ，これを超過できる．CPU使用率がベースラインを超えたとき，超過した分だけEC2はCPUクレジットを消費する．CPUクレジットは一定の割合で回復する．蓄積できる最大CPUクレジット，クレジットの回復率，ベースラインCPU使用率は，インスタンスタイプによって異なる．詳しくは以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/burstable-performance-instances.html キーペア ・キーペアのフィンガープリント値 ローカルに置かれている秘密鍵が，該当するEC2に置かれている公開鍵とペアなのかどうか，フィンガープリント値を照合して確認する方法 $ openssl pkcs8 \\ -in .pem \\ -inform PEM \\ -outform DER \\ -topk8 \\ -nocrypt | openssl sha1 -c ・EC2へのSSH接続 クライアントのSSHプロトコルもつパケットは，まずインターネットを経由して，インターネットゲートウェイを通過する．その後，Route53，ALBを経由せず，そのままEC2へ向かう． 12. ECR ECRとは AWSが提供するDockerイメージのレジストリサービス 設定項目 ・設定項目 設定項目 説明 補足 可視性 リポジトリをパブリックアクセス／プライベートアクセスにするかを設定する． 様々なベンダーがパブリックリポジトリでECRイメージを提供している．参考：https://gallery.ecr.aws/ タグのイミュータビリティ 同じタグ名でイメージがプッシュされた場合に，イメージタグを上書き可能／不可能かを設定できる． プッシュ時にスキャン イメージがプッシュされた時に，イメージにインストールされているライブラリの脆弱性を検証し，一覧表示する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECR/latest/userguide/image-scanning.html 暗号化設定 ライフサイクル ・ライフサイクルポリシー ECRのイメージの有効期間を定義できる． 設定項目 説明 補足 ルールの優先順位 順位の大きさで，ルールの優先度を設定できる． 数字は連続している必要はなく，例えば，10，20，90，のように設定しても良い． イメージのステータス ルールを適用するイメージの条件として，タグの有無や文字列を設定できる． 一致条件 イメージの有効期間として，同条件に当てはまるイメージが削除される閾値を設定できる． 個数，プッシュされてからの期間，などを閾値として設定できる． イメージタグ ・タグ名のベストプラクティス Dockerのベストプラクティスに則り，タグ名にlatestを使用しないようにする．その代わりに，イメージのバージョンごとに異なるタグ名になるようハッシュ値（例：GitHubのコミットID）を使用する． 参考：https://matsuand.github.io/docs.docker.jp.onthefly/develop/dev-best-practices/ 13-01. ECS ECSとは コンテナオーケストレーションを実行する環境を提供する．VPCの外に存在している．ECS，EKS，Fargate，EC2の対応関係は以下の通り． Control Plane（コンテナオーケストレーション環境） Data Plane（コンテナ実行環境） 説明 ECS：Elastic Container Service Fargate，EC2 単一のOS上でコンテナオーケストレーションを実行する． EKS：Elastic Kubernetes Service EC2 複数のOS上それぞれでコンテナオーケストレーションを実行する． 13-02. ECS on EC2 EC2起動タイプのコンテナ ・タスク配置戦略 タスクをインスタンスに配置する時のアルゴリズムを選択できる． 戦略 説明 Spread タスクを各場所にバランスよく配置する Binpack タスクを一つの場所にできるだけ多く配置する． Random タスクをランダムに配置する． 13-03. ECS on Fargate：Elastic Container Service クラスター ・クラスターとは サービス ・サービスとは タスク数の維持管理や，タスクへのロードバランシング，リリースの成否の管理を行う機能のこと． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/service_definition_parameters.html 設定項目 説明 補足 タスク定義 サービスで維持管理するタスクの定義ファミリー名とリビジョン番号を設定する． 起動タイプ タスク内のコンテナの起動タイプを設定する． プラットフォームのバージョン タスクの実行環境のバージョンを設定する． バージョンによって，連携できるAWSリソースが異なる． サービスタイプ タスクの必要数 非スケーリング時またはデプロイ時のタスク数を設定する． 最小ヘルス率と最大率の設定値に影響する． 最小ヘルス率 タスクの必要数の設定を100%とし，新しいタスクのデプロイ時に，稼働中タスクの最低合計数を割合で設定する． 例として，タスク必要数が４個だと仮定する．タスクヘルス最小率を50%とすれば，稼働中タスクの最低合計数は２個となる．デプロイ時の既存タスク停止と新タスク起動では，稼働中の既存タスク／新タスクの数が最低合計数未満にならないように制御される．参考：https://toris.io/2021/04/speeding-up-amazon-ecs-container-deployments 最大率 タスクの必要数の設定を100%とし，新しいタスクのデプロイ時に，稼働中／停止中タスクの最高合計数を割合で設定する． 例として，タスク必要数が４個だと仮定する．タスク最大率を200%とすれば，稼働中／停止中タスクの最高合計数は８個となる．デプロイ時の既存タスク停止と新タスク起動では，稼働中／停止中の既存タスク／新タスクの数が最高合計数を超過しないように制御される．参考：https://toris.io/2021/04/speeding-up-amazon-ecs-container-deployments ヘルスチェックの猶予期間 デプロイ時のALB／NLBのヘルスチェックの状態を確認するまでの待機時間を設定する．猶予期間を過ぎても，ALB／NLBのヘルスチェックが失敗していれば，サービスはタスクを停止し，新しいタスクを再起動する． ALB／NLBではターゲットを登録し，ヘルスチェックを実行するプロセスがある．特にNLBでは，これに時間がかかる．またアプリケーションによっては，コンテナの構築に時間がかかる．そのため，NLBのヘルスチェックが完了する前に，ECSサービスがNLBのヘルスチェックの結果を確認してしまうことがある．例えば，NLBとLaravelを使用する場合は，ターゲット登録とLaravelコンテナの築の時間を加味して，330秒以上を目安とする．例えば，ALBとNuxtjs（SSRモード）を使用する場合は，600秒以上を目安とする．なお，アプリケーションのコンテナ構築にかかる時間は，ローカル環境での所要時間を参考にする． タスクの最小数 スケーリング時のタスク数の最小数を設定する． タスクの最大数 スケーリング時のタスク数の最大数を設定する． ロードバランシング ALBでルーティングするコンテナを設定する． タスクの数 タスクの構築数をいくつに維持するかを設定する． タスクが何らかの原因で停止した場合，空いているAWSサービスを使用して，タスクが自動的に補填される． デプロイメント ローリングアップデート，Blue/Greenデプロイがある． ・ターゲット追跡スケーリングポリシー 設定項目 説明 補足 ターゲット追跡スケーリングポリシー 監視対象のメトリクスがターゲット値を超過しているか否かに基づいて，タスク数のスケーリングが実行される． ECSサービスメトリクス 監視対象のメトリクスを設定する． 『平均CPU』，『平均メモリ』，『タスク当たりのALBからのリクエスト数』を監視できる．SLIに対応するCloudWatchメトリクスも参考にせよ． ターゲット値 タスク数のスケーリングが実行される収束値を設定する． ターゲット値を超過している場合，タスク数がスケールアウトされる．反対に，ターゲット値未満（正確にはターゲット値の９割未満）の場合，タスク数がスケールインされる． スケールアウトクールダウン期間 スケールアウトを発動してから，次回のスケールアウトを発動できるまでの時間を設定する． ・期間を短くし過ぎると，ターゲット値を超過する状態が断続的に続いた場合に，余分なスケールアウトが連続して実行されてしまうため注意する．・期間を長く過ぎると，スケールアウトが不十分になり，ECSの負荷が緩和されないため注意する． スケールインクールダウン期間 スケールインを発動してから，次回のスケールインを発動できるまでの時間を設定する． スケールインの無効化 ターゲット値の設定に応じて，自動的にスケールアウトやスケールインが起こるシナリオ例を示す． 最小タスク数を2，必要タスク数を4，最大数を6，CPU平均使用率を40%に設定するとする． 平常時，CPU使用率40%に維持される． リクエストが増加し，CPU使用率55%に上昇する． タスク数が6つにスケールアウトし，CPU使用率40%に維持される． リクエスト数が減少し，CPU使用率が20%に低下する． タスク数が2つにスケールインし，CPU使用率40%に維持される． ・マイクロサービスアーキテクチャ風 マイクロサービスアーキテクチャのアプリケーション群を稼働させる時，Kubernetesを使用し，またインフラとしてEKSを使用するのが基本である．ただし，モノリスなアプリケーションをECSサービスで分割し，Fargateで稼働させることにより，マイクロサービスアーキテクチャ風のインフラを構築できる． 参考：https://tangocode.com/2018/11/when-to-use-lambdas-vs-ecs-docker-containers/ タスク ・タスク グルーピングされたコンテナ群のこと ・タスク定義とは 各タスクをどのような設定値に基づいて構築するかを設定できる．タスク定義は，バージョンを示す『リビジョンナンバー』で番号づけされる．タスク定義を削除するには，全てのリビジョン番号のタスク定義を登録解除する必要がある． ・タスクのライフサイクル 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task-lifecycle.html#lifecycle-states ・タスクサイズの詳細 設定項目 説明 タスクメモリ タスク当たりのコンテナの合計メモリ使用量 タスクCPU タスク当たりのコンテナの合計CPU使用量 ・新しいタスクを一時的に実行 現在起動中のECSタスクとは別に，新しいタスクを一時的に起動する．CI/CDツールで実行する以外に，ローカルから手動で実行する場合もある．起動時に，overridesオプションを使用して，指定したタスク定義のコンテナ設定を上書きできる．正規表現で設定する必要があり，さらにJSONでは『\\』を『\\\\』にエスケープしなければならない．コマンドが実行された後に，タスクは自動的にStopped状態になる． ＊実装例＊ LaravelのSeederコマンドやロールバックコマンドを，ローカルPCから実行する． #!/bin/bash set -x echo \"Set Variables\" SERVICE_NAME=\"stg-foo-ecs-service\" CLUSTER_NAME=\"stg-foo-ecs-cluster\" TASK_NAME=\"stg-foo-ecs-task-definition\" SUBNETS_CONFIG=$(aws ecs describe-services \\ --cluster ${CLUSTER_NAME} \\ --services ${SERVICE_NAME} \\ --query \"services[].deployments[].networkConfiguration[].awsvpcConfiguration[].subnets[]\") SGS_CONFIG=$(aws ecs describe-services \\ --cluster ${CLUSTER_NAME} \\ --services ${SERVICE_NAME} \\ --query \"services[].deployments[].networkConfiguration[].awsvpcConfiguration[].securityGroups[]\") # 実行したいコマンドをoverridesに設定する． echo \"Run Task\" TASK_ARN=$(aws ecs run-task \\ --launch-type FARGATE \\ --cluster ${CLUSTER_NAME} \\ --platform-version \"1.4.0\" \\ --network-configuration \"awsvpcConfiguration={subnets=${SUBNETS_CONFIG},securityGroups=${SGS_CONFIG}}\" \\ --task-definition ${TASK_NAME} \\ --overrides '{\\\"containerOverrides\\\": [{\\\"name\\\": \\\"laravel-container\\\",\\\"command\\\": [\\\"php\\\", \\\"artisan\\\", \\\"db:seed\\\", \\\"--class=DummySeeder\\\", \\\"--force\\\"]}]}' \\ --query \"tasks[0].taskArn\" | tr -d \"\"\") echo \"Wait until task stopped\" aws ecs wait tasks-stopped \\ --cluster ${CLUSTER_NAME} \\ --tasks ${TASK_ARN} echo \"Get task result\" RESULT=$(aws ecs describe-tasks \\ --cluster ${CLUSTER_NAME} \\ --tasks ${TASK_ARN}) echo ${RESULT} EXIT_CODE=$(echo ${RESULT} | jq .tasks[0].containers[0].exitCode) echo exitCode ${EXIT_CODE} exit ${EXIT_CODE} なお，実行IAMユーザを作成し，ECSタスクを起動できる最低限の権限をアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"iam:PassRole\", \"ecs:RunTask\", \"ecs:DescribeServices\", \"ecs:DescribeTasks\" ], \"Resource\": [ \"arn:aws:ecs:*::service/*\", \"arn:aws:ecs:*::task/*\", \"arn:aws:ecs:*::task-definition/*\", \"arn:aws:iam:::role/*\" ] } ] } ・ECS Exec ECSタスクのコンテナに対して，シェルログインを実行する．ECSサービスにおけるECS-Execオプションの有効化，ssmmessagesエンドポイントの作成，System ManagerにアクセスするためのIAMポリシーの作成，ECSタスク実行ロールへのIAMポリシーの付与，が必要になる． 参考： https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/ecs-exec.html https://docs.aws.amazon.com/ja_jp/systems-manager/latest/userguide/systems-manager-setting-up-messageAPIs.html { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ # ssmmesages APIへのアクセス権限 \"ssmmessages:CreateControlChannel\", \"ssmmessages:CreateDataChannel\", \"ssmmessages:OpenControlChannel\", \"ssmmessages:OpenDataChannel\" ], \"Resource\": \"*\" } ] } なお，事前の設定がなされているかどうかをecs-exec-checkerスクリプトを実行して確認できる． 参考：https://github.com/aws-containers/amazon-ecs-exec-checker #!/bin/bash ECS_CLUSTER_NAME=prd-foo-ecs-cluster ECS_TASK_ID=bar bash bazコンテナに対して，シェルログインを実行する．bashを実行する時に，『/bin/bash』や『/bin/sh』で指定すると，binより上のパスもECSに送信されてしまう．例えば，Windowsなら『C:/Program Files/Git/usr/bin/bash』が送信される）ECSコンテナ内ではbashへのパスが異なるため，接続に失敗する．そのため，bashを直接指定するようにする． #!/bin/bash set -xe ECS_CLUSTER_NAME=prd-foo-ecs-cluster ECS_TASK_ID=bar ECS_CONTAINER_NAME=baz aws ecs execute-command \\ --cluster $ECS_CLUSTER_NAME \\ --task $ECS_TASK_ID \\ --container $ECS_CONTAINER_NAME \\ --interactive \\ --debug \\ --command \"bash\" Fargate ・Fargateとは コンテナの実行環境のこと．『ECS on Fargate』という呼び方は，Fargateが環境の意味合いを持つからである．Fargate環境ではホストが隠蔽されており，実体としてEC2インスタンスをホストとしてコンテナが稼働している（ドキュメントに記載がないが，AWSサポートに確認済み）． 参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-fargate-data-plane/ ・コンテナエージェント コンテナ内で稼働し，コンテナの操作を行うプログラムのこと． ・コンテナ定義の詳細 タスク内のコンテナ一つに対して，環境を設定する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/task_definition_parameters.html 設定項目 対応するdockerコマンドオプション 説明 補足 cpu --cpus タスク全体に割り当てられたCPUのうち，該当のコンテナに割り当てるCPU分を設定する． dnsServers --dns コンテナが名前解決に使用するDNSサーバの\u0010IPアドレスを設定する． essential コンテナが必須か否かを設定する． ・trueの場合，コンテナが停止すると，タスクに含まれる全コンテナが停止する．falseの場合，コンテナが停止しても，その他のコンテナは停止しない． healthCheck(command) --health-cmd ホストマシンからFargateに対して，curlコマンドによるリクエストを送信し，レスポンス内容を確認． healthCheck(interval) --health-interval ヘルスチェックの間隔を設定する． healthCheck(retries) --health-retries ヘルスチェックを成功と見なす回数を設定する． hostName --hostname コンテナにホスト名を設定する． image ECRのURLを設定する． logConfiguration(logDriver) --log-driver ログドライバーを指定することにより，ログの出力先を設定する． Dockerのログドライバーにおおよそ対応しており，Fargateであれば『awslogs，awsfirelens，splunk』に設定できる．EC2であれば『awslogs，json-file，syslog，journald，fluentd，gelf，logentries』を設定できる． logConfiguration(options) --log-opt ログドライバーに応じて，詳細な設定を行う． portMapping --publish--expose ホストマシンとFargateのアプリケーションのポート番号をマッピングし，ポートフォワーディングを行う． containerPortのみを設定し，hostPortは設定しなければ，EXPOSEとして定義できる．参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/APIReference/API_PortMapping.html secrets(volumesFrom) SSMパラメータストアから出力する変数を設定する． memory --memory--memory-reservation タスク全体に割り当てられたメモリのうち，該当のコンテナに割り当てるメモリ分を設定する． mountPoints ulimit Linuxコマンドの--ulimitに相当 ・awslogsドライバー 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/using_awslogs.html#create_awslogs_logdriver_options 設定項目 説明 補足 awslogs-group ログ送信先のCloudWatchログのロググループを設定する． awslogs-datetime-format 日時フォーマットを定義し，またこれをログの区切り単位としてログストリームに出力する． 正規表現で設定する必要があり，さらにJSONでは『\\』を『\\\\』にエスケープしなければならない．例えば『\\\\[%Y-%m-%d %H:%M:%S\\\\]』となる．参考：https://docs.docker.com/config/containers/logging/awslogs/#awslogs-datetime-format awslogs-region ログ送信先のCloudWatchログのリージョンを設定する． awslogs-stream-prefix ログ送信先のCloudWatchログのログストリームのプレフィックス名を設定する． ログストリームには，『//』の形式で送信される． ・割り当てられるプライベートIPアドレス タスクごとに異なるプライベートIPが割り当てられる．このIPアドレスに対して，ALBはルーティングを行う． ロール ・サービスロール サービス機能がタスクを操作するために必要なロールのこと．サービスリンクロールに含まれ，ECSの構築時に自動的にアタッチされる． ・タスクロール タスク内のコンテナのアプリケーションが，他のリソースにアクセスするために必要なロールのこと．アプリケーションにS3やSSMへのアクセス権限を与えたい場合は，タスク実行ロールではなくタスクロールに権限をアタッチする． ＊実装例＊ アプリケーションからCloudWatchログにログを送信するために，ECSタスクロールにカスタマー管理ポリシーをアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"logs:CreateLogStream\", \"logs:PutLogEvents\" ], \"Resource\": [ \"arn:aws:logs:*:*:*\" ] } ] } ＊実装例＊ SSMパラメータストアから変数を取得するために，ECSタスクロールにインラインポリシーをアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ssm:GetParameters\" ], \"Resource\": \"*\" } ] } ・タスク実行ロール タスク上に存在するコンテナエージェントが，他のリソースにアクセスするために必要なロールのこと．AWS管理ポリシーである『AmazonECSTaskExecutionRolePolicy』がアタッチされたロールを，タスクにアタッチする必要がある．このポリシーには，ECRへのアクセス権限の他，CloudWatchログにログを生成するための権限が設定されている．タスク内のコンテナがリソースにアクセスするために必要なタスクロールとは区別すること． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ecr:GetAuthorizationToken\", \"ecr:BatchCheckLayerAvailability\", \"ecr:GetDownloadUrlForLayer\", \"ecr:BatchGetImage\", \"logs:CreateLogStream\", \"logs:PutLogEvents\" ], \"Resource\": \"*\" } ] } ＊実装例＊ Datadogエージェントがクラスターやコンテナにアクセスできるように，ECSタスク実行ロールにカスタマー管理ポリシーをアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"ecs:ListClusters\", \"ecs:ListContainerInstances\", \"ecs:DescribeContainerInstances\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" } ] } ネットワークモードとコンテナ間通信 ・noneモード 外部ネットワークが無く，タスクと外と通信できない． ・hostモード Dockerのhostネットワークに相当する． ・bridgeモード Dockerのbridgeネットワークに相当する． ・awsvpcモード awsの独自ネットワークモード．タスクはElastic Networkインターフェースと紐づけられ，Primary プライベートIPアドレスを割り当てられる．同じタスクに属するコンテナ間は，localhostインターフェイスというENI経由で通信できるようになる（推測ではあるが，Fargate環境でコンテナのホストとなるEC2インスタンスにlocalhostインターフェースが関連付けられる）．これにより，コンテナからコンテナにリクエストを転送するとき（例：NginxコンテナからPHP-FPMコンテナへの転送）は，転送元コンテナにて，転送先のアドレスを『localhost（127.0.0.1）』で指定すれば良い．また，awsvpcモードの独自の仕組みとして，同じタスク内であれば，互いにコンテナポートを開放せずとも，プロセスのリッスンするポートを指定するだけでコンテナ間通信が可能である．例えば，NginxコンテナからPHP-FPMコンテナにリクエストを転送するためには，PHP-FPMプロセスが9000番ポートをリッスンし，さらにコンテナが9000番ポートを開放する必要がある．しかし，awsvpcモードではコンテナポートを開放する必要はない． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/fargate-task-networking.html タスクのデプロイ方法の種類 ・ローリングアップデート 参考：https://toris.io/2021/04/speeding-up-amazon-ecs-container-deployments/ 最小ヘルス率の設定値に基づいて，ローリングアップデート時の稼働中タスクの最低合計数が決定される． 最大率の設定値に基づいて，ローリングアップデート時の稼働中／停止中タスクの最高合計数が決まる ECSは，既存タスクを稼働中のまま，新タスクを最高合計数いっぱいまで構築する． ECSは，猶予期間後にALB／NLBによる新タスクに対するヘルスチェックの結果を確認する．ヘルスチェックが成功していれば，既存タスクを停止する．ただし，最小ヘルス率によるタスクの最低合計数が保たれる． 『新タスクの起動』と『ヘルスチェック確認後の既存タスクの停止』のプロセスが繰り返し実行され，徐々に既存タスクが新タスクに置き換わる． 全ての既存タスクが新タスクに置き換わる． ・Blue/Greenデプロイメント CodeDeployを使用してデプロイを行う．本ノート内を検索せよ． プライベートなECSタスクのアウトバウンド通信 ・プライベートサブネットからの通信 プライベートサブネットにECSタスクを配置した場合，アウトバウンドな通信を実行するためには，NAT GatewayまたはVPCエンドポイントを配置する必要がある．パブリックサブネットに配置すればこれらは不要となるが，パブリックサブネットよりもプライベートサブネットにECSタスクを配置する方が望ましい． ・NAT Gatewayを経由 FargateからECRに対するDockerイメージのプルは，VPCの外側に対するアウトバウンド通信（グローバルネットワーク向き通信）である．以下の通り，NAT Gatewayを設置したとする．この場合，ECSやECRとのアウトバウンド通信がNAT Gatewayを通過するため，高額料金を請求されてしまう． ・VPCエンドポイントを経由 VPCエンドポイントを設け，これに対してアウトバウンド通信を行うようにするとよい．なお，NAT GatewayとVPCエンドポイントの両方を構築している場合，ルートテーブルでは，VPCエンドポイントへのアウトバウンド通信の方が優先される．料金的な観点から，NAT GatewayよりもVPCエンドポイントを経由した方がよい． VPCエンドポイントの接続先 プライベートDNS名 説明 CloudWatchログ logs.ap-northeast-1.amazonaws.com ECSコンテナのログをPOSTリクエストを送信するため． ECR api.ecr.ap-northeast-1.amazonaws.com*.dkr.ecr.ap-northeast-1.amazonaws.com イメージのGETリクエストを送信するため． S3 なし イメージのレイヤーをPOSTリクエストを送信するため SSMパラメータストア ssm.ap-northeast-1.amazonaws.com SSMパラメータストアにGETリクエストを送信するため． SSMシークレットマネージャ ssmmessage.ap-northeast-1.amazonaws.com シークレットマネージャの機能を使用するため． FireLensコンテナ ・FireLensコンテナとは 以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_fluentd_and_fluentbit.html Tips ・割り当てられるパブリックIPアドレス，FargateのIPアドレス問題 FargateにパブリックIPアドレスを持たせたい場合，Elastic IPアドレスの設定項目がなく，動的パブリックIPアドレスしか設定できない（Fargateの再構築後に変化する）．アウトバウンド通信の先にある外部サービスが，セキュリティ上で静的なIPアドレスを要求する場合，アウトバウンド通信（グローバルネットワーク向き通信）時に送信元パケットに付加されるIPアドレスが動的になり，リクエストができなくなってしまう． そこで，Fargateのアウトバウンド通信が，Elastic IPアドレスを持つNAT Gatewayを経由するようにする（Fargateは，パブリックサブネットとプライベートサブネットのどちらに置いても良い）．これによって，Nat GatewayのElastic IPアドレスが送信元パケットに付加されるため，Fargateの送信元IPアドレスを見かけ上静的に扱うことができるようになる． 参考：https://aws.amazon.com/jp/premiumsupport/knowledge-center/ecs-fargate-static-elastic-ip-address/ 14. EFS：Elastic File System EFSとは マウントターゲットと接続された片方のEC2インスタンスから，ファイルを読み込み，これをもう一方に出力する．ファイルの実体はいずれかのEC2に存在しているため，接続を切断している間，片方のEC2インスタンス内のファイルは無くなる．再接続すると，切断直前のファイルが再び表示されようになる． 設定項目 ・一覧 設定項目 説明 補足 パフォーマンスモード スループットモード EFSのスループット性能を設定する． ライフサイクルポリシー しばらくリクエストされていないファイルが低頻度アクセス（IA：Infrequent Access）ストレージクラスに移動保存するまでの期限を設定する． ・ライフサイクルポリシーを有効にしない場合，スタンダードストレージクラスのみが使用される．・画面から両ストレージの使用量を確認できる．参考：https://ap-northeast-1.console.aws.amazon.com/efs/home?region=ap-northeast-1#/file-systems/fs-f77d60d6 ファイルシステムポリシー 他のAWSリソースがEFSを利用する時のポリシーを設定する． 自動バックアップ AWS Backupに定期的に保存するかどうかを設定する． ネットワーク マウントターゲットを設置するサブネット，セキュリティグループを設定する． ・サブネットは，ファイル供給の速度の観点から，マウントターゲットにアクセスするAWSリソースと同じにする．・セキュリティグループは，EC2からのNFSプロトコルアクセスを許可したものを設定する．EC2のセキュリティグループを通過したアクセスだけを許可するために，IPアドレスでは，EC2のセキュリティグループを設定する． スペック ・バーストモードの仕組み スループット性能の自動スケーリングに残高があり，ベースラインを超過した分だけ自動スケーリング残高が減っていく．また，ベースライン未満の分は残高として蓄積されていく． 元々の残高は，ファイルシステムのスタンダードストレージクラスの容量に応じて大きくなる． 参考：https://docs.aws.amazon.com/ja_jp/efs/latest/ug/performance.html#efs-burst-credits 残高は，BurstCreditBalanceメトリクスから確認できる．このメトリクスが常に減少し続けている場合はプロビジョニングモードの方がより適切である． 参考：https://docs.aws.amazon.com/ja_jp/efs/latest/ug/performance.html#using-throughputmode ・プロビジョニングモードの仕組み スループット性能の自動スケーリング機能は無いが，一定の性能は保証されている． 参考：https://docs.aws.amazon.com/ja_jp/efs/latest/ug/performance.html#provisioned-throughput コマンド ・マウント DNS経由で，EFSマウントヘルパーを使用した場合を示す． $ mount -t -o tls :/ # EFSで，マウントポイントを登録 $ mount -t efs -o tls fs-xxxxx:/ /var/www/app # マウントポイントを解除 $ umount /var/www/app # dfコマンドでマウントしているディレクトリを確認できる $ df Filesystem 1K-blocks Used Available Use% Mounted on fs-xxx.efs.ap-northeast-1.amazonaws.com:/ xxx xxx xxx 1% /var/www/cerenavi 15. ElastiCache ElasticCacheとは アプリケーションの代わりに，セッション，クエリCache，を管理する．RedisとMemcachedがある． Redisの設定項目 設定項目 説明 補足 クラスターエンジン キャッシュエンジンを設定する．Redis通常モード，Redisクラスターモードから選択する． Redisクラスターモードと同様に，Redis通常モードもクラスター構成になる．ただ，クラスターモードとはクラスターの構成方法が異なる． ロケーション エンジンバージョンの互換性 選んだキャッシュエンジンのバージョンを設定する． マイナーバージョンが自動的に更新されないように，例えば『6.x』は設定しない方がよい． パラメータグループ グローバルパラメータを設定する． デフォルトを使用せずに独自定義する場合，事前に構築しておく必要がある． ノードのタイプ レプリケーション数 プライマリノードとは別に，リードレプリカノードをいくつ構築するかを設定する． マルチAZにプライマリノードとリードレプリカノードを一つずつ配置させる場合，ここでは『１個』を設定する． マルチAZ プライマリノードとリードレプリカを異なるAZに配置するかどうかを設定する．合わせて，自動フェールオーバーを実行できるようになる． サブネットグループ Redisにアクセスできるサブネットを設定する． セキュリティ セキュリティグループを設定する． クラスターへのデータのインポート あらかじめ作成しておいたバックアップをインポートし，これを元にRedisを構築する． キャッシュデータを引き継ぐことができる．そのため，新しいRedisへのセッションファイルの移行に役立つ．新しいRedisを構築する例としては，Redisのアップグレード時に，セッションIDを引き継いだアップグレード後のRedisを別途構築し，アプリケーションの向き先を古いRedisから新しいRedisに変える，といった状況がある． バックアップ バックアップの有効化，保持期間，時間を設定する． バックアップを取るほどでもないため，無効化しておいて問題ない． メンテナンス メンテナンスの時間を設定する． セッション管理機能 ・仕組み サーバ内のセッションファイルの代わりにセッションIDを管理し，冗長化されたアプリケーション間で共通のセッションIDを使用できるようにする．セッションIDについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_api_restful.html クエリCache管理機能 ・仕組み RDSに対するSQLと読み出されたデータを，キャッシュとして管理する． アプリケーションは，RDSの前に，Redisに対してSQLを実行する． SELECT * FROM users; 始めて実行されたSQLの場合，RedisはSQLをキーとして保存し，Cacheが無いことがアプリケーションに返却する． アプリケーションはRDSに対してSQLを実行する． データが読み出される． アプリケーションはRedisにデータを登録する． # ElastiCacheには，SQLの実行結果がまだ保存されていない *** no cache *** {\"id\"=>\"1\", \"name\"=>\"alice\"} {\"id\"=>\"2\", \"name\"=>\"bob\"} {\"id\"=>\"3\", \"name\"=>\"charles\"} {\"id\"=>\"4\", \"name\"=>\"donny\"} {\"id\"=>\"5\", \"name\"=>\"elie\"} {\"id\"=>\"6\", \"name\"=>\"fabian\"} {\"id\"=>\"7\", \"name\"=>\"gabriel\"} {\"id\"=>\"8\", \"name\"=>\"harold\"} {\"id\"=>\"9\", \"name\"=>\"Ignatius\"} {\"id\"=>\"10\", \"name\"=>\"jonny\"} 次回，アプリケーションは，RDSの前に，Redisに対してSQLを実行する． SELECT * FROM users; Redisは，SQLをキーにしてデータを特定し，アプリケーションに返却する． # ElastiCacheには，SQLの実行結果が既に保存されている *** cache hit *** {\"id\"=>\"1\", \"name\"=>\"alice\"} {\"id\"=>\"2\", \"name\"=>\"bob\"} {\"id\"=>\"3\", \"name\"=>\"charles\"} {\"id\"=>\"4\", \"name\"=>\"donny\"} {\"id\"=>\"5\", \"name\"=>\"elie\"} {\"id\"=>\"6\", \"name\"=>\"fabian\"} {\"id\"=>\"7\", \"name\"=>\"gabriel\"} {\"id\"=>\"8\", \"name\"=>\"harold\"} {\"id\"=>\"9\", \"name\"=>\"Ignatius\"} {\"id\"=>\"10\", \"name\"=>\"jonny\"} ・クエリCacheの操作 # Redis接続コマンド $ /usr/local/sbin/redis-stable/src/redis-cli \\ -c -h -p 6379 # Redis接続中の状態 # 全てのキーを表示 redis xxxxx:6379> keys * # Redis接続中の状態 # キーを指定して，対応する値を表示 redis xxxxx:6379> type # Redis接続中の状態 # Redisが受け取ったコマンドをフォアグラウンドで表示 redis xxxxx:6379> monitor Redisの障害対策 ・フェイルオーバー ノードの障害を検知し，障害が発生したノードを新しいものに置き換えることができる． 障害の発生したノード 挙動 プライマリノード リードレプリカの一つがプライマリノードに昇格し，障害が起きたプライマリノードと置き換えられる． リードレプリカノード 障害が起きたリードレプリカノードが，別の新しいものに置き換えられる． ノードのダウンタイム バックアップとインポート機能を使用して，セッションIDを引き継いだアップグレード後のRedisを別途構築する．その後，アプリケーションの向き先を古いRedisから新しいRedisに変えるようにすると，ダウンタイムを最小限にしてアップグレードできる． 状況 ダウンタイム サービスのアップグレード 1分30秒ほどのダウンタイムが発生する． 16. EventBridge（CloudWatchイベント） EventBridge（CloudWatchイベント）とは AWSリソースで起こったイベントを，他のAWSリソースに転送する．サポート対象のAWSリソースは以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/eventbridge/latest/userguide/what-is-amazon-eventbridge.html パターン ・イベントパターン 指定したAWSリソースでイベントが起こると，以下のようなJSONが送信される．イベントパターンを定義し，JSON構造が一致するイベントのみをターゲットに転送する．イベントパターンに定義しないキーは任意のデータと見なされる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/events/CloudWatchEventsandEventPatterns.html { \"version\": \"0\", \"id\": \"*****\", \"detail-type\": \"\", \"source\": \"aws.\", \"account\": \"*****\", \"time\": \"2021-01-01T00:00:00Z\", \"region\": \"us-west-1\", \"resources\": [ \"\" ], \"detail\": { // その時々のイベントごとに異なるデータ } } ＊実装例＊ Amplifyの指定したIDのアプリケーションが，Amplify Deployment Status Changeのイベントを送信し，これのjobStatusがSUCCEED／FAILEDだった場合に，これを転送する． { \"detail\": { \"appId\": [ \"foo\", \"bar\" ], \"jobStatus\": [ \"SUCCEED\", \"FAILED\" ] }, \"detail-type\": [ \"Amplify Deployment Status Change\" ], \"source\": \"aws.amplify\" } ・スケジュール cron式またはrate式を使用し，定期ジョブを定義づける．これとLambdaを組み合わせることにより，バッチ処理を構築できる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/events/ScheduledEvents.html ターゲット ・ターゲットの一覧 参考：https://docs.aws.amazon.com/ja_jp/eventbridge/latest/userguide/eb-targets.html ・デバッグ EventBridgeでは，どのようなJSONのイベントをターゲットに転送したかを確認できない．そこで，デバッグ時はEventBridgeのターゲットにLambdaを設定し，イベント構造をログから確認する． ＊実装例＊ あらかじめ，イベントの内容を出力する関数をLambdaに作成しておく． // Lambdaにデバッグ用の関数を用意する exports.handler = async (event) => { console.log(JSON.stringify({event}, null, 2)); }; 対象のAWSリソースで任意のイベントが起こった時に，EventBridgeからLambdaに転送するように設定する． { \"source\": \"aws.amplify\" } AWSリソースで意図的にイベントを起こし，Lambdaのロググループから内容を確認する．detailキーにイベントが割り当てられている． { \"event\": { \"version\": \"0\", \"id\": \"b4a07570-eda1-9fe1-da5e-b672a1705c39\", \"detail-type\": \"Amplify Deployment Status Change\", \"source\": \"aws.amplify\", \"account\": \"\", \"time\": \"\", \"region\": \"\", \"resources\": [ \"\" ], \"detail\": { \"appId\": \"\", \"branchName\": \"\", \"jobId\": \"\", \"jobStatus\": \"\" } } } 入力 ・入力トランスフォーマー 入力パスで使用する値を抽出し，入力テンプレートで転送するJSONを定義できる．イベントのJSONの値を変数として出力できる．eventキーをドルマークとして，ドットで繋いでアクセスする． ＊実装例＊ 入力パスにて，使用する値を抽出する．Amplifyで起こったイベントのJSONを変数として取り出す．JSONのキー名が変数名として機能する． { \"appId\": \"$.detail.appId\", \"branchName\": \"$.detail.branchName\", \"jobId\": \"$.detail.jobId\", \"jobStatus\": \"$.detail.jobStatus\", \"region\": \"$.region\" } 入力テンプレートにて，転送するJSONを定義する．例えばここでは，Slackに送信するJSONに出力する．出力するときは，入力パスの変数名を『<>』で囲う．Slackに送信するメッセージの作成ツールは，以下のリンクを参考にせよ． 参考：https://app.slack.com/block-kit-builder { \"channel\": \"XXXXXX\", \"text\": \"Amplifyデプロイ完了通知\", \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \":github: プルリク検証用環境\" } }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \"*結果*: \" } ] }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \"*ブランチ名*: \" } ] }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \"*検証URL*: https://..amplifyapp.com\" } ] }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \":amplify: .console.aws.amazon.com/amplify/home?region=#///|*Amplifyコンソール画面はこちら*>\" } ] }, { \"type\": \"divider\" } ] } 17. Global Accelerator 設定項目 ・基本的設定の詳細 設定項目 説明 補足 Accelerator タイプ エンドポイントグループへのルーティング時のアルゴリズムを設定する． Standard：ユーザに最も近いリージョンにあるエンドポイントグループに，リクエストがルーティングされる． IPアドレスプール Global Acceleratorに割り当てる静的IPアドレスを設定する． ・リスナーの詳細 設定項目 説明 補足 ポート ルーティング先のポート番号を設定する． プロトコル ルーティング先のプロトコルを設定する． Client affinity ユーザごとにルーティング先を固定するかを設定する． ・None：複数のルーティング先があった場合，各ユーザの毎リクエスト時のルーティング先は固定されなくなる．・Source IP：複数のルーティング先があったとしても，各ユーザの毎リクエスト時のルーティング先を固定できるようになる． ・エンドポイントグループの詳細 設定項目 説明 補足 エンドポイントグループ 特定のリージョンに関連付くエンドポイントのグループを設定する． トラフィックダイヤルにて，各エンドポイントグループの重みを設定できる． トラフィックダイヤル 複数のエンドポイントグループがある場合，それぞれの重み（%）を設定する． ・例えば，カナリアリリースのために，新アプリと旧アプリへのルーティングに重みを付ける場合に役立つ． ヘルスチェック ルーティング先に対するヘルスチェックを設定する． ・エンドポイントの詳細 設定項目 説明 補足 エンドポイントタイプ ルーティング先のAWSリソースを設定する． ALB，NLB，EC2，Elastic IPを選択できる． 重み 複数のエンドポイントがある場合，それぞれの重みを設定する． 各エンドポイントの重みの合計値を256とし，1～255で相対値を設定する． クライアントIPアドレスの保持 X-Forwarded-ForヘッダーにクライアントIPアドレスを含めて転送するかどうかを設定する． 素早いレスポンスの理由 最初，クライアントPCからのリクエストはエッジロケーションで受信される．プライベートネットワーク内のエッジロケーションを経由して，ルーティング先のリージョンまで届く．パブリックネットワークを使用しないため，小さなレイテシーでトラフィックをルーティングできる． Global Acceleratorを使用しない場合，クライアントPCのリージョンから指定したリージョンに至るまで，いくつもパブリックネットワークを経由する必要があり，時間がかかってしまう． 以下のサイトで，Global Acceleratorを使用した場合としなかった場合のレスポンス速度を比較できる． 参考：https://speedtest.globalaccelerator.aws/#/ 18. IAM：Identify and Access Management IAM ・IAMとは AWSリソースへのアクセスに関する認証と認可を制御する．認証はアクセスキーとシークレットアクセスキーによって，また認可はIAMロール／IAMポリシー／IAMステートメントによって制御される． ・IAMロールとは IAMポリシーのセットを定義する． ・IAMポリシーとは IAMステートメントのセットを定義する． IAMポリシーの種類 説明 アイデンティティベースのポリシー IAMユーザ，IAMグループ，IAMロール，にアタッチするためのポリシーのこと． リソースベースのインラインポリシー 単一のAWSリソースにインポリシーのこと． アクセスコントロールポリシー json形式で定義する必要が無いポリシーのこと． ＊具体例＊ 以下に，EC2の読み出しのみ権限（AmazonEC2ReadOnlyAccess）をアタッチできるポリシーを示す．このIAMポリシーには，他のAWSリソースに対する権限も含まれている． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"ec2:Describe*\", \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": \"elasticloadbalancing:Describe*\", \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"cloudwatch:ListMetrics\", \"cloudwatch:GetMetricStatistics\", \"cloudwatch:Describe*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": \"autoscaling:Describe*\", \"Resource\": \"*\" } ] } ・IAMステートメントとは AWSリソースに関する認可のスコープを定義する．各アクションについては以下のリンクを参考にせよ． AWSリソースの種類 リンク CloudWatchログ https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/logs/permissions-reference-cwl.html ＊具体例＊ 以下のインラインポリシーがアタッチされたロールを持つAWSリソースは，任意のSSMパラメータを取得できるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ssm:GetParameters\" ], \"Resource\": \"*\" } ] } Statementの項目 説明 Sid 任意の一意な文字列を設定する．空文字でもよい． Effect 許可／拒否を設定する． Action リソースに対して実行できるアクションを設定する． Resource アクションの実行対象に選べるリソースを設定する． 以下に主要なアクションを示す． アクション名 説明 Create リソースを構築する． Describe リソースを表示する． Delete リソースを削除する． Get リソースを取得する． Put リソースを上書きする． ・ARNとは：Amazon Resource Namespace AWSリソースの識別子のこと． 参考：https://docs.aws.amazon.com/ja_jp/general/latest/gr/aws-arns-and-namespaces.html { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Resource\": \"arn:::::\" } ] } IAMロール ・サービスリンクロール AWSリソースを構築した時に自動的に作成されるロール．他にはアタッチできない専用のポリシーがアタッチされている．『AWSServiceRoleFor*****』という名前で自動的に構築される．特に設定せずとも，自動的にリソースにアタッチされる．関連するリソースを削除するまで，ロール自体できない．サービスリンクロールの一覧については，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_aws-services-that-work-with-iam.html ・クロスアカウントのアクセスロール ・プロバイダのアクセスロール アイデンティティベースのポリシー ・アイデンティティベースのポリシーとは IAMユーザ，IAMグループ，IAMロール，にアタッチするためのポリシーのこと． ・AWS管理ポリシー AWSが提供しているポリシーのこと．アタッチ式のポリシーのため，すでにアタッチされていても，他のものにもアタッチできる． ・カスタマー管理ポリシー ユーザが独自に構築したポリシーのこと．すでにアタッチされていても，他のものにもアタッチできる． ・インラインポリシー 単一のアイデンティティにアタッチするためのポリシーのこと．組み込み式のポリシーのため，アイデンティティ間で共有してアタッチすることはできない． ＊実装例＊ IAMロールにインラインポリシーをアタッチする．このロールを持つユーザは，ユーザーアカウントのすべての ACM 証明書を一覧表示できるようになる． { \"Version\":\"2012-10-17\", \"Statement\":[ { \"Effect\":\"Allow\", \"Action\":\"acm:ListCertificates\", \"Resource\":\"*\" } ] } ＊実装例＊ IAMロールにインラインポリシーをアタッチする．このロールを持つユーザは，全てのAWSリソースに，任意のアクションを実行できる． { \"Version\":\"2012-10-17\", \"Statement\":[ { \"Effect\":\"Allow\", \"Action\":\"*\", \"Resource\":\"*\" } ] } リソースベースのインラインポリシー ・リソースベースのインラインポリシーとは 単一のAWSリソースにインポリシーのこと．すでにアタッチされていると，他のものにはアタッチできない． ・バケットポリシー S3にアタッチされる，自身へのアクセスを制御するためのインラインポリシーのこと． ・ライフサイクルポリシー ECRにアタッチされる，イメージの有効期間を定義するポリシー．コンソール画面から入力できるため，基本的にポリシーの実装は不要であるが，TerraformなどのIaCツールでは必要になる． ＊実装例＊ { \"rules\": [ { \"rulePriority\": 1, \"description\": \"Keep last 10 images untagged\", \"selection\": { \"tagStatus\": \"untagged\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } }, { \"rulePriority\": 2, \"description\": \"Keep last 10 images any\", \"selection\": { \"tagStatus\": \"any\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } } ] } ・信頼ポリシー ロールにアタッチされる，Assume Roleを行うためのインラインポリシーのこと． ＊実装例＊ 例えば，以下の信頼ポリシーを任意のロールにアタッチしたとする．その場合，Principalのecs-tasksが信頼されたエンティティと見なされ，ロールをアタッチできるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ecs-tasks.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] } 信頼ポリシーでは，IAMユーザを信頼されたエンティティとして設定することもできる． ＊実装例＊ 例えば，以下の信頼ポリシーを任意のロールにアタッチしたとする．その場合，PrincipalのIAMユーザが信頼されたエンティティと見なされ，ロールをアタッチできるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam:::user/\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"StringEquals\": { \"sts:ExternalId\": \"\" } } } ] } IAMポリシーをアタッチできる対象 ・IAMユーザに対するアタッチ ・IAMグループに対するアタッチ ・IAMロールに対するアタッチ ルートユーザ，IAMユーザ ・ルートユーザとは 全ての権限をもったアカウントのこと． ・IAMユーザとは 特定の権限をもったアカウントのこと． ・credentialsファイルを使用したCLI AWS CLIでクラウドインフラを操作するためには，credentialsファイルに定義されたクレデンシャル情報が必要である．『aws_region』ではなく『aws_default_region』であることに注意する． $ aws configure set aws_access_key_id \"\" $ aws configure set aws_secret_access_key \"\" $ aws configure set aws_default_region \"リージョン>\" # Linux，Unixの場合：$HOME/.aws/ # Windowsの場合：%USERPROFILE%\\.aws\\ [default] aws_access_key_id= aws_secret_access_key= [user1] aws_access_key_id= aws_secret_access_key= ・環境変数を使用したCLI AWS CLIでクラウドインフラを操作するためには，環境変数で定義されたクレデンシャル情報が必要である．『AWS_REGION』ではなく『AWS_DEFAULT_REGION』であることに注意する． $ export AWS_ACCESS_KEY_ID= $ export AWS_SECRET_ACCESS_KEY= $ export AWS_DEFAULT_REGION= IAMグループ ・IAMグループとは IAMユーザをグループ化したもの．IAMグループごとにIAMロールをアタッチすれば，IAMユーザのIAMロールを管理しやすくなる． ・IAMグループへのIAMロールの紐付け IAMグループに対して，IAMロールを紐づける．そのIAMグループに対して，IAMロールをアタッチしたいIAMユーザを追加していく． ・グループ一覧 種類 説明 補足 Administrator 全ての操作に権限がある． PowerUserAccess IAM以外の操作権限がある． ViewOnlyAccess 閲覧のみの操作権限がある． CLI ・CLIの社内アクセス制限 特定の送信元IPアドレスを制限するポリシーをIAMユーザにアタッチすることで，そのIAMユーザがAWS CLIの実行する時に，社外から実行できないように制限をかけられる． ＊実装例＊ { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Deny\", \"Action\": \"*\", \"Resource\": \"*\", \"Condition\": { \"NotIpAddress\": { \"aws:SourceIp\": [ \"nn.nnn.nnn.nnn/32\" ] } } } } ・ユーザ名を変更 ユーザ名は，コンソール画面から変更できず，コマンドで変更する必要がある． $ aws iam update-user --user-name --new-user-name 19. Lambda Lambdaとは 他のAWSリソースのイベントによって駆動する関数を管理できる．ユースケースについては，以下のリンクを参考にせよ． 参考：参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/applications-usecases.html 設定項目 ・一覧 設定項目 説明 補足 ランタイム 関数の実装に使用する言語を設定する． コンテナイメージの関数では使用できない． ハンドラ 関数の実行時にコールしたい具体的メソッド名を設定する． ・コンテナイメージの関数では使用できない．・Node.js：index.js というファイル名で exports.handler メソッドを呼び出したい場合，ハンドラ名をindex.handlerとする レイヤー 異なる関数の間で，特定の処理を共通化できる． コンテナイメージの関数では使用できない． メモリ Lambdaに割り当てるメモリ量を設定する． 最大10240MBまで増設でき，増設するほどパフォーマンスが上がる．インターネットで向上率グラフを検索せよ． タイムアウト 実行ロール Lambda内のメソッドが実行される時に必要なポリシーをもつロールを設定する． 既存ロール Lambdaにロールを設定する． トリガー LambdaにアクセスできるようにするAWSリソースを設定する． 設定されたAWSリソースに応じて，Lambdaのポリシーが自動的に修正される． アクセス権限 Lambdaのポリシーを設定する． トリガーの設定に応じて，Lambdaのポリシーが自動的に修正される． 送信先 LambdaからアクセスできるようにするAWSリソースを設定する． 送信先のAWSリソースのポリシーは自動的に修正されないため，別途，手動で修正する必要がある． 環境変数 Lambdaの関数内に出力する環境変数を設定する． 標準では，環境変数はAWSマネージド型KMSキーによって暗号化される． 同時実行数 同時実行の予約を設定する． プロビジョニングされた同時実行設定 モニタリング LambdaをCloudWatchまたはX-Rayを用いて，メトリクスを収集する． 次の方法がある・CloudWatchによって，メトリクスを収集する．・CloudWatchのLambda Insightsによって，パフォーマンスに関するメトリクスを収集する．・X-Rayによって，APIへのリクエスト，Lambdaコール，Lambdaの下流とのデータ通信をトレースし，これらをスタックトレース化する． ・設定のベストプラクティス 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/best-practices.html#function-configuration Lambdaと関数の関係性 ・Lambdaサービス コンソール画面のLamdaに相当する． ・関数の実行環境 Lambdaの実行環境は，API（ランタイムAPI，ログAPI，拡張API）と実行環境から構成されている．関数は実行環境に存在し，ランタイムAPIを介して，Lambdaによって実行される． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-extensions-api.html#runtimes-extensions-api-lifecycle 実行環境には，３つのフェーズがある． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-context.html#runtimes-lifecycle ・Initフェーズ Lambdaが発火する．実行環境が構築され，関数を実行するための準備が行われる． ・Invokeフェーズ Lambdaは関数を実行する．実行環境側のランタイムは，APIを介してLambdaから関数に引数を渡す．また関数の実行後に，APIを介して返却値をLambdaに渡す． ・Shutdownフェーズ 一定期間，Invokeフェーズにおける関数実行が行われなかった場合，Lambdaはランタイムを終了し，実行環境を削除する． Lambda関数 on Docker ・ベースイメージの準備 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-images.html#runtimes-images-lp ・RIC：Runtime Interface Clients 通常のランタイムはコンテナ内関数と通信できないため，ランタイムの代わりにRICを使用してコンテナ内関数と通信を行う．言語別にRICパッケージが用意されている． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-images.html#runtimes-api-client ・RIE：Runtime Interface Emulator 開発環境のコンテナで，擬似的にLambda関数を再現する．全ての言語で共通のRIEライブラリが用意されている． 参考：https://github.com/aws/aws-lambda-runtime-interface-emulator RIEであっても，稼働させるためにAWSのクレデンシャル情報（アクセスキー，シークレットアクセスキー，リージョン）が必要なため，環境変数やcredentialsファイルを使用して，Lambdaにこれらの値を出力する． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/images-test.html#images-test-env ＊参考＊ $ docker run --rm \\ # エミュレーターをエントリポイントをバインドする． -v ~/.aws-lambda-rie:/aws-lambda \\ -p 9000:8080 \\ # エミュレーターをエントリポイントとして指定する． --entrypoint /aws-lambda/aws-lambda-rie \\ : /go/bin/cmd # ハンドラー関数の引数に合ったJSONデータを送信する． $ curl \\ -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" \\ -d '{}' ＊参考＊ version: \"3.7\" services: lambda: build: context: . dockerfile: ./build/Dockerfile container_name: lambda # エミュレーターをエントリポイントとして指定する． entrypoint: /aws-lambda/aws-lambda-rie env_file: - .docker.env image: : ports: - 9000:8080 # エミュレーターをエントリポイントをバインドする． volumes: - ~/.aws-lambda-rie:/aws-lambda $ docker-compose up lambda $ curl \\ -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" \\ -d '{}' Lambda関数 ・Goの使用例 以下のリンクを参考にせよ． 参考： https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-golang.html https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws_lambda_function.html ・Node.jsの使用例 以下のリンクを参考にせよ． 参考： https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-nodejs.html https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws_lambda_function.html 同時実行 ・同時実行の予約 Lambdaは，関数の実行中に再びリクエストが送信されると，関数のインスタンスを新しく作成する．そして，各関数インスタンスを用いて，同時並行的にリクエストに応じる．標準では，関数の種類がいくつあっても，AWSアカウント当たり，合計で1000個までしかスケーリングして同時実行できない．関数ごとに同時実行数の使用枠を割り当てるためには，同時実行の予約を設定する必要がある．同時実行の予約数を0個とした場合，Lambdがスケーリングしなくなる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/configuration-concurrency.html#configuration-concurrency-reserved VPC外／VPC内 ・VPC外への配置 Lambdaは標準ではVPC外に配置される．この場合，LambdaにENIがアタッチされ，ENIに割り当てられたIPアドレスがLambdaに適用される．Lambdaの実行時にENIは再作成されるため，実行ごとにIPアドレスは変化するが，一定時間内の再実行であればENIは再利用されるため，前回の実行時と同じIPアドレスになることもある． ・VPC内への配置 LambdaをVPC内に配置するように設定する．VPC内に配置したLambdaにはパブリックIPアドレスが割り当てられないため，アウトバウンドな通信を行うためには，NAT Gatewayを設置する必要がある． ポリシー ・実行のための最低限のポリシー Lambdaを実行するためには，デプロイされた関数を使用する権限が必要である．そのため，関数を取得するためのステートメントを設定する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"lambda:InvokeFunction\", \"Resource\": \"arn:aws:lambda:::function:*\" } ] } デプロイ ・直接修正 デプロイを行わずに，関数のソースコードを直接修正し，『Deploy』ボタンでデプロイする． ・S3におけるzipファイル ビルド後のソースコードをzipファイルにしてアップロードする．ローカルPCまたはS3からアップロードできる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/gettingstarted-package.html#gettingstarted-package-zip ・ECRにおけるイメージ コンテナイメージの関数でのみ有効である．ビルド後のソースコードをDockerイメージしてアップロードする．ECRからアップロードできる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/gettingstarted-package.html#gettingstarted-package-images 19-02. Lambda@Edge Lambda@Edgeとは CloudFrontに統合されたLambdaを，特別にLambda@Edgeという． 設定項目 ・トリガーの種類 CloudFrontのビューワーリクエスト，オリジンリクエスト，オリジンレスポンス，ビューワーレスポンス，をトリガーとする．エッジロケーションのCloudFrontに，Lambdaのレプリカが構築される． トリガーの種類 発火のタイミング ビューワーリクエスト CloudFrontが，ビューワーからリクエストを受信した後（キャッシュを確認する前）． オリジンリクエスト CloudFrontが，リクエストをオリジンサーバーに転送する前（キャッシュを確認した後）． オリジンレスポンス CloudFrontが，オリジンからレスポンスを受信した後（キャッシュを確認する前）． ビューワーレスポンス CloudFrontが，ビューワーにレスポンスを転送する前（キャッシュを確認した後）． ・各トリガーのeventオブジェクトへのマッピング 各トリガーのeventオブジェクトへのマッピングは，リンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/lambda-event-structure.html ポリシー ・実行のための最低限のポリシー Lambda@Edgeを実行するためには，最低限，以下の権限が必要である． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"iam:CreateServiceLinkedRole\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"lambda:GetFunction\", \"lambda:EnableReplication*\" ], \"Resource\": \"arn:aws:lambda:::function::\" }, { \"Effect\": \"Allow\", \"Action\": [ \"cloudfront:UpdateDistribution\" ], \"Resource\": \"arn:aws:cloudfront:::distribution/\" } ] } Node.jsを用いた関数例 ・オリジンの動的な切り替え ＊実装例＊ eventオブジェクトのdomainNameとhost.valueに代入されたバケットのドメイン名によって，ルーティング先のバケットが決まる．そのため，この値を切り替えれば，動的オリジンを実現できる．なお，各バケットには同じOAIを設定する必要がある． \"use strict\"; exports.handler = (event, context, callback) => { const request = event.Records[0].cf.request; // ログストリームに変数を出力する． console.log(JSON.stringify({request}, null, 2)); const headers = request.headers; const s3Backet = getBacketBasedOnDeviceType(headers); request.origin.s3.domainName = s3Backet request.headers.host[0].value = s3Backet // ログストリームに変数を出力する． console.log(JSON.stringify({request}, null, 2)); return callback(null, request); }; /** * デバイスタイプに基づいて，オリジンを切り替える． * * @param {Object} headers * @param {string} env * @returns {string} pcBucket|spBucket */ const getBacketBasedOnDeviceType = (headers) => { const pcBucket = env + \"-bucket.s3.amazonaws.com\"; const spBucket = env + \"-bucket.s3.amazonaws.com\"; if (headers[\"cloudfront-is-desktop-viewer\"] && headers[\"cloudfront-is-desktop-viewer\"][0].value === \"true\") { return pcBucket; } if (headers[\"cloudfront-is-tablet-viewer\"] && headers[\"cloudfront-is-tablet-viewer\"][0].value === \"true\") { return pcBucket; } if (headers[\"cloudfront-is-mobile-viewer\"] && headers[\"cloudfront-is-mobile-viewer\"][0].value === \"true\") { return spBucket; } return spBucket; }; オリジンリクエストは，以下のeventオブジェクトのJSONデータにマッピングされている．なお，一部のキーは省略している． { \"Records\": [ { \"cf\": { \"request\": { \"body\": { \"action\": \"read-only\", \"data\": \"\", \"encoding\": \"base64\", \"inputTruncated\": false }, \"clientIp\": \"nnn.n.nnn.nnn\", \"headers\": { \"host\": [ { \"key\": \"Host\", \"value\": \"prd-sp-bucket.s3.ap-northeast-1.amazonaws.com\" } ], \"cloudfront-is-mobile-viewer\": [ { \"key\": \"CloudFront-Is-Mobile-Viewer\", \"value\": true } ], \"cloudfront-is-tablet-viewer\": [ { \"key\": \"loudFront-Is-Tablet-Viewer\", \"value\": false } ], \"cloudfront-is-smarttv-viewer\": [ { \"key\": \"CloudFront-Is-SmartTV-Viewer\", \"value\": false } ], \"cloudfront-is-desktop-viewer\": [ { \"key\": \"CloudFront-Is-Desktop-Viewer\", \"value\": false } ], \"user-agent\": [ { \"key\": \"User-Agent\", \"value\": \"Amazon CloudFront\" } ] }, \"method\": \"GET\", \"origin\": { \"s3\": { \"authMethod\": \"origin-access-identity\", \"customHeaders\": { \"env\": [ { \"key\": \"env\", \"value\": \"prd\" } ] }, \"domainName\": \"prd-sp-bucket.s3.amazonaws.com\", \"path\": \"\", \"port\": 443, \"protocol\": \"https\", \"region\": \"ap-northeast-1\" } }, \"querystring\": \"\", \"uri\": \"/images/12345\" } } } ] } 20. RDS：Relational Database Service 設定項目 設定項目 説明 補足 エンジンのオプション データベースエンジンの種類を設定 エディション Amazon Auroraを選んだ場合の互換性を設定する． キャパシティタイプ エンジンバージョン データベースエンジンのバージョンを指定する． ・SELECT AURORA_VERSION()を使用して，エンジンバージョンを確認できる． レプリケーション機能 DBクラスター識別子 クラスター名を設定する． インスタンス名は，最初に設定できず，RDSの構築後に設定できる． マスタユーザ名 データベースのrootユーザを設定 マスターパスワード データベースのrootユーザのパスワードを設定 DBインスタンスサイズ データベースのインスタンスのスペックを設定する． バースト可能クラスを選ぶこと．ちなみに，Amazon Auroraのデータベース容量は自動でスケーリングするため，設定する必要がない． マルチAZ配置 プライマリインスタンスとは別に，リーダーレプリカをマルチAZ配置で追加するかどうかを設定する． 最初のデータベース名 データベースに自動的に構築されるデータベース名を設定 サブネットグループ データベースにアクセスできるサブネットを設定する． パラメータグループ グローバルパラメータを設定する． デフォルトを使用せずに独自定義する場合，事前に構築しておく必要がある．クラスターパラメータグループとインスタンスパラメータグループがあるが，クラスターパラメータを設定すればよい．各パラメータに適用タイプ（dynamic/static）があり，dynamicタイプは設定の適用に再起動が必要である．新しく作成したクラスタパラメータグループにて以下の値を設定するとよい．・time_zone=Asia/Tokyo・character_set_client=utf8mb4・character_set_connection=utf8mb4・character_set_database=utf8mb4・character_set_results=utf8mb4・character_set_server=utf8mb4・server_audit_logging=1（監査ログをCloudWatchに送信するかどうか）・server_audit_logs_upload=1・general_log=1（通常クエリログをCloudWatchに送信するかどうか）・slow_query_log=1（スロークエリログをCloudWatchに送信するかどうか）・long_query_time=3（スロークエリと見なす最短秒数） ログのエクスポート 必ず，全てのログを選択すること． バックアップ保持期間 RDSがバックアップを保持する期間を設定する． 7日間にしておく． マイナーバージョンの自動アップグレード データベースエンジンのバージョンを自動的に更新するかを設定する． 開発環境では有効化，本番環境とステージング環境では無効化しておく．開発環境で新しいバージョンに問題がなければ，ステージング環境と本番環境にも適用する． データベースインスタンス ・データベースエンジン，RDB，DBMSの対応関係 RDSでは，DBMS，RDBを選べる． DBMSの種類 RDBの種類 MySQL／PostgreSQL Amazon Aurora MariaDB MariaDBデータベース MySQL MySQLデータベース PostgreSQL PostgreSQLデータベース ・データベースインスタンスの種類 読み出し／書き込みインスタンス 読み出しオンリーインスタンス 別名 プライマリインスタンス リードレプリカインスタンス CRUD制限 制限なし．ユーザ権限に依存する． ユーザ権限の権限に関係なく，READしか実行できない． エンドポイント 各インスタンスに，リージョンのイニシャルに合わせたエンヂポイントが割り振られる． 各インスタンスに，リージョンのイニシャルに合わせたエンヂポイントが割り振られる． データ同期 RDSクラスターに対するデータ変更を受けつける． 読み出し／書き込みインスタンスのデータの変更が同期される． インスタンスのダウンタイム ・ダウンタイムの発生条件 その他の全ての項目は，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html#USER_ModifyInstance.Settings 変更する項目 ダウンタイムの有無 補足 インスタンスクラス あり サブネットグループ あり エンジンバージョン あり 20～30秒のダウンタイムが発生する．参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.html メンテナンスウィンドウ 条件付きでなし ダウンタイムが発生する操作が保留中になっている状態で，メンテナンス時間を現在が含まれるように変更すると，保留中の操作がすぐに適用される．そのため，ダウンタイムが発生する． バックアップウインドウ 条件付きでなし 0から0以外の値，0以外の値から0に変更した場合，ダウンタイムが発生する． パラメータグループ なし パラメータグループの変更ではダウンタイムは発生しない．ただし，パラメータグループの変更をインスタンスに反映させる上で再起動が必要なため，ここでダウンタイムが発生する． セキュリティグループ なし マイナーバージョン自動アップグレード なし エンジンバージョンの変更にはダウンタイムが発生するが，自動アップグレードの設定にはダウンタイムが発生しない． パフォーマンスインサイト 条件付きでなし パフォーマンスインサイトの有効化ではダウンタイムが発生しない．ただし，有効化のためにパラメータグループのperformance_schemaを有効化する必要がある．パラメータグループの変更をインスタンスに反映させる上で再起動が必要なため，ここでダウンタイムが発生する． ・再起動ダウンタイムの短縮 非マルチAZ構成の場合，アプリケーションの向き先をプライマリーインスタンスにしたまま，変更対象のデータベースからリードレプリカを新しく作成し，これを更新した後に，リードレプリカを手動フェイルオーバーさせる．フェイルオーバー時に約1～2分のダウンタイムが発生するが，インスタンスの再起動よりも時間が短いため，相対的にダウンタイムを短縮できる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.MySQL.html#USER_UpgradeDBInstance.MySQL.ReducedDowntime マルチAZ構成の場合，アプリケーションの向き先をプライマリーインスタンスにしたまま，既存のリードレプリカを更新し，リードレプリカを自動フェイルオーバーさせる．フェイルオーバー時に約1～2分のダウンタイムが発生するが，インスタンスの再起動よりも時間が短いため，相対的にダウンタイムを短縮できる． ・メンテナンスウインドウ メンテナスウインドウには，以下の状態がある． 状態 説明 利用可能 アクションは実行可能である．また，以降のメンテナンスウィンドウの間に自動的に実行することはない． 次のウィンドウ アクションは実行可能である．また，次回のメンテナンスウィンドウの間に，アクションを自動的に実行する．後でアップグレードを選択することで，『利用可能』の状態に戻すことも可能． 必須 アクションは実行可能である．また，指定されたメンテナンスウィンドウの間に必ず実行され，これは延期できない． 進行中 現在時刻がメンテナンスウィンドウに含まれており，アクションを実行中である． ・ダウンタイムの計測 アプリケーションの目視ではなく，RDSに直接クエリを送信し，レスポンスとRDSイベントログから，ダウンタイムを計測する． ＊実装例＊ 踏み台サーバを経由してRDSに接続し，現在時刻を取得するSQLを送信する．平常アクセス時の再現テストも同時に実行することで，より正確なダウンタイムを取得するようにする．また，ヘルスチェックの時刻を正しくロギングできるように，ローカルPCから時刻を取得する． #!/bin/bash set -x BASTION_HOST=\"\" BASTION_USER=\"\" DB_HOST=\"\" DB_PASSWORD=\"\" DB_USER=\"\" SECRET_KEY=\"~/.ssh/xxx.pem\" SQL=\"SELECT NOW();\" ssh -o serveraliveinterval=60 -f -N -L 3306:${DB_HOST}:3306 -i ${SECRET_KEY} ${BASTION_USER}@${BASTION_HOST} -p 22 for i in {1..900}; do LOCAL_DATETIME=$(date +\"%Y-%m-%d %H:%M:%S\") echo \"---------- No. ${i} Local PC: ${LOCAL_DATETIME} ------------\" >> health_check.txt echo ${SQL} | mysql -u ${DB_USER} -P 3306 -p${DB_PASSWORD} >> health_check.txt 2>&1 & sleep 1 done 上記のシェルスクリプトにより，例えば次のようなログを取得できる．このログからは，15:23:09 ~ 15:23:14の間で，接続に失敗していることを確認できる． ---------- No. 242 Local PC: 2021-04-21 15:23:06 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:06 ---------- No. 243 Local PC: 2021-04-21 15:23:07 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:08 ---------- No. 244 Local PC: 2021-04-21 15:23:08 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2026 (HY000): SSL connection error: error:00000000:lib(0):func(0):reason(0) ---------- No. 245 Local PC: 2021-04-21 15:23:09 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 246 Local PC: 2021-04-21 15:23:10 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 247 Local PC: 2021-04-21 15:23:11 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 248 Local PC: 2021-04-21 15:23:13 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 249 Local PC: 2021-04-21 15:23:14 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 250 Local PC: 2021-04-21 15:23:15 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:16 ---------- No. 251 Local PC: 2021-04-21 15:23:16 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:17 アップグレード時のプライマリインスタンスのRDSイベントログは以下の通りで，ログによるダウンタイムは，再起動からシャットダウンまでの期間と一致することを確認する． ちなみに，リードレプリカは再起動のみを実行していることがわかる． 負荷対策 ・エンドポイントの使い分け インスタンスに応じたエンドポイントが用意されている．アプリケーションからのCRUDの種類に応じて，アクセス先を振り分けることにより，負荷を分散させられる．読み出しオンリーエンドポイントに対して，READ以外の処理を行うと，以下の通り，エラーとなる． /* SQL Error (1290): The MySQL server is running with the --read-only option so it cannot execute this statement */ 種類 エンドポイント クエリの種類 説明 クラスターエンドポイント .cluster-.ap-northeast-1.rds.amazonaws.com 書き込み／読み出し プライマリインスタンスに接続できる． 読み出しエンドポイント .cluster-ro-.ap-northeast-1.rds.amazonaws.com 読み出し リードレプリカインスタンスに接続できる．インスタンスが複数ある場合，クエリが自動的に割り振られる． インスタンスエンドポイント .cwgrq25vlygf.ap-northeast-1.rds.amazonaws.com 選択したインスタンスに接続できる．フェイルオーバーによって読み書きインスタンスと読み出しインスタンスが入れ替わってしまうため，インスタンスエンドポイントを指定しない方が良い．これは，Redisも同じである． ・クエリキャッシュの利用 MySQLやRedisのクエリキャッシュ機能を利用する．ただし，MySQLのクエリキャッシュ機能は，バージョン8で廃止されることになっている． ・ユニークキーまたはインデックスの利用 スロークエリを検出し，そのSQLで対象としているカラムにユニークキーやインデックスを設定する．スロークエリを検出する方法として，RDSのlong_query_timeパラメータに基づいた検出や，EXPLAIN句による予想実行時間の比較などがある．ユニークキー，インデックス，EXPLAIN句，については以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_database_mysql.html ・テーブルを正規化し過ぎない テーブルを正規化すると保守性が高まるが，アプリケーションのSQLでJOIN句が必要になる．しかし，JOIN句を含むSQLは，含まないSQLと比較して，実行速度が遅くなる．そこで，戦略的に正規化し過ぎないようにする． ・インスタンスタイプのスケールアップ インスタンスタイプをスケールアップさせることで，接続過多のエラー（ERROR 1040 (HY000): Too many connections）に対処する．ちなみに現在の最大接続数はパラメータグループの値から確認できる．コンソール画面からはおおよその値しかわからないため，SQLで確認した方が良い． MySQL > SHOW GLOBAL VARIABLES LIKE 'max_connections'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 640 | +-----------------+-------+ 1 row in set (0.00 sec) 障害対策 ・フェイルオーバー RDSのフェイルオーバーには，データベースの種類に応じて，以下の種類のものがある．フェイルオーバー時に約1～2分のダウンタイムが発生する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover データベース フェイルオーバーの仕組み 補足 Aurora リードレプリカがプライマリインスタンスに昇格する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/Concepts.AuroraHighAvailability.html Aurora以外 スタンバイレプリカがプライマリインスタンスに昇格する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html Auroraの場合，フェイルオーバーによって昇格するインスタンスは次の順番で決定される．基本的には，優先度の数値の小さいインスタンスが昇格対象になる．優先度が同じだと，インスタンスクラスが大きいインスタンスが昇格対象になる．インスタンスクラスが同じだと，同じサブネットにあるインスタンスが昇格対象になる． 優先度の順番 インスタンスクラスの大きさ 同じサブネット ・エンジンバージョンアップグレード時の事前調査 エンジンバージョンのアップグレード時，ダウンタイムが発生する．そのため，以下のような報告書のもと，調査と対応を行う． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.html またマージされる内容の調査のため，リリースノートの確認が必要になる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.11Updates.html # 調査 ## バージョンの違い 『SELECT AURORA_VERSION()』を使用して，正確なバージョンを取得する． ## マージされる内容 ベンダーのリリースノートを確認し，どのような『機能追加』『バグ修正』『機能廃止』『非推奨機能』がマージされるかを調査する． 機能廃止や非推奨機能がある場合，アプリケーション内のSQL文に影響が出る可能性がある． ## 想定されるダウンタイム テスト環境でダウンタイムを計測し，ダウンタイムを想定する． # 本番環境対応 ## 日時と周知 対応日時と周知内容を決定する． ## 想定外の結果 本番環境での対応で起こった想定外の結果を記載する． セキュリティ ・配置されるサブネット データベースが配置されるサブネットはプライベートサブネットにする，これには，data storeサブネットと名付ける．アプリケーション以外は，踏み台サーバ経由でしかデータベースにアクセスできないようにする． ・セキュリティグループ コンピューティングからのインバウンド通信のみを許可するように，これらのプライベートIPアドレス（n.n.n.n/32）を設定する． 21. RegionとZone Region ・Regionとは 物理サーバのあるデータセンターの地域名のこと． ・Globalとエッジロケーションとは Regionとは別に，物理サーバが世界中にあり，これらの間ではグローバルネットワークが構築されている．そのため，Globalなサービスは，特定のRegionに依存せずに，全てのRegionと連携できる． 22. Route53 Route53とは クラウドDNSサーバーとして働く．リクエストされた完全修飾ドメイン名とEC2のグローバルIPアドレスをマッピングしている． 設定項目 ・一覧 設定項目 説明 ホストゾーン ドメイン名を設定する． レコードセット 名前解決時のルーティング方法を設定する．サブドメイン名を扱うことも可能． ホストゾーン ・レコードタイプの設定値の違い レコードタイプ 補足 NS IPアドレスの問い合わせに応えられる権威DNSサーバの名前が定義されている． A リクエストを転送したいAWSリソースの，IPv4アドレスまたはDNS名を設定する． AAAA リクエストを転送したいAWSリソースの，IPv6アドレスまたはDNS名を設定する． CNAME リクエストを転送したい任意のサーバのドメイン名を設定する． 転送先はAWSリソースでなくともよい． MX リクエストを転送したいメールサーバのドメイン名を設定する． TXT リクエストを転送したいサーバのドメイン名に関連付けられた文字列を設定する． ・リソースのDNS名，ドメイン名，エンドポイント名 リソースのDNS名は，以下の様に決定される． 種別 リソース 例 DNS名 ALB -..elb.amazonaws.com EC2 ec2-..compute.amazonaws.com ドメイン名 CloudFront .cloudfront.net エンドポイント名 S3 ..amazonaws.com ・レコードタイプの名前解決方法の違い レコードタイプ 名前解決方法（1） （2） （3） A 完全修飾ドメイン名 → パブリックIPv4 → - AAAA 完全修飾ドメイン名 → パブリックIPv6 → - CNAME 完全修飾ドメイン名 → （リダイレクト） → パブリックIPv4 ・CloudFrontへのルーティング CloudFrontにルーティングする場合，CloudFrontのCNAMEをレコード名とすると，CloudFrontのデフォルトドメイン名（xxxxx.cloudfront.net.）が，入力フォームに表示されるようになる． ・Route53を含む多数のDNSサーバによって名前解決される仕組み === （1）完全修飾ドメイン名に対応するIPアドレスのレスポンス === クライアントPCは，自身に保存されるwww.example.jp（完全修飾ドメイン名）のキャッシュを検索する． キャッシュが無ければ，クライアントPCはwww.example.jpを，フォワードプロキシサーバ（キャッシュDNSサーバ）にリクエスト． フォワードプロキシサーバは，DNSキャッシュを検索する． フォワードプロキシサーバは，ルートDNSサーバにwww.example.jpのIPアドレスを問い合わせる． ルートDNSサーバは，NSレコードとして定義された権威DNSサーバ名をレスポンス． フォワードプロキシサーバは，www.example.jpを，リバースプロキシサーバに代理リクエスト．次いで，リバースプロキシサーバは，DNSサーバ（ネームサーバ）にwww.example.jpのIPアドレスを問い合わせる． DNSサーバは，NSレコードとして定義された権威DNSサーバ名をレスポンス． フォワードプロキシサーバは，www.example.jpを，リバースプロキシサーバに代理リクエスト．次いで，リバースプロキシサーバは，グローバルリージョンRoute53にwww.example.jpのIPアドレスを問い合わせる． グローバルリージョンRoute53はDNSサーバとして機能し，リバースプロキシサーバに東京リージョンALBのIPアドレスをレスポンス．次いで，リバースプロキシサーバは，東京リージョンALBのIPアドレスを，フォワードプロキシサーバに代理レスポンス．（※ NATによるIPアドレスのネットワーク間変換が起こる） 完全修飾ドメイン名 Route53 IPv4アドレス http://www.example.com ⇄ 203.142.205.139 フォワードプロキシサーバは，東京リージョンALBのIPアドレスを，クライアントPCに代理レスポンス． クライアントPCは東京リージョンALBのIPアドレスにリクエストを送信する． === （2）東京リージョンALBのIPアドレスに対応するWebページのレスポンス === クライアントPCは，レスポンスされた東京リージョンALBのIPアドレスを基に，Webページを，リバースプロキシサーバにリクエスト． リバースプロキシサーバは，Webページを，東京リージョンALBに代理リクエスト． 東京リージョンALBは，EC2やFargateにリクエストを転送する． EC2やFargateは，Webページをリバースプロキシサーバにレスポンス． リバースプロキシサーバは，WebページをクライアントPCに代理レスポンス． ・AWS以外でドメインを購入した場合 DNSサーバによる名前解決は，ドメインを購入したドメインレジストラで行われる．そのため，AWS以外でドメインを購入した場合，Route53のNSレコード値を，ドメインレジストラに登録する必要がある．これにより，ドメインレジストラに対してIPアドレスの問い合わせがあった場合は，Route53のNSレコード値がレスポンスされるようになる．NSレコード値を元に，クライアントはRoute53にアクセスする． ・Route53におけるDNSキャッシュ ルートサーバは世界に13機しか存在しておらず，世界中の名前解決のリクエストを全て処理することは現実的に不可能である．そこで，IPアドレスとドメイン名の関係をキャッシュするプロキシサーバ（キャッシュDNSサーバ）が使用されている．基本的には，プロキシサーバとDNSサーバは区別されるが，Route53はプロキシサーバとDNSサーバの機能を両立している． リゾルバー ・リゾルバーとは 要勉強． 23. S3：Simple Storage Service S3とは クラウド外付けストレージとして働く．S3に保存するCSSファイルや画像ファイルを管理できる． 設定項目 ・主要項目 設定項目 説明 バケット バケットに関して設定する． バッチオペレーション アクセスアナライザー ・プロパティの詳細 設定項目 説明 補足 バージョニング サーバアクセスのログ記録 静的サイトホスティング オブジェクトレベルのログ記録 デフォルト暗号化 オブジェクトのロック Transfer acceleration イベント リクエスタ支払い ・外部／内部ネットワークからのアクセス制限の詳細 設定項目 説明 補足 ブロックパブリックアクセス パブリックネットワークがS3にアクセスする時の許否を設定する． ・パブリックアクセスを有効にすると，パブリックネットワークから『https://.s3.amazonaws.com』というようにURLを指定して，S3にアクセスできるようになる．ただし非推奨．・パブリックアクセスを全て無効にすると，パブリックネットワークからの全アクセスを遮断できる．・特定のオブジェクトで，アクセスコントロールリストを制限した場合，そのオブジェクトだけはパブリックアクセスにならない． バケットポリシー IAMユーザ（クロスアカウントも可）またはAWSリソースがS3へにアクセスするためのポリシーで管理する． ・IAMユーザ（クロスアカウントも可）やAWSリソースがS3にアクセスするために必要である．ただし代わりに，IAMポリシーをAWSリソースにアタッチすることでも，アクセスを許可できる．・ポリシーをアタッチできないCloudFrontやALBなどでは，自身へのアクセスログを生成するために必須である． アクセスコントロールリスト IAMユーザ（クロスアカウントも可）がS3にアクセスする時の許否を設定する． ・バケットポリシーと機能が重複する．・仮にバケット自体のブロックパブリックアクセスを無効化したとしても，特定のオブジェクトでアクセスコントロールリストを制限した場合，そのオブジェクトだけはパブリックアクセスにならない． CORSの設定 レスポンスヘッダー ・レスポンスヘッダーの設定 レスポンスヘッダーに埋め込むHTTPヘッダーを，メタデータとして設定する． 設定可能なヘッダー 説明 補足 ETag コンテンツの一意な識別子．ブラウザキャッシュの検証に使用される． 全てのコンテンツにデフォルトで設定されている． Cache-Control Expiresと同様に，ブラウザにおけるキャッシュの有効期限を設定する． 全てのコンテンツにデフォルトで設定されている． Content-Type コンテンツのMIMEタイプを設定する． 全てのコンテンツにデフォルトで設定されている． Expires Cache-Controlと同様に，ブラウザにおけるキャッシュの有効期限を設定する．ただし，Cache-Controlの方が優先度が高い． Content-Disposition Content-Encoding x-amz-website-redirect-location コンテンツのリダイレクト先を設定する． バケットポリシーの例 ・S3のARNについて ポリシーにおいて，S3のARでは，『arn:aws:s3:::/*』のように，最後にバックスラッシュアスタリスクが必要． ・ALBのアクセスログの保存を許可 パブリックアクセスが無効化されたS3に対して，ALBへのアクセスログを保存したい場合，バケットポリシーを設定する必要がある．バケットポリシーには，ALBからS3へのログ書き込み権限を実装する．『\"AWS\": \"arn:aws:iam::582318560864:root\"』において，582318560864は，ALBアカウントIDと呼ばれ，リージョンごとに値が決まっている．これは，東京リージョンのアカウントIDである．その他のリージョンのアカウントIDについては，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-access-logs.html#access-logging-bucket-permissions ＊実装例＊ { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::582318560864:root\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::/*\" } ] } ・CloudFrontのファイル読み出しを許可 パブリックアクセスが無効化されたS3に対して，CloudFrontからのルーティングで静的ファイルを読み出したい場合，バケットポリシーを設定する必要がある． ＊実装例＊ { \"Version\": \"2008-10-17\", \"Id\": \"PolicyForCloudFrontPrivateContent\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity \" }, \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\" } ] } ・CloudFrontのアクセスログの保存を許可 2020-10-08時点の仕様では，パブリックアクセスが無効化されたS3に対して，CloudFrontへのアクセスログを保存することはできない．よって，危険ではあるが，パブリックアクセスを有効化する必要がある． // ポリシーは不要 ・Lambdaからのアクセスを許可 バケットポリシーは不要である．代わりに，AWS管理ポリシーの『AWSLambdaExecute』がアタッチされたロールをLambdaにアタッチする必要がある．このポリシーには，S3へのアクセス権限の他，CloudWatchログにログを生成するための権限が設定されている． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"logs:*\" ], \"Resource\": \"arn:aws:logs:*:*:*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"s3:GetObject\", \"s3:PutObject\" ], \"Resource\": \"arn:aws:s3:::*\" } ] } ・特定のIPアドレスからのアクセスを許可 パブリックネットワーク上の特定のIPアドレスからのアクセスを許可したい場合，そのIPアドレスをポリシーに設定する必要がある． { \"Version\": \"2012-10-17\", \"Id\": \"S3PolicyId1\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": \"*\", \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"IpAddress\": { \"aws:SourceIp\": \"/32\" } } } ] } CORS設定 ・指定したドメインからのGET送信を許可 [ { \"AllowedHeaders\": [ \"Content-*\" ], \"AllowedMethods\": [ \"GET\" ], \"AllowedOrigins\": [ \"https://example.jp\" ], \"ExposeHeaders\": [], \"MaxAgeSeconds\": 3600 } ] CLI ・バケット内ファイルを表示 ＊コマンド例＊ 指定したバケット内のファイル名を表示する． $ aws s3 ls s3:// ・バケット内容量を合計 ＊コマンド例＊ 指定したバケット内のファイル容量を合計する． $ aws s3 ls s3:// --summarize --recursive --human-readable 24. Security Group Security Groupとは アプリケーションのクラウドパケットフィルタリング型ファイアウォールとして働く．インバウンド通信（プライベートネットワーク向き通信）では，プロトコルや受信元IPアドレスを設定でき，アウトバウンド通信（グローバルネットワーク向き通信）では，プロトコルや送信先プロトコルを設定できる． 設定項目 ・一覧 インバウンドルールとアウトバウンドルールを設定できる． インバウンドルール ・パケットフィルタリング型ファイアウォール パケットのヘッダ情報に記載された送信元IPアドレスやポート番号などによって，パケットを許可するべきかどうかを決定する．速度を重視する場合はこちら．ファイアウォールとWebサーバの間には，NATルータやNAPTルータが設置されている．これらによる送信元プライベートIPアドレスから送信元グローバルIPアドレスへの変換についても参考にせよ． ・セキュリティグループIDの紐づけ ソースに対して，セキュリティグループIDを設定した場合，そのセキュリティグループがアタッチされているENIと，このENIに関連付けられたリソースからのトラフィックを許可できる．リソースのIPアドレスが動的に変化する場合，有効な方法である． 参考：https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/VPC_SecurityGroups.html#DefaultSecurityGroup ・アプリケーションEC2の例 ALBに割り振られる可能性のあるIPアドレスを許可するために，ALBのSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 HTTP TCP 80 ALBのSecurity Group ID HTTP access from ALB HTTPS TCP 443 踏み台EC2のSecurity Group ID SSH access from bastion EC2 ・踏み台EC2の例 タイプ プロトコル ポート ソース 説明 SSH TCP 22 社内のグローバルIPアドレス SSH access from global ip addess ・EFSの例 EC2に割り振られる可能性のあるIPアドレスを許可するために，EC2のSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 NFS TCP 2049 アプリケーションEC2のSecurity Group ID NFS access from app EC2 ・RDSの例 EC2に割り振られる可能性のあるIPアドレスを許可するために，EC2のSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 MYSQL/Aurora TCP 3306 アプリケーションEC2のSecurity Group ID MYSQL access from app EC2 ・Redisの例 EC2に割り振られる可能性のあるIPアドレスを許可するために，EC2のSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 カスタムTCP TCP 6379 アプリケーションEC2のSecurity Group ID TCP access from app EC2 ・ALBの例 CloudFrontと連携する場合，CloudFrontに割り振られる可能性のあるIPアドレスを許可するために，全てのIPアドレスを許可する．その代わりに，CloudFrontにWAFを紐づけ，ALBの前でIPアドレスを制限するようにする．CloudFrontとは連携しない場合，ALBのSecurity GroupでIPアドレスを制限するようにする． タイプ プロトコル ポート ソース 説明 HTTP TCP 80 0.0.0.0/0 HTTP access from CloudFront HTTPS TCP 443 0.0.0.0/0 HTTPS access from CloudFront アウトバウンドルール ・任意AWSリソースの例 タイプ プロトコル ポート 送信先 説明 すべてのトラフィック すべて すべて 0.0.0.0/0 Full access Zone ・Availability Zoneとは Regionは，さらに，各データセンターは物理的に独立したAvailability Zoneというロケーションから構成されている．例えば，東京Regionには，3つのAvailability Zoneがある．AZの中に，VPCサブネットを作ることができ，そこにEC2を構築できる． 25. SES：Simple Email Service SESとは クラウドメールサーバとして働く．メール受信をトリガーとして，アクションを実行する． 設定項目 ・主要項目 設定項目 説明 補足 Domain SESのドメイン名を設定する． 設定したドメイン名には，『10 inbound-smtp.us-east-1.amazonaws.com』というMXレコードタイプの値が紐づく． Email Addresses 送信先として認証するメールアドレスを設定する．設定するとAWSからメールが届くので，指定されたリンクをクリックする． Sandboxモードの時だけ機能する． Sending Statistics SESで収集されたデータをメトリクスで確認できる． Request Increased Sending Limitsのリンクにて，Sandboxモードの解除を申請できる． SMTP Settings SMTP-AUTHの接続情報を確認できる． アプリケーションの25番ポートは送信制限があるため，465番を使用する．これに合わせて，SESも受信で465番ポートを使用するようにする． Rule Sets メールの受信したトリガーとして実行するアクションを設定できる． IP Address Filters ・Rule Setsの詳細 設定項目 説明 Recipiet 受信したメールアドレスで，何の宛先の時にこれを許可するかを設定する． Actions 受信を許可した後に，これをトリガーとして実行するアクションを設定する． 仕様上の制約 ・構築リージョンの制約 SESは連携するAWSリソースと同じリージョンに構築しなければならない． ・Sandboxモードの解除 SESはデフォルトではSandboxモードになっている．Sandboxモードでは以下の制限がかかっており．サポートセンターに解除申請が必要である． 制限 説明 送信制限 SESで認証したメールアドレスのみに送信できる． 受信制限 1日に200メールのみ受信できる． SMTP-AUTH ・AWSにおけるSMTP-AUTHの仕組み 一般的なSMTP-AUTHでは，クライアントユーザの認証が必要である．同様にして，AWSにおいてもこれが必要であり，IAMユーザを用いてこれを実現する．送信元となるアプリケーションにIAMユーザを紐付け，このIAMユーザにはユーザ名とパスワードを設定する．アプリケーションがSESを介してメールを送信する時，アプリケーションに対して，SESがユーザ名とパスワードを用いた認証を実行する．ユーザ名とパスワードは後から確認できないため，メモしておくこと．SMTP-AUTHの仕組みについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_internet.html?h=smtp 26. SNS：Simple Notification Service SNSとは パブリッシャーから発信されたメッセージをエンドポイントで受信し，サブスクライバーに転送するAWSリソース． 設定項目 ・主要項目 設定項目 説明 トピック 複数のサブスクリプションをグループ化したもの． サブスクリプション エンドポイントで受信するメッセージの種類を設定する． ・トピックの詳細 設定項目 説明 サブスクリプション サブスクリプションを登録する． アクセスポリシー トピックへのアクセス権限を設定する． 配信再試行ポリシー サブスクリプションのHTTP/Sエンドポイントが失敗した時のリトライ方法を設定する．参考：https://docs.aws.amazon.com/ja_jp/sns/latest/dg/sns-message-delivery-retries.html 配信ステータスのログ記録 サブスクリプションへの発信のログをCloudWatchLogsに転送するように設定する． 暗号化 ・サブスクリプションの詳細 メッセージの種類 転送先 補足 Kinesis Data Firehose Kinesis Data Firehose SQS SQS Lambda Lambda Eメール 任意のメールアドレス HTTP/S 任意のドメイン名 Chatbotのドメイン名は『https://global.sns-api.chatbot.amazonaws.com』 JSON形式のメール 任意のメールアドレス SMS SMS 受信者の電話番号を設定する． 27. SQS：Simple Queue Service SQSとは クラウドメッセージキューとして働く．パブリッシャーが送信したメッセージは，一旦SQSに追加される．その後，サブスクライバーは，SQSに対してリクエストを送信し，メッセージを取り出す．異なるVPC間でも，メッセージキューを同期できる． 設定項目 ・SQSの種類 設定項目 説明 スタンダード方式 サブスクライバーの取得レスポンスを待たずに，次のキューを非同期的に転送する． FIFO方式 サブスクライバーの取得レスポンスを待ち，キューを同期的に転送する． CLI ・キューURLを取得 キューのURLを取得する． $ aws sqs get-queue-url --queue-name ・キューに受信リクエストを送信 キューに受信リクエストを送信し，メッセージを受信する． $ SQS_QUEUE_URL=$(aws sqs get-queue-url --queue-name ) $ aws sqs receive-message --queue-url ${SQS_QUEUE_URL} キューに受信リクエストを送信し，メッセージを受信する．また，メッセージの内容をファイルに書き出す． $ SQS_QUEUE_URL=$(aws sqs get-queue-url --queue-name ) $ aws sqs receive-message --queue-url ${SQS_QUEUE_URL} > receiveOutput.json { \"Messages\": [ { \"Body\": \"\", \"ReceiptHandle\": \"AQEBUo4y+XVuRSe4jMv0QM6Ob1viUnPbZ64WI01+Kmj6erhv192m80m+wgyob+zBgL4OMT+bps4KR/q5WK+W3tnno6cCFuwKGRM4OQGM9omMkK1F+ZwBC49hbl7UlzqAqcSrHfxyDo5x+xEyrEyL+sFK2MxNV6d0mF+7WxXTboyAu7JxIiKLG6cUlkhWfk3W4/Kghagy5erwRhwTaKtmF+7hw3Y99b55JLFTrZjW+/Jrq9awLCedce0kBQ3d2+7pnlpEcoY42+7T1dRI2s7um+nj5TIUpx2oSd9BWBHCjd8UQjmyye645asrWMAl1VCvHZrHRIG/v3vgq776e1mmi9pGxN96IW1aDZCQ1CSeqTFASe4=\", \"MD5OfBody\": \"6699d5711c044a109a6aff9fc193aada\", \"MessageId\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\" } ] } 28. STS：Security Token Service STSとは AWSリソースに一時的にアクセスできる認証情報（アクセスキー，シークレットアクセスキー，セッショントークン）を発行する．この認証情報は，一時的なアカウント情報として使用できる． STSの設定手順 1. IAMロールに信頼ポリシーをアタッチ 必要なポリシーが設定されたIAMロールを構築する．その時，信頼ポリシーにおいて，ユーザのARNを信頼されたエンティティとして設定しておく．これにより，そのユーザに対して，ロールをアタッチできるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam:::user/\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"StringEquals\": { \"sts:ExternalId\": \"\" } } } ] } 2. ロールを引き受けたアカウント情報をリクエスト 信頼されたエンティティ（ユーザ）から，STS（https://sts.amazonaws.com）に対して，ロールのアタッチをリクエストする． #!/bin/bash set -xeuo pipefail set -u # 事前に環境変数にインフラ環境名を代入する． case $ENV in \"test\") aws_account_id=\"\" aws_access_key_id=\"\" aws_secret_access_key=\"\" aws_iam_role_external_id=\"\" ;; \"stg\") aws_account_id=\"\" aws_access_key_id=\"\" aws_secret_access_key=\"\" aws_iam_role_external_id=\"\" ;; \"prd\") aws_account_id=\"\" aws_access_key_id=\"\" aws_secret_access_key=\"\" aws_iam_role_external_id=\"\" ;; *) echo \"The parameter ${ENV} is invalid.\" exit 1 ;; esac # 信頼されたエンティティのアカウント情報を設定する． aws configure set aws_access_key_id \"$aws_account_id\" aws configure set aws_secret_access_key \"$aws_secret_access_key\" aws configure set aws_default_region \"ap-northeast-1\" # https://sts.amazonaws.com に，ロールのアタッチをリクエストする． aws_sts_credentials=\"$(aws sts assume-role \\ --role-arn \"arn:aws:iam::${aws_access_key_id}:role/${ENV}-\" \\ --role-session-name \"\" \\ --external-id \"$aws_iam_role_external_id\" \\ --duration-seconds \"\" \\ --query \"Credentials\" \\ --output \"json\")\" STSへのリクエストの結果，ロールがアタッチされた新しいIAMユーザ情報を取得できる．この情報には有効秒数が存在し，期限が過ぎると新しいIAMユーザになる．秒数の最大値は，該当するIAMロールの概要の最大セッション時間から変更できる． レスポンスされるデータは以下の通り． { \"AssumeRoleUser\": { \"AssumedRoleId\": \":\", \"Arn\": \"arn:aws:sts::assumed-role//\" }, \"Credentials\": { \"SecretAccessKey\": \"\", \"SessionToken\": \"\", \"Expiration\": \"\", \"AccessKeyId\": \"\" } } 3-1. アカウント情報を取得（１） jqを使用して，レスポンスされたJSONデータからアカウント情報を抽出する．環境変数として出力し，使用できるようにする．あるいは，AWSのcredentialsファイルを作成してもよい． 参考：https://stedolan.github.io/jq/ #!/bin/bash cat assumed_user.sh export AWS_ACCESS_KEY_ID=\"$(echo \"$aws_sts_credentials\" | jq -r \".AccessKeyId\")\" export AWS_SECRET_ACCESS_KEY=\"$(echo \"$aws_sts_credentials\" | jq -r \".SecretAccessKey\")\" export AWS_SESSION_TOKEN=\"$(echo \"$aws_sts_credentials\" | jq -r \".SessionToken\")\" export AWS_ACCOUNT_ID=\"$aws_account_id\" export AWS_DEFAULT_REGION=\"ap-northeast-1\" EOF 3-2. アカウント情報を取得（２） jqを使用して，レスポンスされたJSONデータからアカウント情報を抽出する．ロールを引き受けた新しいアカウントの情報を，credentialsファイルに書き込む． #!/bin/bash aws configure --profile ${ENV}-repository > ~/.aws/credentials 4. 接続確認 ロールを引き受けた新しいアカウントを使用して，AWSリソースに接続できるかを確認する．アカウント情報の取得方法としてcredentialsファイルの作成を選んだ場合，profileオプションが必要である． #!/bin/bash # 3-2を選んだ場合，credentialsファイルを参照するオプションが必要がある． aws s3 ls --profile 2020-xx-xx xx:xx:xx 29. Step Functions Step Functionsとは AWSサービスを組み合わせて，イベント駆動型アプリケーションを構築できる． AWSリソースのAPIコール ・APIコールできるリソース 参考：https://docs.aws.amazon.com/step-functions/latest/dg/connect-supported-services.html ・Lambda ＊実装例＊ { \"StartAt\": \"Call Lambda\", \"States\": { \"Call Lambda\": { \"Type\": \"Task\", \"Resource\": \"arn:aws:states:::lambda:invoke.waitForTaskToken\", \"Parameters\": { \"FunctionName\": \"arn:aws:lambda:ap-northeast-1:xxxxx:foo-function:1\" }, \"Retry\": [ { \"ErrorEquals\": [ \"\" ], \"MaxAttempts\": 0 } ], \"End\": true, \"Comment\": \"The state that call Lambda\" } } } 30. VPC：Virtual Private Cloud VPCとは クラウドプライベートネットワークとして働く．プライベートIPアドレスが割り当てられた，VPCと呼ばれるプライベートネットワークを仮想的に構築できる．異なるAvailability Zoneに渡ってEC2を立ち上げることによって，クラウドサーバをデュアル化することできる． VPCのパケット通信の仕組み 参考：https://pages.awscloud.com/rs/112-TZM-766/images/AWS-08_AWS_Summit_Online_2020_NET01.pdf Internet Gateway，NAT Gateway ・Internet Gatewayとは VPCの出入り口に設置され，グローバルネットワークとプライベートネットワーク間（ここではVPC）におけるNAT（静的NAT）の機能を持つ．一つのパブリックIPに対して，一つのEC2のプライベートIPを紐づけられる．NAT（静的NAT）については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_internet.html ・NAT Gatewayとは NAPT（動的NAT）の機能を持つ．一つのパブリックIPに対して，複数のEC2のプライベートIPを紐づけられる．パブリックサブネットに置き，プライベートサブネットのEC2からのレスポンスを受け付ける．NAPT（動的NAT）については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_internet.html ・比較表 Internet Gateway NAT Gateway 機能 グローバルネットワークとプライベートネットワーク間（ここではVPC）におけるNAT（静的NAT） NAPT（動的NAT） 設置場所 VPC上 パブリックサブネット内 Route Table（= マッピングテーブル） ・ルートテーブルとは クラウドルータのマッピングテーブルとして働く．ルータについては，別ノートのNATとNAPTを参考にせよ． Destination（プライベートIPの範囲） Target xx.x.x.x/xx Destinationの範囲内だった場合の送信先 ・ルートテーブルの種類 種類 説明 メインルートテーブル VPCの構築時に自動で構築される．どのルートテーブルにも関連付けられていないサブネットのルーティングを設定する． カスタムルートテーブル 特定のサブネットのルーティングを設定する． ・具体例1 上の図中で，サブネット2にはルートテーブル1が関連づけられている．サブネット2内のEC2の送信先のプライベートIPアドレスが，10.0.0.0/16の範囲内にあれば，インバウンド通信と見なし，local（VPC内の他サブネット）を送信先に選び，範囲外にあれば通信を破棄する． Destination（プライベートIPアドレス範囲） Target 10.0.0.0/16 local 指定範囲以外の場合 通信破棄 ・具体例2 上の図中で，サブネット3にはルートテーブル2が関連づけられている．サブネット3内のEC2の送信先のプライベートIPアドレスが，10.0.0.0/16の範囲内にあれば，インバウンド通信と見なし，local（VPC内の他サブネット）を送信先に選び，0.0.0.0/0（local以外の全IPアドレス）の範囲内にあれば，アウトバウンド通信と見なし，インターネットゲートウェイを送信先に選ぶ． Destination（プライベートIPアドレス範囲） Target 10.0.0.0/16 local 0.0.0.0/0 Internet Gateway Network ACL：Network Access Control List ・Network ACLとは サブネットのクラウドパケットフィルタリング型ファイアウォールとして働く．ルートテーブルとサブネットの間に設置され，双方向のインバウンドルールとアウトバウンドルールを決定する． ・ACLルール ルールは上から順に適用される．例えば，インバウンドルールが以下だった場合，ルール100が最初に適用され，サブネットに対する，全IPアドレス（0.0.0.0/0）からのインバウンド通信を許可していることになる． ルール # タイプ プロトコル ポート範囲 / ICMP タイプ ソース 許可 / 拒否 100 すべての トラフィック すべて すべて 0.0.0.0/0 ALLOW * すべての トラフィック すべて すべて 0.0.0.0/0 DENY VPCサブネット クラウドプライベートネットワークにおけるセグメントとして働く． ・パブリックサブネットとは 非武装地帯に相当する．攻撃の影響が内部ネットワークに広がる可能性を防ぐために，外部から直接リクエストを受ける， ・プライベートサブネットとは 内部ネットワークに相当する．外部から直接リクエストを受けずにレスポンスを返せるように，内のNATを経由させる必要がある． ・同一VPC内の各AWSリソースに割り当てる最低限のIPアドレス数 一つのVPC内には複数のサブネットが入る．そのため，サブネットのIPアドレス範囲は，サブネットの個数だけ狭めなければならない．また，VPCがもつIPアドレス範囲から，VPC内の各AWSリソースにIPアドレスを割り当てていかなければならない．VPC内でIPアドレスが枯渇しないように，　以下の手順で，割り当てを考える． rfc1918 に準拠し，VPCに以下の範囲内でIPアドレスを割り当てる． IPアドレス サブネットマスク（CIDR形式） 範囲 10.0.0.0 ~ 10.255.255.255 /8 10.0.0.0/8 172.16.0.0 ~ 172.31.255.255 /12 172.16.0.0/12 192.168.0.0 ~ 192.168.255.255 /16 192.168.0.0/16 VPC内の各AWSリソースにIPアドレス範囲を割り当てる． AWSサービスの種類 最低限のIPアドレス数 ALB ALB1つ当たり，8個 オートスケーリング 水平スケーリング時のEC2最大数と同じ個数 VPCエンドポイント VPCエンドポイント1つ当たり，1個 ECS Elastic Network Interface 数と同じ個数 Lambda Elastic Network Interface 数と同じ個数 ・サブネットの種類 サブネットには，役割ごとにいくつか種類がある． 名前 役割 Public subnet (Frontend Subnet) NATGatewayを配置する． Private app subnet アプリケーション，Nginxなどを配置する． Private datastore subnet RDS，Redisなどを配置する VPCエンドポイント ・設定項目 VPCのプライベートサブネット内のリソースが，VPC外のリソースに対して，アウトバウンド通信を実行できるようにする．Gateway型とInterface型がある．VPCエンドポイントを使用しない場合，プライベートサブネット内からのアウトバウンド通信には，インターネットゲートウェイとNAT Gatewayを使用する必要がある． ＊（例）＊ ECS Fargateをプライベートサブネットに置いた場合に，ECS FargateからVPC外にあるAWSリソースに対するアウトバウンドな通信のために必要．（例：CloudWatchログ，ECR，S3，SSM） ・メリット インターネットゲートウェイとNAT Gatewayの代わりに，VPCエンドポイントを使用すると，料金が少しだけ安くなり，また，VPC外のリソースとの通信がより安全になる． ・タイプ タイプ 説明 リソース例 Interface型 プライベートリンクともいう．プライベートIPアドレスを持つENIとして機能し，AWSリソースからアウトバウンドな通信を受信する． S3，DynamoDB以外の全てのリソース Gateway型 ルートテーブルにおける定義に従う．VPCエンドポイントとして機能し，AWSリソースからアウトバウンドな通信を受信する． S3，DynamoDBのみ ENI：Elastic Network Interface ・ENIとは クラウドネットワークインターフェースとして働く．物理ネットワークにおけるNICについては以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_network_internet.html ・関連付けられるリソース リソースの種類 役割 補足 ALB ENIに関連付けられたパブリックIPアドレスをALBに割り当てられる． EC2 ENIに関連付けられたパブリックIPアドレスがEC2に割り当てられる． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/using-eni.html#eni-basics Fargate環境のEC2 明言されていないため推測ではあるが，ENIに関連付けられたlocalインターフェースがFargate環境でコンテナのホストとなるEC2インスタンスに割り当てられる． Fargate環境のホストがEC2とは明言されていない．参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-fargate-data-plane/ Elastic IP ENIにElastic IPアドレスが関連付けられる．このENIを他のAWSリソースに関連付けることにより，ENIを介して，Elastic IPを関連付けられる． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/using-eni.html#managing-network-interface-ip-addresses GlobalAccelerator NAT Gateway ENIに関連付けられたパブリックIPアドレスがNAT Gatewayに割り当てられる． RDS Security Group ENIにセキュリティグループが関連付けれる．このENIを他のAWSリソースに関連付けることにより，ENIを介して，セキュリティグループを関連付けられる． VPCエンドポイント Interface型のVPCエンドポイントとして機能する． IPアドレスの関連付け ・種類 IPアドレスの種類 説明 自動割り当てパブリックIPアドレス（動的IPアドレス） 動的なIPアドレスで，EC2の再構築後に変化する． Elastic IP（静的IPアドレス） 静的なIPアドレスで，再構築後も保持される． ・関連付け 種類 補足 インスタンスとの関連付け 非推奨の方法である．参考：https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/vpc-eips.html#vpc-eip-overview ENIとの関連付け 推奨される方法である．参考：https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/vpc-eips.html#vpc-eip-overview 30-02. VPC間，VPC-オンプレ間の通信 VPCピアリング接続 ・VPCピアリング接続とは 『一対一』の関係で，『異なるVPC間』の双方向通信を可能にする． ・VPCピアリング接続の可否 アカウント VPCのあるリージョン VPC内のCIDRブロック 接続の可否 同じ／異なる 同じ／異なる 全て異なる 〇 同じものが一つでもある ✕ VPC に複数の IPv4 CIDR ブロックがあり，一つでも 同じCIDR ブロックがある場合は，VPC ピアリング接続はできない． たとえ，IPv6が異なっていても，同様である． VPCエンドポイントサービス ・VPCエンドポイントサービスとは VPCエンドポイントとは異なる機能なので注意．Interface型のVPCエンドポイント（プライベートリンク）をNLBに関連付けることにより，『一対多』の関係で，『異なるVPC間』の双方向通信を可能にする．エンドポイントのサービス名は，『com.amazonaws.vpce.ap-northeast-1.vpce-svc-xxxxx』になる．API GatewayのVPCリンクは，VPCエンドポイントサービスに相当する． Transit Gateway ・Transit Gatewayとは 『多対多』の関係で，『異なるVPC間』や『オンプレ-VPC間』の双方向通信を可能にする．クラウドルーターとして働く． 各サービスとの比較 機能 VPCピアリング接続 VPCエンドポイントサービス Transit gateway 通信可能なVPC数 一対一 一対一，一対多 一対一，一対多，多対多 通信可能なIPアドレスの種類 IPv4，IPv6 IPv4 IPv4，IPv6 接続可能なリソース 制限なし NLBでルーティングできるリソースのみ 制限なし CIDRブロックによる通信の可否 × ◯ × クロスアカウント ◯ ◯ ◯ クロスリージョン ◯ × ◯ VPC間 ◯ ◯ ◯ VPC-オンプレ間 × × ◯ 31. WAF：Web Applicarion Firewall 設定項目 定義できるルール数や文字数に制限がある．以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/limits.html 設定項目 説明 補足 Web ACLs：Web Access Control List 各トリガーと許可／拒否アクションの関連付けを『ルール』とし，これをセットで設定する． アタッチするAWSリソースに合わせて，リージョンが異なる． IP sets アクション実行のトリガーとなるIPアドレス ・許可するIPアドレスは，意味合いに沿って異なるセットとして構築するべき．例えば，社内IPアドレスセット，協力会社IPアドレスセット，など・拒否するIPアドレスはひとまとめにしてもよい． Regex pattern sets アクション実行のトリガーとなるURLパスの文字列 ・許可／拒否する文字列は，意味合いに沿って異なる文字列セットとして構築するべき．例えば，ユーザエージェントセット，リクエストパスセット，など Rule groups AWS Markets AWSリソース vs. サイバー攻撃 サイバー攻撃の種類 対抗するAWSリソースの種類 マルウェア なし 傍受，盗聴 VPC内の特にプライベートサブネット間のピアリング接続．VPC外を介さずにデータを送受信できる． ポートスキャン セキュリティグループ DDoS Shield ゼロディ WAF インジェクション WAF XSS WAF データ漏洩 KMS，CloudHSM 組織内部での裏切り IAM 設定項目 ・主要項目 設定項目 説明 補足 Web ACLs アクセス許可と拒否のルールを定義する． Bot Control Botに関するアクセス許可と拒否のルールを定義する． IP Sets IPアドレスの共通部品を管理する． Regex pattern sets 正規表現パターンの共通部品を管理する． Rule groups ルールの共通部品を管理する． 各WAFに同じルールを設定する場合，ルールグループを使用するべきである．ただ，ルールグループを使用すると，これらのルールを共通のメトリクスで監視しなければならなくなる．そのため，もしメトリクスを分けるのであれば，ルールグループを使用しないようにする． ・Web ACLsの詳細 設定項目 説明 補足 Overview WAFによって許可／拒否されたリクエストのアクセスログを確認できる． Rules 順番にルールを判定し，一致するルールがあればアクションを実行する．この時，一致するルールの後にあるルールは．判定されない． AWSマネージドルールについては，以下のリンクを参考にせよ．参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/aws-managed-rule-groups-list.html Associated AWS resources WAFをアタッチするAWSリソースを設定する． CloudFront，ALBなどにアタッチできる． Logging and metrics アクセスログをKinesis Data Firehoseに出力するように設定する． ・OverviewにおけるSampled requestsの見方 『全てのルール』または『個別のルール』におけるアクセス許可／拒否の履歴を確認できる．ALBやCloudFrontのアクセスログよりも解りやすく，様々なデバッグに役立つ．ただし，３時間分しか残らない．一例として，CloudFrontにアタッチしたWAFで取得できるログを以下に示す． GET /foo/ # ホスト Host: example.jp Upgrade-Insecure-Requests: 1 # ユーザエージェント User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Sec-Fetch-Mode: navigate Sec-Fetch-User: ?1 Sec-Fetch-Dest: document # CORSであるか否か Sec-Fetch-Site: same-origin Accept-Encoding: gzip, deflate, br Accept-Language: ja,en;q=0.9 # Cookieヘッダー Cookie: sessionid=; _gid=; __ulfpc=; _ga= ルール ・ルールの種類 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/classic-web-acl-rules-creating.html 種類 説明 レートベース 同じ送信元IPアドレスからの５分間当たりのリクエスト数制限をルールに付与する． レギュラー リクエスト数は制限しない． ・ルールの粒度のコツ わかりやすさの観点から，可能な限り設定するステートメントを少なくし，一つのルールに一つの意味合いだけを持たせるように命名する． ・Count（検知）モード ルールに該当するリクエスト数を数え，許可／拒否せずに次のルールを検証する．計測結果に応じて，Countモードを無効化し，拒否できるようにする． 参考：https://oji-cloud.net/2020/09/18/post-5501/ ・Countアクションの上書き ルールのCountモードが有効になっている場合に，Countアクションに続けて，そのルールの元々のアクションを実行する．そのため，Countアクションしつつ，Blockアクションを実行できる（仕様がややこしすぎるので，なんとかしてほしい）． 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/web-acl-rule-group-override-options.html 元々のアクション Countモード オーバライド 結果 Block ON チェックあり Countし，その後Blockを実行する．そのため，その後のルールは検証せずに終了する． Block ON チェックなし Countのみを実行する．そのため，その後のルールも検証する． Block OFF チェックあり Countモードが無効なため，設定に意味がない． Block OFF チェックなし Countモードが無効なため，設定に意味がない． ルールの具体例 ・ユーザエージェント拒否 ＊具体例＊ 悪意のあるユーザエージェントを拒否する． ルール：block-user-agents Statementの順番 If a request Inspect Match type Regex pattern set Then 挙動 0 matches URI path Matches pattern from regex pattern set 文字列セット Block 指定した文字列を含むユーザエージェントの場合，アクセスすることを拒否する． Default Action 説明 Allow 指定したユーザエージェントでない場合，全てのファイルパスにアクセスすることを許可する． ・CI/CDツールのアクセスを許可 ＊具体例＊ 社内の送信元IPアドレスのみ許可した状態で，CircleCIなどのサービスが社内サービスにアクセスできるようにする． ルール：allow-request-including-access-token Statementの順番 If a request Inspect Header field name Match type String to match Then 挙動 0 matches Header authorization Exactly matched string 『Bearer 』で文字列を設定する Allow authorizationヘッダーに指定した文字列を含むリクエストの場合，アクセスすることを拒否する． Default Action 説明 Block 正しいトークンを持たないアクセスの場合，全てのファイルパスにアクセスすることを拒否する． ・特定のパスを社内アクセスに限定 ＊具体例＊ アプリケーションにおいて，特定のURLパスにアクセスできる送信元IPアドレスを，社内だけに制限する．二つのルールを構築する必要がある． ルール：allow-access--to-url-path Statementの順番 If a request Inspect IP set Match type Regex pattern set Then 挙動 0 matches (AND) Originates from an IP address in 社内IPセット - - - 社内の送信元IPアドレスの場合，指定したファイルパスにアクセスすることを許可する． 1 matches URI path - Matches pattern from regex pattern set 文字列セット Allow 0番目かつ，指定した文字列を含むURLパスアクセスの場合，アクセスすることを許可する． ルール：block-access-to-url-path Statementの順番 If a request Inspect Match type Regex pattern set Then 挙動 0 matches URI path Matches pattern from regex pattern set 文字列セット Block 指定した文字列を含むURLパスアクセスの場合，アクセスすることを拒否する． Default Action 説明 Allow 指定したURLパス以外のアクセスの場合，そのパスにアクセスすることを許可する． ・社内アクセスに限定 ＊具体例＊ アプリケーション全体にアクセスできる送信元IPアドレスを，特定のIPアドレスだけに制限する． ルール：allow-global-ip-addresses Statementの順番 If a request Inspect IP set Originating address Then 挙動 0 matches (OR) Originates from an IP address in 社内IPセット Source IP address - 社内の送信元IPアドレスの場合，全てのファイルパスにアクセスすることを許可する． 1 matches Originates from an IP address in 協力会社IPセット Source IP address Allow 0番目あるいは，協力会社の送信元IPアドレスの場合，全てのファイルパスにアクセスすることを許可する． Default Action 説明 Block 指定した送信元IPアドレス以外の場合，全てのファイルパスにアクセスすることを拒否する． 32. WorkMail WorkMailとは Gmail，サンダーバード，Yahooメールなどと同類のメール管理アプリケーション． 設定項目 設定項目 説明 補足 Users WorkMailで管理するユーザを設定する． Domains ユーザに割り当てるメールアドレスのドメイン名を設定する． @{組織名}.awsapps.comをドメイン名としてもらえる．ドメイン名の検証が完了した独自ドメイン名を設定することもできる． Access Controle rules 受信するメール，受信を遮断するメール，の条件を設定する． 33. 負荷テスト Distributed Load Testing（分散負荷テスト） ・分散負荷テストとは AWSから提供されている負荷を発生させるインフラ環境のこと．CloudFormationで構築でき，Fargateを使用して，ユーザからのリクエストを擬似的に再現できる． 参考：https://d1.awsstatic.com/Solutions/ja_JP/distributed-load-testing-on-aws.pdf ・インフラ構成 34. コスト管理 コスト管理の観点 ・スペック ・時間単価 ・数量 ・月額料金 SLA：Service Level Agreement ・SLAとは サービスレベル合意と訳せる．インターネットサービスに最低限のサービスのレベルを保証し，これを下回った場合には返金できるように合意するもの．SLAとして，例えば以下がある． 項目 説明 レベル例 返金率 サーバ稼働率 サーバの時間当たりの稼働率 99.9%以上 10% 障害回復時間 障害が起こってから回復するまでの時間 2時間以内 10% 障害お問い合わせ 障害発生時のお問い合わせ可能時間帯 24時間365日 10% ・AWSのSLA AWSではサービスレベルの項目として，サーバ稼働率を採用している．これに対して，ほとんどのAWSリソースで，以下のSLAが設定されている． 毎月の稼働率 サービスクレジットの割合 99.0％以上SLA未満 10% 95.0％以上99.0％未満 25% 95.0%未満 100% 各リソースにSLAが定義されている．例として，EC2やECSのSLAを参考にせよ． 参考：https://d1.awsstatic.com/legal/AmazonComputeServiceLevelAgreement/Amazon%20Compute%20Service%20Level%20Agreement_Japanese_2020-07-22_Updated.pdf Service Quotas ・Service Quotastとは 各種AWSリソースの設定の上限値を上げられる． 参考：https://docs.aws.amazon.com/ja_jp/servicequotas/latest/userguide/intro.html ・各種AWSリソースの上限値 参考：https://docs.aws.amazon.com/ja_jp/general/latest/gr/aws-service-information.html ・方法 参考：https://docs.aws.amazon.com/ja_jp/servicequotas/latest/userguide/request-quota-increase.html 34-02. リソース別コスト CloudFront ・転送 オリジンに転送する前にキャッシュを用いてレスポンスを返信できるため，オリジンでかかる料金を抑えられる． EBS ・ボリュームサイズ ボリュームの使用率にかかわらず，構築されたボリュームの合計サイズに基づいて，料金が発生する．そのため，安易に500GiBを選んではいけない． EC2 ・料金体系の選択 使い方に応じた料金体系を選べる．レスポンスの返信時に料金が発生する． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/concepts.html#ec2-pricing 種類 説明 補足 オンデマンドインスタンス 参考：https://aws.amazon.com/jp/ec2/pricing/on-demand/ Savings Plans リザーブドインスタンス EC2インスタンスの一定期間分の使用料金を前払いし，その代わりに安く利用できるようになる． スポットインスタンス ・料金発生の条件 インスタンスのライフサイクルの状態に応じて，料金が発生する． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html インスタンスの状態 料金発生の有無 補足 pending なし running あり stopping 条件付きでなし 停止準備中の間は料金が発生し，休止準備中の間は発生しない． stopped なし shutting-down なし terminated なし ECS ・ECRの容量 500MBを超えると，請求が発生するため，古いイメージを定期的に削除する必要がある． Lambda ・実行時間の従量課金制 関数を実行している時間分だけ料金がかかる．関数を使用せずに設置しているだけであれば，料金はかからない． RDS ・料金体系 以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/User_DBInstanceBilling.html 種類 説明 オンデマンドインスタンス 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_OnDemandDBInstances.html リザーブドインスタンス RDSインスタンスの一定期間分の使用料金を前払いし，その代わりに安く利用できるようになる．参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_WorkingWithReservedDBInstances.html SES ・送受信数 受信は1000件/月まで，送信は62000/月まで無料である． VPC ・レスポンス 35. タグ タグ付け戦略 ・よくあるタグ タグ名 用途 Name リソース自体に名前を付けられない場合，代わりにタグで名付けるため． Environment 同一のAWS環境内に異なる実行環境が存在している場合，それらを区別するため． User 同一のAWS環境内にリソース別に所有者が存在している場合，それらを区別するため． ・タグ付けによるフィルタリング AWSの各リソースには，タグをつけることができる．例えば，AWSコストエクスプローラーにて，このタグでフィルタリングすることにより，任意のタグが付いたリソースの請求合計額を確認できる． "},"public/infrastructure_cloud_computing_aws_api_gateway_import.html":{"url":"public/infrastructure_cloud_computing_aws_api_gateway_import.html","title":"▶ ︎API Gatewayインポート機能","keywords":"","body":"API Gatewayインポート機能 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. APIGateway拡張機能 ・必要なキー APIGatewayのインポートに当たり，OpenAPIのYAMLファイルにキーを新たに実装する必要がある． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions.html x-amazon-apigateway-integrationキー ・x-amazon-apigateway-integrationキーとは 該当するHTTPメソッドで統合リクエストや統合レスポンスを定義するために x-amazon-apigateway-integrationキー が必要である．各項目の説明は以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions-integration.html 各種パラメータのマッピングも可能である．メソッドリクエストから統合リクエストへのマッピングについては，以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions-integration-requestParameters.html 統合レスポンスからメソッドレスポンスへのマッピングについては，以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions-integration-responseParameters.html ・設定項目（VPCリンク&プロキシ統合） paths: /users: get: # ～ 省略 ～ #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: \"GET\" # 転送するHTTPメソッド uri: \"http:///api/v1/users/\" # 転送先のバックエンドURL requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" # 転送するカスタムヘッダーとAPIキー integration.request.querystring.userId: method.request.querystring.userId # マッピングするクエリパラメータ # パスパラメータ間のマッピングであれば，integration.request.path.userId: method.request.path.userId # 他パラメータからボディへのマッピングであれば，integration.request.header.userId: method.request.body.userId connectionType: VPC_LINK # VPCリンクを使用 connectionId: # VPCリンクのID passthroughBehavior: when_no_match # プロキシ統合の場合は設定の変更不可で固定 type: http_proxy # プロキシ統合を使用 responses: # プロキシ統合の場合は設定の変更不可で固定 default: statusCode: 200 ・設定項目（VPCリンク&非プロキシ統合の場合） パススルー条件やresponseキー以下の統合レスポンスを設定できる． paths: /users: post: x-amazon-apigateway-integration: httpMethod: POST uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" requestTemplates: application/json: '{\"body\" : $input.json(\"$\")}' passthroughBehavior: when_no_templates # 統合リクエストのマッピングテンプレートのパススルー条件を選択 connectionType: VPC_LINK connectionId: type: http # 非プロキシ統合 responses: # 統合レスポンスを設定 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' # レスポンス統合のマッピングテンプレート 400: statusCode: 400 401: statusCode: 401 ・設定項目（モック統合） パススルー条件を設定できる．モックに処理を定義する必要がある paths: /users: post: x-amazon-apigateway-integration: type: mock # モック統合を使用 requestTemplates: application/json: '{\"statusCode\": 200}' # リクエストの処理 passthroughBehavior: when_no_templates # 統合リクエストのマッピングテンプレートのパススルー条件を選択 responses: 200: statusCode: 200 responseTemplates: application/json: '{\"id\": 1}' # レスポンスの処理 400: statusCode: 400 401: statusCode: 401 x-amazon-apigateway-request-validatorsキー ・x-amazon-apigateway-request-validatorsキーとは メソッドリクエストで各種パラメータのバリデーションを定義するために，x-amazon-apigateway-request-validatorsキーが必要である．実際に定義したものを使用する時は，後述のx-amazon-apigateway-request-validatorキーが必要である． ・設定項目 各種パラメータのいずれをバリデーションの対象とするかを指定したうえで，エイリアス名を定義する．ルートで定義する． paths: /users: # ～ 省略 ～ #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false x-amazon-apigateway-request-validatorキー ・x-amazon-apigateway-request-validatorキーとは メソッドリクエストで各種パラメータのバリデーションを実行するために，x-amazon-apigateway-request-validatorキーが必要である． ・設定項目 事前に定義したx-amazon-apigateway-request-validatorsキーの中から，使用するバリデーションのエイリアス名を宣言する． paths: /users: post: # ～ 省略 ～ #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 # エイリアス名を宣言 # ～ 省略 ～ #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false 02. サンプルYAML サンプルについて ・注意点 インポートにあたり，以下に注意する．Swagger EditorでAPIの仕様書のHTMLファイルを確認できる． 参考：https://editor.swagger.io/ OpenAPI仕様のバージョン2.0と3.0に対応している． x-amazon-apigateway-integrationキーを各HTTPメソッドに定義する． API Gatewayがsecurityキーのルート定義に非対応のため，冗長ではあるが，各HTTPメソッドに個別に定義する． リクエストメソッドで受信するAPIキーのヘッダー名は，小文字で「x-api-key」以外は設定できない．ただし，統合リクエストで転送する時に付与するヘッダー名は「X-API-Key」と設定できる． 統合リクエストでバックエンドに転送するAPIキーは，シングルクオートで囲う必要がある． APIキーの作成は手動で行う必要がある． ステージの作成は手動で行う必要がある． serversキーの実装はインポートしても反映できない． マッピングテンプレートはVTLによる定義が可能である． ・その他非対応な記法 その他の非対応の記述については，以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-known-issues.html#api-gateway-known-issues-rest-apis VPCリンク＆プロキシ統合 実装例 openapi: 3.0.0 info: title: example-api-with-proxy-integration # API名 description: The API for example with proxy integration # APIの説明 termsOfService: https://www.example.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.example.com/support # 連絡先に関するURL email: support@example.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン servers: - url: https://{env}.example.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: query # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.querystring.userId: method.request.querystring.userId # マッピングするクエリパラメータ connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # path itemオブジェクト #=========================== post: tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: [ ] requestBody: # リクエストボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type example: # リクエストボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # 正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: POST uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: PUT uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type example: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"認証に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # カスタムヘッダー名 in: header VPCリンク＆非プロキシ統合 実装例 openapi: 3.0.0 info: title: example-api-with-non-proxy-integration # API名 description: The API for example with non-proxy integration. # APIの説明 termsOfService: https://www.example.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.example.com/support # 連絡先に関するURL email: support@example.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン servers: - url: https://{env}.example.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: query # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.querystring.userId: method.request.querystring.userId # マッピングするクエリパラメータ passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 #=========================== # path itemオブジェクト #=========================== post: tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: [ ] requestBody: # リクエストボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type example: # リクエストボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # 正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: POST uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" requestTemplates: application/json: '{\"body\" : $input.json(\"$\")}' passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 # type: http #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 404: statusCode: 404 #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: PUT uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type example: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"認証に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # カスタムヘッダー名 in: header モック統合 API Gatewayのエンドポイントに対して，以下のパラメータでリクエストを送信すると，レスポンスを確認できる． GET https://xxxxx.execute-api.ap-northeast-1.amazonaws.com/dev/users/?userId=1 X-API-Key：XXXXX 実装例 openapi: 3.0.0 info: title: example-api-with-mock-integration # API名 description: The API for example with mock integration # APIの説明 termsOfService: https://www.example.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.example.com/support # 連絡先に関するURL email: support@example.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン servers: - url: https://{env}.example.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: query # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{[{\"id\": 1,\"name\": test}]}' 400: statusCode: 400 401: statusCode: 401 #=========================== # path itemオブジェクト #=========================== post: tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: [ ] requestBody: # リクエストボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type example: # リクエストボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # 正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{\"id\": 1}' 400: statusCode: 400 401: statusCode: 401 # type: mock #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{[{\"id\": 1,\"name\": test}]}' 400: statusCode: 400 401: statusCode: 401 404: statusCode: 404 #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{\"id\": 1}' 400: statusCode: 400 401: statusCode: 401 #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type example: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"認証に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # カスタムヘッダー名 in: header "},"public/infrastructure_cloud_computing_aws_lambda_function.html":{"url":"public/infrastructure_cloud_computing_aws_lambda_function.html","title":"▶ ︎Lambda関数","keywords":"","body":"Lambda関数 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ ハンドラ関数 ハンドラ関数とは 自身から起動することはなく，外部から要求されて実行される関数のこと． 参考：https://garop.com/36/ Lambdaハンドラ関数 ・非同期ハンドラ関数（Async handlers） Lambdaはハンドラ関数を非同期関数としてコールし，引数のオブジェクト（event）に値をわたす．ハンドラ関数の初期名はhandlerであるが別名でもよい．returnまたはthrowを使用して，Lambdaのコール元にレスポンスを送信する．レスポンスとして，Promiseオブジェクトを送信することもできる． 参考：https://docs.aws.amazon.com/lambda/latest/dg/nodejs-handler.html#nodejs-handler-async ＊実装例＊ Node.jsの場合を示す． exports.handler = async (event) => { const response = { \"statusCode\": null, \"body\" : null }; response.statusCode = 200; response.body = \"Hello World!\" // もしくはthrowを使用して，レスポンスを送信する． return response; } const aws = require(\"aws-sdk\"); const s3 = new aws.S3(); exports.handler = async function(event) { // Promiseオブジェクトをレスポンスとして送信する． return s3.listBuckets().promise(); } exports.handler = async (event) => { // Promiseオブジェクトをレスポンスとして送信する． return new Promise((resolve, reject) => { // 何らかの処理 } } ・同期ハンドラ関数（Non-async handlers） Lambdaはハンドラ関数を同期関数としてコールし，引数（eventオブジェクト，contextオブジェクト，callback関数）に値をわたす．このオブジェクトにはメソッドとプロパティを持つ．ハンドラ関数の初期名はhandlerであるが別名でもよい．callbackメソッドを使用して，Lambdaのコール元にPromiseオブジェクトのレスポンスを送信する． 参考：https://docs.aws.amazon.com/lambda/latest/dg/nodejs-handler.html#nodejs-handler-sync（※『Non』が翻訳をおかしくしているため，英語版を推奨） ＊実装例＊ Node.jsの場合を示す．レスポンスを返信するには，doneメソッド，succeedメソッド，callbackメソッドが必要である．また，処理を終える場合はreturnで返却する必要がある． exports.handler = (event, context, callback) => { // なんらかの処理 // context以前の処理を待機はしない context.done(null, /*レスポンス*/); // 処理を終える場合 // return context.done(null, /*レスポンス*/) } exports.handler = (event, context, callback) => { // なんらかの処理 // context以前の処理を待機はしない context.succeed( /*レスポンス*/ ); // 処理を終える場合 // return context.succeed( /*レスポンス*/ ) } exports.handler = (event, context, callback) => { // なんらかの処理 // callback以前の処理を待機する． callback(null, /*レスポンス*/); // 処理を終える場合 // return callback(null, /*レスポンス*/) } ・予約された引数の説明 引数 説明 補足 eventオブジェクト HTTPリクエストに関するデータが代入されている． Lambdaにリクエストを送信するAWSリソースごとに，オブジェクトの構造が異なる．構造は以下の通り．参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-services.html contextオブジェクト Lambdaに関するデータ（名前，バージョンなど）を取得できるメソッドとプロパティが代入されている． オブジェクトの構造は以下の通り参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/nodejs-context.html callback関数 代入されている関数の実体は不明である．全ての処理が終わるまで実行が待機され，Lambdaのコール元にレスポンスを送信する． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/nodejs-handler.html ・テストとデバッグ Lambdaで関数を作成すると，CloudWatchログのロググループに，『/aws/lambda/』というグループが自動的に作成される．Lambdaの関数内で発生したエラーやconsole.logメソッドのログはここに出力されるため，都度確認すること． ・ベストプラクティス 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/best-practices.html#function-code Go aws-lambda-go ・aws-lambda-goとは Lambdaで稼働するGoにおいて，Lambdaの機能を使用するためのパッケージのこと．イベント駆動であり，他のAWSリソースのイベントをパラメータとして受信できる．contextパラメータについては以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-context.html ・Start関数 Lamda関数を実行するための関数．Start関数に渡すパラメータには，必ず一つでもerrorインターフェースの実装が含まれている必要がある．もし含まれていない場合は，Lambdaで内部エラーが起こる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-handler.html package main import ( \"context\" \"fmt\" \"github.com/aws/aws-lambda-go/lambda\" ) type MyEvent struct { Name string `json:\"name\"` } // HandleRequest リクエストをハンドリングします． func HandleRequest(ctx context.Context, name MyEvent) (string, error) { return fmt.Sprintf(\"Hello %s!\", name.Name), nil } func main() { // Lambda関数を実行します． lambda.Start(HandleRequest) } イベントの種類 ・イベントの全種類 参考：https://github.com/aws/aws-lambda-go/tree/master/events#overview ・SNSイベントの場合 package main import ( \"context\" \"github.com/aws/aws-lambda-go/events\" \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-lambda-go/lambdacontext\" ) /** * Lambdaハンドラー関数 */ func HandleRequest(context context.Context, event events.SNSEvent) (string, error) { } func main() { lambda.Start(HandleRequest) } ・CloudWatchイベントの場合 package main import ( \"context\" \"github.com/aws/aws-lambda-go/events\" \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-lambda-go/lambdacontext\" ) /** * Lambdaハンドラー関数 */ func HandleRequest(context context.Context, event events.CloudWatchEvent) (string, error) { } func main() { lambda.Start(HandleRequest) } ・APIGatewayイベントの場合 package main import ( \"context\" \"github.com/aws/aws-lambda-go/events\" \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-lambda-go/lambdacontext\" ) /** * Lambdaハンドラー関数 */ func HandleRequest(context context.Context, event events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) { } func main() { lambda.Start(HandleRequest) } レスポンス ・正常系 正常系レスポンスの構成要素については以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/API_Invoke.html#API_Invoke_ResponseElements 文字列を返却すると，Lambdaはその文字列をそのまま返信する．また，JSONをレスポンスすることもできる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-handler.html#golang-handler-structs ・異常系 Lambdaのエラーレスポンスのステータスコードについては以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/API_Invoke.html#API_Invoke_Errors エラーレスポンスのメッセージボディには以下のJSONが割り当てられる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-exceptions.html#go-exceptions-createfunction { \"errorMessage\": \"\", \"errorType\": \"\" } errorsパッケージのNew関数を使用すると，内部で発生したエラーメッセージをオーバーライドできる． package main import ( \"errors\" \"github.com/aws/aws-lambda-go/lambda\" ) func HandleRequest() (string, error) { return \"\", errors.New(\"something went wrong!\") } func main() { lambda.Start(OnlyErrors) } /* 結果 { \"errorMessage\": \"something went wrong!\", \"errorType\": \"errorString\" } */ ログ ・レポートログ 種類 RequestId リクエストID Duration イベントの処理時間 Billed Duration Lambdaの課金対象の時間 Memory Size Lambdaのメモリサイズ Max Memory Used Lambdaが実際に使用するメモリの最大量 ・ログの出力方法 標準パッケージのfmt，または任意のロギングパッケージを使用し，標準出力／標準エラー出力に出力する．CloudWatchログにてこれを確認する． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-logging.html Node.js aws-sdk-js ・aws-sdk-jsとは Lambdaで稼働するJavaScriptにおいて，Lambdaの機能を使用するためのパッケージのこと．イベント駆動であり，他のAWSリソースのイベントをパラメータとして受信できる． ・標準で使用可能なモジュール モジュール名 補足 Node.jsの標準モジュール 参考：https://nodejs.org/api/index.html aws-sdk 参考：https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/ 関数 ・API Gateway & S3 ＊実装例＊ API Gatewayでリクエストを受信し，それに応じて特定のデータをS3に保存する．LambdaがS3に対してアクションを実行できるように，事前に，AWS管理ポリシーの『AWSLambdaExecute』がアタッチされたロールをLambdaにアタッチしておく必要がある． \"use strict\"; const aws = require(\"aws-sdk\"); const s3 = new aws.S3(); exports.handler = (event, context, callback) => { // API Gatewayとのプロキシ統合を意識したJSON構造にする // レスポンスメッセージの初期値 const response = { \"statusCode\": null, \"body\" : null }; // 認証バリデーション if (event.headers[\"X-API-Key\"] !== process.env.X_API_KEY) { response.statusCode = 401; response.body = \"An API key is invalid.\"; return callback(null, response); } // リクエストメッセージバリデーション if (!event.headers || !event.body) { response.statusCode = 400; response.body = \"Parameters are not found.\"; return callback(null, response); } s3.putObject({ Bucket: \"\", Key: \"\", Body: \"\", }, (err, data) => { if (err) { response.statusCode = 500; response.body = \"[ERROR] \" + err; return callback(null, response); } response.statusCode = 200; response.body = \"OK\"; return callback(null, response); }); }; ・Amplify & EventBridge & SlackAPI ＊実装例＊ AmplifyのイベントをEventBridgeでキャッチし，これをLambdaに転送する．Lambdaでは，メッセージを構成し，SlackAPIに送信する． \"use strict\"; const aws = require(\"aws-sdk\"); const https = require(\"https\"); const {format} = require(\"util\"); /** * 非同期ハンドラ関数 * * @param event * @returns Promise */ exports.handler = async (event) => { console.log(JSON.stringify({event}, null, 2)); const amplify = new aws.Amplify({apiVersion: \"2017-07-25\"}); const option = { appId: event.detail.appId, branchName: event.detail.branchName }; let result; try { // Amplifyのブランチ情報を取得します． const app = await amplify.getBranch(option).promise(); console.log(JSON.stringify({app}, null, 2)); const message = await buildMessage(event, app); console.log(message); result = await postMessageToSlack(message); console.log(JSON.stringify({result}, null, 2)); } catch (error) { console.error(error); } return result; }; /** * メッセージを作成します． * * @param event * @param app * @returns string */ const buildMessage = (event, app) => { return JSON.stringify({ channel: process.env.SLACK_CHANNEL_ID, text: \"develop環境 通知\", attachments: [{ color: event.detail.jobStatus === \"SUCCEED\" ? \"#00FF00\" : \"#ff0000\", blocks: [ { type: \"section\", text: { type: \"mrkdwn\", text: format( \"%s環境\", event.detail.appId === process.env.AMPLIFY_APP_ID_PC ? \":computer: PC\" : \":iphone: SP\" ) } }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*結果*: %s\", event.detail.jobStatus === \"SUCCEED\" ? \"成功\" : \"失敗\", ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*ブランチ名*: %s\", event.detail.branchName ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*プルリクURL*: https://github.com/xxx-repository/compare/%s\", event.detail.branchName ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*検証URL*: https://%s.%s.amplifyapp.com\", app.branch.displayName, event.detail.appId ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \":amplify: \", event.region, event.region, event.detail.appId, app.branch.displayName, event.detail.jobId ) }] }, { type: \"divider\" } ] }] }); }; /** * メッセージを送信します． * * @param message * @returns Promise */ const postMessageToSlack = (message) => { return new Promise((resolve, reject) => { const options = { host: \"slack.com\", path: \"/api/chat.postMessage\", method: \"POST\", headers: { \"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + process.env.SLACK_API_TOKEN, \"Content-Length\": Buffer.byteLength(message) } }; const request = https.request(options, (response) => { console.info({response}, null, 2); let tmp; // 正常なレスポンスからデータを取り出します． response.on(\"data\", (data) => { tmp = data; }); // 異常なレスポンスからエラーを取り出します． response.on(\"error\", (error) => { tmp = error; }); // data，error，end，の間でawaitの効力は横断できない． // そのため，できるだけendで事後処理を実装し，awaitを使用するようにする． response.on(\"end\", async () => { tmp = await toStringWithPromise(tmp); const body = await jsonParseWithPromise(tmp); const result = { statusCode: response.statusCode, body: body }; if (!response.statusCode === 200 || !body.ok) { console.error(\"Failed\"); return reject(result); } console.info(\"Succeeded\"); return resolve(result); }); }); request.on(\"error\", (error) => { console.error(JSON.stringify({error}, null, 2)); }); // メッセージボディを設定して，リクエストを送信します． request.write(message); request.end(); console.log(JSON.stringify({request}, null, 2)); }); }; /** * toStringメソッドの結果をPromiseオブジェクトで返却します． * * @param param * @returns Promise */ const toStringWithPromise = async (param) => { return param.toString() } /** * parseメソッドの結果をPromiseオブジェクトで返却します． * * @param param * @returns Promise */ const jsonParseWithPromise = async (param) => { return JSON.parse(param) } "},"public/infrastructure_cloud_computing_gcp.html":{"url":"public/infrastructure_cloud_computing_gcp.html","title":"▶ ︎Google Cloud Platform","keywords":"","body":"Google Cloud Platform はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. GCPによるWebサービスのリリース GCPから，グローバルIPアドレスと完全修飾ドメイン名が提供され，Webサービスがリリースされる． クラウドデザイン例 以下のデザイン例では，Dualシステムが採用されている． GAE：Google App Engine：GAE クラウドデプロイサーバとして働く．AWSにおけるElastic Beanstalkに相当する． GCE：Google Compute Engine クラウドWebサーバとして働く．AWSにおけるEC2に相当する． SSLサーバ証明書の設置場所 ・認証局 サーバ提供者 自社の中間認証局名 ルート認証局名 GCP Google Trust Services "},"public/infrastructure_as_code.html":{"url":"public/infrastructure_as_code.html","title":"▶ ︎Infrastructure as Code","keywords":"","body":"Infrastructure as Code はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 仮想サーバ(仮想マシン)のコード化 仮想サーバの構成管理 ・コード化ツールの種類 ツール名 対象のProvider Ansible 要勉強 Puppet 要勉強 Chef 要勉強 ・Ansible Ansibleでは，ymlの文法を用いて関数処理を実行できる． ファイル名 役割 playbook.yml ソフトウェアのインストールタスクの手順 inventory/* 反映先のサーバの情報 group_vars/* 複数のサーバへの設定 host_vars/* 単一のサーバへの設定 02. コンテナのコード化 コンテナの構成管理 ・コード化ツールの種類 名前 対象のProvider Dockerfile Docker Ansible Container 要勉強 03. クラウドインフラストラクチャのコード化 クラウドインフラストラクチャオーケストレーション ・コード化ツールの種類 名前 対象のプロバイダー Terraform いろいろ AWS CloudFormation AWS Azure Resource Manager Azure メリット ・変更をコードレビュー可能 画面上からインフラを変更する場合，画面共有しながら操作し，レビューと変更を同時に行うことになる．コード化により，レビューを事前に行ったうえで変更する，という手順を踏める． ・ヒューマンエラーが減る 画面上からの変更であると，ヒューマンエラーが起こってしまう．コード化すれば，これが減る． ・再利用や冗長化が簡単 複数のアプリケーションのために，同様の設定で同様のインフラを構築する場合や，一つのアプリケーションのために，インフラを冗長化する場合，いくつも手動で構築する必要があり，労力がかかる．コード化すれば，これが楽になる． ・過去の変更が記録に残る 画面上からの変更であると，過去の変更履歴が残らない．ソースコードをバージョン管理すれば，Issueと紐づけて，履歴を残せる． デメリット ・運用のスピードが落ちる 運用時に，画面上からの操作であればすぐに終わる変更であるのにもかかわらず，コード化により，変更までに時間がかかる．そのため例えばAWSとすると，運用時に変更する頻度が多いインフラ（例：API Gateway（VPCリンクを含む），IAMユーザ（紐づけるロールやポリシーを含む））はコード化せず，あえて画面上から構築する． ・プロバイダーの機能追加に追従しにくい プロバイダーは日々機能を追加している．画面上からの操作であればすぐにこの機能を支えるが，コード化により，ツールのバージョンをアップグレードしなければ，この機能を使えない．運用時に便利な機能をすぐに使えないため，インフラを改善できないことに繋がる．また，エンジニアの『新機能を使ってみたい欲』が行き場を失う． ・リリースの心理的ハードルが高い 画面上から変更すれば，インフラ変更のリリース中に予期せぬエラーが起こることはまずない．しかし，コード化ツールでは，変更のリリース中に予期せぬエラーが起こる可能性は決して低くないため，リリースの心理的ハードルが高くなる． "},"public/infrastructure_as_code_terraform.html":{"url":"public/infrastructure_as_code_terraform.html","title":"▶ ︎Terraform","keywords":"","body":"Terraform はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コマンド global option 参考：https://www.terraform.io/docs/cli/commands/index.html#switching-working-directory-with-chdir init ・-backend=false ローカルにstateファイルを作成する． 参考：https://www.terraform.io/docs/language/settings/backends/index.html $ terraform init -backend=false # ディレクトリを指定することも可能 $ terraform -chdir= init -backend=false ・-backend=true, -backend-config 実インフラにstateファイルを作成する．代わりに，terraform settingsブロック内のbackendで指定しても良い．ただし，terraform settingブロック内では変数を使用できないため，こちらのオプションが推奨である． $ terraform init \\ -backend=true \\ -reconfigure \\ # バケット名 -backend-config=\"bucket=foo-tfstate-bucket\" \\ # tfstateファイル名 -backend-config=\"key=terraform.tfstate\" \\ # credentialsファイルのプロファイル名 -backend-config=\"profile=bar\" \\ -backend-config=\"encrypt=true\" ・-reconfigure Terraformを初期化する． 参考：https://www.terraform.io/docs/cli/commands/init.html#backend-initialization $ terraform init -reconfigure ・-upgrade 現在のバージョンに基づいて，lockファイル，モジュール，プラグインのアップグレード／ダウングレードを行う． 参考：https://www.terraform.io/docs/cli/commands/init.html#upgrade $ terraform init -upgrade validate ・オプション無し 設定ファイルの検証を行う． $ terraform validate Success! The configuration is valid. # ディレクトリを指定することも可能 $ terraform -chdir= validate fmt ・-check インデントを揃えるべき箇所が存在するかどうかを判定する．もし存在する場合「1」，存在しない場合は「0」を返却する． $ terraform fmt -check ・-recursive 設定ファイルのインデントを揃える．処理を行ったファイルが表示される． # -recursive: サブディレクトリを含む全ファイルをフォーマット $ terraform fmt -recursive main.tf graph rosource間の依存関係をグラフ化する．これにより，どのresourceが他のどのresourceを使用しているかがわかる．Graphvizのダウンロードが必要である． 参考：https://graphviz.org/download/ $ terraform graph | dot -Tsvg > graph.svg import ・-var-file terraformによる構築ではない方法で，すでにクラウド上にリソースが構築されている場合，これをterraformの管理下におく必要がある．リソースタイプとリソース名を指定し，stateファイルに実インフラの状態を書き込む．現状，全てのリソースを一括してimportする方法は無い．リソースIDは，リソースによって異なるため，リファレンスの「Import」または「Attributes Referenceのid」を確認すること（例えば，ACMにとってのIDはARNだが，S3バケットにとってのIDはバケット名である）． $ terraform import \\ -var-file=foo.tfvars \\ . モジュールを使用している場合，指定の方法が異なる． $ terraform import \\ -var-file=foo.tfvars \\ module... 例えば，AWS上にすでにECRが存在しているとして，これをterraformの管理下におく． $ terraform import \\ -var-file=foo.tfvars \\ module.ecr.aws_ecr_repository.www xxxxxxxxx そして，ローカルのstateファイルと実インフラの差分が無くなるまで，importを繰り返す． $ terraform plan -var-file=foo.tfvars No changes. Infrastructure is up-to-date. ・importを行わなかった場合のエラー もしimportを行わないと，すでにクラウド上にリソースが存在しているためにリソースを構築できない，というエラーになる． （エラー例1） Error: InvalidParameterException: Creation of service was not idempotent. （エラー例2） Error: error creating ECR repository: RepositoryAlreadyExistsException: The repository with name 'tech-notebook_www' already exists in the registry with id 'XXXXXXXXXXXX' refresh ・-var-file クラウドに対してリクエストを行い，現在のリソースの状態をtfstateファイルに反映する． $ terraform refresh -var-file=foo.tfvars plan ・シンボルの見方 構築（+），更新（~），削除（-），再構築（-/+）で表現される． + create ~ update in-place - destroy -/+ destroy and then create replacement ・出力内容の読み方 前半部分と後半部分に区別されている．前半部分は，Terraform管理外の方法（画面上，他ツール）による実インフラの変更について，その変更前後を検出する．ただの検出のため，applyによって変更される実インフラを表しているわけではない．そして後半部分は，Terraformのソースコードの変更によって，実インフラがどのように変更されるか，を表している．結果の最後に表示される対象リソースの数を確認しても，前半部分のリソースは含まれていないことがわかる． Note: Objects have changed outside of Terraform Terraform detected the following changes made outside of Terraform since the last \"terraform apply\": # Terraform管理外の方法（画面上，他ツール）による実インフラの変更について，その変更前後を検出． Unless you have made equivalent changes to your configuration, or ignored the relevant attributes using ignore_changes, the following plan may include actions to undo or respond to these changes. ───────────────────────────────────────────────────────────────────────────── Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: # Terraformのソースコードの変更によって，実インフラがどのように変更されるか． Plan: 0 to add, 1 to change, 0 to destroy. ・差分認識される／されない変更 変更内容 される／されない リソース名の変更 される モジュール名の変更 される ファイルやディレクトリを指定するパスの変更 されない リソースにハードコーディングされた値を環境変数に変更（tfvarsファイルに移行） されない ・-var-file クラウドに対してリクエストを行い，現在のリソースの状態をtfstateファイルには反映せずに，設定ファイルの記述との差分を検証する．スクリプト実行時に，変数が定義されたファイルを実行すると，variableで宣言した変数に，値が格納される． $ terraform plan -var-file=foo.tfvars # ディレクトリを指定することも可能 # 第一引数で変数ファイルの相対パス，第二引数でをルートモジュールの相対パス $ terraform plan -chdir= \\ -var-file=/foo.tfvars 差分がなければ，以下の通りになる． No changes. Infrastructure is up-to-date. This means that Terraform did not detect any differences between your configuration and real physical resources that exist. As a result, no actions need to be performed. ・-target 特定のリソースに対して，planコマンドを実行する． $ terraform plan \\ -var-file=foo.tfvars \\ -target=. モジュールを使用している場合，指定の方法が異なる． $ terraform plan \\ -var-file=foo.tfvars \\ -target=module... ・-refresh このオプションをつければ，refreshコマンドを同時に実行してくれる．ただ，標準でtrueなので，不要である． $ terraform plan \\ -var-file=foo.tfvars \\ -refresh=true https://github.com/hashicorp/terraform/issues/17311 ・-parallelism 並列処理数を設定できる．標準値は10である． $ terraform plan \\ -var-file=foo.tfvars \\ -parallelism=30 ・-out 実行プランファイルを生成する．applyコマンドのために使用できる． $ terraform plan \\ -var-file=foo.tfvars \\ # 実行プランファイル名 -out=foo.tfplan apply ・-var-file AWS上にクラウドインフラストラクチャを構築する． $ terraform apply -var-file foo.tfvars # ディレクトリを指定することも可能 $ terraform -chdir= apply \\ -var-file=/foo.tfvars 成功すると，以下のメッセージが表示される． Apply complete! Resources: 1 added, 0 changed, 0 destroyed. ・-target 特定のリソースに対して，applyコマンドを実行する． $ terraform apply \\ -var-file=foo.tfvars \\ -target=. モジュールを使用している場合，指定の方法が異なる． $ terraform apply \\ -var-file=foo.tfvars \\ -target=module... ・-parallelism 並列処理数を設定できる．標準値は10である． $ terraform apply \\ -var-file=foo.tfvars \\ -parallelism=30 ・実行プランファイル 事前に，planコマンドによって生成された実行プランファイルを元に，applyコマンドを実行する．実行プランを渡す場合は，変数をオプションに設定する必要はない． $ terraform apply foo.tfplan taint ・-var-file stateファイルにおける指定されたリソースのtaintedフラグを立てる．例えば，applyしたが，途中でエラーが発生してしまい，実インフラに中途半端はリソースが構築されてしまうことがある．ここで，taintedを立てておくと，実インフラのリソースを削除したと想定したplanを実行できる． $ terraform taint \\ -var-file=foo.tfvars \\ module... この後のplanコマンドのログからも，-/+で削除が行われる想定で，差分を比較していることがわかる． $ terraform plan -var-file=foo.tfvars An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: -/+ destroy and then create replacement Terraform will perform the following actions: -/+ . (tainted) (new resource required) id: '1492336661259070634' => (forces new resource) Plan: 1 to add, 0 to change, 1 to destroy. state list ・オプション無し ファイル内で定義しているリソースの一覧を表示する． $ terraform state list 以下の通り，モジュールも含めて，リソースが表示される． aws_instance.www-1a aws_instance.www-1c aws_key_pair.key_pair module.alb_module.aws_alb.alb module.ami_module.data.aws_ami.amazon_linux_2 module.route53_module.aws_route53_record.r53_record module.route53_module.aws_route53_zone.r53_zone module.security_group_module.aws_security_group.security_group_alb module.security_group_module.aws_security_group.security_group_ecs module.security_group_module.aws_security_group.security_group_instance module.vpc_module.aws_internet_gateway.internet_gateway module.vpc_module.aws_route_table.route_table_public module.vpc_module.aws_route_table_association.route_table_association_public_1a module.vpc_module.aws_route_table_association.route_table_association_public_1c module.vpc_module.aws_subnet.subnet_public_1a module.vpc_module.aws_subnet.subnet_public_1c module.vpc_module.aws_vpc.vpc 01-02. バージョン バージョン管理 ・lockファイル 現在使用中のプロバイダーのバージョンが定義される．これにより，他の人がリポジトリを使用する時に，異なるバージョンのプロバイダーを宣言できないようにする．もし，異なるバージョンを使用したい場合は，以下のコマンドを実行する．これにより，lockファイルのアップグレード／ダウングレードが実行される． $ terraform init -upgrade Terraform／プロバイダーのアップグレード 1. 現在のTerraformのバージョンでapplyコマンドを実行 アップグレードと同時に新しいAWSリソースをデプロイせずに，アップグレードのみに専念する．そのために，現在のTerraformのバージョンでapplyコマンドを実行し，差分が無いようにしておく． 2. アップグレード以外の作業を済ませておく 低いバージョンのTerraformに対して，より高いバージョンをデプロイすることは可能である．反対に，高いバージョンのTerraoformに対して，より低いバージョンをデプロイできない．そのため，アップグレードしてしまうと，それ以外のTeraformバージョンの異なる作業に影響が出る． 3. メジャーバージョン単位でアップグレード Terraformでは，メジャーバージョン単位でアップグレードを行うことが推奨されている．そのため，現在のバージョンと最新バージョンがどんなに離れていても，必ず一つずつメジャーバージョンをアップグレードするように気をつける． 参考：https://www.terraform.io/upgrade-guides/1-0.html 4. planコマンドの警告／エラーを解消 アップグレードに伴って，非推奨／廃止の機能がリリースされ，警告／エラーが出力される場合がある．警告／エラーを解消できるように，記法やオプション値を修正する．場合によってはtfstateファイルの差分として表示されているだけで，実インフラとの差分ではない場合もあるため，planで差分があったとしても，実インフラに影響がなければ問題ない． 5. Terraformの後にプロバイダーをアップグレード Terraformとプロバイダーのバージョンは独立して管理されている．プロバイダーはTerraformが土台になって稼働するため，一旦，Terraformのアップグレードを済ませてから，プロバイダーをアップグレードする． 01-03. ディレクトリ構成 ルートモジュールの構成 ・稼働環境別 稼働環境別に，foo.tfvarsファイルで値を定義する． terraform_project/ ├── modules │ ├── route53 # Route53 │ │ ├── dev # 開発 │ | ├── prd # 本番 │ | └── stg # ステージング │ | │ ├── ssm # SSM | | ├── dev │ | ├── prd │ | └── stg │ | │ └── waf # WAF | ├── dev │ ├── prd │ └── stg | ├── dev # 開発環境ルートモジュール │ ├── dev.tfvars │ ├── main.tf │ ├── providers.tf │ ├── tfnotify.yml │ └── variables.tf │ ├── prd # 本番環境ルートモジュール │ ├── prd.tfvars │ ├── main.tf │ ├── providers.tf │ ├── tfnotify.yml │ └── variables.tf │ └── stg # ステージング環境ルートモジュール ├── stg.tfvars ├── main.tf ├── providers.tf ├── tfnotify.yml └── variables.tf リソースのモジュールの構成 　・対象リソース別 一つのリソースの設定が対象のリソースごとに異なる場合，冗長性よりも保守性を重視して，リソースに応じたディレクトリに分割する． terraform_project/ └── modules ├── cloudwatch # CloudWatch │ ├── alb # ALB | ├── cloudfront # CloudFront | ├── ecs # ECS | ├── lambda # Lambda | └── rds # RDS | └── waf # WAF ├── alb # ALB ├── api_gateway # API Gateway └── cloudfront # CloudFront ・稼働環境別 一つのリソースの設定が稼働環境ごとに異なる場合，冗長性よりも保守性を重視して，稼働環境に応じたディレクトリに分割する． terraform_project/ └── modules ├── route53 # Route53 │ ├── dev # 開発 | ├── prd # 本番 | └── stg # ステージング | ├── ssm # SSM | ├── dev | ├── prd | └── stg | └── waf # WAF └── alb ├── dev ├── prd └── stg ・リージョン別 一つのリソースの設定がリージョンごとに異なる場合，冗長性よりも保守性を重視して，リージョンに応じたディレクトリに分割する． terraform_project/ └── modules └── acm # ACM ├── ap-northeast-1 # 東京リージョン └── us-east-1 # バージニアリージョン ・共通セット別 WAFで使用するIPパターンセットと正規表現パターンセットには，CloudFrontタイプとRegionalタイプがある．Regionalタイプは，同じリージョンの異なるAWSリソース間で共通して使用できるため，共通セットとしてディレクトリ分割を行う． terraform_project/ └── modules └── waf # WAF ├── alb ├── api_gateway ├── cloudfront └── regional_sets # Regionalタイプのセット ├── ip_sets # IPセット | ├── prd | └── stg | └── regex_pattern_sets # 正規表現パターンセット ├── prd └── stg ・ファイルの切り分け ポリシーのためにJSONを定義する場合，Terraformのソースコードにハードコーディングせずに，切り分けるようにする．また，「カスタマー管理ポリシー」「インラインポリシー」「信頼ポリシー」も区別し，ディレクトリを分割している．なお，templatefileメソッドでこれを読みこむ時，shellファイルではなく，tplファイルとして定義しておく必要あるため，注意する． terraform_project/ └── modules ├── ecr #ECR │ └── ecr_lifecycle_policy.tpl # ECRライフサイクル │ ├── ecs # ECS │ └── container_definitions.tpl # コンテナ定義 │ ├── iam # IAM │ └── policies | ├── customer_managed_policies # カスタム管理ポリシー | | ├── aws_cli_executor_access_policy.tpl | | ├── aws_cli_executor_access_address_restriction_policy.tpl | | ├── cloudwatch_logs_access_policy.tpl | | └── lambda_edge_execution_policy.tpl | | | ├── inline_policies # インラインポリシー | | └── ecs_task_policy.tpl | | | └── trust_policies # 信頼ポリシー | ├── cloudwatch_events_policy.tpl | ├── ecs_task_policy.tpl | ├── lambda_policy.tpl | └── rds_policy.tpl | └── s3 # S3 └── policies # バケットポリシー └── alb_bucket_policy.tpl CI/CDディレクトリ ・opsディレクトリ TerraformのCI/CDで必要なシェルスクリプトは，opsディレクトリで管理する． terraform_project/ ├── .circleci # CI/CDツールの設定ファイル └── ops # TerraformのCI/CDの自動化シェルスクリプト 02. ルートモジュールにおける実装 tfstateファイル ・tfstateファイルとは 実インフラのインフラの状態が定義されたjsonファイルのこと．初回時，applyコマンドを実行し，成功もしくは失敗したタイミングで生成される． terraform settings ・terraform settingsとは terraformの実行時に，エントリポイントとして機能するファイル． ・required_providers AWSやGCPなど，使用するプロバイダを定義する．プロバイダによって，異なるリソースタイプが提供される．一番最初に読みこまれるファイルのため，変数やモジュール化などが行えない． ＊実装例＊ terraform { required_providers { # awsプロバイダを定義 aws = { # グローバルソースアドレスを指定 source = \"hashicorp/aws\" # プロバイダーのバージョン変更時は initを実行 version = \"3.0\" } } } ・backend stateファイルを管理する場所を設定する．S3などの実インフラで管理する場合，アカウント情報を設定する必要がある．代わりに，initコマンド実行時に指定しても良い．標準値はlocalである．変数を使用できず，ハードコーディングする必要があるため，もし値を動的に変更したい場合は，initコマンドのオプションを使用して値を渡すようにする． 参考：https://www.terraform.io/docs/language/settings/backends/s3.html#credentials-and-shared-configuration ＊実装例＊ terraform { # ローカルPCで管理するように設定 backend \"local\" { path = \"${path.module}/terraform.tfstate\" } } terraform { # S3で管理するように設定 backend \"s3\" { # バケット名 bucket = \"foo-tfstate-bucket\" # stateファイル名 key = \"terraform.tfstate\" region = \"ap-northeast-1\" # credentialsファイルの場所 shared_credentials_file = \"$HOME/.aws/credentials\" # credentialsファイルのプロファイル名 profile = \"bar-profile\" } } どのユーザもバケット内のオブジェクトを削除できないように，ポリシーを設定しておくとよい． ＊実装例＊ { \"Version\": \"2008-10-17\", \"Statement\": [ { \"Effect\": \"Deny\", \"Principal\": \"*\", \"Action\": \"s3:DeleteObject\", \"Resource\": \"arn:aws:s3:::foo-tfstate-bucket/*\" } ] } provider ・providerとは Terraformがリクエストを送信するプロバイダ（AWS，GCP，Azure，など）を選択し，そのプロバイダにおけるアカウント認証を行う．terraform settingsで定義したプロバイダ名を指定する必要がある． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { # awsプロバイダを定義 aws = { # 何らかの設定 } } backend \"s3\" { # 何らかの設定 } } # awsプロバイダを指定 provider \"aws\" { # アカウント認証の設定 } multiple providers ・multiple providersとは 複数のproviderを実装し，エイリアスを使用して，これらを動的に切り替える方法． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } } provider \"aws\" { # 標準値とするリージョン region = \"ap-northeast-1\" } provider \"aws\" { # 別リージョン alias = \"ue1\" region = \"us-east-1\" } ・子モジュールでproviderを切り替える 子モジュールでproviderを切り替えるには，ルートモジュールでproviderの値を明示的に渡す必要がある． ＊実装例＊ module \"route53\" { source = \"../modules/route53\" providers = { aws = aws.ue1 } # その他の設定値 } さらに子モジュールで，providerの値を設定する必要がある． ＊実装例＊ ############################################### # Route53 ############################################### resource \"aws_acm_certificate\" \"example\" { # CloudFrontの仕様のため，us-east-1リージョンでSSL証明書を作成します． provider = aws domain_name = \"example.co.jp\" subject_alternative_names = [\"*.example.co.jp\"] validation_method = \"DNS\" tags = { Name = \"prd-foo-example-cert\" } lifecycle { create_before_destroy = true } } アカウント情報の設定方法 ・ハードコーディングによる設定 リージョンの他，アクセスキーとシークレットキーをハードコーディングで設定する．誤ってコミットしてしまう可能性があるため，ハードコーディングしないようにする． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } backend \"s3\" { bucket = \"foo-tfstate-bucket\" key = \"terraform.tfstate\" region = \"ap-northeast-1\" # アクセスキー access_key = \"*****\" # シークレットアクセスキー secret_key = \"*****\" } } provider \"aws\" { region = \"ap-northeast-1\" # アクセスキー access_key = \"*****\" # シークレットアクセスキー secret_key = \"*****\" } ・credentialsファイルによる設定 　AWSアカウント情報は，~/.aws/credentialsファイルに記載されている． # 標準プロファイル [default] aws_access_key_id=***** aws_secret_access_key=***** # 独自プロファイル [bar-profile] aws_access_key_id=***** aws_secret_access_key=***** credentialsファイルを読み出し，プロファイル名を設定することにより，アカウント情報を参照できる． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } # credentialsファイルから，アクセスキー，シークレットアクセスキーを読み込む backend \"s3\" { # バケット名 bucket = \"foo-tfstate-bucket\" # stateファイル名 key = \"terraform.tfstate\" region = \"ap-northeast-1\" # credentialsファイルの場所 shared_credentials_file = \"$HOME/.aws/credentials\" # credentialsファイルのプロファイル名 profile = \"bar-profile\" } } # credentialsファイルから，アクセスキー，シークレットアクセスキーを読み込む provider \"aws\" { region = \"ap-northeast-1\" profile = \"foo\" shared_credentials_file = \"$HOME/.aws/\" } ・環境変数による設定 Credentialsファイルではなく，exportを使用して，必要な情報を設定しておくことも可能である．参照できる環境変数名は決まっている． # regionの代わり $ export AWS_DEFAULT_REGION=\"ap-northeast-1\" # access_keyの代わり $ export AWS_ACCESS_KEY_ID=\"*****\" # secret_keyの代わり $ export AWS_SECRET_ACCESS_KEY=\"*****\" # profileの代わり $ export AWS_PROFILE=\"bar-profile\" #tokenの代わり（AmazonSTSを使用する場合） $ export AWS_SESSION_TOKEN=\"*****\" 環境変数を設定した上でteraformを実行すると，値がproviderに自動的に出力される．CircleCIのような，一時的に環境変数が必要になるような状況では有効な方法である． terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } # リージョン，アクセスキー，シークレットアクセスキーは不要 backend \"s3\" { bucket = \"\" key = \"\" } } # リージョン，アクセスキー，シークレットアクセスキーは不要 provider \"aws\" {} module ・moduleとは ルートモジュールで子モジュール読み込み，子モジュールに対して変数を渡す． ・実装方法 ＊実装例＊ ############################### # ALB ############################### module \"alb\" { # モジュールのResourceを参照 source = \"../modules/alb\" # モジュールに他のモジュールのアウトプット値を渡す． acm_certificate_api_arn = module.acm.acm_certificate_api_arn } 03. 変数 環境変数 ・優先順位 上の項目ほど優先される． 参考：https://www.terraform.io/docs/language/values/variables.html#variable-definition-precedence ・-var，-var-file $ terraform plan -var=\"foo=foo\" $ terraform plan -var=\"foo=foo\" -var=\"bar=bar\" $ terraform plan -var-file=xxxxx.tfvars ・*.auto.tfvarsファイル，*.auto.tfvars.jsonファイル ・terraform.tfvars.jsonファイル ・terraform.tfvarsファイル #　ファイルを指定しなくとも読み込まれる $ terraform plan ・TF_VAR_XXXXX 環境変数としてエクスポートしておくと自動的に読み込まれる．XXXXXの部分が変数名としてTerraformに渡される． $ printenv TF_VAR_ecr_image_tag=foo tfvarsファイル ・tfvarsファイルの用途 実行ファイルに入力したい環境変数を定義する．『terraform.tfvars』という名前にすると，terraformコマンドの実行時に自動的に読み込まれる．各サービスの間で実装方法が同じため，VPCのみ例を示す． ＊実装例＊ ############################### # VPC ############################### vpc_cidr_block = \"n.n.n.n/n\" # IPv4アドレス範囲 ・値のデータ型 単一値，list型，map型で定義できる．AZ，サブネットのCIDR，RDSのパラメータグループ値，などはmap型として保持しておくとよい．また，IPアドレスのセット，ユーザエージェント，などはlist型として保持しておくとよい．なお，RDSのパラメータグループの適正値については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws.html ＊実装例＊ ############################################### # RDS ############################################### variable \"rds_parameter_group_values\" { type = map(string) } ############################################### # VPC ############################################### variable \"vpc_availability_zones\" { type = map(string) } variable \"vpc_cidr\" { type = string } variable \"vpc_endpoint_port_https\" { type = number } variable \"vpc_subnet_private_datastore_cidrs\" { type = map(string) } variable \"vpc_subnet_private_app_cidrs\" { type = map(string) } variable \"vpc_subnet_public_cidrs\" { type = map(string) } ############################################### # WAF ############################################### variable \"waf_allowed_global_ip_addresses\" { type = list(string) } variable \"waf_blocked_user_agents\" { type = list(string) } ############################################### # RDS ############################################### rds_parameter_group_values = { time_zone = \"asia/tokyo\" character_set_client = \"utf8mb4\" character_set_connection = \"utf8mb4\" character_set_database = \"utf8mb4\" character_set_results = \"utf8mb4\" character_set_server = \"utf8mb4\" server_audit_events = \"connect,query,query_dcl,query_ddl,query_dml,table\" server_audit_logging = 1 server_audit_logs_upload = 1 general_log = 1 slow_query_log = 1 long_query_time = 3 } ############################################### # VPC ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } vpc_cidr = \"n.n.n.n/23\" vpc_subnet_private_datastore_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } vpc_subnet_private_app_cidrs = { a = \"n.n.n.n/25\", c = \"n.n.n.n/25\" } vpc_subnet_public_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } ############################################### # WAF ############################################### waf_allowed_global_ip_addresses = [ \"n.n.n.n/32\", \"n.n.n.n/32\", ] waf_blocked_user_agents = [ \"XXXXX\", \"YYYYY\" ] variable ・variableとは リソースで使用する変数のデータ型を定義する． ＊実装例＊ ############################################### # ECS ############################################### variable \"ecs_container_laravel_port_http\" { type = number } variable \"ecs_container_nginx_port_http\" { type = number } ############################################### # RDS ############################################### variable \"rds_auto_minor_version_upgrade\" { type = bool } variable \"rds_instance_class\" { type = string } variable \"rds_parameter_group_values\" { type = map(string) } 04. リソースの実装 resource ・resourceとは AWSのAPIに対してリクエストを送信し，クラウドインフラの構築を行う． ・実装方法 ＊実装例＊ ############################################### # ALB ############################################### resource \"aws_lb\" \"this\" { name = \"prd-foo-alb\" load_balancer_type = \"application\" security_groups = [\"*****\"] subnets = [\"*****\",\"*****\"] } data ・dataとは AWSのAPIに対してリクエストを送信し，クラウドインフラに関するデータを取得する．ルートモジュールに実装することも可能であるが，各モジュールに実装した方が分かりやすい． ・実装方法 ＊実装例＊ 例として，タスク定義名を指定して，AWSから ############################################### # ECS task definition ############################################### data \"aws_ecs_task_definition\" \"this\" { task_definition = \"prd-foo-ecs-task-definition\" } ＊実装例＊ 例として，AMIをフィルタリングした上で，AWSから特定のAMIの値を取得する． ############################################### # AMI ############################################### data \"aws_ami\" \"bastion\" { most_recent = true owners = [\"amazon\"] filter { name = \"architecture\" values = [\"x86_64\"] } filter { name = \"root-device-type\" values = [\"ebs\"] } filter { name = \"name\" values = [\"amzn-ami-hvm-*\"] } filter { name = \"virtualization-type\" values = [\"hvm\"] } filter { name = \"block-device-mapping.volume-type\" values = [\"gp2\"] } } output ・outputとは モジュールで構築されたリソースがもつ特定の値を出力する．可読性の観点から，リソース一括ではなく，具体的なattributeをアウトプットする． ・実装方法 ＊実装例＊ 例として，ALBを示す．resourceブロックとdataブロックでアウトプットの方法が異なる． ############################################### # ALB ############################################### output \"alb_zone_id\" { value = aws_lb.this.zone_id } output \"elb_service_account_arn\" { value = data.aws_elb_service_account.this.arn } ・count関数のアウトプット 後述の説明を参考にせよ． ・for_each関数のアウトプット 後述の説明を参考にせよ． 05. メタ引数 メタ引数とは 全てのリソースで使用できるオプションのこと． depends_on ・depends_onとは リソース間の依存関係を明示的に定義する．Terraformでは，基本的にリソース間の依存関係が暗黙的に定義されている．しかし，複数のリソースが関わると，リソースを適切な順番で構築できない場合があるため，そういったときに使用する． ・ALB target group vs. ALB，ECS 例として，ALB target groupを示す．ALB Target groupとALBのリソースを適切な順番で構築できないため，ECSの構築時にエラーが起こる．ALBの後にALB target groupを構築する必要がある． ＊実装例＊ ############################################### # ALB target group ############################################### resource \"aws_lb_target_group\" \"this\" { name = \"prd-foo-alb-tg\" port = 80 protocol = \"HTTP\" vpc_id = \"*****\" deregistration_delay = \"60\" target_type = \"ip\" slow_start = \"60\" health_check { interval = 30 path = \"/healthcheck\" protocol = \"HTTP\" timeout = 5 unhealthy_threshold = 2 matcher = 200 } depends_on = [aws_lb.this] } ・Internet Gateway vs. EC2，Elastic IP，NAT Gateway 例として，NAT Gatewayを示す．NAT Gateway，Internet Gateway，のリソースを適切な順番で構築できないため，Internet Gatewayの構築後に，NAT Gatewayを構築するように定義する必要がある． ############################################### # EC2 ############################################### resource \"aws_instance\" \"bastion\" { ami = \"*****\" instance_type = \"t2.micro\" vpc_security_group_ids = [\"*****\"] subnet_id = \"*****\" key_name = \"prd-foo-bastion\" associate_public_ip_address = true disable_api_termination = true tags = { Name = \"prd-foo-bastion\" } depends_on = [var.internet_gateway] } ############################################### # Elastic IP ############################################### resource \"aws_eip\" \"nat_gateway\" { for_each = var.vpc_availability_zones vpc = true tags = { Name = format( \"prd-foo-ngw-%s-eip\", each.value ) } depends_on = [aws_internet_gateway.this] } ############################################### # NAT Gateway ############################################### resource \"aws_nat_gateway\" \"this\" { for_each = var.vpc_availability_zones subnet_id = aws_subnet.public[each.key].id allocation_id = aws_eip.nat_gateway[each.key].id tags = { Name = format( \"prd-foo-%s-ngw\", each.value ) } depends_on = [aws_internet_gateway.this] } ・S3バケットポリシー vs. パブリックアクセスブロックポリシー 例として，S3を示す．バケットポリシーとパブリックアクセスブロックポリシーを同時に構築できないため，構築のタイミングが重ならないようにする必要がある． ############################################### # S3 ############################################### # foo bucket resource \"aws_s3_bucket\" \"foo\" { bucket = \"prd-foo-foo-bucket\" acl = \"private\" } # Public access block resource \"aws_s3_bucket_public_access_block\" \"foo\" { bucket = aws_s3_bucket.foo.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # Bucket policy attachment resource \"aws_s3_bucket_policy\" \"foo\" { bucket = aws_s3_bucket.foo.id policy = templatefile( \"${path.module}/policies/foo_bucket_policy.tpl\", { foo_s3_bucket_arn = aws_s3_bucket.foo.arn s3_cloudfront_origin_access_identity_iam_arn = var.s3_cloudfront_origin_access_identity_iam_arn } ) depends_on = [aws_s3_bucket_public_access_block.foo] } count ・countとは 指定した数だけ，リソースの構築を繰り返す．count.indexでインデックス数を出力する． ＊実装例＊ ############################################### # EC2 ############################################### resource \"aws_instance\" \"server\" { count = 4 ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" tags = { Name = \"ec2-${count.index}\" } } ・list型でアウトプット リソースの構築にcount関数を使用した場合，そのリソースはlist型として扱われる．そのため，キー名を指定してアウトプットできる．この時，アウトプットはlist型になる．ちなみに，for_each関数で構築したリソースはアスタリスクでインデックス名を指定できないので，注意． ＊実装例＊ 例として，VPCのサブネットを示す．ここでは，パブリックサブネット，applicationサブネット，datastoreサブネット，をcount関数で構築したとする． ############################################### # Public subnet ############################################### resource \"aws_subnet\" \"public\" { count = 2 # ～ 省略 ～ } ############################################### # Private subnet ############################################### resource \"aws_subnet\" \"private_app\" { count = 2 # ～ 省略 ～ } resource \"aws_subnet\" \"private_datastore\" { count = 2 # ～ 省略 ～ } ############################################### # Output VPC ############################################### output \"public_subnet_ids\" { value = aws_subnet.public[*].id } output \"private_app_subnet_ids\" { value = aws_subnet.private_app[*].id } output \"private_datastore_subnet_ids\" { value = aws_subnet.private_datastore[*].id } for_each ・for_eachとは 事前にfor_eachに格納したmap型のkeyの数だけ，リソースを繰り返し実行する．繰り返し処理を行う時に，countとは違い，要素名を指定して出力できる． ＊実装例＊ 例として，subnetを繰り返し構築する． ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } vpc_cidr = \"n.n.n.n/23\" vpc_subnet_private_datastore_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } vpc_subnet_private_app_cidrs = { a = \"n.n.n.n/25\", c = \"n.n.n.n/25\" } vpc_subnet_public_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } ############################################### # Public subnet ############################################### resource \"aws_subnet\" \"public\" { for_each = var.vpc_availability_zones vpc_id = aws_vpc.this.id cidr_block = var.vpc_subnet_public_cidrs[each.key] availability_zone = \"${var.region}${each.value}\" map_public_ip_on_launch = true tags = { Name = format( \"prd-foo-pub-%s-subnet\", each.value ) } } ・冗長化されたAZにおける設定 冗長化されたAZで共通のルートテーブルを構築する場合，そこで，for_each関数を使用すると，少ない実装で構築できる．for_each関数で構築されたリソースはapply中にmap構造として扱われ，リソース名の下層にキー名でリソースが並ぶ構造になっている．これを参照するために，『.[each.key].』とする ＊実装例＊ パブリックサブネット，プライベートサブネット，プライベートサブネットに紐づくNAT Gatewayの設定が冗長化されたAZで共通の場合，for_each関数で構築する． ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } ############################################### # Internet Gateway ############################################### resource \"aws_internet_gateway\" \"this\" { vpc_id = aws_vpc.this.id tags = { Name = \"prd-foo-igw\" } } ############################################### # Route table (public) ############################################### resource \"aws_route_table\" \"public\" { vpc_id = aws_vpc.this.id route { cidr_block = \"0.0.0.0/0\" gateway_id = aws_internet_gateway.this.id } tags = { Name = \"prd-foo-pub-rtb\" } } ############################################### # Route table (private) ############################################### resource \"aws_route_table\" \"private_app\" { for_each = var.vpc_availability_zones vpc_id = aws_vpc.this.id route { cidr_block = \"0.0.0.0/0\" nat_gateway_id = aws_nat_gateway.this[each.key].id } tags = { Name = format( \"prd-foo-pvt-%s-app-rtb\", each.value ) } } ############################################### # NAT Gateway ############################################### resource \"aws_nat_gateway\" \"this\" { for_each = var.vpc_availability_zones subnet_id = aws_subnet.public[each.key].id allocation_id = aws_eip.nat_gateway[each.key].id tags = { Name = format( \"prd-foo-%s-ngw\", each.value ) } depends_on = [aws_internet_gateway.this] } ・単一値でアウトプット リソースの構築にfor_each関数を使用した場合，そのリソースはmap型として扱われる．そのため，キー名を指定してアウトプットできる． ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } ############################################### # Output VPC ############################################### output \"public_a_subnet_id\" { value = aws_subnet.public[var.vpc_availability_zones.a].id } output \"public_c_subnet_id\" { value = aws_subnet.public[var.vpc_availability_zones.c].id } ・map型でアウトプット ＊実装例＊ ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } ############################################### # Output VPC ############################################### output \"public_subnet_ids\" { value = { a = aws_subnet.public[var.vpc_availability_zones.a].id, c = aws_subnet.public[var.vpc_availability_zones.c].id } } output \"private_app_subnet_ids\" { value = { a = aws_subnet.private_app[var.vpc_availability_zones.a].id, c = aws_subnet.private_app[var.vpc_availability_zones.c].id } } output \"private_datastore_subnet_ids\" { value = { a = aws_subnet.private_datastore[var.vpc_availability_zones.a].id, c = aws_subnet.private_datastore[var.vpc_availability_zones.c].id } } ############################################### # ALB ############################################### resource \"aws_lb\" \"this\" { name = \"prd-foo-alb\" subnets = values(private_app_subnet_ids) security_groups = [var.alb_security_group_id] internal = false idle_timeout = 120 enable_deletion_protection = true access_logs { enabled = true bucket = var.alb_s3_bucket_id } } dynamic ・dynamicとは 指定したブロックを繰り返し構築する． ＊実装例＊ 例として，RDSパラメータグループのparameterブロックを，map型変数を使用して繰り返し構築する． ############################################### # Variables ############################################### rds_parameter_group_values = { time_zone = \"asia/tokyo\" character_set_client = \"utf8mb4\" character_set_connection = \"utf8mb4\" character_set_database = \"utf8mb4\" character_set_results = \"utf8mb4\" character_set_server = \"utf8mb4\" server_audit_events = \"connect,query,query_dcl,query_ddl,query_dml,table\" server_audit_logging = 1 server_audit_logs_upload = 1 general_log = 1 slow_query_log = 1 long_query_time = 3 } ############################################### # RDS Cluster Parameter Group ############################################### resource \"aws_rds_cluster_parameter_group\" \"this\" { name = \"prd-foo-cluster-pg\" description = \"The cluster parameter group for prd-foo-rds\" family = \"aurora-mysql5.7\" dynamic \"parameter\" { for_each = var.rds_parameter_group_values content { name = parameter.key value = parameter.value } } } ＊実装例＊ 例として，WAFの正規表現パターンセットのregular_expressionブロックを，list型変数を使用して繰り返し構築する． ############################################### # Variables ############################################### waf_blocked_user_agents = [ \"FooCrawler\", \"BarSpider\", \"BazBot\", ] ############################################### # WAF Regex Pattern Sets ############################################### resource \"aws_wafv2_regex_pattern_set\" \"cloudfront\" { name = \"blocked-user-agents\" description = \"Blocked user agents\" scope = \"CLOUDFRONT\" dynamic \"regular_expression\" { for_each = var.waf_blocked_user_agents content { regex_string = regular_expression.value } } } lifecycle ・lifecycleとは リソースの構築，更新，そして削除のプロセスをカスタマイズする． ・create_before_destroy リソースを新しく構築した後に削除するように，変更できる．通常時，Terraformの処理順序として，リソースの削除後に構築が行われる．しかし，他のリソースと依存関係が存在する場合，先に削除が行われることによって，他のリソースに影響が出てしまう．これに対処するために，先に新しいリソースを構築し，紐づけし直してから，削除する必要がある． ＊実装例＊ 例として，ACM証明書を示す．ACM証明書は，ALBやCloudFrontに関連付いており，新しい証明書に関連付け直した後に，既存のものを削除する必要がある． ############################################### # For foo domain ############################################### resource \"aws_acm_certificate\" \"foo\" { # ～ 省略 ～ # 新しい証明書を構築した後に削除する． lifecycle { create_before_destroy = true } } ＊実装例＊ 例として，RDSのクラスターパラメータグループとサブネットグループを示す．クラスターパラメータグループとサブネットグループは，RDSに関連付いており，新しいクラスターパラメータグループに関連付け直した後に，既存のものを削除する必要がある． ############################################### # RDS Cluster Parameter Group ############################################### resource \"aws_rds_cluster_parameter_group\" \"this\" { # ～ 省略 ～ lifecycle { create_before_destroy = true } } ############################################### # RDS Subnet Group ############################################### resource \"aws_db_subnet_group\" \"this\" { # ～ 省略 ～ lifecycle { create_before_destroy = true } ＊実装例＊ 例として，Redisのパラメータグループとサブネットグループを示す．ラメータグループとサブネットグループは，RDSに関連付いており，新しいパラメータグループとサブネットグループに関連付け直した後に，既存のものを削除する必要がある． ############################################### # Redis Parameter Group ############################################### resource \"aws_elasticache_parameter_group\" \"redis\" { # ～ 省略 ～ lifecycle { create_before_destroy = true } } ############################################### # Redis Subnet Group ############################################### resource \"aws_elasticache_subnet_group\" \"redis\" { # ～ 省略 ～ lifecycle { create_before_destroy = true } } ・ignore_changes 実インフラのみで起こったリソースの構築・更新・削除を無視し，tfstateファイルに反映しないようにする．これにより，オプションをignore_changesしたタイミング以降，実インフラとtfstateファイルに差分があっても，tfstateファイルの値が更新されなくなる．一つのテクニックとして，機密情報をignore_changesに指定し，tfstateファイルへの書き込みを防ぐ方法がある． ＊実装例＊ 例として，ECSを示す．ECSでは，AutoScalingによってタスク数が増加する．そのため，これらを無視する必要がある． ############################################### # ECS Service ############################################### resource \"aws_ecs_service\" \"this\" { # ～ 省略 ～ lifecycle { ignore_changes = [ # AutoScalingによるタスク数の増減を無視． desired_count, ] } } ＊実装例＊ 例として，Redisを示す．Redisでは，AutoScalingによってプライマリ数とレプリカ数が増減する．そのため，これらを無視する必要がある． ############################################### # Redis Cluster ############################################### resource \"aws_elasticache_replication_group\" \"redis\" { # ～ 省略 ～ lifecycle { ignore_changes = [ # プライマリ数とレプリカ数の増減を無視します． number_cache_clusters ] } } } ＊実装例＊ 使用例はすくないが，ちなみにリソース全体を無視する場合はallを設定する． resource \"aws_foo\" \"foo\" { # ～ 省略 ～ lifecycle { ignore_changes = all } } 06. tpl形式の切り出しと読み出し templatefile関数 ・templatefile関数とは 第一引数でポリシーが定義されたファイルを読み出し，第二引数でファイルに変数を渡す．ファイルの拡張子はtplとするのがよい． ＊実装例＊ 例として，S3を示す． ############################################### # S3 bucket policy ############################################### resource \"aws_s3_bucket_policy\" \"alb\" { bucket = aws_s3_bucket.alb_logs.id policy = templatefile( \"${path.module}/policies/alb_bucket_policy.tpl\", { aws_elb_service_account_arn = var.aws_elb_service_account_arn aws_s3_bucket_alb_logs_arn = aws_s3_bucket.alb_logs.arn } ) } バケットポリシーを定義するtpl形式ファイルでは，string型で出力する場合は\"${}\"で，int型で出力する場合は${}で出力する．ここで拡張子をjsonにしてしまうと，int型の出力をjsonの構文エラーとして扱われてしまう． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"${aws_elb_service_account_arn}/*\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"${aws_s3_bucket_alb_logs_arn}/*\" } ] } ポリシーのアタッチ containerDefinitionsの設定 ・containerDefinitionsとは タスク定義のうち，コンテナを定義する部分のこと． ＊実装例＊ { \"ipcMode\": null, \"executionRoleArn\": \"\", \"containerDefinitions\": [ ], ~ ~ ~ その他の設定 ~ ~ ~ } ・設定方法 int型を変数として渡せるように，拡張子をjsonではなくtplとするのが良い．imageキーでは，ECRイメージのURLを指定する．イメージタグは任意で指定でき，もし指定しない場合は，『latest』という名前のタグが自動的に割り当てられる．イメージタグにハッシュ値が割り当てられている場合，Terraformでは時系列で最新のタグ名を取得する方法がないため，，secretsキーでは，SSMのパラメータストアの値を参照できる．ログ分割の目印を設定するawslogs-datetime-formatキーでは，タイムスタンプを表す\\\\[%Y-%m-%d %H:%M:%S\\\\]を設定すると良い．これにより，同じ時間に発生したログを一つのログとしてまとめることができるため，スタックトレースが見やすくなる． ＊実装例＊ [ { # コンテナ名 \"name\": \"laravel\", # ECRのURL．タグを指定しない場合はlatestが割り当てられる． \"image\": \"*****.dkr.ecr.ap-northeast-1.amazonaws.com/prd-foo-laravel-repository\", \"essential\": true, \"portMappings\": [ { \"containerPort\": 80, \"hostPort\": 80, \"protocol\": \"tcp\" } ], \"secrets\": [ { # アプリケーションの環境変数名 \"name\": \"DB_HOST\", # SSMのパラメータ名 \"valueFrom\": \"/prd-foo/DB_HOST\" }, { \"name\": \"DB_DATABASE\", \"valueFrom\": \"/prd-foo/DB_DATABASE\" }, { \"name\": \"DB_PASSWORD\", \"valueFrom\": \"/prd-foo/DB_PASSWORD\" }, { \"name\": \"DB_USERNAME\", \"valueFrom\": \"/prd-foo/DB_USERNAME\" }, { \"name\": \"REDIS_HOST\", \"valueFrom\": \"/prd-foo/REDIS_HOST\" }, { \"name\": \"REDIS_PASSWORD\", \"valueFrom\": \"/prd-foo/REDIS_PASSWORD\" }, { \"name\": \"REDIS_PORT\", \"valueFrom\": \"/prd-foo/REDIS_PORT\" } ], \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { # ロググループ名 \"awslogs-group\": \"/prd-foo/laravel/log\", # スタックトレースのグループ化（同時刻ログのグループ化） \"awslogs-datetime-format\": \"\\\\[%Y-%m-%d %H:%M:%S\\\\]\", # リージョン \"awslogs-region\": \"ap-northeast-1\", # ログストリーム名のプレフィクス \"awslogs-stream-prefix\": \"/container\" } } } ] 07. 命名規則 module AWSリソースのアルファベット順にmoduleを並べる．また，変数やアウトプット値をモジュールに渡す時もAWSリソースのアルファベット順とする． 変数の命名 ・単数形と複数形の命名分け 複数の値をもつlist型の変数であれば複数形で命名する．一方で，string型など値が一つしかなければ単数形とする． ＊実装例＊ 例として，VPCを示す． ############################################### # VPC variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } vpc_cidr = \"n.n.n.n/23\" vpc_subnet_private_datastore_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } vpc_subnet_private_app_cidrs = { a = \"n.n.n.n/25\", c = \"n.n.n.n/25\" } vpc_subnet_public_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } 環境変数の命名 AWSリソースのアルファベット順に環境変数を並べる，環境変数の名前は，使用するAWSリソースの名前を最初につけるようにする．list型またはmap型であれば複数形，それ以外であれば単数形とする． ############################################### # Route53 ############################################### # ～ 省略 ～ ############################################### # VPC ############################################### # ～ 省略 ～ ############################################### # WAF ############################################### waf_blocked_user_agents = [ \"AdCrawler\", ] 複数のAWSリソースで使用する場合は，『General』とし，グローバルな名前にする． ############################################### # General ############################################### camel_case_prefix = \"Bar\" region = \"ap-northeast-1\" environment = \"stg\" service = \"bar\" リソースとデータリソースの命名 ・リソース名で種類を表現 リソース名において，リソースタイプを繰り返さないようにする．もし種類がある場合，リソース名でその種類を表現する． ＊実装例＊ 例として，VPCを示す． ############################################### # VPC route table ############################################### # 良い例 resource \"aws_route_table\" \"public\" { } resource \"aws_route_table\" \"private\" { } ############################################### # VPC route table ############################################### # 悪い例 resource \"aws_route_table\" \"route_table_public\" { } resource \"aws_route_table\" \"route_table_private\" { } ・this 一つのリソースタイプに，一つのリソースしか種類が存在しない場合，thisで命名する．ただし，後から種類が増えることがよくあるため，非推奨である． ＊実装例＊ resource \"aws_internet_gateway\" \"this\" { } ・AWSリソース名 --とする． 接頭辞は， -とする． 接尾辞は，AWSリソース名とする． ＊実装例＊ 例として，CloudWatchを示す．この時，他のresourceと比較して，種類はALBのHTTPCode_TARGET_4XX_Countメトリクスに関するアラームと見なせる．そのため，alb_httpcode_4xx_countと名付けている． resource \"aws_cloudwatch_metric_alarm\" \"alb_httpcode_target_4xx_count\" { alarm_name = \"prd-foo-alb-httpcode-target-4xx-count-alarm\" } ・設定の順序，行間 最初にcountやfor_eachを設定し改行する．その後，各リソース別の設定を行間を空けずに記述する（この順番にルールはなし）．最後に共通の設定として，tags，depends_on，lifecycle，の順で配置する．ただし実際，これらの全ての設定が必要なリソースはない． ＊実装例＊ ############################################### # EXAMPLE ############################################### resource \"aws_baz\" \"this\" { for_each = var.vpc_availability_zones # 最初にfor_each # スペース subnet_id = aws_subnet.public[*].id # 各設定（順番にルールなし） # スペース tags = { Name = format( \"prd-foo-%d-baz\", each.value ) } # スペース depends_on = [] # スペース lifecycle { create_before_destroy = true } } アウトプット値の命名 ・基本ルール アウトプット値の名前は，『__』で命名する． ＊実装例＊ 例として，CloudWatchを示す．リソース名はecs_container_nginx，リソースタイプはaws_cloudwatch_log_group，attributeはnameオプションである． output \"ecs_container_nginx_cloudwatch_log_group_name\" { value = aws_cloudwatch_log_group.ecs_container_nginx.name } ＊実装例＊ 例として，IAM Roleを示す． ############################################### # Output IAM Role ############################################### output \"ecs_task_execution_iam_role_arn\" { value = aws_iam_role.ecs_task_execution.arn } output \"lambda_execute_iam_role_arn\" { value = aws_iam_role.lambda_execute.arn } output \"rds_enhanced_monitoring_iam_role_arn\" { value = aws_iam_role.rds_enhanced_monitoring.arn } ・thisは省略 リソース名がthisである場合，アウトプット値名ではこれを省略してもよい． ＊実装例＊ 例として，ALBを示す． ############################################### # Output ALB ############################################### output \"alb_zone_id\" { value = aws_lb.this.zone_id } output \"alb_dns_name\" { value = aws_lb.this.dns_name } ・冗長なattribute名は省略 ＊実装例＊ 例として，ECRを示す． ############################################### # Output ECR ############################################### output \"laravel_ecr_repository_url\" { value = aws_ecr_repository.laravel.repository_url } output \"nginx_ecr_repository_url\" { value = aws_ecr_repository.nginx.repository_url } 08. 各リソースタイプ独自の仕様 AMI ・まとめ ＊実装例＊ ############################################### # For bastion ############################################### data \"aws_ami\" \"bastion\" { # 後述の説明を参考にせよ．（１） most_recent = false # 後述の説明を参考にせよ．（１） owners = [\"amazon\"] filter { name = \"name\" values = [\"amzn-ami-hvm-2018.03.0.20201028.0-x86_64-gp2\"] } filter { name = \"image-id\" values = [\"ami-040c9333a9c90b2b6\"] } } （１）取得するAMIのバージョンを固定 取得するAMIが常に最新になっていると，EC2が再構築されなねない．そこで，特定のAMIを取得できるようにしておく．most_recentは無効化しておき，特定のAMをフィルタリングする． API Gateway ・まとめ ＊実装例＊ ############################################### # REST API ############################################### resource \"aws_api_gateway_rest_api\" \"foo\" { name = \"prd-foo-api-for-foo\" description = \"The API that enables two-way communication with prd-foo\" # VPCリンクのプロキシ統合のAPIを定義したOpenAPI仕様 # 後述の説明を参考にせよ．（１） body = templatefile( \"${path.module}/open_api.yaml\", { api_gateway_vpc_link_foo_id = aws_api_gateway_vpc_link.foo.id nlb_dns_name = var.nlb_dns_name } ) endpoint_configuration { types = [\"REGIONAL\"] } lifecycle { ignore_changes = [ policy ] } } ############################################### # Deployment ############################################### resource \"aws_api_gateway_deployment\" \"foo\" { rest_api_id = aws_api_gateway_rest_api.foo.id # 後述の説明を参考にせよ．（１） triggers = { redeployment = sha1(aws_api_gateway_rest_api.foo.body) } lifecycle { create_before_destroy = true } } ############################################### # Stage ############################################### resource \"aws_api_gateway_stage\" \"foo\" { deployment_id = aws_api_gateway_deployment.foo.id rest_api_id = aws_api_gateway_rest_api.foo.id stage_name = var.environment } （１）OpenAPI仕様のインポートと差分認識 あらかじめ用意したOpenAPI仕様のYAMLファイルをbodyオプションのパラメータとし，これをインポートすることにより，APIを定義できる．YAMLファイルに変数を渡すこともできる．APIの再デプロイのトリガーとして，redeploymentパラメータにbodyパラメータのハッシュ値を渡すようにする．これにより，インポート元のYAMLファイルに差分があった場合に，Terraformがredeploymentパラメータの値の変化を認識できるようになり，再デプロイを実行できる． （※）ステージ名を取得する方法はない API Gatewayのステージ名を参照するためには，resourceを使用する必要があり，dataではこれを取得することができない．もしステージをコンソール画面上から構築している場合，ステージのARNを参照することができないため，ARNを自力で作る必要がある．API Gatewayの各ARNについては，以下を参考にせよ． https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/arn-format-reference.html ＊実装例＊ WAFにAPI Gatewayを関連づけるために，ステージのARNが必要である．これは自力で作る． ############################################### # Web ACL Association ############################################### resource \"aws_wafv2_web_acl_association\" \"api_gateway\" { resource_arn = \"${var.api_gateway_rest_arn}/stages/prd\" web_acl_arn = aws_wafv2_web_acl.api_gateway.arn } CloudFront ・まとめ ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { price_class = \"PriceClass_200\" web_acl_id = var.cloudfront_wafv2_web_acl_arn aliases = [var.route53_domain_foo] comment = \"prd-foo-cf-distribution\" enabled = true # 後述の説明を参考にせよ．（１） retain_on_delete = true viewer_certificate { acm_certificate_arn = var.foo_acm_certificate_arn ssl_support_method = \"sni-only\" minimum_protocol_version = \"TLSv1.2_2019\" } logging_config { bucket = var.cloudfront_s3_bucket_regional_domain_name include_cookies = true } restrictions { geo_restriction { restriction_type = \"none\" } } # ～ 省略 ～ } （１）削除保持機能 Terraformでは，retain_on_deleteで設定できる．固有の設定で，AWSに対応するものは無い． ・originブロック Origins画面に設定するオリジンを定義する． ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { # ～ 省略 ～ # オリジン（ここではS3としている） origin { domain_name = var.s3_bucket_regional_domain_name origin_id = \"S3-${var.s3_bucket_id}\" s3_origin_config { origin_access_identity = aws_cloudfront_origin_access_identity.s3_foo.cloudfront_access_identity_path } } # ～ 省略 ～ } resource \"aws_cloudfront_distribution\" \"this\" { # ～ 省略 ～ # オリジン（ここではALBとしている） origin { domain_name = var.alb_dns_name origin_id = \"ELB-${var.alb_name}\" custom_origin_config { origin_ssl_protocols = [\"TLSv1.2\"] origin_protocol_policy = \"match-viewer\" origin_read_timeout = 30 origin_keepalive_timeout = 5 http_port = var.alb_listener_port_http https_port = var.alb_listener_port_https } } # ～ 省略 ～ } ・ordered_cache_behaviorブロック Behavior画面に設定するオリジンにルーティングするパスを定義する． ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { # ～ 省略 ～ ordered_cache_behavior { path_pattern = \"/images/*\" target_origin_id = \"S3-${var.s3_bucket_id}\" viewer_protocol_policy = \"redirect-to-https\" allowed_methods = [\"GET\", \"HEAD\", \"OPTIONS\", \"PUT\", \"POST\", \"PATCH\", \"DELETE\"] cached_methods = [\"GET\", \"HEAD\"] min_ttl = 0 max_ttl = 31536000 default_ttl = 86400 compress = true forwarded_values { query_string = true cookies { forward = \"none\" } } } # ～ 省略 ～ } ・default_cache_behavior Behavior画面に設定するオリジンにルーティングする標準パスを定義する． ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { default_cache_behavior { target_origin_id = \"ELB-${var.alb_name}\" viewer_protocol_policy = \"redirect-to-https\" allowed_methods = [\"GET\", \"HEAD\", \"OPTIONS\", \"PUT\", \"POST\", \"PATCH\", \"DELETE\"] cached_methods = [\"GET\", \"HEAD\"] min_ttl = 0 max_ttl = 31536000 default_ttl = 86400 compress = true forwarded_values { query_string = true headers = [\"*\"] cookies { forward = \"all\" } } } # ～ 省略 ～ } ECR ・ライフサイクルポリシー ECRにアタッチされる，イメージの有効期間を定義するポリシー．コンソール画面から入力できるため，基本的にポリシーの実装は不要であるが，TerraformなどのIaCツールでは必要になる． { \"rules\": [ { \"rulePriority\": 1, \"description\": \"Keep last 10 images untagged\", \"selection\": { \"tagStatus\": \"untagged\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } }, { \"rulePriority\": 2, \"description\": \"Keep last 10 images any\", \"selection\": { \"tagStatus\": \"any\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } } ] } ECS ・まとめ ＊実装例＊ ############################################### # ECS Service ############################################### resource \"aws_ecs_service\" \"this\" { name = \"prd-foo-ecs-service\" cluster = aws_ecs_cluster.this.id launch_type = \"FARGATE\" platform_version = \"1.4.0\" desired_count = var.ecs_service_desired_count deployment_maximum_percent = 200 deployment_minimum_healthy_percent = 100 # 後述の説明を参考にせよ．（１） health_check_grace_period_seconds = 330 # 後述の説明を参考にせよ．（２） task_definition = \"${aws_ecs_task_definition.this.family}:${max(aws_ecs_task_definition.this.revision, data.aws_ecs_task_definition.this.revision)}\" network_configuration { security_groups = [var.ecs_security_group_id] subnets = [var.private_a_app_subnet_id, var.private_c_app_subnet_id] assign_public_ip = false } load_balancer { target_group_arn = var.alb_target_group_arn container_name = \"nginx\" container_port = 80 } load_balancer { target_group_arn = var.nlb_target_group_arn container_name = \"nginx\" container_port = 80 } depends_on = [ # 後述の説明を参考にせよ．（３） var.alb_listener_https, var.nlb_listener ] lifecycle { ignore_changes = [ # ※後述の説明を参考にせよ（４） desired_count, ] } } （１）ヘルスチェック猶予期間 タスクの起動が完了する前にサービスがロードバランサ－のヘルスチェックを検証し，Unhealthyと誤認してしまうため，タスクの起動完了を待機する．例えば，ロードバランサ－が30秒間隔でヘルスチェックを実行する場合は，30秒単位で待機時間を増やし，適切な待機時間を見つけるようにする． （２）実インフラのリビジョン番号の追跡 アプリケーションのデプロイによって，実インフラのタスク定義のリビジョン番号が増加するため，これを追跡できるようにする． 参考：https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ecs_task_definition （３）ALB/NLBリスナーの構築を待機 Teraformは，特に依存関係を実装しない場合に，『ターゲットグループ → ALB/NLB → リスナー』の順でリソースを構築する．問題として，ALB/NLBやリスナーの構築が終わる前に，ECSサービスの構築が始まってしまう．ALB/NLBの構築（※リスナーも含む可能性）が完全に完了しない状態では，ターゲットグループはECSサービスに関連付けらず，これが完了する前にECSサービスがターゲットグループを参照しようとするため，エラーになる．リスナーの後にECSサービスを構築するようにし，『ターゲットグループ → ALB/NLB → リスナー → ECSサービス』の順でリソースを構築できるようにする． 参考：https://github.com/hashicorp/terraform/issues/12634#issuecomment-313215022 （４）AutoScalingによるタスク数の増減を無視 AutoScalingによって，タスク数が増減するため，これを無視する． （※）タスク定義の更新 Terraformでタスク定義を更新すると，現在動いているECSで稼働しているタスクはそのままに，新しいリビジョン番号のタスク定義が作成される．コンソール画面の「新しいリビジョンの作成」と同じ挙動である．実際にタスクが増えていることは，サービスに紐づくタスク定義一覧から確認できる．次のデプロイ時に，このタスクが用いられる． （※）サービスのデプロイの削除時間 ECSサービスの削除には『ドレイニング』の時間が発生する．約2分30秒かかるため，気長に待つこと． （※）ローリングアップデート applyで，新しいリビジョン番号のタスク定義を作成すると，これを用いてローリングアップデートが自動で実行されることに注意する．ただ，ローリングアップデートの仕組み上，新しいタスクのヘルスチェックが失敗すれば，既存のタスクは停止せずにそのまま稼働するため，安心ではあるが．．． EC2 ・まとめ ＊実装例＊ ############################################### # For bastion ############################################### resource \"aws_instance\" \"bastion\" { ami = \"*****\" instance_type = \"t2.micro\" vpc_security_group_ids = [\"*****\"] subnet_id = \"*****\" associate_public_ip_address = true # ※後述の説明を参考にせよ（１） key_name = \"prd-foo-bastion\" disable_api_termination = true tags = { Name = \"prd-foo-bastion\" } # ※後述の説明を参考にせよ（２） depends_on = [var.internet_gateway] } （１）キーペアはコンソール上で設定 誤って削除しないように，またソースコードに機密情報をハードコーディングしないように，キーペアはコンソール画面で作成した後，key_nameでキー名を指定するようにする． （２）インターネットゲートウェイの後に構築 インターネットゲートウェイの後にEC2を構築できるようにする． 参考：https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway#argument-reference IAMユーザ ・カスタマー管理ポリシーを持つロール 事前に，tpl形式のカスタマー管理ポリシーを定義しておく．構築済みのIAMロールに，aws_iam_policyリソースを使用して，AWS管理ポリシーをIAMユーザにアタッチする． ＊実装例＊ ローカルからAWS CLIコマンドを実行する必要がある場合に，コマンドを特定の送信元IPアドレスを特定のものに限定する．事前に，list型でIPアドレスを定義する． ############################################### # IP addresses ############################################### global_ip_addresses = [ \"nn.nnn.nnn.nnn/32\", \"nn.nnn.nnn.nnn/32\" ] また事前に，指定した送信元IPアドレス以外を拒否するカスタマー管理ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Deny\", \"Action\": \"*\", \"Resource\": \"*\", \"Condition\": { \"NotIpAddress\": { \"aws:SourceIp\": ${global_ip_addresses} } } } } コンソール画面で作成済みのIAMユーザの名前を取得する．tpl形式のポリシーにlist型の値を渡す時，jsonencode関数を使用する必要がある． ############################################### # For IAM User ############################################### data \"aws_iam_user\" \"aws_cli_command_executor\" { user_name = \"aws_cli_command_executor\" } resource \"aws_iam_policy\" \"aws_cli_command_executor_ip_address_restriction\" { name = \"prd-aws-cli-command-executor-ip-address-restriction-policy\" description = \"Allow global IP addresses\" policy = templatefile( \"${path.module}/policies/customer_managed_policies/aws_cli_command_executor_ip_address_restriction_policy.tpl\", { global_ip_addresses = jsonencode(var.global_ip_addresses) } ) } ・AWS管理ポリシー IAMユーザにAWS管理ポリシーをアタッチする． ＊実装例＊ ############################################### # For IAM User ############################################### resource \"aws_iam_user_policy_attachment\" \"aws_cli_command_executor_s3_read_only_access\" { user = data.aws_iam_user.aws_cli_command_executor.user_name policy_arn = \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\" } IAMロール ・信頼ポリシーを持つロール コンソール画面でロールを作成する場合は意識することはないが，特定のリソースにロールをアタッチするためには，ロールに信頼ポリシーを組み込む必要がある．事前に，tpl形式の信頼ポリシーを定義しておく．aws_iam_roleリソースを使用して，IAMロールを構築すると同時に，これに信頼ポリシーをアタッチする． ＊実装例＊ 事前に，ECSタスクのための信頼ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ecs-tasks.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] } ECSタスクロールとECSタスク実行ロールに信頼ポリシーアタッチする． ############################################### # IAM Role For ECS Task Execution ############################################### resource \"aws_iam_role\" \"ecs_task_execution\" { name = \"prd-foo-ecs-task-execution-role\" description = \"The role for prd-foo-ecs-task\" assume_role_policy = templatefile( \"${path.module}/policies/trust_policies/ecs_task_policy.tpl\", {} ) } ############################################### # IAM Role For ECS Task ############################################### resource \"aws_iam_role\" \"ecs_task\" { name = \"prd-foo-ecs-task-role\" description = \"The role for prd-foo-ecs-task\" assume_role_policy = templatefile( \"${path.module}/policies/trust_policies/ecs_task_policy.tpl\", {} ) } ＊実装例＊ 事前に，Lambda@Edgeのための信頼ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": [ \"lambda.amazonaws.com\", \"edgelambda.amazonaws.com\" ] }, \"Action\": \"sts:AssumeRole\" } ] } Lambda実行ロールに信頼ポリシーアタッチする． ############################################### # IAM Role For Lambda@Edge ############################################### # ロールに信頼ポリシーをアタッチします． resource \"aws_iam_role\" \"lambda_execute\" { name = \"prd-foo-lambda-execute-role\" assume_role_policy = templatefile( \"${path.module}/policies/lambda_execute_role_trust_policy.tpl\", {} ) } ・インラインポリシーを持つロール 事前に，tpl形式のインラインポリシーを定義しておく．aws_iam_role_policyリソースを使用して，インラインポリシーを構築すると同時に，これにインラインポリシーをアタッチする． ＊実装例＊ 事前に，ECSタスクに必要最低限の権限を与えるインラインポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ssm:GetParameters\" ], \"Resource\": \"*\" } ] } ECSタスクロールとECSタスク実行ロールにインラインポリシーアタッチする． ############################################### # IAM Role For ECS Task ############################################### resource \"aws_iam_role_policy\" \"ecs_task\" { name = \"prd-foo-ssm-read-only-access-policy\" role = aws_iam_role.ecs_task_execution.id policy = templatefile( \"${path.module}/policies/inline_policies/ecs_task_policy.tpl\", {} ) } ・AWS管理ポリシーを持つロール 事前に，tpl形式のAWS管理ポリシーを定義しておく．aws_iam_role_policy_attachmentリソースを使用して，実インフラにあるAWS管理ポリシーを構築済みのIAMロールにアタッチする．ポリシーのARNは，AWSのコンソール画面を確認する． ＊実装例＊ ############################################### # IAM Role For ECS Task Execution ############################################### resource \"aws_iam_role_policy_attachment\" \"ecs_task_execution\" { role = aws_iam_role.ecs_task_execution.name policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" } ・カスタマー管理ポリシーを持つロール 事前に，tpl形式のインラインポリシーを定義しておく．aws_iam_role_policyリソースを使用して，カスタマー管理ポリシーを構築する．aws_iam_role_policy_attachmentリソースを使用して，カスタマー管理ポリシーを構築済みのIAMロールにアタッチする． ＊実装例＊ 事前に，ECSタスクに必要最低限の権限を与えるカスタマー管理ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"logs:CreateLogStream\", \"logs:PutLogEvents\" ], \"Resource\": [ \"arn:aws:logs:*:*:*\" ] } ] } ECSタスクロールにカスタマー管理ポリシーアタッチする． ############################################### # IAM Role For ECS Task ############################################### resource \"aws_iam_policy\" \"ecs_task\" { name = \"prd-foo-cloudwatch-logs-access-policy\" description = \"Provides access to CloudWatch Logs\" policy = templatefile( \"${path.module}/policies/customer_managed_policies/cloudwatch_logs_access_policy.tpl\", {} ) } resource \"aws_iam_role_policy_attachment\" \"ecs_task\" { role = aws_iam_role.ecs_task.name policy_arn = aws_iam_policy.ecs_task.arn } ・サービスリンクロール サービスリンクロールは，AWSリソースの構築時に自動的に作成され，アタッチされる．そのため，Terraformの管理外である．aws_iam_service_linked_roleリソースを使用して，手動で構築することが可能であるが，数が多く実装の負担にもなるため，あえて管理外としても問題ない． ＊実装例＊ サービス名を指定して，Application Auto Scalingのサービスリンクロールを構築する． ############################################### # IAM Role For ECS Service ############################################### # Service Linked Role resource \"aws_iam_service_linked_role\" \"ecs_service_auto_scaling\" { aws_service_name = \"ecs.application-autoscaling.amazonaws.com\" } ############################################### # Output IAM Role ############################################### output \"ecs_service_auto_scaling_iam_service_linked_role_arn\" { value = aws_iam_service_linked_role.ecs_service_auto_scaling.arn } Application Auto Scalingにサービスリンクロールをアタッチする．手動で設定することも可能であるが，Terraformの管理外で自動的にアタッチされるため，あえて妥協しても良い． ######################################### # Application Auto Scaling For ECS ######################################### resource \"aws_appautoscaling_target\" \"ecs\" { service_namespace = \"ecs\" resource_id = \"service/prd-foo-ecs-cluster/prd-foo-ecs-service\" scalable_dimension = \"ecs:service:DesiredCount\" max_capacity = 4 min_capacity = 2 # この設定がなくとも，サービスリンクロールが自動的に構築され，AutoScalingにアタッチされる． role_arn = var.ecs_service_auto_scaling_iam_service_linked_role_arn } LBリスナーとターゲットグループ ・まとめ ＊実装例＊ ############################################### # NLB target group ############################################### resource \"aws_lb_target_group\" \"this\" { name = \"prd-foo-nlb-tg\" port = 80 protocol = \"TCP\" vpc_id = \"*****\" deregistration_delay = \"60\" target_type = \"ip\" # ※後述の説明を参考にせよ（１） slow_start = \"0\" # ※後述の説明を参考にせよ（２） health_check { protocol = \"HTTP\" healthy_threshold = 3 path = \"/healthcheck\" } # stickiness ※後述の説明を参考にせよ（３） # https://registry.terraform.io/providers/hashicorp/aws/3.16.0/docs/resources/lb_target_group#stickiness lifecycle { create_before_destroy = false } } （１）NLBはスロースタートに非対応 NLBに紐づくターゲットグループはスロースタートに非対応のため，これを明示的に無効化する必要がある． （２）NLBヘルスチェックには設定可能な項目が少ない ターゲットグループの転送プロトコルがTCPの場合は，設定できないヘルスチェックオプションがいくつかある．ヘルスチェックプロトコルがHTTPまたはHTTPSの時のみ，パスを設定できる． 参考：https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_target_group#health_check （３）NLBスティッキーネスは明示的に無効化 スティッキネス機能を無効化する場合，AWSプロバイダーのアップグレード時に問題が起こらないように，このブロックを実装しないようにする．リンク先のNOTE文を参考にせよ． 参考：https://registry.terraform.io/providers/hashicorp/aws/3.16.0/docs/resources/lb_target_group#stickiness （※）ターゲットグループの削除時にリスナーを先に削除できない． LBリスナーがターゲットグループに依存しているが，Terraformがターゲットグループの削除時にリスナーを先に削除しようとしないため，以下のようなエラーが発生する． Error deleting Target Group: ResourceInUse: Target group 'arn:aws:elasticloadbalancing:ap-northeast-1:123456789:targetgroup/xxxxx-tg/xxxxx' is currently in use by a listener or a rule status code: 400, request id: xxxxx このエラーが発生した場合，コンソール画面上でLBリスナーを削除したうえで，もう一度applyする． 参考：https://github.com/hashicorp/terraform-provider-aws/issues/1315#issuecomment-415423529 RDS ・まとめ ＊実装例＊ ######################################### # RDS Cluster ######################################### resource \"aws_rds_cluster\" \"this\" { engine = \"aurora-mysql\" engine_version = \"5.7.mysql_aurora.2.08.3\" cluster_identifier = \"prd-foo-rds-cluster\" # 後述の説明を参考にせよ．（１） master_username = var.rds_db_master_username_ssm_parameter_value master_password = var.rds_db_master_password_ssm_parameter_value port = var.rds_db_port_ssm_parameter_value database_name = var.rds_db_name_ssm_parameter_value vpc_security_group_ids = [var.rds_security_group_id] db_subnet_group_name = aws_db_subnet_group.this.name db_cluster_parameter_group_name = aws_rds_cluster_parameter_group.this.id storage_encrypted = true backup_retention_period = 7 preferred_backup_window = \"00:00-00:30\" copy_tags_to_snapshot = true final_snapshot_identifier = \"final-db-snapshot\" skip_final_snapshot = false enabled_cloudwatch_logs_exports = [\"audit\", \"error\", \"general\", \"slowquery\"] preferred_maintenance_window = \"sun:01:00-sun:01:30\" # 後述の説明を参考にせよ．（２） apply_immediately = true # 後述の説明を参考にせよ．（３） availability_zones = [\"${var.region}${var.vpc_availability_zones.a}\", \"${var.region}${var.vpc_availability_zones.c}\"] deletion_protection = true lifecycle { ignore_changes = [ # 後述の説明を参考にせよ．（４） availability_zones ] } } ############################################### # RDS Cluster Instance ############################################### resource \"aws_rds_cluster_instance\" \"this\" { for_each = var.vpc_availability_zones engine = \"aurora-mysql\" engine_version = \"5.7.mysql_aurora.2.08.3\" identifier = \"prd-foo-rds-instance-${each.key}\" cluster_identifier = aws_rds_cluster.this.id instance_class = var.rds_instance_class db_subnet_group_name = aws_db_subnet_group.this.id db_parameter_group_name = aws_db_parameter_group.this.id monitoring_interval = 60 monitoring_role_arn = var.rds_iam_role_arn auto_minor_version_upgrade = var.rds_auto_minor_version_upgrade preferred_maintenance_window = \"sun:01:00-sun:01:30\" apply_immediately = true # 後述の説明を参考にせよ．（５） # preferred_backup_window } （１）SSMパラメータストア Terraformに値をハードコーディングしたくない場合は，SSMパラメータストアで値を管理し，これをデータリソースで取得するようにする． （２）メンテナンスウインドウ時に変更適用 メンテナンスウインドウ時の変更適用をTerraformで行う場合，一段階目にapply_immediatelyオプションをfalseに変更してapplyし，二段階目に修正をapplyする． （３）クラスターにはAZが３つ必要 クラスターでは，レプリケーションのために，３つのAZが必要である．そのため，指定したAZが２つであっても，コンソール画面上で３つのAZが自動的に設定される．Terraformがこれを認識しないように，ignore_changesでAZを指定しておく必要がある． 参考： https://github.com/hashicorp/terraform-provider-aws/issues/7307#issuecomment-457441633 https://github.com/hashicorp/terraform-provider-aws/issues/1111 （４）インスタンスを配置するAZは選べない 事前にインスタンスにAZを表す識別子を入れたとしても，Terraformはインスタンスを配置するAZを選べない．そのため，AZと識別子の関係が逆になってしまうことがある．多くの場合， Cゾーンのインスタンスが最初に構築されるため，インスタンスのゾーン名と配置されるA/Cゾーンが逆になる．その場合は，デプロイ後に手動で名前を変更すればよい．この変更は，Terraformが差分として認識しないので問題ない． （５）インスタンスにバックアップウインドウは設定しない クラスターとインスタンスの両方に，preferred_backup_windowを設定できるが，RDSインスタンスに設定してはいけない． Route53 ・まとめ ＊実装例＊ ############################################### # For foo domain ############################################### resource \"aws_route53_zone\" \"foo\" { name = var.route53_domain_foo } resource \"aws_route53_record\" \"foo\" { zone_id = aws_route53_zone.foo.id name = var.route53_domain_foo type = \"A\" alias { name = var.alb_dns_name zone_id = var.alb_zone_id evaluate_target_health = false } } Route Table ・メインルートテーブルは自動構築 Terraformを用いてVPCを構築した時，メインルートテーブルが自動的に構築される．そのため，これはTerraformの管理外である． S3 ・バケットポリシー S3アタッチされる，自身へのアクセスを制御するためにインラインポリシーのこと．詳しくは，AWSのノートを参照せよ．定義したバケットポリシーは，aws_s3_bucket_policyでロールにアタッチできる． ・ALBアクセスログ ALBがバケットにログを書き込めるように，『ELBのサービスアカウントID』を許可する必要がある． ＊実装例＊ ############################################### # S3 bucket policy ############################################### # S3にバケットポリシーをアタッチします． resource \"aws_s3_bucket_policy\" \"alb\" { bucket = aws_s3_bucket.alb_logs.id policy = templatefile( \"${path.module}/policies/alb_bucket_policy.tpl\", {} ) } ALBのアクセスログを送信するバケット内には，自動的に『/AWSLogs/』の名前でディレクトリが生成される．そのため，『arn:aws:s3:::/*』の部分を最小権限として，『arn:aws:s3:::/AWSLogs//;*』にしてもよい．東京リージョンのELBサービスアカウントIDは，『582318560864』である． 参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-access-logs.html#access-logging-bucket-permissions { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::582318560864:root\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::/*\" } ] } ・NLBアクセスログ ALBがバケットにログを書き込めるように，『delivery.logs.amazonaws.com』からのアクセスを許可する必要がある． ＊実装例＊ ############################################### # S3 bucket policy ############################################### # S3にバケットポリシーをアタッチします． resource \"aws_s3_bucket_policy\" \"nlb\" { bucket = aws_s3_bucket.nlb_logs.id policy = templatefile( \"${path.module}/policies/nlb_bucket_policy.tpl\", {} ) } NLBのアクセスログを送信するバケット内には，自動的に『/AWSLogs/』の名前でディレクトリが生成される．そのため，『arn:aws:s3:::/*』の部分を最小権限として，『arn:aws:s3:::/AWSLogs//;*』にしてもよい． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSLogDeliveryWrite\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"delivery.logs.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } }, { \"Sid\": \"AWSLogDeliveryAclCheck\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"delivery.logs.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::\" } ] } WAF ・ruleブロック ＊実装例＊ API Gateway用のWAFに，特定のユーザエージェントを拒否するルールを設定する． resource \"aws_wafv2_web_acl\" \"api_gateway\" { rule { name = \"block-user-agents\" priority = 0 statement { regex_pattern_set_reference_statement { # 別ディレクトリのmain.tfファイルに分割した正規表現パターンセットを参照する． arn = var.wafv2_regex_pattern_set_regional_block_user_agents_arn field_to_match { # ヘッダーを検証する． single_header { name = \"user-agent\" } } text_transformation { priority = 0 type = \"NONE\" } } } action { block {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFBlockUserAgentsRule\" sampled_requests_enabled = true } } default_action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayALBWAFRules\" sampled_requests_enabled = true } # ～ 省略 ～ } ＊実装例＊ API Gateway用のWAFに，特定のグローバルIPアドレスを拒否するルールを設定する． resource \"aws_wafv2_web_acl\" \"api_gateway\" { rule { name = \"block-global-ip-addresses\" priority = 0 statement { ip_set_reference_statement { # 別ディレクトリのmain.tfファイルに分割したIPアドレスセットを参照する． arn = var.waf_blocked_global_ip_addresses } } action { block {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFBlockGlobalIPAddressesRule\" sampled_requests_enabled = true } } default_action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFRules\" sampled_requests_enabled = true } # ～ 省略 ～ } ＊実装例＊ API Gateway用のWAFに，SQLインジェクションを拒否するマネージドルールを設定する． resource \"aws_wafv2_web_acl\" \"api_gateway\" { rule { name = \"block-sql-injection\" priority = 0 statement { # マネージドルールを使用する． managed_rule_group_statement { vendor_name = \"AWS\" name = \"AWSManagedRulesSQLiRuleSet\" } } override_action { count {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFBlockSQLInjectionRule\" sampled_requests_enabled = true } } default_action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFRules\" sampled_requests_enabled = true } # ～ 省略 ～ } ＊実装例＊ ALB用のWAFに，APIキーまたはBearerトークンをOR条件ルールを設定する．あくまで例としてで，本来であれば，別々のルールとした方が良い． resource \"aws_wafv2_web_acl\" \"api_gateway\" { # x-api-keyヘッダーにAPIキーを含むリクエストを許可します． rule { name = \"allow-request-including-api-key\" priority = 3 statement { or_statement { # APIキーを持つのリクエストを許可します． statement { byte_match_statement { positional_constraint = \"EXACTLY\" search_string = var.waf_api_key_ssm_parameter_value field_to_match { single_header { name = \"x-api-key\" } } text_transformation { priority = 0 type = \"NONE\" } } } # Bearerトークンを持つリクエストを許可します． statement { byte_match_statement { positional_constraint = \"EXACTLY\" search_string = var.waf_bearer_token_ssm_parameter_value field_to_match { single_header { name = \"authorization\" } } text_transformation { priority = 0 type = \"NONE\" } } } } } action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFAllowRequestIncludingAPIKeyRule\" sampled_requests_enabled = true } } # ～ 省略 ～ } ・IPセットの依存関係 WAFのIPセットと他設定の依存関係に癖がある．新しいIPセットへの付け換えと古いIPセットの削除を同時にデプロイしないようにする．もし同時に行った場合，Terraformは古いIPセットの削除処理を先に実行するが，これはWAFに紐づいているため，ここでエラーが起こってしまう．そのため，IPセットを新しく設定し直す場合は，以下の通り二つの段階に分けてデプロイするようにする．ちなみに，IPセットの名前を変更する場合は，更新処理ではなく削除を伴う再構築処理が実行されるため注意する． 新しいIPセットのresourceを実装し，ACLに関連付け，デプロイする． 古いIPセットのresourceを削除し，デプロイする． もし，これを忘れてしまった場合は，画面上で適当なIPセットに付け換えて，削除処理を実行できるようにする． 共通の設定 ・Terraform管理外のAWSリソース 以下のAWSリソースはTerraformで管理しない方が便利である．また，AWSの仕様上の理由で，管理外になってしまうものもある．Terraformの管理外のリソースには，コンソール画面上から，「Not managed by = Terraform」というタグをつけた方が良い． AWSリソース 管理外の部分 管理外の理由 API Gateway，紐づくVPCリンク 全て バックエンドチームがスムーズにAPIを構築できるようにするため． Chatbot 全て AWSがAPIを公開していないため，Terraformで構築できない． EC2 秘密鍵 Terraformで構築する時にGitHubで秘密鍵を管理する必要があるため，セキュリティ上の理由で却下する． Global Accelerator セキュリティグループ リソースを構築するとセキュリティグループが自動生成されるため，セキュリティグループのみTerraformで管理できない． IAMユーザ 全て IAMユーザグループ 全て IAMロール ・ユーザに紐づくロール・サービスリンクロール サービスリンクロールは，AWSリソースの構築に伴って，自動的に作られるため，Terraformで管理できない．ただし，数が多いためあえて行わないが，Terraformで構築してAWSリソースに関連付けることもことも可能である． Network Interface 全て 他のAWSリソースの構築に伴って，自動的に構築されるため，Terraformで管理できない． RDS admin以外のユーザ 個別のユーザ作成のために，mysql providerという機能を使用する必要がある．しかし，使用する上でディレクトリ構成戦略と相性が悪い． Route53 ネームサーバーレコード ホストゾーンを作成すると，レコードとして，ネームサーバレコードの情報が自動的に設定される．これは，Terraformの管理外である． S3 tfstateの管理バケット tfstateファイルを格納するため，Terraformのデプロイより先に存在している必要がある． SSMパラメータストア 全て ECSに機密な環境変数を出力するため． ・削除保護機能のあるAWSリソース 削除保護設定のあるAWSリソースに癖がある．削除保護の無効化とリソースを削除を同時にデプロイしないようにする．もし同時に行った場合，削除処理を先に実行するが，削除は保護されたままなので，エラーになる．エラーになる．そのため，このAWSリソースを削除する時は，以下の通り二つの段階に分けてデプロイするようにする． 削除保護を無効化（false）に変更し，デプロイする． ソースコードを削除し，デプロイする． もし，これを忘れてしまった場合は，画面上で削除処理を無効化し，削除処理を実行できるようにする． AWSリソース名 Terraform上での設定名 ALB enable_deletion_protection EC2 disable_api_termination RDS deletion_protection 09. CircleCIとの組み合わせ circleci ・設定ファイル CI/CDの構成は以下の通りとした． env 説明 dev プルリクのレビュー時に，コードの変更を検証するためのインフラ環境 stg ステージング環境 prd 本番環境 jobs 説明 plan aws-cliのインストールからterraform plan -outコマンドまでの一連の処理を実行する． 承認ジョブ apply stg環境またはprd環境にデプロイ destroy_dev プルリクでdev環境にデプロイしたインフラを削除する． workflows 説明 feature featureブランチからdev環境にデプロイ develop developブランチからstg環境にデプロイ main mainブランチからprd環境にデプロイ version: 2.1 executors: primary_container: parameters: env: type: enum enum: [ \"dev\", \"stg\", \"prd\" ] docker: - image: hashicorp/terraform:x.xx.x working_directory: ~/foo_infrastructure environment: ENV: > commands: # AWSにデプロイするための環境を構築します． aws_setup: steps: - run: name: Install jq command: | apk add curl curl -o /usr/bin/jq -L https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 chmod +x /usr/bin/jq - run: name: Install aws-cli command: | apk add python3 apk add py-pip pip3 install awscli aws --version - run: name: Assume role command: | set -x source ./ops/assume.sh # terraform initを行います． terraform_init: steps: - run: name: Terraform init command: | set -x source ./ops/terraform_init.sh # terraform fmtを行います． terraform_fmt: steps: - run: name: Terraform fmt command: | set -x source ./ops/terraform_fmt.sh # terraform validateを行います． terraform_validate: steps: - run: name: Terraform validate command: | set -x source ./ops/terraform_validate.sh # terraform planを行います． terraform_plan: steps: - run: name: Terraform plan command: | set -x source ./ops/terraform_plan.sh ls -la # terraform applyを行います． terraform_apply: steps: - run: name: Terraform apply command: | set -x ls -la source ./ops/terraform_apply.sh jobs: plan: parameters: exr: type: executor executor: > steps: - checkout - aws_setup - terraform_init - terraform_fmt - terraform_validate - terraform_plan - persist_to_workspace: root: . paths: - . apply: parameters: exr: type: executor executor: > steps: - attach_workspace: at: . - terraform_apply workflows: # Dev env feature: jobs: - plan: name: plan_dev exr: name: primary_container env: dev filters: branches: only: - /feature.*/ - apply: name: apply_dev exr: name: primary_container env: dev requires: - plan_dev # Staging env develop: jobs: - plan: name: plan_stg exr: name: primary_container env: stg filters: branches: only: - develop - hold_apply: name: hold_apply_stg type: approval requires: - plan_stg - apply: name: apply_stg exr: name: primary_container env: stg requires: - hold_apply_stg # Production env main: jobs: - plan: name: plan_prd exr: name: primary_container env: prd filters: branches: ignore: /.*/ tags: only: /release\\/.*/ - hold_apply: name: hold_apply_prd type: approval requires: - plan_prd filters: branches: ignore: /.*/ tags: only: /release\\/.*/ - apply: name: apply_prd exr: name: primary_container env: prd requires: - hold_apply_prd filters: branches: ignore: /.*/ tags: only: /release\\/.*/ シェルスクリプト ・assume_role.sh AWSのノートを参照せよ． ・terraform_apply.sh #!/bin/bash set -xeuo pipefail # credentialsの情報を出力します． source ./aws_envs.sh terraform -chdir=./${ENV} apply \\ -parallelism=30 \\ ${ENV}.tfplan | ./ops/tfnotify --config ./${ENV}/tfnotify.yml apply ・terraform_destroy_dev.sh #!/bin/bash set -xeuo pipefail if [ $ENV = \"dev\" ]; then # credentialsの情報を出力します． source ./aws_envs.sh terraform -chdir=./${ENV} destroy -var-file=foo.tfvars else echo \"The parameter ${ENV} is invalid.\" exit 1 fi ・terraform_fmt.sh #!/bin/bash set -xeuo pipefail terraform fmt \\ -recursive \\ -check ・terraform_init.sh #!/bin/bash set -xeuo pipefail # credentialsの情報を出力します． source ./aws_envs.sh terraform -chdir=./${ENV} init \\ -upgrade \\ -reconfigure \\ -backend=true \\ -backend-config=\"bucket=${ENV}-tfstate-bucket\" \\ -backend-config=\"key=terraform.tfstate\" \\ -backend-config=\"encrypt=true\" ・terraform_plan.sh #!/bin/bash set -xeuo pipefail # credentialsの情報を出力します． source ./aws_envs.sh terraform -chdir=./${ENV} plan \\ -var-file=./${ENV}/foo.tfvars \\ -out=${ENV}.tfplan \\ -parallelism=30 | ./ops/tfnotify --config ./${ENV}/tfnotify.yml plan ・terraform_validate.sh #!/bin/bash set -xeuo pipefail terraform -chdir=./${ENV} validate tfnotify ・tfnotifyとは terraformのplanまたはapplyの処理結果を，POSTで送信するバイナリファイルのこと．URLや送信内容を設定ファイルで定義する． ・コマンド CircleCIで利用する場合は，commandの中で，以下からダウンロードしたtfnotifyのバイナリファイルを実行する．環境別にtfnotifyを配置しておくとよい． https://github.com/mercari/tfnotify/releases/tag/v0.7.0 #!/bin/bash set -xeuo pipefail terraform -chdir=./${ENV} plan | ./ops/tfnotify --config ./${ENV}/tfnotify.yml plan ・設定ファイル あらかじめ，GitHubのアクセストークンを発行し，CIツールの環境変数に登録しておく． ＊実装例＊ 例として，GitHubの特定のリポジトリのプルリクエストにPOSTで送信する． # https://github.com/mercari/tfnotify --- ci: circleci notifier: github: # 環境変数に登録したパーソナルアクセストークン token: $GITHUB_TOKEN repository: # 送信先のユーザ名もしくは組織名 owner: \"foo-company\" name: \"foo-repository\" terraform: plan: template: | {{ .Title }} for staging [CI link]( {{ .Link }} ) {{ .Message }} {{if .Result}} {{ .Result }} {{end}} Details (Click me) {{ .Body }} apply: template: | {{ .Title }} {{ .Message }} {{if .Result}} {{ .Result }} {{end}} Details (Click me) {{ .Body }} "},"public/infrastructure_virtualization_comparison.html":{"url":"public/infrastructure_virtualization_comparison.html","title":"▶ ︎仮想化技術の比較","keywords":"","body":"仮想化技術の比較 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 仮想化技術の種類 仮想化技術とは 自身の開発環境でWebサイトを動かしたい場合，まず，パソコン内にLinux環境のWebサーバ，APサーバ，DBサーバなどの物理サーバを仮想的に構築する．そして，自身のパソコンをクライアント，各仮想サーバをリクエスト先に見立てて，SSHプロトコルを用いてこれらのサーバにリモートログインする．仮想環境の構築方法にはいくつか種類がある． ホスト型仮想化 ・ホスト型仮想化とは ホストOS上で，各サーバを仮想的に構築する． ・Provider例 VMware Workstation，Oracle VM VirtualBox，など ハイパーバイザー型仮想化 ・ハイパーバイザー型仮想化とは BIOSから起動したハイパーバイザー上で，各サーバを仮想的に構築する（※ホストOSは用いない）． ・Provider例 VMware vSphere Hypervisor，Xen，KVM，など コンテナ型仮想化 ・コンテナ型仮想化とは ホストOS上で，サーバではなく，サーバとしての機能を持つコンテナを仮想的に構築する．カーネルのリソースを分割できるNamespace（PID namespace，Network namespace，UID namespace）とControl Groupsを用いて，単一のOS上に独立したコンテナを構築する． → DockerToolboxがちょい違う ・Provider例 Docker，LXC，OpenVZ，など 01-02. 各仮想化のパフォーマンスの比較 起動速度の違い ホスト型とハイパーバイザ型では，ハードウェア（CPU，メモリ，ハードディスク）とゲストOSを仮想化することが必要である．一方で，コンテナ型では，ハードウェアとゲストOSの仮想化は行わず，namespaceを用いてコンテナを構成するため，その分起動が速い． 処理速度の違い ・Overheadの小ささ ゲストOS上のアプリを操作する場合，ホスト型とハイパーバイザ型では，ハードウェアやハイパーバイザーを経由する必要がある．この分だけ，時間（Overhead）を要する．一方で，コンテナ型では，各コンテナがホストOSとカーネルを共有するため，Overheadが小さい． ・Overheadの比較 sysbenchというベンチマークツールを用いて，CPU・メモリ・ファイルI/Oに着目し，物理マシン・コンテナ型仮想化（Docker）・ホスト型仮想化（VirtualBox）のパフォーマンスを比較すると，コンテナ型であるDockerは最もOverheadが小さい． "},"public/infrastructure_virtualization_container.html":{"url":"public/infrastructure_virtualization_container.html","title":"▶ ︎コンテナ","keywords":"","body":"コンテナ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Dockerによるコンテナの構築 Dockerの操作 ・Dockerクライアント Dockerクライアントは，接続によって，Dockerデーモンを操作できる． ・Dockerデーモン ホストOS上で稼働し，Dockerの操作を担う．Dockerクライアントは，Dockerデーモンを通して，Docker全体を操作できる． 02. コンテナに接続するまでの手順 手順の流れ Docker Hubから，ベースとなるイメージをインストールする． Dockerfileがイメージレイヤーからなるイメージをビルド． コマンドによって，イメージ上にコンテナレイヤーを生成し，コンテナを構築． コマンドによって，停止中のコンテナを起動． コマンドによって，起動中のコンテナに接続． 02-02. イメージのインストール ベースとなるイメージ（ベースイメージ）のインストール ・Docker Hubとは イメージは，実行OSによらずに一貫してビルドできるため，配布できる．Docker Hubには，カスタマイズする上でのベースとなるイメージが提供されている． ・ベースイメージの種類 イメージ 特徴 相性の良いシステム例 scratch 以下の通り，何も持っていない・OS：無・パッケージ：無・パッケージマネージャ：無 ？ BusyBox ・OS：Linux（※ディストリビューションではない）・パッケージ：基本ユーティリティツール・パッケージマネージャ：無 組み込みシステム Alpine Linux ・OS：Linux（※ディストリビューションではない）・パッケージ：基本ユーティリティツール・パッケージマネージャ：Apk ？ ・対応可能なCPUアーキテクチャの種類 Dockerは全てのPCで稼働できるわけではなく，イメージごとに対応可能なCPUアーキテクチャ（AMD系，ARM系，など）がある．同じOSでも，機種ごとに搭載されるCPUアーキテクチャは異なる．例えば，MacBook 2020 にはIntel，またMacBook 2021（M1 Mac）にはARMベースの独自CPUが搭載されているため，ARMに対応したイメージを選ぶ必要がある．ただし，イメージがOSのCPUアーキテクチャに対応しているかどうかを開発者が気にする必要はなく，docker pull時に，OSのCPUアーキテクチャに対応したイメージが自動的に選択されるようになっている． 参考：https://github.com/docker-library/official-images#architectures-other-than-amd64 ・バージョン イメージのバージョンには種類があり，追跡できるバージョンアップが異なる．ここでは，composerのイメージを例に挙げる． 参考：https://hub.docker.com/_/composer/?tab=description&page=1&ordering=last_updated composerバージョン 追跡できるバージョンアップ 2.0.9 バージョンを直指定し，追跡しない． 2.0 「2.0.X」のマイナーアップデートのみを追跡する． 2 「2.X」と「2.0.X」のマイナーアップデートのみを追跡する． latest メジャーアップデートとマイナーアップデートを追跡する． ・ベースイメージをインストール ＊コマンド例＊ レジストリ側に保管されているイメージを検索する． $ docker search ＊コマンド例＊ レジストリ側のイメージをクライアント側にインストールする． $ docker pull : ＊コマンド例＊ ホストOSにインストールされたイメージを確認する． $ docker images ・イメージを削除 ＊コマンド例＊ コンテナに使用されていないイメージを一括で削除 $ docker image prune ＊コマンド例＊ タグ名のないイメージのみを全て削除する． $ docker rmi --force $(sudo docker images --filter \"dangling=true\" --all --quiet) 02-03. イメージのビルド コマンド ・イメージのビルド ＊コマンド例＊ キャッシュ無しで，指定のDockerfileを基に，イメージをビルドする．失敗した時は削除するように，--force-rmオプションを有効化する． $ docker build --file Dockerfile --tag : --force-rm=true --no-cache . ・Docker Hubに登録 ＊コマンド例＊ ホストOSで作成したイメージを，指定したDockerHubのユーザにアップロードする． $ docker push /: ・ECRに登録 ＊コマンド例＊ ホストOSで作成したイメージを，指定したECRにアップロードする．事前にタグを付け替える必要がある． # タグを $ docker tag : /: $ docker push /: ・イメージのデバッグ ＊コマンド例＊ ビルドに失敗したイメージからコンテナを構築し，接続する．rmオプションを設定し，接続の切断後にコンテナを削除する．Dockerfileにおいて，イメージのプロセスの起動コマンドをENTRYPOINTで設定している場合は，後から上書きできなくなるため，runコマンドの引数として新しいコマンドを渡せずに，デバッグができないことがある． $ docker run --rm -it /bin/bash # コンテナの中 root@xxxxxxxxxx: イメージレイヤーの積み重ね ・Dockerfileの仕組み 任意のイメージをベースとして，新しいイメージをビルドするためには，ベースのイメージの上に，他のイメージレイヤーを積み重ねる必要がある．この時，Dockerfileを用いて，各命令によってイメージレイヤーを積み重ねていく． ・Dockerfileの記述方法 任意のイメージをベースとして，新しいイメージをビルドするためには，以下の5つ順番で命令を用いて，イメージレイヤーを積み重ねていく．命令は，慣例的に大文字で記述する． ＊実装例＊ NginxのイメージをビルドするためのDockerfileを示す．命令のパラメータの記述形式には，文字列形式，JSON形式がある．ここでは，JSON形式で記述する． # ベースのイメージ（CentOS）を，コンテナにインストール FROM centos:8 # ubuntu上に，nginxをインストール RUN yum update -y \\ && yum install -y \\ nginx # ホストOSの設定ファイルを，コンテナ側の指定ディレクトリにコピー COPY infra/docker/web/nginx.conf /etc/nginx/nginx.conf # nginxをデーモン起動 CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] # コンテナのポートを開放を明示する．これはドキュメンテーションとしての機能しかない． EXPOSE 80 命令 処理 FROM ベースのイメージを，コンテナにインストール. RUN ベースイメージ上に，ソフトウェアをインストール. COPY ・ホストOSのファイルをイメージレイヤー化し，コンテナの指定ディレクトリにコピー.・イメージのビルド時にコピーされるだけで，ビルド後のコードの変更は反映されない．・nginx.confファイル，php.iniファイル，などの設定ファイルをホストOSからコンテナにコピーしたい時によく使う． CMD イメージのプロセスの起動コマンドを実行．runコマンドの引数として，上書きできる． VOLUME Volumeマウントを行う．COPYとは異なり，ビルド後のコードの変更が反映される．Docker Composeで記述した方が良い． EXPOSE コンテナのポートを開放する．また，イメージの利用者にとってのドキュメンテーション機能もあり，ポートマッピングを実行する時に使用可能なコンテナポートとして保証する機能もある．参考：・https://docs.docker.com/engine/reference/builder/#expose・https://www.whitesourcesoftware.com/free-developer-tools/blog/docker-expose-port/また加えて，プロセス自体が命令をリッスンできるようにポートを設定する必要がある．ただし，多くの場合標準でこれが設定されている．（例：PHP-FPMでは，/usr/local/etc/www.conf.defaultファイルと/usr/local/etc/php-fpm.d/www.confファイルには，listen = 127.0.0.1:9000の設定がある） ENTRYPOINT イメージのプロセスの起動コマンドを実行．CMDとは異なり，後から上書き実行できない．使用者に，コンテナの起動方法を強制させたい場合に適する． ENV OS上のコマンド処理で扱える変数を定義する．Dockerfileの命令では扱えない．ARGとの違いの具体例については下記． ARG Dockerfikeの命令で扱える変数を定義する．OS上のコマンド処理では扱えない．ENVとの違いの具体例については下記． ADD ・ホストOSのファイルを，コンテナの指定ディレクトリにコピー（COPYと同じ）・インターネットからファイルをダウンロードし，解凍も行う．・イメージのビルド時にコピーされるだけで，ビルド後のコードの変更は反映されない． WORKDIR 絶対パスによる指定で，現在のディレクトリを変更. ・CMDの決め方 DockerfileでCMDを指定しない場合，イメージのデフォルトのバイナリファイルが割り当てられる．一旦，デフォルトのバイナリファイルを確認した後に，これをDockerfileに明示的に実装するようにする． CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2b2d3dfafee8 xxxxx \"/bin/sh\" 11 seconds ago Up 8 seconds 0.0.0.0:8000->8000/tcp xxxxx 静的型付け言語ではプロセスの起動時に，代わりにアーティファクトのバイナリファイルを実行しても良い．その場合，binディレクトリにバイナリファイルとしてのアーティファクトを配置することになる．しかし，binディレクトリへのアクセス権限がないことがあるため，その場合は，一つ下にディレクトリを作成し，そこにバイナリファイルを置くようにする． # /go/bin にアクセスできない時は，/go/bin/cmdにアーティファクトを置く． ERROR: for xxx-container Cannot start service go: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: \"/go/bin\": permission denied: unknown ・ENTRYPOINTの注意点 イメージのプロセスの起動コマンドを後から上書きできなくなるため，runコマンドの引数として新しいコマンドを渡せずに，デバッグができないことがある． # 上書きできず，失敗してしまう． $ docker run --rm -it /bin/bash ・ENVとARGの違い 一つ目に，ENVが使えて，ARGが使えない例． # ENVは，OS上のコマンド処理で扱える変数を定義 ARG PYTHON_VERSION=\"3.8.0\" RUN pyenv install ${PYTHON_VERSION} # ARGは，OS上のコマンド処理では扱えない ARG PYTHON_VERSION=\"3.8.0\" RUN pyenv install ${PYTHON_VERSION} # ===> 変数を展開できない 二つ目に，ARGが使えて，ENVが使えない例． # ARGは,Dockerfikeの命令で扱える変数を定義 ARG OS_VERSION=\"8\" FROM centos:${OS_VERSION} # ENVは，OS上のコマンド処理では扱えない ENV OS_VERSION \"8\" FROM centos:${OS_VERSION} # ===> 変数を展開できない 三つ目に，これらの違いによる可読性の悪さの対策として，ENVとARGを組み合わせた例． # 最初に全て，ARGで定義 ARG CENTOS_VERSION=\"8\" ARG PYTHON_VERSION=\"3.8.0\" # 変数展開できる FROM centos:${OS_VERSION} # ARGを事前に宣言 ARG PYTHON_VERSION # 必要に応じて，事前にENVに詰め替える． ENV PYTHON_VERSION ${PYTHON_VERSION} # 変数展開できる RUN pyenv install ${PYTHON_VERSION} ・Docker Hubに対する継続的インテグレーション 方法 仕組み GitHub Actions GitHubが，Docker Hubに対して，pushを行う． Circle CI GitHubが，Circle CIに対して，送信WebHookを行う． Docker Hub Auto Build GitHubが，Docker Hubに対して，送信WebHookを行う． ・Dockerfileを使用するメリット Dockerfileを用いない場合，各イメージレイヤーのインストールを手動で行わなければならない．しかし，Dockerfileを用いることで，これを自動化することができる． 02-04 イメージの軽量化 プロセス単位によるDockerfileの分割 これは，Dockerの原則である．アプリケーションを稼働させるには，最低限，Webサーバミドルウェア，アプリケーション，DBMSが必要である．これらを，個別のコンテナで稼働させ，ネットワークで接続するようにする． キャッシュを削除 Unixユーティリティをインストールすると，キャッシュが残る． ＊実装例＊ FROM centos:8 RUN dnf upgrade -y \\ && dnf install -y \\ curl \\ # メタデータ削除 && dnf clean all \\ # キャッシュ削除 && rm -rf /var/cache/dnf RUNコマンドをまとめる Dockerfileの各命令によって，イメージ レイヤーが一つ増えてしまうため，同じ命令に異なるパラメータを与える時は，これを一つにまとめてしまう方が良い．例えば，以下のような時， # ベースイメージ上に，複数のソフトウェアをインストール RUN yum -y isntall httpd RUN yum -y install php RUN yum -y install php-mbstring RUN yum -y install php-pear これは，以下のように一行でまとめられる．イメージレイヤーが少なくなり，イメージを軽量化することができる． # ベースイメージ上に，複数のソフトウェアをインストール RUN yum -y install httpd php php-mbstring php-pear さらに，これは以下のようにも書くことができる． # ベースイメージ上に，複数のソフトウェアをインストール RUN yum -y install \\ httpd \\ php \\ php-mbstring \\ php-pear マルチステージビルド ・マルチステージビルドとは 一つのDockerfile内に複数の独立したステージを定義する方法．以下の手順で作成する． シングルステージビルドに成功するDockerfileを作成する． ビルドによって生成されたバイナリファイルがどこに配置されるかを場所を調べる． Dockerfileで，二つ目のFROMを宣言する． 一つ目のステージで，バイナリファイルをコンパイルするだけで終わらせる． 二つ目のステージで，Unixユーティリティをインストールする．また，バイナリファイルを一つ目のステージからコピーする． ・コンパイルされたバイナリファイルを再利用 ＊実装例＊ # 中間イメージ FROM golang:1.7.3 AS builder WORKDIR /go/src/github.com/alexellis/href-counter/ RUN go get -d -v golang.org/x/net/html COPY app.go . RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . # 最終イメージ FROM alpine:latest RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=builder /go/src/github.com/alexellis/href-counter/app . CMD [\"./app\"] ・実行環境別にステージを分ける ＊実装例＊ #=================== # Global ARG #=================== ARG NGINX_VERSION=\"1.19\" ARG LABEL=\"Hiroki \" #=================== # Build Stage #=================== FROM nginx:${NGINX_VERSION} as build RUN apt-get update -y \\ && apt-get install -y \\ curl \\ vim \\ # キャッシュ削除 && apt-get clean #=================== # Develop Stage #=================== FROM build as develop LABEL mantainer=${LABEL} COPY ./infra/docker/www/develop.nginx.conf /etc/nginx/nginx.conf CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] #=================== # Production Stage #=================== FROM build as production LABEL mantainer=${LABEL} COPY ./infra/docker/www/production.nginx.conf /etc/nginx/nginx.conf CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] 可能な限りOSイメージをベースとしない ・OSイメージをベースとした場合（悪い例） OSベンダーが提供するベースイメージを使用すると，不要なバイナリファイルが含まれてしまう．原則として，一つのコンテナで一つのプロセスしか実行せず，OS全体のシステムは不要なため，OSイメージをベースとしないようにする． ＊実装例＊ # CentOSイメージを，コンテナにインストール FROM centos:8 # PHPをインストールするために，EPELとRemiリポジトリをインストールして有効化． RUN dnf upgrade -y \\ && dnf install -y \\ https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm \\ https://rpms.remirepo.net/enterprise/remi-release-8.rpm \\ && dnf module enable php:remi-${PHP_VERSION} \\ # フレームワークの要件のPHP拡張機能をインストール && dnf install -y \\ php \\ php-bcmath \\ php-ctype \\ php-fileinfo \\ php-json \\ php-mbstring \\ php-openssl \\ php-pdo \\ php-tokenizer \\ php-xml \\ && dnf clean all \\ && rm -Rf /var/cache/dnf # DockerHubのComposerイメージからバイナリファイルを取得 COPY --from=composer /usr/bin/composer /usr/bin/composer ＊実装例＊ # CentOSイメージを，コンテナにインストール FROM centos:8 # nginxをインストール RUN dnf upgrade -y \\ 　　&& dnf install -y \\ 　　 nginx \\ 　　 curl \\ 　　&& dnf clean all \\ 　　&& rm -Rf /var/cache/dnf COPY infra/docker/web/nginx.conf /etc/nginx/nginx.conf CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] EXPOSE 80 ・ミドルウェアイメージをベースとした場合（良い例） 代わりに，ミドルウェアベンダーが提供するベースイメージを使用するようにする． ＊実装例＊ # Nginxイメージを，コンテナにインストール FROM nginx:1.19 # NginxイメージがUbuntuベースなためにapt-getコマンド RUN apt-get updatedocke -y \\ && apt-get install -y \\ curl \\ && apt-get clean COPY ./infra/docker/www/production.nginx.conf /etc/nginx/nginx.conf ・言語イメージをベースとした場合 代わりに，言語ベンダーが提供するベースイメージを使用するようにする． # ここに実装例 ・alpineイメージをベースとした場合 # ここに実装例 02-05. イメージ上でのコンテナレイヤーの生成，コンテナの構築 コンテナレイヤーの生成 ・コンテナレイヤーとは イメージレイヤーの上に積み重ねられる コマンド ・コンテナレイヤー生成，コンテナ構築 ＊コマンド例＊ コンテナレイヤーを生成し，コンテナを構築．起動はしない． $ docker create : ・停止中のコンテナを起動 コンテナを起動する．startコマンドでは，アタッチモードによる起動しかできない． ＊コマンド例＊ 停止中コンテナをアタッチモードによって起動する． $ docker start -i ・停止中のコンテナを削除 停止中のコンテナのみを全て削除する． ＊コマンド例＊ $ docker container prune 起動中／停止中の全てコンテナを削除する． $ docker rm --force $(docker ps --all --quiet) ・停止中のコンテナからイメージ作成 停止中のコンテナからイメージを作成する． ＊コマンド例＊ $ docker commit $ docker commit /: ・ポートマッピング 指定したホストポートとコンテナポートのマッピングを実行する．--publish-allオプションではホストポートをランダムに選んでポートマッピングを実行する． 参考：https://www.whitesourcesoftware.com/free-developer-tools/blog/docker-expose-port/ $ docker run -d -it --name --publish=8080:80 : /bin/bash ・コンテナポート開放 コンテナポート公開をexposeオプションで設定できる．これはDockerfileでEXPOSE命令として設定してもよい．なお，プロセスのリッスンするポートと合わせる必要がある． 参考：https://www.whitesourcesoftware.com/free-developer-tools/blog/docker-expose-port/ $ docker run -d -it --name --expose=80 : /bin/bash 02-06. 起動中のコンテナの操作 コマンド ・起動中のコンテナ情報を表示 ＊コマンド例＊ コンテナの起動と停止にかかわらず，IDなどを一覧で表示． $ docker ps -a ＊コマンド例＊ 起動中コンテナの全ての設定内容を表示する．grepとも組み合わせられる． $ docker inspect $ docker inspect | grep IPAddress ・起動中のコンテナを停止 ＊コマンド例＊ 起動中コンテナを停止する． $ docker stop ＊コマンド例＊ 全てのコンテナを停止する． $ docker stop $(docker ps --all --quiet) ・起動中のコンテナに接続 ＊コマンド例＊ デタッチドモードによって，起動中のコンテナに接続する． $ docker attach ・起動中のコンテナ内でコマンドを実行 ＊コマンド例＊ デタッチドモードによって，起動中のコンテナ内でコマンドを実行する．実行するコマンドがshellやbashの場合，コンテナに接続できる． # i：interactive，t：tty（対話モード） $ docker exec -it /bin/bash # イメージ内に/bin/bash がない場合 $ docker exec -it /bin/sh ・起動中のコンテナにホストOSのファイルをコピー DockerfileのCOPYコマンドを使用してコンテナ内に配置しているファイルに関して，変更のたびにイメージをビルドを行うことは面倒のため，ホストOSからコンテナにコピーし，再読み込みを行う．ただし，コンテナを再構築すると元に戻ってしまうことに注意． ＊コマンド例＊ # ホストのファイルをコンテナにコピー $ docker cp ./docker/www/nginx.conf :/etc/nginx/nginx.conf # コンテナに接続後に，nginxの設定ファイルを再読み込み． $ docker exec -it bin/bash # もしくはbin/sh [root@:~] $ nginx -s reload [root@:~] $ exit # アクセスログを確認 $ docker logs 接続コマンドの違い ・attach ＊コマンド例＊ 起動中のコンテナに接続する．exitコマンドを使用して，コンテナとの接続を切断した後，コンテナが停止してしまう． # デタッチドモードによる起動 $ docker run -d -it --name : /bin/bash # デタッチドモードによって起動中のコンテナに接続 $ docker attach # PID=1で，1つの/bin/bashプロセスが稼働していることが確認できる [root@:~] ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 16152 3872 pts/0 Ss+ 18:06 0:00 /bin/bash root 33 0.0 0.1 45696 3732 pts/1 R+ 18:22 0:00 ps aux # コンテナとの接続を切断 [root@:~] exit # コンテナの状態を確認 $ docker container ps -a --no-trunc # ==> コンテナのSTATUSがEXITedになっている ・exe ＊コマンド例＊ 起動中のコンテナでコマンドを実行する．実行するコマンドがshellやbashの場合，コンテナに接続できる．exitコマンドを使用して，コンテナとの接続を切断した後でも，コンテナが起動し続ける． # デタッチドモードによる起動 $ docker run -d -it --name : /bin/bash # 対話モードを使用して，デタッチドモードによって起動中のコンテナに接続 $ docker exec -it /bin/bash # もしくはbin/sh # PID=1,17で，2つの/bin/bashプロセスが稼働していることが確認できる [root@:~] ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 16152 3872 pts/0 Ss+ 18:06 0:00 /bin/bash root 17 0.0 0.1 16152 4032 pts/1 Ss 18:21 0:00 /bin/bash root 34 0.0 0.1 45696 3732 pts/1 R+ 18:22 0:00 ps aux # コンテナとの接続を切断 [root@:~] exit # コンテナの状態を確認 $ docker container ps -a --no-trunc # ==> コンテナのSTATUSがUPになっている 02-07. コンテナ構築とコンテナ操作 コマンド ・コンテナを新しく構築し，コンテナ内でコマンドを実行 すでに停止中または起動中のコンテナが存在していても，これとは別にコンテナを新しく構築し，起動する．さらにそのコンテナ内でコマンドを実行する．起動時にshellプロセスやbashプロセスを実行すると，コンテナに接続できる．何も渡さない場合は，デフォルトのプロセスとしてshellプロセスが実行される．runコマンドでは，アタッチモードとデタッチモードを選ぶことができる．新しく起動したコンテナを停止後に自動削除する場合は，rmオプションを付けるようにする． ＊コマンド例＊ # アタッチモードによる起動．フォアグラウンドで起動する． $ docker run -a -it --rm --name : /bin/bash # デタッチドモードによる起動．バックグラウンドで起動する． $ docker run -d -it --rm --name : /bin/bash コンテナを起動する時に，bashプロセスを実行すると以下のようなエラーが出ることがある．その場合は，shellプロセスを実行するようにする． docker: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: exec: \"/bin/bash\": stat /bin/bash: no such file or directory: unknown. 起動モードの違い ・アタッチモード起動 アタッチモードは，フォアグラウンド起動である．ターミナルにプロセスのログが表示されないため，同一ターミナルで他のコマンドを入力できる． ＊コマンド例＊ # -a：atattch mode $ docker run -a -it --name : /bin/bash ・デタッチドモード起動 デタッチドモードは，バックグラウンド起動である．ターミナルにプロセスのログが表示され続けるため，同一ターミナルで他のコマンドを入力できない．プロセスのログを監視できるが，他のプロセスを入力するためには，そのターミナル上でコンテナを停止させる必要がある． ＊コマンド例＊ # -d；detached mode $ docker run -d -it --name : /bin/bash 03. コンテナ側に対するマウント方法 Bindマウント ・Bindマウントとは ホストOSの/Usersディレクトリをコンテナ側にマウントする方法．コンテナで作成されたデータをホストOSに永続化する方法として，非推奨である．また，Dockerfileまたはdocker-composeファイルに記述する方法があるが，後者が推奨である． ＊コマンド例＊ # ホストOSをコンテナ側にbindマウント $ docker run -d -it --name /bin/bash \\ --mount type=bind, src=home/projects/, dst=/var/www/ ・マウント元として指定できるディレクトリ 以下の通り，ホストOSのマウント元のディレクトリにはいくつか選択肢がある． Volumeマウント ・Volume（Data Volume），Dockerエリアとは ホストOSのDockerエリア（/var/lib/docker/volumesディレクトリ）に保存される永続データのこと．Data Volumeともいう．Volumeへのパス（/var/lib/docker/volumes//_data）は，マウントポイントという． ・Volumeマウントとは ホストOSにあるDockerエリアのマウントポイントをコンテナ側にマウントする方法．コンテナで作成されたデータをホストOSに永続化する方法として推奨である． ＊コマンド例＊ Docker Composeで行うことが推奨されている． # ホストOSのDockerエリアにVolumeを作成 $ docker volume create # DockerエリアのVolumeの一覧を表示 $ docker volume ls # DockerエリアのVolumeを削除 $ docker volume rm # DockerエリアのVolumeの詳細を表示 $ docker volume inspect [ { \"CreatedAt\": \"2020-09-06T15:04:02Z\", \"Driver\": \"local\", \"Labels\": { \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.26.2\", \"com.docker.compose.volume\": \"xxx\" }, \"Mountpoint\": \"/var/lib/docker/volumes/_xxx/_data\", \"Name\": \"_xxx\", \"Options\": null, \"Scope\": \"local\" } ] # DockerエリアをVolumeマウントして起動 # マウントポイントのVolume名を使用 $ docker run -d -it --name /bin/bash \\ --mount type=volume, src= volume-driver=local, dst= ＊実装例＊ DockerfileでVolumeマウントを行う場合，マウント先のコンテナ側ディレクトリ名を指定する．Dockerエリアのマウントポイントは，自動的に作成される．Docker Composeで行うことが推奨されている． FROM ubuntu RUN mkdir /myvol RUN echo \"hello world\" > /myvol/greeting # マウント先のコンテナ側ディレクトリ名 VOLUME /myvol ・Data Volumeコンテナによる永続化データの提供 Volumeを使用する場合のコンテナ配置手法の一つ．DockerエリアのVolumeをData Volumeをコンテナ （Data Volumeコンテナ）のディレクトリにマウントしておく．Volumeを使用する時は，Dockerエリアを参照するのではなく，Data Volumeコンテナを参照するようにする． ＊実装例＊ # ここに実装例 一時ファイルシステムマウント 04. ホストとコンテナの間のネットワーク接続 bridgeネットワーク ・bridgeネットワークとは 複数のコンテナ間に対して，仮想ネットワークで接続させる．また，仮想ネットワークを物理ネットワークの間を，仮想ブリッジを用いてbridge接続する．ほとんどの場合，この方法を用いる． 参考：https://www.itmedia.co.jp/enterprise/articles/1609/21/news001.html 物理サーバへのリクエストメッセージがコンテナに届くまでを以下に示す．物理サーバの8080番ポートと，WWWコンテナの80番ポートのアプリケーションの間で，ポートフォワーディングを行う．これにより，『http://:8080』にリクエストを送信すると，WWWコンテナのポート番号に転送されるようになる． 処理場所 リクエストメッセージの流れ プライベートIPアドレス例 ポート番号例 コンテナ内プロセス プロセスのリッスンするポート :80 ↑ コンテナ コンテナポート ・http://127.0.0.1・http:// :80 ↑ ホストOS 仮想ネットワーク http://172.XX.XX.XX ↑ ホストOS 仮想ブリッジ ↑ ホストハードウェア 物理サーバのNIC（ Ethernetカード） http://127.0.0.1 :8080 ・ネットワークの接続方法確認 ＊コマンド例＊ $ docker network ls NETWORK ID NAME DRIVER SCOPE ae25b9b7740b bridge bridge local aeef782b227d tech-notebook_default bridge local ・コンテナへのホスト名割り当て コンテナ内のetc/hostsファイルで，コンテナのプライベートIPアドレスを確認できる．hostnameオプションで命名していればその名前，指定していなければランダムな文字列が割り当てられる． ＊コマンド例＊ $ docker run -d -it --hostname --name --publish=8080:80 : /bin/bash $ docker exec -it /bin/bash [root@:/] cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 172.18.0.2 ・未使用のネットワークを削除 $ docker network prune ・ネットワークに接続するコンテナを確認 複数のコンテナが起動している時に，コンテナがいずれのネットワークを使用しているかを確認する． $ docker network inspect noneネットワーク ・noneネットワークとは 特定のコンテナを，ホストOSや他のコンテナとは，ネットワーク接続させない． ＊コマンド例＊ $ docker network list NETWORK ID NAME DRIVER SCOPE 7edf2be856d7 none null local hostネットワーク ・hostネットワークとは 特定のコンテナに対して，ホストOSと同じネットワーク情報をもたせる． ＊コマンド例＊ $ docker network list NETWORK ID NAME DRIVER SCOPE ac017dda93d6 host host local コンテナ間の接続方法 ・『ホストOS』から『ホストOS（localhost）』にリクエスト 『ホストOS』から『ホストOS』に対して，アウトバウンドなリクエストを送信する．ここでのホストOSのホスト名は，『localhost』となる．リクエストは，ポートフォワーディングされたコンテナに転送される．ホストOSとコンテナの間のネットワーク接続の成否を確認できる． ＊コマンド例＊ 『ホストOS』から『ホストOS』に対してアウトバウンドなリクエストを送信し，ホストOSとappコンテナの間の成否を確認する． # ホストOSで実行 $ curl --fail http://localhost:8080/ ・『コンテナ』から『コンテナ』にリクエスト 『コンテナ』から『コンテナ』に対して，アウトバウンドなリクエストを送信する．ここでのコンテナのホスト名は，コンテナ内の『/etc/hosts』に定義されたものとなる．リクエストはホストOSを経由せず，そのままコンテナに送信される．コンテナ間のネットワーク接続の成否を確認できる．コンテナのホスト名の定義方法については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_virtualization_container_orchestration.html ＊コマンド例＊ 『appコンテナ』から『nginxコンテナ』に対して，アウトバウンドなリクエストを送信し，appコンテナとnginxコンテナの間の成否を確認する． # コンテナ内で実行 $ curl --fail http://:80/ ・『コンテナ』から『ホストOS（host.docker.internal）』にリクエスト 『コンテナ』から『ホストOS』に対して，アウトバウンドなリクエストを送信する．ここでのホストOSのホスト名は，『host.docker.internal』になる．リクエストは，ホストOSを経由して，ポートフォワーディングされたコンテナに転送される．ホストOSとコンテナの間のネットワーク接続の成否を確認できる． # コンテナ内で実行 $ curl --fail http://host.docker.internal:8080/ 05. プラグイン Volumeプラグイン ・NFSストレージ NFSプラグインを使用することで，永続化データを/var/lib/docker/volumesではなく，NFSストレージに保存する． ＊実装例＊ 以下にdocker-composeを使用した場合を示す．docker-composeについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_virtualization_container_orchestration.html version: \"3.7\" services: app: build: # 省略 ports: # 省略 depends_on: # 省略 volumes: - example:/data # 下方のオプションが適用される． volumes: example: driver_opts: # NFSプラグインを使用し，NFSストレージに保存． type: \"nfs\" o: \"addr=10.40.0.199,nolock,soft,rw\" device: \":/nfs/example\" 06. ロギング コマンド ・docker logsの参照先ディレクトリ コンテナ内の/dev/stdout（標準出力）と/dev/stderr（標準エラー出力）に出力されたログをまとめて表示する．ログファイルに出力しない理由として，出力先がログファイルであると，開発環境のコンテナ内のアプリケーションサイズが肥大化してしまう．これを防ぐために，ログファイルにエラーを出力しないようにしている． ・指定したコンテナのログを確認 ＊コマンド例＊ # 指定した行数だけ，ログを表示する． $ docker logs --follow=true --tail=500 各ベンダーのイメージのログ出力先 ・nginxイメージ 公式のnginxイメージは，/dev/stdoutというシンボリックリンクを，/var/log/nginx/access.logに作成している．また，/dev/stderrというシンボリックリンクを，/var/log/nginx/error.logに作成している．これにより，これらのファイルに対するログの出力は，/dev/stdoutと/dev/stderrに転送される． ・php-fpmイメージ 要勉強． ロギングドライバー ・ロギングドライバーとは コンテナ内の/dev/stdoutと/dev/stderrに出力されたログを，ファイルやAPIに対して出力する． ロギングドライバー名 ログの出力先 備考 json-file /var/lib/docker/containers/＜コンテナID＞/＜コンテナID＞-json.logファイル デフォルトの設定． none ログを記録しない． awslogs CloudWatch LogsのAPI docker logsコマンドで確認できない． gcplogs Google Cloud LoggingのAPI docker logsコマンドで確認できない． "},"public/infrastructure_virtualization_container_orchestration.html":{"url":"public/infrastructure_virtualization_container_orchestration.html","title":"▶ ︎コンテナオーケストレーション","keywords":"","body":"コンテナオーケストレーション はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コンテナオーケストレーションの種類 単一ホストOS上のコンテナオーケストレーション 単一ホストOS上のコンテナが対象である．異なるDockerfileに基づいて，Dockerイメージのビルド，コンテナレイヤーの生成，コンテナの構築，コンテナの起動，を実行できる． ツール名 ベンダー Docker Compose Docker ECS：Elastic Container Service Amazon 複数ホストOSに渡るコンテナオーケストレーション 複数ホストOS上のコンテナが対象である．どのホストOSのDockerデーモンに対して，どのコンテナに関する操作を行うのかを選択的に命令できる． 参考：https://www.techrepublic.com/article/simplifying-the-mystery-when-to-use-docker-docker-compose-and-kubernetes/ ツール名 ベンダー Docker Swarm Docker Kubernetes Google EKS：Elastic Kubernetes Service Amazon 02. コンテナデザインパターン サイドカー・パターン ・サイドカー・パターンとは アプリケーションコンテナを補助するコンテナとして，同じECSタスクやPod内に配置する． ・ロギングコンテナの配置 FluentBitコンテナをサイドカーコンテナとして稼働させ，アプリケーションコンテナから送信されたログを他にルーティングする． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_fluentd_and_fluentbit.html ・メトリクス収集コンテナの配置 Datadogコンテナをサイドカーコンテナとして稼働させ，アプリケーションコンテナからメトリクスを収集する． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_datadog.html アンバサダー・パターン アダプター・パターン "},"public/infrastructure_virtualization_container_orchestration_docker_compose.html":{"url":"public/infrastructure_virtualization_container_orchestration_docker_compose.html","title":"▶ ︎Docker Compose","keywords":"","body":"Docker Compose はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コマンド config ・configとは バリデーションとして，docker-compose.ymlファイルを展開する．ファイル内で，相対パスや変数を使用している場合，これらが正しく設定されているかを確認できる． ・オプションなし $ docker-compose config build ・buildとは イメージをビルドする． ・--no-cache キャッシュを使用せずにイメージをビルドする． $ docker-compose build --no-cache up ・upとは 指定したサービスのイメージのビルド，コンテナレイヤー生成，コンテナ構築，コンテナ起動を行う．コンテナ構築までが完了していて停止中が存在する場合，これをコンテナを起動する．また起動中のコンテナがあれば，これを再起動する．オプションにより起動モードが異なる． ・オプションなし 指定したサービスのイメージのビルド，コンテナレイヤー生成，コンテナ構築，コンテナ起動を行う．アタッチモードでコンテナを起動する． # アタッチモード $ docker-compose up ・-d 指定したサービスのイメージのビルド，コンテナレイヤー生成，コンテナ構築，コンテナ起動を行う．デタッチドモードでコンテナを起動する． # デタッチモード $ docker-compose up -d ・--build イメージをビルドし，コンテナを構築する． $ docker-compose up --build run ・runとは すでに停止中または起動中のコンテナが存在していても，これとは別にコンテナを新しく構築し，起動する．さらにそのコンテナ内でコマンドを実行する．起動時にbashプロセスやbashプロセスを実行すると，コンテナに接続できる．何も渡さない場合は，デフォルトのプロセスとしてbashプロセスが実行される．runコマンドでは，アタッチモードとデタッチモードを選ぶことができる．新しく起動したコンテナを停止後に自動削除する場合は，rmオプションを付けるようにする．service-portsオプションを使用しないと，ホストOSとコンテナ間のポートフォワーディングを有効化できないため注意する． ・--service-ports 既存コンテナを残して，指定したサービスの新しいコンテナをアタッチモードで起動する．また，ホストOSとコンテナ間のポートフォワーディングを有効化する． # アタッチモード $ docker-compose run --rm --service-ports ・-d --service-ports 既存コンテナを残して，指定したサービスの新しいコンテナをデタッチドモードで起動する．また，ホストOSとコンテナ間のポートフォワーディングを有効化する． # デタッチモード $ docker-compose run --rm -d --service-ports stop ・stopとは 指定したサービスの起動中コンテナを全て停止する． ・オプションなし $ docker-compose stop down ・downとは 指定したリソースを削除する． ・--rmi --volumes --remove-orphans 全てのリソース（イメージ，コンテナ，ボリューム，ネットワーク）を削除する． $ docker-compose down --rmi all --volumes --remove-orphans logs ・logsとは コンテナ内に入ることなく，起動プロセスから出力されるログを確認することできる． ・オプションなし バックグラウンドでログを表示する． $ docker-compose logs ・-f フォアグラウンドでログを表示する． $ docker-compose logs -f 02. docker-compose.yml services ・servicesとは コンテナオーケストレーションにおける一つのコンテナを定義する．コンテナ名と異なり，サービス名は他のプロジェクトと重複してもよい．docker-composeコマンドの引数として指定するため，できるだけ簡潔にする．オプション一覧は以下を参考にせよ． 参考：https://docs.docker.jp/compose/compose-file.html ・args DockerfileのARGSに展開する変数を定義する．Dockerfileに直接実装することとの使い分けとして，Dockerfileの実装は簡単に変更できないが，docker-compose.ymlファイルにおける定義は変更しやすい．そのため，使用者に変更して欲しくない変数はDockerfileに実装し，変更しても問題ない変数はこのオプションを使用する．他に，マルチステージビルドを使用しており，全てのステージで共通した変数を展開したい場合，このオプションを使用すると展開する変数を共通化できる． ＊実装例＊ build: args: - PARAM=$PARAM ARG PARAM ENV PARAM=${PARAM} ＊実装例＊ # ここに実装例 ・build: dockerfile Dockerfileの名前．パスごと指定する． ＊実装例＊ build: dockerfile: ./infra/docker/www/Dockerfile ・build: context 指定したDockerfileのあるディレクトリをカレントディレクトリとして，Dockerデーモン（Dockerエンジン）に送信するディレクトリを指定する． ＊実装例＊ build: context: . ・build: target ビルドするステージ名．主に，マルチステージビルドの時に使用する． ＊実装例＊ build: target: develop ・command コンテナの起動時に最初に実行するコマンドを設定する．Dockerfileを必要とせず，ベンダーが提供するイメージをそのまま使用するような場合に役立つ． ＊実装例＊ mysqlイメージを使用してコンテナを構築するときに，最初に文字コードを設定するコマンドを実行する． command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci ・container_name コンテナ名を命名する．サービス名とは異なり，コンテナ名は他のプロジェクトと重複しないようにする． ＊実装例＊ container_name: www ・depends_on コンテナが起動する順番を設定する． ＊実装例＊ DBコンテナの起動後に，該当するコンテナを起動するようにする． depends_on: - db ・env_file，environment コンテナで展開する環境変数を定義する．Dockerfile内での環境変数とは異なり，マルチステージビルドの全ステージで使用できる．dotenv系ライブラリを使用しなくてもよくなる． ＊実装例＊ mysqlイメージを使用した場合，データベースの環境変数の設定が必要である．データベースの環境変数は，バックエンドコンテナでも必要なため，environmentキーに直接環境変数を設定せずに，envファイルに定義した環境変数をenvironmentキーで参照するとよい． env_file: - .env environment: MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD} # rootユーザのパス MYSQL_DATABASE: ${DB_DATABASE} # データベース名 MYSQL_USER: ${DB_USER} # 一般ユーザ名 MYSQL_PASSWORD: ${DB_PASSWORD} # 一般ユーザのパス # .envファイル MYSQL_ROOT_PASSWORD=foo # rootユーザのパス MYSQL_DATABASE=bar # データベース名 MYSQL_USER=baz # 一般ユーザ名 MYSQL_PASSWORD=qux # 一般ユーザのパス mysqlイメージでは，環境変数の設定に応じて，コンテナ起動時にSQLが実行されるようになっている．データベース名の環境変数が設定されている場合は『CREATE DATABASE』，またユーザ名とパスワードが設定されている場合は『CREATE USER』と『GRANT ALL』のSQLが実行される． 参考：https://github.com/docker-library/mysql/blob/master/5.7/docker-entrypoint.sh#L308-L322 ルートユーザ名は定義できず，『root』となる． 参考：https://github.com/docker-library/mysql/blob/master/5.7/docker-entrypoint.sh#L156 ・extra_host コンテナに，ユーザ定義のプライベートIPアドレスと，これにマッピングされたホスト名を設定する．マッピングは，/etc/hostsファイルに書き込まれる．もし設定しなかった場合，サービス名またはコンテナ名がホスト名として扱われる． extra_hosts: - www:162.242.195.82 $ cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters # ユーザ定義のプライベートIPアドレスと，これにマッピングされたホスト名 162.242.195.82 www 172.23.0.3 c9bd8ace335d ・hostname ＊実装例＊ コンテナに割り当てられるプライベートIPアドレスに，指定したホスト名をマッピングする．マッピングは，/etc/hostsファイルに書き込まれる．もし設定しなかった場合，サービス名またはコンテナ名がホスト名として扱われる． ＊実装例＊ hostname: www $ cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters # プライベートIPアドレスにマッピングされたホスト名 172.18.0.3 www ・networks コンテナを接続する内部／外部ネットワークのエイリアス名を設定する．ネットワーク名ではなく，エイリアス名を指定することに注意する． ＊実装例＊ networks: # 内部／外部ネットワークのエイリアス名を指定する． - foo-network ネットワークに接続されているコンテナはコマンドで確認できる． # 指定したネットワークに接続するコンテナを確認する． $ docker network inspect foo-network [ { \"Name\": \"foo-network\", 〜 省略 〜 \"Containers\": { \"e681fb35e6aa5c94c85acf3522a324d7d75aad8eada13ed1779a4f8417c3fb44\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" \"33632947e4210126874a7c26dce281642a6040e1acbebbdbbe8ba333c281dff8\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" } }, 〜 省略 〜 \"Labels\": { \"com.docker.compose.network\": \"foo-network\", \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.29.0\" } } ] なお，接続するネットワークは明示的に指定しなくてもよい．その場合，『_default』というネットワークが，『default』というエイリアス名で作成される． networks: # defaultは，明示的に指定してもしなくてもどちらでもよい． - default $ docker network inspect _default [ { \"Name\": \"_default\", 〜 省略 〜 \"Containers\": { \"e681fb35e6aa5c94c85acf3522a324d7d75aad8eada13ed1779a4f8417c3fb44\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" \"33632947e4210126874a7c26dce281642a6040e1acbebbdbbe8ba333c281dff8\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" } }, 〜 省略 〜 \"Labels\": { \"com.docker.compose.network\": \"default\", \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.29.0\" } } ] ・image イメージに名前をつける．標準では，『プロジェクト名_サービス名』となる． ＊実装例＊ image: tech-notebook-www: ・platform コンテナのCPUアーキテクチャを設定する． ＊実装例＊ platform: linux/amd64 ・ports ホストOSとコンテナの間のポートフォワーディングを設定する．コンテナのみポート番号を指定した場合，ホストOS側のポート番号はランダムになる． ＊実装例＊ ports: - \"8080:80\" # : ・stdin_open docker-composeコマンドの裏側で実行されるrunコマンドにおいて，iオプションを有効化する． ＊実装例＊ stdin_open: true ・tty docker-composeコマンドの裏側で実行されるrunコマンドにおいて，tオプションを有効化する．疑似ターミナルを割り当てるによって，exitの後もバックグラウンドでコンテナを起動させ続けられる． ＊実装例＊ tty: true ・volumes（Bindマウント） 最上層とservice内で，異なるVolume名を記述した場合，Bindマウントを定義する．ホストOSにある/Usersディレクトリをコンテナ側にマウントする． ＊実装例＊ volumes: - ./app:/var/www/app # : ・volumes（Volumeマウント） 最上層とservice内の両方に，同じVolume名を記述した場合，Volumeマウントを定義する．DockerエリアにVolumeが作成され，serviceオプション内に設定したvolumesオプションでVolumeマウントを行う． ＊実装例＊ service: db: volumes: # volumeマウント - mysql_volume:/var/www/lib/mysql volumes: # volume名 mysql_volume: # localで，ホストOSのDockerエリアを指定 driver: local ・変数展開 環境変数をdocker-compose.ymlファイルに展開する．変数の展開にあたり，docker-compose.ymlファイルと同じ階層にある.envファイルが自動的に読み込まれる．この展開にenv_fileオプションを使用することはできない．そのため，例えば.envファイル以外の名前の環境変数ファイルを変数展開のために使用することはできない． ＊実装例＊ build: # 出力元の値は，.envファイルに定義しなければならない． target: ${APP_ENV} image: ${APP_ENV}-foo-app networks ・networksとは 標準のネットワークを作成する．ただし定義しなくとも自動的に構築される．ネットワーク名は，指定しない場合に『_default』になる． ・default - name ネットワーク名をユーザ定義名にする． networks: default: # ユーザ定義のネットワーク名とエイリアス名 name: foo-network なお，このネットワークを明示的に設定する場合は，エイリアス名（default）で指定する． networks: # defaultは，明示的に指定してもしなくてもどちらでもよい． - default $ docker network ls NETWORK ID NAME DRIVER SCOPE ************ foo-network bridge local $ docker network inspect foo-network [ { \"Name\": \"foo-network\", 〜 省略 〜 \"Containers\": { \"e681fb35e6aa5c94c85acf3522a324d7d75aad8eada13ed1779a4f8417c3fb44\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" \"33632947e4210126874a7c26dce281642a6040e1acbebbdbbe8ba333c281dff8\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" } }, 〜 省略 〜 \"Labels\": { \"com.docker.compose.network\": \"foo-network\", \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.29.0\" } } ] ・external 異なるdocker-compose.ymlファイルから接続できるネットワークを作成する．作成されるネットワーク名とエイリアス名は，externalキーの上部で設定したものになる． ＊実装例＊ バックエンドとフロントエンドが異なるdocker-compose.ymlファイルで管理されている．フロントエンドコンテナからバックエンドコンテナに接続できるように，ネットワークを作成する． # バックエンドのDocker-compose services: app: container_name: backend-container # --- 省略 --- # networks: # 作成したい外部ネットワーク名とエイリアス名 backend: external: true フロントエンドコンテナにて，エイリアス名にネットワーク名を指定して， # フロントエンドのDocker-compose services: app: container_name: frontend-container # 内部／外部ネットワークのいずれかのエイリアス名を指定する． networks: - backend # --- 省略 --- # networks: default: external: # 接続したい外部ネットワーク名とエイリアス名 name: backend 作成した内部／外部ネットワークは，コマンドで確認できる．『_default』というネットワーク名になる． ＊コマンド例＊ $ docker network ls NETWORK ID NAME DRIVER SCOPE ************ backend bridge local 03. イメージ別Tips mysqlイメージ ・ビルド時にSQL実行 mysqlコンテナにはdocker-entrypoint-initdb.dディレクトリがある．このディレクトリに配置されたsqlファイルやbashプロセスは，mysqlコンテナのビルド時にdocker-entrypoint.shファイルによって実行される．そのため，Bindマウントを用いてこのディレクトリにファイルを置くことで，初期データの投入や複数データベースの作成を実現できる．具体的な実行タイミングについては，以下を参考にせよ． 参考：https://github.com/docker-library/mysql/blob/master/8.0/Dockerfile.debian#L92-L93 ＊実装例＊ mysqlコンテナに，PHPUnitの実行時のみ使用するデータベースを追加する．以下のような，docker-compose.ymlファイルを作成する． version: \"3.7\" services: db: container_name: foo-mysql hostname: foo-mysql image: mysql:5.7 ports: - \"3307:3306\" volumes: - mysql_volume:/var/www/lib/mysql # docker-entrypoint-initdb.dディレクトリにBindマウントを行う． - ./infra/docker/mysql/init:/docker-entrypoint-initdb.d environment: MYSQL_ROOT_PASSWORD: foo MYSQL_DATABASE: foo MYSQL_USER: foo MYSQL_PASSWORD: foo TZ: \"Asia/Tokyo\" command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci networks: - default volumes: mysql_volume: また，docker-entrypoint-initdb.dディレクトリに配置するファイルとして，以下のsqlファイルを作成する．このファイルでは，testというデータベースを作成するためのSQLを実装する． -- /infra/docker/mysql/initにSQLファイルを置く． CREATE DATABASE IF NOT EXISTS `test` COLLATE 'utf8mb4_general_ci' CHARACTER SET 'utf8mb4'; GRANT ALL ON *.* TO 'foo'@'%' ; PHPUnitで接続するデータベースを指定する方法については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_testing.html "},"public/infrastructure_virtualization_container_orchestration_kubernetes.html":{"url":"public/infrastructure_virtualization_container_orchestration_kubernetes.html","title":"▶ ︎Kubernetes","keywords":"","body":"Kubernetes はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コマンド Kubectl ・Kubectlとは 02. .yml spec／statu 参考：https://kubernetes.io/ja/docs/concepts/overview/working-with-objects/kubernetes-objects/ Node ・Master Node Kubernetesが実行されるホスト物理サーバを指す． ・Worker Node Dockerが実行されるホスト仮想サーバを指す． Service ・Serviceとは Podにリクエストを転送するロードバランサーとして機能する． 参考：https://kubernetes.io/ja/docs/concepts/services-networking/service/ ・定義 apiVersion: v1 kind: Service metadata: name: my-service # Service名 spec: selector: app: MyApp ports: - protocol: TCP port: 80 # Service受信ポート targetPort: 9376 # 転送先のPod受信ポート Pod ・Podとは ホスト仮想サーバ上のコンテナを最小グループ単位のこと．Podを単位として，コンテナ起動／停止や水平スケールイン／スケールアウトを実行する． 参考：https://kubernetes.io/ja/docs/concepts/workloads/pods/ AWS ECSタスクにおける類似するessential機能やオートスケーリングについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws.html ＊例＊ PHP-FPMコンテナとNginxコンテナを稼働させる場合，これら同じPodに配置する． ・定義 apiVersion: batch/v1 kind: Job metadata: name: hello spec: template: # Pod spec: containers: - name: hello # Pod内コンテナ名 image: busybox # イメージ command: ['sh', '-c', 'echo \"Hello, Kubernetes!\" && sleep 3600'] # コンテナ起動時コマンド restartPolicy: OnFailure Secret ・Secretとは セキュリティに関するデータを管理し，コンテナに選択的に提供するもの． Replica Set ・Replica Set（Replication Controller）とは 02. Istio Istioとは ただし，Istioを必ずしも使用する必要はなく，Kubernetesの標準の機能でこれを実現してもよい． 参考：https://qiita.com/Ladicle/items/4ba57078128d6affadd5 システムのコンポーネント間通信を制御しきれない． 障害時に何が起こるか分からない． 鍵と証明書を管理しきれない． システムの全体像が把握できない ・依存関係の解決 マイクロサービスアーキテクチャの各アプリケーションを管理するソフトウェアのこと．機能『A ---> B ---> C ---> D』を持つモノリシックアプリケーションがあるとする．これをマイクロサービス化して，ABCDを別々のアプリケーションに分割する．それぞれのアプリケーションがPod上で稼働することになる．しかし，これだけではABCDが独立しておらず，各機能は一つ前の機能に依存している．この依存関係を解決する． Istiod ・Istiodとは Envoyを管理する機能のこと．Envoyは，各アプリケーションから通信を委譲され，アプリケーション間の通信を代理で行う． "},"public/infrastructure_virtualization_container_orchestration_docker_swarm.html":{"url":"public/infrastructure_virtualization_container_orchestration_docker_swarm.html","title":"▶ ︎Docker Swarm","keywords":"","body":"Docker Swarm はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 概念 "},"public/infrastructure_virtualization_server.html":{"url":"public/infrastructure_virtualization_server.html","title":"▶ ︎仮想サーバ（仮想マシン）","keywords":"","body":"仮想サーバ（仮想マシン） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Providerによる仮想サーバ（仮想マシン）の構築 Providerの操作 ・Providerとは 基本ソフトウェアにおける制御プログラムや一連のハードウェアを仮想的に構築できる．これを，仮想サーバ（仮想マシンとも）という．構築方法の違いによって，『ホスト型』，『ハイパーバイザ型』に分類できる． Provisionerの操作 ・Provisionerとは Providerによって構築された仮想サーバに，Web開発のためのソフトウェアをインストールすることができる（構成管理することができる）．具体的には，プログラミング言語やファイアウォールをインストールする． VagrantによるProviderとProvisionerの操作 ・Vagrantとは ProviderとProvisionerの操作を自動化できる．チームメンバーが別々に仮想サーバを構築する場合，ProviderとProvisionerの処理によって作られる仮想サーバの環境に，違いが生じてしまう．Vagrantを使う場合，ProviderとProvisionerによる処理方法は，Vagrantfileに記述されている．このために，Vagrantを用いれば，チームメンバーが同じソフトウェアの下で，仮想サーバを構築し，ソフトウェアをインストールすることができる． ・サーバの情報の管理方法 サーバの情報は，.envファイルで以下の様に管理する．全ての値が文字列として認識されるため，数値や真偽値は使用できない． #======================================= # Webサーバ情報 #======================================= WEB_HOST= #======================================= # データベースサーバ情報 #======================================= DB_HOST=foo-db DB_NAME=foo DB_USER=foo DB_PASSWORD=***** ・主なvagrantコマンド コマンド 処理 vagrant up 仮想サーバ起動 vagrant halt 仮想サーバ停止 vagrant ssh 仮想サーバへのリモート接続 vagrant global-status 起動中仮想サーバの一覧 02. フレームワークのビルトインサーバの構築 "},"public/infrastructure_ci_cd.html":{"url":"public/infrastructure_ci_cd.html","title":"▶ ︎CI／CD","keywords":"","body":"CI & CD はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. CICDパイプライン ・CICDパイプラインとは Commitから本番環境へのDeployまでのプロセスを『継続的に』行うことを，CI：Continuous Integration』という．また，変更内容をステージング環境などに自動的に反映し，『継続的に』リリースすることを，CD：Continuous Deliveryという． ・自動化できるプロセスとできないプロセス プロセス 自動化の可否 説明 Build 〇 CI/CDツールとIaCツールで自動化可能 Unitテスト，Functionalテスト 〇 CI/CDツールとテストフレームワークで自動化可能． Integrationテスト ✕ テスト仕様書を作成し，動作を確認する必要がある． コーディング規約に関するReview 〇 CI/Cdツールと静的解析ツール 仕様に関するReview ✕ GitHub上でレビューする必要がある． ステージング環境へのデプロイ 〇 CI/CDツールで自動化可能． 本番環境へのデプロイ 〇 CI/CDツールで自動化可能． "},"public/infrastructure_circleci.html":{"url":"public/infrastructure_circleci.html","title":"▶ ︎CircleCI","keywords":"","body":"CircleCI はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. CircleCIとは 設定ファイルの参考ドキュメント https://circleci.com/docs/reference-2-1/#circleci-2-1-reference 設定ファイルのデバッグ ・デバッグの事前準備 デバッグでは行数がわからない仕様になっている．そこで，Workflowのjobのどこで失敗しているのかを特定するために，検証しないjobをコメントアウトしておく． workflows: # build以外を実行しないようにすることで，buildのみを検証できる． build-test-and-deploy: jobs: - build # - test1: # requires: # - build # - test2: # requires: # - test1 # - deploy: # requires: # - test2 ・バリデーション ホストOS側で，以下のコマンドを実行する． $ circleci config validate # 以下の文章が表示されれば問題ない． # Config file at .circleci/config.yml is valid. ・処理の展開 設定ファイルを実行した時の処理を展開し，ファイルに出力できる $ circleci config process .circleci/config.yml > .circleci/process.yml ・ローカルテスト コマンドにより，テストに必要なDockerイメージをpullし，コンテナを構築する．続いて，コンテナ内でCircleCIを実行する．バージョン2.1以降では，事前に，設定ファイルの処理を展開しておく必要がある． # バージョン2.1の設定ファイルの処理を展開 $ circleci config process .circleci/config.yml > .circleci/process.yml # 専用のDockerコンテナを構築し，展開ファイルを元にテストを実行 $ circleci local execute -c .circleci/process.yml --job ・CircleCIコンテナにssh接続 CircleCIコンテナにssh接続し，コンテナ内で生成されたファイルを確認することができる． $ -i ~/.ssh/ ・Test Insights 各テストのパフォーマンスや成功失敗率を確認できる． https://circleci.com/docs/2.0/insights-tests/ PHPUnitの自動実行 ・仕組み テストクラスを実装したうえで，新機能を設計実装する． リポジトリへPushすると，CIツールがGituHubからブランチの状態を取得する． CIツールによって，DockerHubから取得したDockerfileのビルド，PHPUnitなどが自動実行される． 結果を通知することも可能． PHPStanの自動実行 ・仕組み 02-02. version versionとは CircleCIのバージョンを宣言． ＊実装例＊ version: 2.1 02-03. parameters parameters ・parametersとは 種類 参照範囲 値を設定する場所 command parameters command内で定義する．定義されたcommand内のみで定義できる． workflows job parameters job内で定義する．定義されたjob内のみで参照できる． workflows executors parameter executors内で定義する．定義されたexecutos内のみで参照できる． job pipeline parameters トップレベルで定義する．リポジトリ内でのみ参照できる． workflows command parameters ・値の出力方法 引数名を使用して，parametersから値を出力する． > ・job parameterを参照 定義できるデータ型は，job parameterと同じ．定義されたcommand内のみで定義できる． version: 2.1 commands: sayhello: description: \"Echo hello world\" # 引数の定義 parameters: to: type: string # デフォルト値 default: \"Hello World\" steps: - run: echo > job parameters ・値の出力方法 引数名を使用して，parametersから値を出力する． > ・デフォルト値について 引数が与えられなかった場合に適用されるdefaultを設定できる．defaultを設定しない場合，引数が必須と見なされる． version: 2.1 commands: sayhello: description: \"Echo hello world\" parameters: to: type: string default: \"Hello World\" steps: - run: echo > ・string型 引数として，任意の文字列を渡したいときに使用する．workflowsにて，値を設定する． ＊実装例＊ version: 2.1 commands: print: # 引数を定義 parameters: message: # デフォルト値が無い場合は必須 type: string steps: - run: echo > jobs: cat-file: parameters: file: type: string steps: - print: # parametersの値を渡す message: Printing > - run: cat > workflows: my-workflow: jobs: - cat-file: # workflowにて文字列型の値を設定 file: test.txt ・boolean型 多くの場合，引数がTrueの場合のみ，特定のstepを実行したい時に用いる．jobで定義した後，workflowsにて値を設定する．workflowsにて，値を設定する． ＊実装例＊ version: 2.1 jobs: job_with_optional_custom_checkout: # 引数の定義 parameters: custom_checkout: type: boolean # デフォルト値 default: false machine: true steps: - when: # 引数がtrueの場合 condition: > steps: - run: echo \"my custom checkout\" - unless: # 引数のfalseの場合 condition: > steps: - checkout workflows: build-test-deploy: jobs: - job_with_optional_custom_checkout: # workflowにてbool型の値を設定 custom_checkout: true ・enum型 引数として，特定の文字列や整数のみを渡したいときに用いる．workflowsにて，値を設定する． ＊実装例＊ version: 2.1 jobs: deploy: parameters: # 引数を定義 environment: # デフォルト値 default: \"test\" type: enum enum: [\"test\", \"stg\", \"prd\"] steps: - run: # デフォルト値testを与えるときは何も設定しない name: Deploy to > command: # 何らかの処理 workflows: deploy: jobs: - deploy: # workflowにてenum型の値を設定 environment: stg executors parameter ・値の出力方法 引数名を使用して，parametersから値を出力する． > ・job parametersを参照 引数として，任意の文字列をexecutorsに渡したいときに使用する．他のparametersとは異なり，jobにて，値を設定する． version: 2.1 executors: python: # 引数の定義 parameters: tag: type: string # デフォルト値 default: latest myspecialvar: type: string docker: - image: circleci/python:> environment: MYPRECIOUS: > jobs: build: executor: name: python tag: \"2.7\" # jobにて文字列型の値を設定 myspecialvar: \"myspecialvalue\" ・workflowで値を設定する 公式リファレンスには載っていないため，方法としては非推奨．parameterを渡したいexecutorを使いまわしたい時に使用する． version: 2.1 executors: python: # 引数の定義 parameters: env: type: enum enum: [ \"2.7\", \"3.5\" ] myspecialvar: type: string docker: - image: circleci/python:> environment: MYPRECIOUS: > jobs: build: # 引数の定義 parameters: # executorをデータ型として選択 executor_param: type: executor executor: > workflows: version: 2.1 build-push: jobs: - build: # jobにてexecutor名を設定し，さらにexecutorに値を渡す executor_param: name: python # バージョン3.5を設定 tag: \"2.7\" myspecialvar: \"myspecialvalue\" - build: executor_param: name: python # バージョン3.5を設定 tag: \"3.5\" myspecialvar: \"myspecialvalue\" pipeline parameters ・値の出力方法 引数名を使用して，pipeline.parametersから値を出力する． > ・job parametersを参照 定義できるデータ型は，job parameterと同じ．リポジトリ内でのみ参照できる． version: 2.1 parameters: # 引数を定義 image-tag: type: string # デフォルト値 default: \"latest\" workingdir: type: string default: \"~/main\" jobs: build: docker: - image: circleci/node:> auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD environment: IMAGETAG: > working_directory: > steps: - run: echo \"Image tag used was ${IMAGETAG}\" - run: echo \"$(pwd) == >\" workflows: my-workflow: jobs: - build: # 引数名: 渡す値 image-tag: \"1.0\" workdir: \"/tmp\" 02-04. jobs jobs ・jobsとは 複数のjobを定義する．Workflowsを使わない場合は，少なくとも一つのjobにはbuildという名前を使用しなければならない． ・jobの粒度 粒度 説明 備考 build プログラムの実行環境を構築する． buildとtestを分割しにくい場合は，同じjobで定義してもよい． test 種々のテスト（Unitテスト，Functionalテスト，など）を実行する． deploy ステージング環境または本番環境へのデプロイを実行する． docker，machine ・仮想環境の選択 jobを実行する仮想環境を選択できる． ・dockerタイプとは Dockerコンテナを実行環境として設定する．これを選択したうえで，Dockerイメージのビルド（Docker composeを含む）を実行する場合，実行環境Dockerコンテナの中でDockerコンテナを構築するという入れ子構造になる．これは非推奨のため，setup_remote_dockerを使用して，実行環境Dockerコンテナとは別の環境でjobを行う必要がある．また，dockerコマンドがインストールされていないイメージで合った場合に，setup_remote_dockerを有効化すると，これを使用できるようになる．machineタイプを選んだ場合，setup_remote_dockerは不要である．ただし，ボリュームマウントを使用できなくなるので注意する．また，DockerfileのCOPYコマンドが機能しなくなる． 参考：https://circleci.com/docs/ja/2.0/building-docker-images/ ＊実装例＊ version: 2.1 jobs: build: docker: - image: circleci/foo steps: - checkout # コンテナが入れ子にならないようにする． - setup_remote_docker - run: | # DockerHubへのログイン echo \"$DOCKER_PASS\" | docker login --username $DOCKER_USER --password-stdin docker run -d --name db company/proprietary-db:1.2.3 # Dockerイメージのビルド - run: docker build -t company/app:$CIRCLE_BRANCH . # DockerイメージのDockerHubへのデプロイ - run: docker push company/app:$CIRCLE_BRANCH ・machineタイプとは Linuxサーバを実行環境として設定する． ＊実装例＊ version: 2.1 jobs: build: machine: true steps: - checkout - run: | # DockerHubへのログイン echo \"$DOCKER_PASS\" | docker login --username $DOCKER_USER --password-stdin docker run -d --name db company/proprietary-db:1.2.3 # Dockerイメージのビルド - run: docker build -t company/app:$CIRCLE_BRANCH . # DockerイメージのDockerHubへのデプロイ - run: docker push company/app:$CIRCLE_BRANCH steps ・stepsとは 処理をMap型で定義する． ・when，unless if文を定義する．whenでは条件がtrueの場合，またunlessではfalseの場合に実行するstepを定義する． ＊実装例＊ version: 2.1 jobs: custom_checkout: parameters: custom_checkout_parameters: type: bool # デフォルト値はfalse default: false machine: true steps: # 引数がtrueの場合 - when: condition: > steps: - run: echo \"独自のチェックアウト処理\" # 引数がfalseの場合 - unless: condition: > steps: - checkout workflows: version: 2.1 build-test-deploy: jobs: - custom_checkout: # 引数名: 渡す値 custom_checkout_parameters: true ・restore_cache，save_cache ビルドのアーティファクトをキャッシュとして保存する．この機能を使用しない場合，例えば，CircleCIコンテナでcomposer installを実行すると，毎回のWorkflowで同じライブラリがインストールされる．しかし，Workflowのたびに，ライブラリをインストールするのは非効率である．そこで，composer.jsonファイルの実装が変更されない限り，前回のWorkflowのビルド時に，vendorディレクトリに配置されたアーティファクトを再利用するようにする．この機能は，複数のWorkflowの間だけでなく，一つのWorkflowの中でも利用できる． 参考：https://circleci.com/docs/ja/2.0/caching/#%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5 ＊実装例＊ composerを使用してライブラリをインストールする時に，前回の結果を再利用する． version: 2.1 jobs: build: steps: # composer.jsonが変更されている場合は処理をスキップ． - restore_cache: key: - v1-dependecies-{{ checksum \"composer.json\" }} - v1-dependencies- # 取得したcomposer.jsonを元に，差分のvendorをインストール - run: name: Run composer install commands: | composer install -n --prefer-dist # 最新のvendorディレクトリをキャッシュとして保存 - save_cache: key: v1-dependecies-{{ checksum \"composer.json\" }} paths: - ./vendor ＊実装例＊ yarnを使用してライブラリをインストールする時に，前回の結果を再利用する． version: 2.1 jobs: build_and_test: docker: - image: circleci/python:3.8-node steps: - checkout - restore_cache: keys: - v1-dependencies-{{ checksum \"package.json\" }} - v1-dependencies- - run: name: Run yarn install commands: | yarn install - save_cache: paths: - node_modules key: v1-dependencies-{{ checksum \"yarn.lock\" }} - run: name: Run yarn build commands : | yarn build - run: name: Run yarn test commands : | yarn test ただ，この機能はcommandsで共通化した方が可読性が良い． ＊実装例＊ version: 2.1 commands: restore_vendor: steps: # composer.jsonの実装が変更されていない場合は処理をスキップ． - restore_cache: key: - v1-dependencies-{{ checksum \"composer.json\" }} - v1-dependencies- save_vendor: steps: # 最新のvendorを保存． - save_cache: key: v1-dependencies-{{ checksum \"composer.json\" }} paths: - ./vendor jobs: build: steps: - restore_vendor # 取得したcomposer.jsonを元に，差分のvendorをインストール - run: name: Run composer install commands: | composer install -n --prefer-dist - save_vendor ・persist_to_workspace，attach_workspace CircleCIでは，jobごとに異なる仮想環境が構築されるため，他のjobで使用された一時ファイルを再利用したい場合に，これを使う． ＊実装例＊ version: 2.1 jobs: jobA: steps: # Workspaceにファイルをアップロード - persist_to_workspace: # jobAにて，Workspaceとするディレクトリのroot root: /tmp/workspace # Rootディレクトリを基準とした相対パス（\"./\"以外の場合は，ディレクトリの作成が必要） # パラメータは環境変数として出力できないので注意 paths: - target/application.jar - build/* jobB: steps: # persist_to_workspaceで作成されたWorkspaceからファイルをダウンロード - attach_workspace: # jobAとは異なるディレクトリに，ファイルをダウンロードしてもよい at: /tmp/workspace 全てのディレクトリを保持するような場合がほとんどと思われるため，カレントディレクトリ以下（.）を指定するのがよい． ＊実装例＊ version: 2.1 jobs: jobA: steps: - persist_to_workspace: root: . paths: - . jobB: steps: - attach_workspace: at: . 02-04. commands commandsとは 設定を部品化し，異なるjobでstepとして繰り返し利用できる． 部品化と再利用 ＊実装例＊ version: 2.1 commands: sayhello: description: \"Echo hello world\" parameters: text: type: string default: \"Hello World\" steps: # parametersの値を渡す - run: echo > jobs: myjob: docker: - image: \"circleci/node:9.6.1\" steps: # command名 - sayhello: # 引数名: 渡す値 text: \"Lev\" 02-05. executors executors ・executorsとは 実行環境に関する設定を部品化し，異なるjobで繰り返し利用できる． 部品化と再利用 ＊実装例＊ version: 2.1 executors: # ホストOS環境名 my-executor: # ホストOS環境 docker: - image: circleci/ruby:2.5.1-node-browsers working_directory: ~/foo_project environment: XX: xx YY: yy jobs: my-job: executor: my-executor steps: - run: echo \"${XX}と${YY}です\" 02-06. Workflow Workflowの粒度 ・ブランチ別 ＊実装例＊ workflows: # Featureブランチをレビュー feature: jobs: - build: name: build_feat filters: branches: only: - /feature.*/ - test: name: test_feat requires: - build_feat # ステージング環境にデプロイ develop: jobs: - build: name: build_stg filters: branches: only: - develop - test: name: test_stg requires: - build_stg - deploy: name: deploy_stg requires: - test_stg # 本番環境にデプロイ main: jobs: - build: name: build_prd filters: branches: only: - main - test: name: test_prd requires: - build_prd - deploy: name: deploy_prd requires: - test_prd 特殊なsteps ・pre-steps，post-steps 事前にjobに定義する必要はない．workspaceで，コールされるjobの引数として設定することで，そのjob内の最初と最後に，stepsを追加できる． ＊実装例＊ version: 2.1 jobs: bar: machine: true steps: - checkout - run: command: echo \"building\" - run: command: echo \"testing\" workflows: build: jobs: - bar: # Workspace前に行う処理 pre-steps: - run: command: echo \"install custom dependency\" # Workspace後に行う処理 post-steps: - run: command: echo \"upload artifact to s3\" Orbsを使う場合は，オプションに引数を渡す前に定義する． ＊実装例＊ workflows: build: jobs: - aws-foo/build-push-yyy: # Workspace前に行う処理 pre-steps: - run: command: echo \"FOO\" # Workspace後に行う処理 post-steps: - run: command: echo \"FOO\" # Orbsのオプション name: foo dockerfile: foo tag: foo filters ・filtersとは コミットされた時にjobが発火するブランチ名，あるいは発火しないブランチ名，を設定する．正規表現で実装する必要がある． ・only，ignore よくあるパターン 説明 /.*/ 全てのブランチを明示的に指定 /feature\\/.*/ 「feature/」と名前のついたブランチを指定 ＊実装例＊ workflows: version: 2.1 build: jobs: - foo: filters: branches: only: - /.*/ workflows: version: 2.1 build: jobs: - foo: filters: branches: ignore: - /feature\\/.*/ ・tags タグをつけたコミットに対して発火する．ignoreキーで全てのブランチを指定することにより，マージによる発火を防ぐことができる． workflows: version: 2.1 build: jobs: - foo: filters: branches: ignore: /.*/ tags: only: /release\\/.*/ 02-07. 環境変数 CircleCIにおける環境変数とは ・環境変数の種類と参照範囲 参照レベル 方法 説明 Bash export，source，$BASH_ENV runにおけるcommand内のみで参照できる．ただし，$BASH_ENVを使用すれば，異なるcommands間で値を共有可能． Container environment job内の特定のコンテナのみで参照できる． Job environment job内のみで参照できる． Project Environment Variables機能 リポジトリ内のみ参照できる． Global Contexts機能 異なるリポジトリ間で参照できる． ・環境変数の出力方法 環境変数をechoの引数に指定する．あらかじめエンコードされた環境変数を管理しておき，base64 --decodeを実行して出力すると，安全に環境変数を管理できる．ここで出力している環境変数は，以下のノートを参考にせよ 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_framework_vuejs.html jobs: build_and_ docker: - image: circleci/python:3.8-node steps: - checkout - run: name: Make env file command: | echo $API_URL_BROWSER | base64 --decode > .env echo $API_URL | base64 --decode >> .env echo $OAUTH_CLIENT_ID | base64 --decode >> .env echo $OAUTH_CLIENT_SECRET | base64 --decode >> .env echo $GOOGLE_MAP_QUERY_URL | base64 --decode >> .env - run: name: Install node module commands: | yarn install - run: name: Generate nuxt-ts commands: | yarn nuxt-ts generate なお，文字列の中に値を出力する変数展開の場合，${}を使用する． # 変数展開の場合 steps: - checkout - run: name: FOO commands: | echo \"This is ${FOO}\" Bashレベル ・commandキーによる設定 一番参照範囲が小さく，runにおける同じcommand内のみで参照できる．command内で使用する環境変数を定義するためには，『$BASH_ENV』にexport処理を格納する必要がある．定義したものを使用するためには，『$BASH_ENV』をsourceで読み込む必要があるために注意する． 参考：https://circleci.com/docs/ja/2.0/env-vars/#%E3%82%B7%E3%82%A7%E3%83%AB-%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E3%81%AE%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%81%AE%E8%A8%AD%E5%AE%9A ＊実装例＊ version: 2.1 jobs: build: docker: - image: smaant/lein-flyway:2.7.1-4.0.3 auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD steps: - run: name: Update PATH and Define Environment Variable at Runtime command: | echo \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV echo \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV source $BASH_ENV echo \"$PATH\" echo \"$VERY_IMPORTANT\" CircleCIではrunを実行する時に『$BASH_ENV』がsourceで自動的に読み込まれるようになっている．そのため，『$BASH_ENV』は複数のrun間」で共有できる．ただし，Alpineベースのイメージでは，この共有機能を使えないため注意する（かなりたくさんある）． 参考：https://github.com/circleci/circleci-docs/issues/1650 version: 2.1 jobs: build: docker: - image: smaant/lein-flyway:2.7.1-4.0.3 auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD steps: - run: name: Update PATH and Define Environment Variable at Runtime command: | echo \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV echo \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV - run: name: Echo # BASH_ENVが自動的に読み込まれる． command: | echo \"$PATH\" echo \"$VERY_IMPORTANT\" ・シェルスクリプトによる設定 環境変数に値を設定する処理をシェルスクリプトに切り分け，環境変数を使用する前にこれを読み込む． ＊実装例＊ version: 2.1 jobs: build: docker: - image: smaant/lein-flyway:2.7.1-4.0.3 auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD steps: - run: name: Update PATH and Define Environment Variable at Runtime command: | source export_envs.sh echo \"$PATH\" echo \"$VERY_IMPORTANT\" #!/bin/bash set -xeuo pipefail echo \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV echo \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV # 環境変数を出力します． source $BASH_ENV ・ヒアドキュメントで作成したシェルスクリプトによる設定 ヒアドキュメントを使用して，環境変数を設定できるシェルスクリプトを作成し，これを読み込む．ヒアドキュメントでは，各行でechoが実行される．そのため，echoの実装が不要であることに注意する． ＊実装例＊ cat \"export_envs.sh\" #!/bin/bash set -xeuo pipefail \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV source $BASH_ENV EOF Containerレベル Bashレベルより参照範囲が大きく，job内のみで参照できる．environmentをimageと同じ階層で定義する． version: 2.1 jobs: build: docker: - image: postgres:9.4.1 # imageと同じ階層で定義（） environment: POSTGRES_USER: root Projectレベル Containerレベルより参照範囲が大きく，プロジェクト内，すなわちリポジトリ内のみで参照できる．Environment Variables機能を使用する．環境変数の値が４文字未満，または環境変数の値が true、True、false、False のいずれかの場合，CircleCIの処理で出力されるプロジェクトの環境変数はマスキングされないため，注意が必要である． Grobalレベル Projectレベルより参照範囲が大きく，異なるプロジェクト間，すなわちリポジトリ間で参照できる．Contexts機能を使用する． 02-08. Docker Compose in CircleCI docker-composeのインストール ・dockerタイプの場合 自分でdocker-composeをインストールする必要がある．実行環境としてのDockerコンテナと，ビルドしたDockerコンテナが入れ子にならないように，setup_remote_dockerを実行する必要がある．ただし，ボリュームマウントを使用できなくなるので注意する． version: 2.1 jobs: build: machine: image: circleci/classic:edge steps: - checkout - setup_remote_docker - run: name: Install Docker Compose command: | set -x curl -L https://github.com/docker/compose/releases/download/1.11.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose - run: name: docker-compose up command: | set -x docker-compose up --build -d ・machineタイプの場合（推奨） 実行環境にmachineタイプを選択した場合，すでにdocker-composeがインストールされている． 参考：https://circleci.com/docs/ja/2.0/configuration-reference/#%E4%BD%BF%E7%94%A8%E5%8F%AF%E8%83%BD%E3%81%AA-machine-%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8 docker-compose & dockerize ・docker/install-dockerize CircleCIでDocker Composeを使用する場合に必要である．Docker Composeは，コンテナの構築の順番を制御できるものの，コンテナ内のプロセスの状態を気にしない．そのため，コンテナの構築後に，プロセスが完全に起動していないのにもかかわらず，次のコンテナの構築を開始してしまう．これにより，プロセスが完全に起動していないコンテナに対して，次に構築されたコンテナが接続処理を行ってしまうことがある．これを防ぐために，プロセスの起動を待機してから，接続処理を行うようにする．dockerizeの代わりの方法として，sleepコマンドを使用してもよい． 参考：https://github.com/docker/compose/issues/374#issuecomment-126312313 ＊実装例＊ LaravelコンテナとMySQLコンテナの場合を示す．コンテナ内に対してコマンドを実行する時のディレクトリは，DockerfileのWORKDIRによって決まるので注意する． version: 2.1 orbs: docker: circleci/docker@x.y.z commands: restore_vendor: steps: - restore_cache: key: - v1-dependecies-{{ checksum composer.json }} - v1-dependencies- save_vendor: steps: - save_cache: key: v1-dependecies-{{ checksum composer.json }} paths: - /vendor jobs: build_and_test: # Docker Composeの時はmachineタイプを使用する machine: image: ubuntu-1604:201903-01 steps: - checkout - run: name: Make env file command: | echo $ENV | base64 --decode > .env - run: name: Make env docker file command: | cp .env.docker.example .env.docker - run: name: Docker config command: | docker-compose config - run: name: Docker compose up command: | set -xe docker network create foo-network docker-compose up --build -d - restore_vendor # Dockerコンテナに対してcomspoerコマンドを送信 - run: name: Composer install command: | docker-compose exec laravel-container composer install -n --prefer-dist - save_vendor # Dockerizeをインストール - docker/install-dockerize: version: v0.6.1 - run: name: Wait for MySQL to be ready command: | # 代わりにsleepコマンドでもよい． dockerize -wait tcp://localhost:3306 -timeout 1m # Dockerコンテナに対してマイグレーションコマンドを送信 - run: name: Run artisan migration command: | docker-compose exec laravel-container php artisan migrate --force # Dockerコンテナに対してPHP-Unitコマンドを送信 - run: name: Run unit test command: | dockercompose exec laravel-container ./vendor/bin/phpunit # Dockerコンテナに対してPHP-Stanコマンドを送信 - run: name: Run static test command: | docker-compose exec laravel-container ./vendor/bin/phpstan analyse --memory-limit=512M DLC：Docker Layer Cache ・DLCとは CircleCIでDockerイメージをビルドした後，各イメージレイヤーをDLCボリュームにキャッシュする．そして，次回以降のビルド時に，差分がないイメージレイヤーをDLCボリュームからプルして再利用する．これにより，Dockerイメージのビルド時間を短縮できる． ・使用例 machineタイプで使用する場合，machineキーの下でdocker_layer_cachingを使う． ＊実装例＊ version: 2.1 orbs: docker: circleci/docker@x.y.z jobs: build_and_test: # Docker Composeの時はmachineタイプを使用する machine: image: ubuntu-1604:201903-01 # DLCを有効化 docker_layer_caching: true steps: - checkout - run: name: Make env file command: | echo $ENV_TESTING | base64 --decode > .env - run: name: Make env docker file command: | cp .env.docker.example .env.docker - run: name: Docker compose up command: | set -xe docker network create foo-network docker-compose up --build -d dockerタイプで使用する場合，dockerキーの下でdocker_layer_cachingを使う． ＊実装例＊ version: 2.1 jobs: build_and_push: executor: docker/docker steps: - setup_remote_docker # DLCを有効化 docker_layer_caching: true - checkout - docker/check - docker/build: image: / - docker/push: image: / 02-09. CircleCIライブラリ orbs ・orbsとは CircleCIから提供される汎用的なパッケージの使用を読み込む． ＊実装例＊ version: 2.1 orbs: hello: circleci/hello-build@0.0.5 workflows: \"Hello Workflow\": jobs: - hello/hello-build ・jobs，commands，executors 構造 説明 jobs workflowsにて，Orbsからjobとして使用できる． commands jobにて，stepとして使用できる． executors exexutorにて，事前定義されたexecutorsとして使用できる． ・オプションへの引数の渡し方と注意点 AWS認証情報は，CircleCIのデフォルト名と同じ環境変数名で登録しておけば，オプションで渡さなくとも，自動で入力してくれる．オプションがenv_var_name型は，基本的に全てのスコープレベルの環境変数を受け付ける．ただしAlpineベースのイメージでは，『$BASH_ENV』を用いて，複数のrun間で環境変数を共有できず，orbsのステップに環境変数を渡せないため注意する． 参考：https://github.com/circleci/circleci-docs/issues/1650 ＊実装例＊ version: 2.1 orbs: aws-foo: circleci/aws-foo@x.y.z jobs: foo_bar_baz: docker: - image: circleci/python:x.y.z steps: - attach_workspace: at: . - setup_remote_docker: - aws-cli/install - aws-cli/setup - aws-foo/foo-bar-baz: # デフォルト名であれば，記述しなくても自動的に入力してくれる． account-url: $AWS_ECR_ACCOUNT_URL_ENV_VAR_NAME aws-access-key-id: $ACCESS_KEY_ID_ENV_VAR_NAME aws-secret-access-key: $SECRET_ACCESS_KEY_ENV_VAR_NAME region: $AWS_REGION_ENV_VAR_NAME aws-cli ・commands: install aws-cliコマンドのインストールを行う． ・commands: setup aws-cliコマンドのインストールと，Credentials情報の設定を行う．AWSリソースを操作するために使用する． ＊実装例＊ CloudFrontに保存されているCacheを削除する．フロントエンドをデプロイしたとしても，CloudFrontに保存されているCacheを削除しない限り，CacheがHitしたユーザには過去のファイルがレスポンスされてしまう．そのため，S3へのデプロイ後に，Cacheを削除する必要がある． version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 jobs: cloudfront_create_invalidation: docker: - image: cimg/python:3.9-node steps: - checkout - aws-cli/setup - run: name: Run create invalidation command: | echo $AWS_CLOUDFRONT_ID | base64 --decode | aws cloudfront create-invalidation --distribution-id $AWS_CLOUDFRONT_ID --paths \"/*\" workflows: # ステージング環境にデプロイ develop: jobs: # 直前に承認ジョブを挿入する - hold: name: hold_create_invalidation_stg type: approval - cloudfront_create_invalidation: name: cloudfront_create_invalidation_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: # 直前に承認ジョブを挿入する - hold: name: hold_create_invalidation_prd type: approval - cloudfront_create_invalidation: name: cloudfront_create_invalidation_prd filters: branches: only: - main ただし，credentialsファイルの作成では，orbsを使用しない方がより簡潔に条件分岐を実装できるかもしれない． #!/bin/bash set -xeuo pipefail case \"$APP_ENV\" in \"stg\") AWS_ACCESS_KEY_ID=$STG_AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=$STG_AWS_SECRET_ACCESS_KEY ;; \"prd\") AWS_ACCESS_KEY_ID=\"$PRD_AWS_ACCESS_KEY_ID\" AWS_SECRET_ACCESS_KEY=\"$PRD_AWS_SECRET_ACCESS_KEY\" ;; *) echo \"The parameter ${APP_ENV} is invalid.\" exit 1 ;; esac # defaultプロファイルにクレデンシャル情報を設定する． aws configure aws-ecr ・jobs：build-and-push-image CircleCIコンテナでDockerイメージをビルドし，ECRにデプロイする．remote-docker-layer-cachingを使用して，Docker Layer Cacheを有効化できる． ＊実装例＊ version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecr: circleci/aws-ecr@6.15.2 jobs: aws-ecr/build-and-push-image: name: ecr_build_and_push_image # Docker Layer Cacheを使用するかどうか（有料） remote-docker-layer-caching: true # リポジトリがない時に作成するかどうか． create-repo: true no-output-timeout: 20m # projectを作業ディレクトリとした時の相対パス dockerfile: ./infra/docker/Dockerfile path: \".\" profile-name: myProfileName repo: \"{$SERVICE}-repository\" # CircleCIのハッシュ値によるバージョニング tag: $CIRCLE_SHA1 # job内にて，attach_workspaceステップを実行． attach-workspace: true # attach_workspaceステップ実行時のrootディレクトリ workspace-root: aws-ecs ・jobs：deploy-update-service（ローリングアップデート使用時） ECRイメージを使用して，新しいリビジョン番号のタスク定義を作成し，またこれを使用してコンテナをデプロイする．verify-revision-is-deployedオプションを使用して，ECSサービスが更新された後，実行されているタスクがタスク定義に合致しているかを監視する．例えば，タスクが「Runnning」にならずに「Stopped」になってしまう場合や，既存のタスクが「Stopped」にならずに「Running」のままになってしまう場合，この状態はタスク定義に合致しないので，検知できる． 参考：https://circleci.com/docs/ja/2.0/ecs-ecr/#deploy-the-new-docker-image-to-an-existing-aws-ecs-service ＊実装例＊ version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecs: circleci/aws-ecs@2.2.1 jobs: aws-ecs/deploy-update-service: name: ecs_update_service_by_rolling_update # タスク定義名を指定 family: \"${SERVICE}-ecs-task-definition\" # クラスター名を指定 cluster-name: \"${SERVICE}-cluster\" # サービス名を指定 service-name: \"${SERVICE}-service\" # コンテナ定義のコンテナ名とイメージタグを上書き．イメージはCircleCIのハッシュ値でタグ付けしているので必須． container-image-name-updates: \"container=laravel,tag=${CIRCLE_SHA1},container=nginx,tag=${CIRCLE_SHA1}\" # サービス更新後のタスク監視 verify-revision-is-deployed: true workflows: # ステージング環境にデプロイ develop: jobs: - ecs_update_service_by_rolling_update: name: ecs_update_service_by_rolling_update_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - ecs_update_service_by_rolling_update: name: ecs_update_service_by_rolling_update_production filters: branches: only: - main ・jobs：deploy-update-service（B/Gデプロイメント使用時） ECSタスク定義を更新する．さらに，Blue/Greenデプロイメントがそのタスク定義を指定し，ECSサービスを更新する．ローリングアップデートと同様にして，verify-revision-is-deployedオプションを使用できる． ＊実装例＊ version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecs: circleci/aws-ecs@2.2.1 jobs: aws-ecs/deploy-update-service: name: ecs_update_service_by_code_deploy # タスク定義名を指定 family: \"${SERVICE}-ecs-task-definition\" # クラスター名を指定 cluster-name: \"${SERVICE}-cluster\" # サービス名を指定 service-name: \"${SERVICE}-service\" # CodeDeployにおけるデプロイの作成を設定 deployment-controller: CODE_DEPLOY codedeploy-application-name: $SERVICE codedeploy-deployment-group-name: \"${SERVICE}-deployment-group\" codedeploy-load-balanced-container-name: www-container codedeploy-load-balanced-container-port: 80 # コンテナ名とイメージタグを指定．イメージはCircleCIのハッシュ値でタグ付けしているので必須． container-image-name-updates: \"container=laravel,tag=${CIRCLE_SHA1},container=nginx,tag=${CIRCLE_SHA1}\" # サービス更新後のタスク監視 verify-revision-is-deployed: true workflows: # ステージング環境にデプロイ develop: jobs: - ecs_update_service_by_code_deploy: name: ecs_update_service_by_code_deploy_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - ecs_update_service_by_code_deploy: name: ecs_update_service_by_code_deploy_production filters: branches: only: - main ・jobs：run-task 現在起動中のECSタスクとは別に，新しいタスクを一時的に起動する．起動時に，overridesオプションを使用して，指定したタスク定義のコンテナ設定を上書きできる．正規表現で設定する必要があり，さらにJSONでは「\\」を「\\\\」にエスケープしなければならない．コマンドが実行された後に，タスクは自動的にStopped状態になる． 上書きできるキーの参照リンク：https://docs.aws.amazon.com/cli/latest/reference/ecs/run-task.html ＊実装例＊ 例えば，データベースに対してマイグレーションを実行するためのECSタスクを起動する．overridesオプションでコンテナ定義のコマンドを上書きする． version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecs: circleci/aws-ecs@2.2.1 jobs: aws-ecs/run-task: name: ecs_run_task_for_migration cluster: \"${SERVICE}-ecs-cluster\" # LATESTとするとその時点の最新バージョンを自動で割り振られてしまう． platform-version: 1.4.0 awsvpc: true launch-type: FARGATE subnet-ids: $AWS_SUBNET_IDS security-group-ids: $AWS_SECURITY_GROUPS # タスク定義名．最新リビジョン番号が自動補完される． task-definition: \"${SERVICE}-ecs-task-definition\" # タスク起動時にマイグレーションコマンドを実行するように，Laravelコンテナの　commandキーを上書き overrides: \"{\\\\\\\"containerOverrides\\\\\\\":[{\\\\\\\"name\\\\\\\": \\\\\\\"laravel-container\\\\\\\",\\\\\\\"command\\\\\\\": [\\\\\\\"php\\\\\\\", \\\\\\\"artisan\\\\\\\", \\\\\\\"migrate\\\\\\\", \\\\\\\"--force\\\\\\\"]}]}\" workflows: # ステージング環境にデプロイ develop: jobs: - ecs_run_task_for_migration: name: ecs_run_task_for_migration_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - ecs_run_task_for_migration: name: ecs_run_task_for_migration_production filters: branches: only: - main aws-code-deploy ・jobs：deploy S3にソースコードとappspecファイルをデプロイできる．また，CodeDeployを用いて，これをEC2にデプロイできる． ＊実装例＊ version: 2.1 orbs: aws-code-deploy: circleci/aws-code-deploy@1.0.1 jobs: aws-code-deploy/deploy: name: code_deploy application-name: $SERVICE} # appspecファイルを保存するバケット名 bundle-bucket: \"${SERVICE}-bucket\" # appspecファイルのあるフォルダ bundle-source: ./infra/aws_codedeploy # appspecファイルをzipフォルダで保存 bundle-type: zip # zipフォルダ名 bundle-key: foo-bundle deployment-config: CodeDeployDefault.ECSAllAtOnce deployment-group: \"${SERVICE}-deployment-group\" # ECSにアクセスできるCodeDeployサービスロール service-role-arn: $CODE_DEPLOY_ROLE_FOR_ECS workflows: # ステージング環境にデプロイ develop: jobs: - code_deploy: name: code_deploy_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - code_deploy: name: code_deploy_production filters: branches: only: - main slack ・commands：notify ジョブの終了時に，成功または失敗に基づいて，ステータスを通知する．ジョブの最後のステップとして設定しなければならない． version: 2.1 orbs: slack: circleci/slack@4.1 commands: # 他のジョブ内で使用できるようにcommandとして定義 notify_of_failure: steps: - slack/notify: event: fail template: basic_fail_1 jobs: deploy: steps: # ～ 省略 ～ workflows: # ステージング環境にデプロイ develop: jobs: - deploy: name: deploy_stg filters: branches: only: - develop # 失敗時に通知 post-steps: - notify_of_failure: # 本番環境にデプロイ main: jobs: - deploy: name: deploy_production filters: branches: only: - main # 失敗時に通知 post-steps: - notify_of_failure: "},"public/infrastructure_capistrano.html":{"url":"public/infrastructure_capistrano.html","title":"▶ ︎Capistrano","keywords":"","body":"Capistrano はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ Capistranoとは ・仕組み 自身のパソコンからクラウドデプロイサーバにリモート接続する． クラウドデプロイサーバの自動デプロイツール（例：Capistrano）が，クラウドデプロイサーバからクラウドWebサーバにリモート接続する． 自動デプロイツールが，クラウドWebサーバのGitを操作し，pullあるいはcloneを実行する．その結果，GitHubからクラウドデプロイサーバに指定のブランチの状態が取り込まれる． "},"public/infrastructure_fluentd_and_fluentbit.html":{"url":"public/infrastructure_fluentd_and_fluentbit.html","title":"▶ ︎Fluentd／FluentBit","keywords":"","body":"Fluentd／FluentBit はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Fluentd／FluentBitとは 概要 アプリケーションからログを収集し，これをフィルタリングした後，複数の宛先に転送する． 参考：https://docs.fluentbit.io/manual/about/fluentd-and-fluent-bit Fluentd vs. FluentBit Fluentd FluentBit スコープ コンテナ／サーバ 組み込みLinux／コンテナ／サーバ 言語 C & Ruby NS メモリ最大使用量 40MB 650KB 依存関係 標準プラグインで一定数のRuby gemに依存する． 標準プラグインではライブラリに依存しない． パフォーマンス 高 高 プラグイン数 1000個以上 70個 02. ログの収集／転送の仕組み ログパイプライン ・ログパイプラインとは ・設定ファイルのセクション一覧 参考：https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/configuration-file ・設定ファイルのバリデーション 参考：https://cloud.calyptia.com/visualizer SERVICE ・SERVICEセクションとは パイプライン全体の設定やファイルの読み込みを定義する．各設定の頭文字は大文字とする． [SERVICE] Flush 1 # 猶予時間 Grace 30 # 転送対象の最低ログレベル Log_Level info # 読み込まれるParsers Multilineファイルの名前 Parsers_File parsers_multiline.conf # 読み込まれるStream Processorファイルの名前 Streams_File stream_processor.conf INPUT ・INPUTセクションとは ログのパイプラインへの入力方法を定義する． 参考：https://docs.fluentbit.io/manual/concepts/data-pipeline/input プラグインを用いて，ログの入力方法を指定する． 参考：https://docs.fluentbit.io/manual/pipeline/inputs ・forwardプラグイン 転送されたログを指定されたポートでリッスンし，パイプラインに入力する． 参考：https://docs.fluentbit.io/manual/pipeline/inputs/forward [INPUT] # プラグイン名 Name forward Listen 0.0.0.0 # プロセスのリッスンポート Port 24224 ・tailプラグイン 複数行のログを結合し，パイプラインに入力する．v1.8を境にオプションが変わっていることに注意する． 参考：https://docs.fluentbit.io/manual/pipeline/inputs/tail [INPUT] # プラグイン名 Name tail # ログの場所．ワイルドカードを使用できる． Path /var/log/*.log # 使用するパーサー名 multiline.parser laravel PARSE ・PARSEセクションとは ・MULTILINE_PARSERセクション 参考：https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/multiline-parsing [MULTILINE_PARSER] # パーサー名 name laravel # パーサータイプ type regex flush_timeout 1000 # パーサールール．スタックトレースの文頭をstart_state，また以降に結合する文字列をcontで指定する． rule \"start_state\" \"\\[%Y-%m-%d %H:%M:%S\\]\" \"cont\" rule \"cont\" \"#*\" \"cont\" FILTER ・FILTERセクションとは 特定の文字列を持つログのみをBUFFERセクションに転送する． ・multilineプラグイン 参考：https://docs.fluentbit.io/manual/pipeline/filters/multiline-stacktrace [FILTER] # プラグイン名 name multiline match * multiline.key_content log # 使用するパーサー名 multiline.parser laravel ・stdoutプラグイン 参考：https://docs.fluentbit.io/manual/pipeline/filters/standard-output [FILTER] # プラグイン名 Name stdout Match * OUTPUT ・OUTPUTセクションとは ログの出力方法を定義する．設定可能な転送先の種類については，以下を参考にせよ． 参考：https://docs.fluentbit.io/manual/pipeline/outputs 転送先サービス オプションのリンク Datadog 参考：https://docs.fluentbit.io/manual/pipeline/outputs/datadog CloudWatch 参考：https://docs.fluentbit.io/manual/pipeline/outputs/cloudwatch ・プラグイン 転送先サービス ベースイメージのリンク 補足 NewRelic https://github.com/newrelic/newrelic-fluent-bit-output NewRelicプラグインがインストールされている． AWS https://github.com/aws/aws-for-fluent-bit AWSから提供される他の全てのFluentBitイメージを束ねたものであり，AWSの各種リソースに転送するためのプラグインがインストールされている． https://github.com/aws/amazon-cloudwatch-logs-for-fluent-bit CloudWatchLogsプラグインがインストールされている． https://github.com/aws/amazon-kinesis-streams-for-fluent-bit Kinesis Streamsプラグインがインストールされている． https://github.com/aws/amazon-kinesis-firehose-for-fluent-bit Kinesis Firehoseプラグインがインストールされている． ログを何らかの外部サービスに転送する場合，プラグインをインストールする必要がある．なお，FluentBitは標準でdatadogプラグインがインストールされているため，datadogプラグインのインストールは不要である．Datadogプラグインについては以下のリンクを参考にせよ． 参考：https://github.com/DataDog/fluent-plugin-datadog ・datadogプラグイン ######################### # Datadogへの転送 ######################### [OUTPUT] # プラグイン名 Name datadog # 転送対象とするログのタグ Match laravel # 転送先ホスト Host http-intake.logs.datadoghq.com TLS on compress gzip # DatadogのAPIキー． apikey ***** # DatadogログエクスプローラーにおけるService名 dd_service prd-foo # DatadogログエクスプローラーにおけるSource名 dd_source prd-foo dd_message_key log # 追加タグ dd_tags env:prd-foo [OUTPUT] Name datadog Match nginx Host http-intake.logs.datadoghq.com TLS on compress gzip apikey ***** dd_service prd-foo dd_source prd-foo dd_message_key log dd_tags env:prd-foo 代わりに，同じ設定をFireLensのlogConfigurationキーとしても適用することもできる． 参考：https://github.com/aws-samples/amazon-ecs-firelens-examples/blob/mainline/examples/fluent-bit/datadog/README.md \"logConfiguration\": { \"logDriver\":\"awsfirelens\", \"options\": { \"Name\": \"datadog\", \"Host\": \"http-intake.logs.datadoghq.com\", \"TLS\": \"on\", \"apikey\": \"\", \"dd_service\": \"prd-foo\", \"dd_source\": \"prd-foo\", \"dd_tags\": \"env:prd-foo\", \"provider\": \"ecs\" } }, ・cloudwatch_logsプラグイン 設定ファイルに予約されたAWS変数を使用できる．以下のリンクを参考にせよ． 参考：https://github.com/aws/amazon-cloudwatch-logs-for-fluent-bit#templating-log-group-and-stream-names ######################### # CloudWatchログへの転送 ######################### [OUTPUT] # プラグイン名 Name cloudwatch_logs # 転送対象とするログのタグ Match laravel # アウトプットJSONのうち，宛先に転送するキー名 log_key log region ap-northeast-1 # 予約変数あり． log_group_name /prd-foo-ecs-container/laravel/log # ログストリーム名．予約変数あり．タスクIDなど出力できる． log_stream_name container/laravel/$(ecs_task_id) [OUTPUT] Name cloudwatch_logs Match nginx log_key log region ap-northeast-1 log_group_name /prd-foo-ecs-container/nginx/log log_stream_name container/nginx/$(ecs_task_id) CloudWatchログに送信されるデータはJSONになっている．logキーに全てのログのテキストが割り当てられている．特定のキーの値のみをCloudWatchログに送信する場合，log_keyオプションでキー名を指定する．例えば，logキーのみを送信する場合，『log』と指定する． 参考：https://blog.msysh.me/posts/2020/07/split_logs_into_multiple_target_with_firelens_and_rewrite_tag.html { \"container_id\": \"*****\", \"container_name\": \"prd-foo-ecs-container\", \"ecs_cluster\": \"prd-foo-ecs-cluster\", \"ecs_task_arn\": \"arn:aws:ecs:ap-northeast-1:****:task/cluster-name/*****\", \"ecs_task_definition\": \"prd-foo-ecs-task-definition:1\", \"log\": \"\", \"source\": \"stdout\", \"ver\": \"1.5\" } BUFFERセクションとは ・BUFFERセクションとは 参考：https://docs.fluentbit.io/manual/administration/buffering-and-storage ・STREAM_TASKセクションとは ログパイプラインにおいて，FILTERセクション後にログに対してクエリ処理を行い，ログにタグ付けを行う．タグ付けされたログは，INPUTセクションに再度取り込まれ，最終的にOUTPUTセクションまで渡される． 参考：https://docs.fluentbit.io/manual/stream-processing/overview#stream-processor STREAM_TASKセッションは，ログSQLで定義される． 参考：https://docs.fluentbit.io/manual/stream-processing/getting-started/fluent-bit-sql [STREAM_TASK] Name foo Exec CREATE STREAM foo AS SELECT * FROM TAG:'foo'; 03. Fargateコンテナからのログ収集 FireLensコンテナ ・FireLensコンテナとは AWSが提供するFluentBit／Fluentdイメージによって構築されるコンテナであり，Fargateコンテナのサイドカーコンテナとして配置される．Fargateコンテナからログが送信されると，コンテナ内で稼働するFluentBit／Fluentdがこれを収集し，これを他のサービスに転送する．構築のための実装例については，以下のリンクを参考にせよ． 参考： https://github.com/aws-samples/amazon-ecs-firelens-examples https://aws.amazon.com/jp/blogs/news/announcing-firelens-a-new-way-to-manage-container-logs/ ・ログの転送先 FluentBit／Fluentdが対応する他のサービスにログを転送できる． 参考：https://docs.fluentbit.io/manual/pipeline/outputs サイドカーコンテナパターン ・サイドカーコンテナパターンとは サイドカーコンテナパターンを含むコンテナデザインパターンについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_virtualization_container_orchestration.html ・ログの収集／転送の仕組み 以下の順番でログの収集／転送を実行する． 参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-firelens-for-amazon-ecs-tasks/ メインのコンテナは，Fluentdログドライバーを介して，ログをFireLensコンテナに送信する．Fluentdログドライバーについては，以下を参考にせよ． 参考：https://docs.docker.com/config/containers/logging/fluentd/ FireLensコンテナは，これを受信する． コンテナ内で稼働するFluentBitのログパイプラインのINPUTに渡され，FluentBitはログを処理する． OUTPUTセクションに渡され，FluentBitは指定した外部サービスにログを転送する． ・ログ転送プロセス FireLensコンテナでは，FluentBitまたはFlunetdがログ転送プロセスとして稼働する．FireLensコンテナを使用せずに，独自のコンテナを構築して稼働させることも可能であるが，FireLensコンテナを使用すれば，主要なセットアップがされているため，より簡単な設定でFluentBitまたはFlunetdを使用できる．FluentBitの方がより低負荷で稼働するため，FluentBitが推奨されている． 参考： https://aws.amazon.com/jp/blogs/news/under-the-hood-firelens-for-amazon-ecs-tasks/ https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/using_firelens.html ベースイメージ ・FluentBitイメージ FireLensコンテナのベースイメージとなるFluentBitイメージがAWSから提供されている．AWSリソースにログを転送するためのプラグインがすでに含まれている．なお，DatadogプラグインはFluentBit自体にインストール済みである．パブリックECRリポジトリからプルしたイメージをそのまま使用する場合と，プライベートECRリポジトリで再管理してから使用する場合がある． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/firelens-using-fluentbit.html [/fluent-bit]$ ls -la -rw-r--r-- 1 root root 26624256 Sep 1 18:04 cloudwatch.so # 旧CloudWatchLogsプラグイン -rw-r--r-- 1 root root 26032656 Sep 1 18:04 firehose.sきゅう # Kinesis Firehoseプラグイン -rw-r--r-- 1 root root 30016544 Sep 1 18:03 kinesis.so # Kinesis Streamsプラグイン ... ・パブリックECRリポジトリを使用する場合 ECSのコンテナ定義にて，パブリックECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているconfファイルの設定をそのまま使用する場合は，こちらを採用する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/firelens-using-fluentbit.html#firelens-image-ecr ・プライベートECRリポジトリを使用する場合 あらかじめ，DockerHubからFluentBitイメージをプルするためのDockerfileを作成し，プライベートECRリポジトリにイメージをプッシュしておく．ECSのコンテナ定義にて，プライベートECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているconfファイルの設定を上書きしたい場合は，こちらを採用する． FROM amazon/aws-for-fluent-bit:latest 参考： https://hub.docker.com/r/amazon/aws-for-fluent-bit https://github.com/aws/aws-for-fluent-bit https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/firelens-using-fluentbit.html#firelens-image-dockerhub 標準設定の上書き ・標準設定ファイルの種類 aws-for-fluent-bitイメージの/fluent-bit/etcディレクトリには標準で設定ファイルが用意されている．追加設定を実行するファイルはここに配置する． [/fluent-bit/etc]$ ls -la -rw-r--r-- 1 root root 251 Sep 1 17:57 fluent-bit.conf -rw-r--r-- 1 root root 1564 Sep 27 02:15 fluent-bit_custom.conf # 追加設定用 -rw-r--r-- 1 root root 4664 Sep 1 18:07 parsers.conf -rw-r--r-- 1 root root 584 Sep 1 18:07 parsers_ambassador.conf -rw-r--r-- 1 root root 226 Sep 1 18:07 parsers_cinder.conf -rw-r--r-- 1 root root 2798 Sep 1 18:07 parsers_extra.conf -rw-r--r-- 1 root root 240 Sep 1 18:07 parsers_java.conf -rw-r--r-- 1 root root 845 Sep 1 18:07 parsers_mult.conf -rw-r--r-- 1 root root 291 Sep 27 02:15 parsers_multiline.conf -rw-r--r-- 1 root root 2954 Sep 1 18:07 parsers_openstack.conf -rw-r--r-- 1 root root 579 Sep 27 02:15 stream_processor.conf # 追加設定用 FireLensコンテナの/fluent-bit/etc/fluent-bit.confファイルは以下の通りとなり，ローカルPCでFluentBitコンテナを起動した場合と異なる構成になっていることに注意する． 参考：https://dev.classmethod.jp/articles/check-fluent-bit-conf/ [INPUT] Name tcp Listen 127.0.0.1 Port 8877 Tag firelens-healthcheck [INPUT] Name forward unix_path /var/run/fluent.sock [INPUT] Name forward Listen 127.0.0.1 Port 24224 [FILTER] Name record_modifier Match * Record ecs_cluster sample-test-cluster Record ecs_task_arn arn:aws:ecs:ap-northeast-1:123456789012:task/sample-test-cluster/d4efc1a0fdf7441e821a3683836ad69a Record ecs_task_definition sample-test-webapp-taskdefinition:15 [OUTPUT] Name null Match firelens-healthcheck ・fluent-bit_custom.confファイル FireLensコンテナの/fluent-bit/etc/fluent-bit.confファイルを，コンテナ定義のconfig-file-valueキーで指定し，追加設定を実行する．これにより，FireLensコンテナにINCLUDE文が挿入される． 参考：https://dev.classmethod.jp/articles/check-fluent-bit-conf/ [INPUT] Name tcp Listen 127.0.0.1 Port 8877 Tag firelens-healthcheck [INPUT] Name forward unix_path /var/run/fluent.sock [INPUT] Name forward Listen 127.0.0.1 Port 24224 [FILTER] Name record_modifier Match * Record ecs_cluster sample-test-cluster Record ecs_task_arn arn:aws:ecs:ap-northeast-1:123456789012:task/sample-test-cluster/13c0122f7f384cb7a67088d183dd46d9 Record ecs_task_definition sample-test-webapp-taskdefinition:9 @INCLUDE /fluent-bit/etc/fluent-bit_custom.conf # INCLUDE文が挿入される． [OUTPUT] Name null Match firelens-healthcheck ちなみに，標準の設定ファイルには，INPUTセクションがすでに定義されているため，fluent-bit_custom.confファイルではINPUTセクションを定義しなくても問題ない． 参考：https://github.com/aws/aws-for-fluent-bit/blob/mainline/fluent-bit.conf [INPUT] Name forward Listen 0.0.0.0 Port 24224 [OUTPUT] Name cloudwatch Match ** region us-east-1 log_group_name fluent-bit-cloudwatch log_stream_prefix from-fluent-bit- auto_create_group true ・stream_processor.confファイル STREAM_TASKセクションにて，ログのタグ付けを定義する．FireLensコンテナのパイプラインでは，『-firelens-』という名前でログが処理されている．そのため，Stream Processorでログを抽出するためには，クエリで『FROM TAG:'*-firelens-*'』を指定する必要がある．ちなみに，STREAM_TASKセクションでタグ付けされたログは，INPUTセクションから再び処理し直される． 参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-firelens-for-amazon-ecs-tasks/ # appコンテナのログへのタグ付け [STREAM_TASK] Name laravel Exec CREATE STREAM web WITH (tag='laravel') AS SELECT log FROM TAG:'*-firelens-*' WHERE container_name = 'laravel'; # webコンテナのログへのタグ付け [STREAM_TASK] Name nginx Exec CREATE STREAM web WITH (tag='nginx') AS SELECT log FROM TAG:'*-firelens-*' WHERE container_name = 'nginx'; # 全てのコンテナのログへのタグ付け [STREAM_TASK] Name containers Exec CREATE STREAM container WITH (tag='containers') AS SELECT * FROM TAG:'*-firelens-*'; [SERVICE] Flush 1 Grace 30 Log_Level info # ファイルを読み込む Parsers_File parsers_multiline.conf Streams_File stream_processor.conf ・parsers_multiline.confファイル MULTILINE_PARSERセクションにて，スタックトレースログの各行の結合を定義する． 参考：https://github.com/aws-samples/amazon-ecs-firelens-examples/blob/mainline/examples/fluent-bit/filter-multiline/README.md [MULTILINE_PARSER] name laravel type regex flush_timeout 1000 rule \"start_state\" \"/(Dec \\d+ \\d+\\:\\d+\\:\\d+)(.*)/\" \"cont\" rule \"cont\" \"/^\\s+at.*/\" \"cont\" [SERVICE] flush 1 log_level info parsers_file /parsers_multiline.conf [FILTER] name multiline match * multiline.key_content log # ファイルを読み込む．組み込みパーサ（goなど）を使用することも可能． multiline.parser go, laravel FireLensコンテナのコンテナ定義 ・全体 [ { \"name\": \"\", \"image\": \"\", \"essential\": true, \"portMappings\": [ { \"containerPort\": 80, \"hostPort\": 80, \"protocol\": \"tcp\" } ], \"logConfiguration\": { \"logDriver\": \"awsfirelens\", \"options\": { \"Name\": \"forward\" } } }, { # FireLensコンテナ名がlog_routerとなることは固定 \"name\": \"log_router\", \"image\": \"\", \"essential\": false, \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { # FireLensコンテナ自体がCloudWatchログにログ出力 \"awslogs-group\": \"\", \"awslogs-region\": \"\", \"awslogs-stream-prefix\": \"\" } }, \"firelensConfiguration\": { # FireLensコンテナでFluentBitを稼働させる \"type\": \"fluentbit\", \"options\": { \"config-file-type\": \"file\", # 設定上書きのため読み込み \"config-file-value\": \"/fluent-bit/etc/fluent-bit_custom.conf\" # ECSの情報をFireLensに送信するかどうか \"enable-ecs-log-metadata\": \"true\" } }, \"portMappings\": [], \"memoryReservation\": 50, \"secrets\": [ { \"name\": \"DD_API_KEY\", \"valueFrom\": \"\" }, { \"name\": \"DD_ENV\", \"valueFrom\": \"\" } ] } ] ・name FireLensコンテナをサイドカーとして構築するために，コンテナ定義を実装する．FireLensコンテナは『log_routeter』とする． ・logConfiguration 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/firelens-example-taskdefs.html#firelens-example-forward 項目 説明 type メインコンテナからFireLensコンテナにログを送信できるように，ログドライバーのタイプとして『fluentbit』を設定する． config-file-type FluentBitの設定ファイルを読み込むために，fileとする． config-file-value optionsキーにて，ログ転送時の設定が可能であるが，それらはfluent-bit.confファイルにも設定可能であるため，転送の設定はできるだけfluent-bit.confファイルに実装する．FireLensコンテナ自体のログは，CloudWatchログに送信するように設定し，メインコンテナから受信したログは監視ツール（Datadogなど）に転送する． enable-ecs-log-metadata（標準で有効化） 有効にした場合，Datadogのログコンソールで，例えば以下のようなタグが付けられる．反対に無効にした場合，以下のようなタグが付けられる．参考：https://tech.spacely.co.jp/entry/2020/11/28/173356 environment，secrets コンテナ内のfluent-bit.confファイルに変数を出力できるように，コンテナの環境変数に値を定義する． 04. CloudWatchログ 以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_cloud_computing_aws.html "},"public/infrastructure_datadog.html":{"url":"public/infrastructure_datadog.html","title":"▶ ︎Datadog","keywords":"","body":"Datadog はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Datadogとは 概要 02. メトリクス／ログ収集 on Ec2 Datadogエージェント on EC2 ・Datadogエージェント on EC2とは 常駐プログラムであり，アプリケーションからメトリクスやログを収集し，Datadogに転送する． 参考：https://docs.datadoghq.com/ja/agent/amazon_ecs/?tab=awscli 03. メトリクス収集 on Fargate Datadogエージェント on Fargate ・Datadogエージェント on Fargateとは 常駐プログラムであり，アプリケーションからメトリクスをDatadogに転送する．EC2用のDatadogエージェントとは異なり，ログは転送しない． 参考：https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens#%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97 ・環境変数 グローバルオプションとして役立つ環境変数を以下に示す． 参考：https://docs.datadoghq.com/ja/agent/docker/?tab=%E6%A8%99%E6%BA%96#%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3 変数名 説明 補足 DatadogコンソールURL DD_API_KEY DatadogコンテナがあらゆるデータをDatadogに送信するために必要である． DD_ENV APMを用いる場合に，サービスやトレース画面にて，envタグに文字列を設定する． サービス単位で絞り込めるように，prd-fooやstg-fooとした方が良い． https://app.datadoghq.com/apm/services DD_HOSTNAME ホストマップ https://app.datadoghq.com/infrastructure/map ECS_FARGATE Fargateを用いる場合に，これを宣言する． 任意で選択できるメトリクスの収集として役立つ環境変数を以下に示す．一部のメトリクスは，標準では収集しないようになっており，収集するためにエージェントを有効化する必要がある． 参考：https://docs.datadoghq.com/ja/agent/docker/?tab=%E6%A8%99%E6%BA%96#%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E5%8F%8E%E9%9B%86-agent 変数名 説明 補足 DatadogコンソールURL DD_APM_ENABLED APMエージェントを有効化する． Fargateを使用している場合，APMエージェントを有効化するだけでなく，分散トレースを送信できるように，サービスにパッケージのインストールが必要である．参考：・https://app.datadoghq.com/apm/docs?architecture=host-based&framework=php-fpm&language=php・https://docs.datadoghq.com/ja/tracing/#datadog-%E3%81%B8%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B9%E3%82%92%E9%80%81%E4%BF%A1 https://app.datadoghq.com/apm/home DD_LOGS_ENABLED - DD_PROCESS_AGENT_ENABLED ライブプロセスを有効化し，実行中のプロセスを収集する．参考：https://docs.datadoghq.com/ja/infrastructure/process/?tab=linuxwindows https://app.datadoghq.com/containers カスタムメトリクスの収集として役立つ環境変数を以下に示す． 参考：https://docs.datadoghq.com/ja/agent/docker/?tab=%E6%A8%99%E6%BA%96#dogstatsd-%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%A0%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9 変数名 説明 DatadogコンソールURL DD_DOGSTATSD_NON_LOCAL_TRAFFIC Datadogコンテナのカスタムメトリクスの受信を有効化する． トレースエージェント ・トレースエージェントとは Dockerエージェントにて，DD_APM_ENABLEDの環境変数にtrueを割り当てると，トレースエージェントが有効になる．APMエージェントを有効化し，分散トレースを収集できる．APMでは，分散トレースを元にして，サービス間の依存関係をサービスマップとして確認できる． 参考： https://docs.datadoghq.com/ja/agent/docker/apm/?tab=linux https://docs.datadoghq.com/ja/tracing/#datadog-apm-%E3%81%AE%E7%A2%BA%E8%AA%8D ・環境変数 一部の環境変数は，Dockerエージェントの環境変数と重なる． 参考：https://docs.datadoghq.com/ja/agent/docker/apm/?tab=linux#docker-apm-agent-%E3%81%AE%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0 変数名 説明 補足 DD_LOG_LEVEL APMに送信するログレベルを設定する． Datadogコンテナ ・Datadogコンテナとは Datadogが提供するdatadogイメージによって構築されるコンテナであり，コンテナのサイドカーコンテナとして配置される．コンテナ内で稼働するDatadog Dockerエージェントが，コンテナからメトリクスを収集し，Datadogにこれを転送する． 参考：https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens#%E6%A6%82%E8%A6%81 ・Datadogコンテナの配置 [ { # laravelコンテナ }, { # nginxコンテナ }, { # datadogコンテナ \"name\": \"datadog\", \"image\": \"datadog/agent:latest\", \"essential\": false, \"portMappings\": [ { \"containerPort\": 8126, \"hostPort\": 8126, \"protocol\": \"tcp\" } ], \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/prd-foo/laravel/log\", \"awslogs-region\": \"ap-northeast-1\" \"awslogs-stream-prefix\": \"/container\" } }, \"cpu\": 10, \"memory\": 256, \"environment\": [ { \"name\": \"ECS_FARGATE\", \"value\": \"true\" }, { \"name\": \"DD_PROCESS_AGENT_ENABLED\", \"value\": \"true\" }, { \"name\": \"DD_DOGSTATSD_NON_LOCAL_TRAFFIC\", \"value\": \"true\" }, { \"name\": \"DD_APM_ENABLED\", \"value\": \"true\" }, { \"name\": \"DD_LOGS_ENABLED\", \"value\": \"true\" }, { # アプリケーションに対するenvタグ \"name\": \"DD_ENV\", \"value\": \"foo\" }, { # アプリケーションに対するserviceタグ \"name\": \"DD_SERVICE\", \"value\": \"foo\" }, { # アプリケーションに対するversionタグ \"name\": \"DD_VERSION\", \"value\": \"latest\" } ], \"secrets\": [ { \"name\": \"DD_API_KEY\", \"valueFrom\": \"/prd-foo/DD_API_KEY\" } ], \"dockerLabels\": { # ECSコンテナに対するenvタグ \"com.datadoghq.tags.env\": \"prd\", # ECSコンテナに対するserviceタグ \"com.datadoghq.tags.service\": \"foo\", # ECSコンテナに対するversionタグ \"com.datadoghq.tags.version\": \"1.0.0\" } } ] ・IAMロール Datadogコンテナがコンテナからメトリクスを収集できるように，ECSタスク実行ロールにポリシーを追加する必要がある． 参考：https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens#iam-%E3%83%9D%E3%83%AA%E3%82%B7%E3%83%BC%E3%81%AE%E4%BD%9C%E6%88%90%E3%81%A8%E4%BF%AE%E6%AD%A3 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"ecs:ListClusters\", \"ecs:ListContainerInstances\", \"ecs:DescribeContainerInstances\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" } ] } 03-02. トレーシングパッケージ トレーシングパッケージとは APM機能を用いる時に，トレースエージェントが稼働するDatadogコンテナに分散トレースを送信できるよう，サービスのコンテナでトレーシングパッケージをインストールする必要がある．パッケージはアプリケーションによって読み込まれた後，『http://localhost:8126』を指定して，分散トレースを送信するようになる． 参考：https://docs.datadoghq.com/ja/tracing/#datadog-%E3%81%B8%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B9%E3%82%92%E9%80%81%E4%BF%A1 パッケージ一覧 参考：https://docs.datadoghq.com/ja/developers/libraries/#apm-%E3%81%A8%E5%88%86%E6%95%A3%E5%9E%8B%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%B3%E3%82%B0%E3%82%AF%E3%83%A9%E3%82%A4%E3%82%A2%E3%83%B3%E3%83%88%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA PHPトレーシングパッケージ ・インストール 各サービスのDockerfileにて，パッケージをインストールする． 参考：https://docs.datadoghq.com/tracing/setup_overview/setup/php/?tab=containers ENV DD_TRACE_VERSION=0.63.0 # GitHubからパッケージをダウンロード RUN curl -Lo https://github.com/DataDog/dd-trace-php/releases/download/${DD_TRACE_VERSION}/datadog-php-tracer_${DD_TRACE_VERSION}_amd64.deb \\ # 解凍 && dpkg -i datadog-php-tracer.deb \\ # 残骸ファイルを削除 && rm datadog-php-tracer.deb アプリケーションがパッケージを読み込んだか否かをコマンドで確認できる． # 成功の場合 root@*****:/ php --ri=ddtrace ddtrace Datadog PHP tracer extension For help, check out the documentation at https://docs.datadoghq.com/tracing/languages/php/ (c) Datadog 2020 ... まだまだ続く # 失敗の場合 root@*****:/ php --ri=ddtrace Extension 'ddtrace' not present. ・環境変数 環境変数を使用できる．分散トレースのタグ名に反映される．環境変数については，以下のリンクを参考にせよ． 参考：https://docs.datadoghq.com/ja/tracing/setup_overview/setup/php/?tab=%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A#%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%82%B3%E3%83%B3%E3%83%95%E3%82%A3%E3%82%AE%E3%83%A5%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3 変数名 説明 画面 DD_SERVICE アプリケーション DD_SERVICE_MAPPING APMにて，標準で設定されるサービス名を上書きする．（例）laravel:foo-laravel,pdo:foo-pdo https://app.datadoghq.com/apm/services トレーサーの設定の状態は，php --ri=ddtraceコマンドの結果得られるJSONを整形することで確認できる． root@*****:/ php --ri=ddtrace Datadog tracing support => enabled Version => 0.57.0 DATADOG TRACER CONFIGURATION => { ..... } # Node.jsトレーシングパッケージ ・TypeScriptやモジュールバンドルを使っている場合 エントリポイントとなるnuxt.config.jsファイルにて，一番最初にDatadogのトレースパッケージを読み込み，初期化する． 参考：https://docs.datadoghq.com/ja/tracing/setup_overview/setup/nodejs/?tab=%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A#typescript-%E3%81%A8%E3%83%90%E3%83%B3%E3%83%89%E3%83%A9%E3%83%BC import 'dd-trace/init' // フレームワークを含むパッケージのインポートが続く また，初期化時に設定した環境変数を使用できる．APMのサービスのタグ名に反映される． 参考：https://docs.datadoghq.com/ja/tracing/setup_overview/setup/nodejs/?tab=%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A#%E3%82%B3%E3%83%B3%E3%83%95%E3%82%A3%E3%82%AE%E3%83%A5%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3 サービスの識別 ・サービスタイプ トレーシングパッケージによって，サービスは『Web』『DB』『Cache』『Cache』の４つに分類される．各サービスのspan.type属性に割り当てられるタイプ名から自動的に割り振られる．タイプ名の種類については，以下のリンクを参考にせよ． 参考： https://github.com/DataDog/dd-trace-php/blob/master/src/api/Type.php https://docs.datadoghq.com/ja/tracing/visualization/services_list/#%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%BF%E3%82%A4%E3%83%97 ・タグ トレーシングパッケージによって，サービスにタグを追加できる． 参考：https://github.com/DataDog/dd-trace-php/blob/master/src/api/Tag.php メトリクスの識別 ・メトリクスの識別子 分散トレースの各メトリクスは，『trace..』で識別できる． 参考：https://docs.datadoghq.com/ja/tracing/guide/metrics_namespace/ ・スパン名 識別子のスパン名は，span.name属性から構成される．spanには，サービス名を割り当てる．トレーシングパッケージによって，redis，laravel.request，rails，pdoなどが自動で割り当てられる． ・メトリクスサフィックス メトリクス名を割り当てる．トレーシングパッケージによって，duration，hits，span_countなどが自動で割り当てられる． 04. ログ収集 on Fargate FireLensコンテナ ・FireLensコンテナとは Datadogコンテナはコンテナからログを収集できないため，代わりにFireLensコンテナを用いる必要がある．以下のリンクを参考にせよ． 参考： https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_fluentd_and_fluentbit.html ・ログエクスプローラ FireLensコンテナからDatadogに転送されたログは，ログエクスプローラで確認できる． 参考：https://app.datadoghq.com/logs ベースイメージ ・Datadogイメージ DatadogコンテナのベースイメージとなるDatadogイメージがDatadog公式から提供されている．パブリックECRリポジトリからプルしたイメージをそのまま用いる場合と，プライベートECRリポジトリで再管理してから用いる場合がある． ・パブリックECRリポジトリを用いる場合 ECSのコンテナ定義にて，パブリックECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているyamlファイルの設定をそのまま用いる場合は，こちらを採用する． 参考： https://gallery.ecr.aws/datadog/agent https://github.com/DataDog/datadog-agent ・プライベートECRリポジトリを用いる場合 あらかじめ，DockerHubからdatadogイメージをプルするためのDockerfileを作成し，プライベートECRリポジトリにイメージをプッシュしておく．ECSのコンテナ定義にて，プライベートECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているyamlファイルの設定を上書きしたい場合は，こちらを採用する． FROM data/agent:latest 参考：https://hub.docker.com/r/datadog/agent 標準設定の上書き 参考：https://github.com/DataDog/datadog-agent/blob/main/pkg/config/config_template.yaml ログと分散トレースの接続 ログとトレーシングパッケージによるタグに同じタグ名を付与すると，ログと分散トレースを紐づけることができる． https://docs.datadoghq.com/ja/tracing/connect_logs_and_traces/ 05. ログエクスプローラ attribute（属性） ・予約済み属性 参考：https://docs.datadoghq.com/ja/logs/log_configuration/attributes_naming_convention/ 属性名 説明 補足 host 送信元ホストを識別する． Datadogコンテナの環境変数にて，DD_HOSTNAMEを用いてホストタグを設定する．これにより，ホストマップでホストを俯瞰できるようになるだけでなく，ログエクスプローラでホストタグが属性として付与される．（例）foo，bar-backend，baz-frontend source ログの生成元を識別する． ベンダー名を使用するとわかりやすい．（例）laravel，nginx，redis status ログのレベルを識別する． service ログの生成元のアプリケーションを識別する． ログとAPM分散トレースを紐づけるため，両方に同じ名前を割り当てる必要がある．（例）foo，bar-backend，baz-frontend trace_id 分散トレースとログを紐づけるIDを識別する． message ログメッセージを識別する． ・標準属性 標準で用意された属性． 参考：https://docs.datadoghq.com/ja/logs/log_configuration/attributes_naming_convention/#%E6%A8%99%E6%BA%96%E5%B1%9E%E6%80%A7 { \"container_id\": \"*****\", \"container_name\": \"/prd-foo-ecs-container\", \"date\": 1632949140000, \"log_status\": \"NOTICE\", \"service\": \"foo\", \"source\": \"laravel\", \"timestamp\": 1632916740240 } ・スタックトレース属性 スタックトレースログを構成する要素に付与される属性のこと． 参考：https://docs.datadoghq.com/ja/logs/log_collection/?tab=host#%E3%82%B9%E3%82%BF%E3%83%83%E3%82%AF%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B9%E3%81%AE%E5%B1%9E%E6%80%A7 ログパーサー ・パーサーとは ログに対して，何かしらの加工を実行する． ・Grokパーサー パースルール（%{MATCHER:EXTRACT:FILTER}）を用いて，ログの値を属性に割り当てる． 参考： https://docs.datadoghq.com/ja/logs/processing/parsing/?tab=matcher https://docs.datadoghq.com/ja/logs/processing/processors/?tab=ui#grok-%E3%83%91%E3%83%BC%E3%82%B5%E3%83%BC ＊例＊ アプリケーションによって，以下のようなログが生成されるとする． [2021-01-01 00:00:00] staging.ERROR: ログのメッセージ [2021-01-01 00:00:00] production.ERROR: ログのメッセージ 以下のようなルールを定義する．ここでは，dateマッチャーとwordマッチャーを用いている．また，log_statusというカスタム属性に対して，wordマッチャーによって検出された文字列を付与している． FooRule \\[%{date(\"yyyy-MM-dd HH:mm:ss\"):date}\\]\\s+(production|staging).%{word:log_status}\\:.+ これにより，ログの値が属性に割り当てられる． { \"date\": 1630454400000, \"log_status\": \"INFO\" } ・Categoryパーサー 検索条件に一致する属性を持つログに対して，属性を新しく付与する． ＊例＊ ログに対してGrokパーサを実行し，属性にログの値を割り当てる．status_code属性を持つログに対して，status_category属性を付与する．この時，status_code属性の数値に応じて，status_category属性にステータスを表す文字列を割り当てる．その後，status_category属性に対してステータスリマッパーを実行する．これにより，status_category属性に割り当てられた文字列に応じて，ログレベルがマッピングされる． パースルールの構成 ・マッチャー 参考：https://docs.datadoghq.com/ja/logs/processing/parsing/?tab=matcher#%E3%83%9E%E3%83%83%E3%83%81%E3%83%A3%E3%83%BC%E3%81%A8%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%83%BC ・フィルター 参考：https://docs.datadoghq.com/ja/logs/processing/parsing/?tab=filter#%E3%83%9E%E3%83%83%E3%83%81%E3%83%A3%E3%83%BC%E3%81%A8%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%83%BC リマッパー ・リマッパーとは 指定した属性に割り当てられた値を，Datadogにおけるログ指標に対応付ける． ・ログステータスリマッパー 属性に割り当てられた文字列を，ルールに基づいて，特定のログレベル（INFO，WARNING，ERROR，など）にマッピングする．判定ルールについては，以下のリンクを参考にせよ． 参考：https://docs.datadoghq.com/ja/logs/processing/processors/?tab=ui#%E3%83%AD%E3%82%B0%E3%82%B9%E3%83%86%E3%83%BC%E3%82%BF%E3%82%B9%E3%83%AA%E3%83%9E%E3%83%83%E3%83%91%E3%83%BC インデックス ・インデックスとは 転送されたログをグループ化し，グループ別に異なる処理を実行する． 参考：https://docs.datadoghq.com/ja/logs/indexes/ 06. APM 図の種類 スケールの種類 ・log（対数）スケール ・linear（線形）スケール ・２の累乗スケール ・sqrt（平方根）スケール 07. その他 各識別子の有効期間 変更前の識別子は，時間経過とともにDatadogから削除される． 参考：https://docs.datadoghq.com/ja/dashboards/faq/historical-data/ "},"public/hardware.html":{"url":"public/hardware.html","title":"▶ ︎ハードウェア","keywords":"","body":"ハードウェア はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ハードウェアとは ハードウェアの種類 ・ユーザの操作が，ソフトウェアを介して，ハードウェアに伝わるまで ・CPU（プロセッサ） CPUは制御と演算を行う．CPUの制御部分は，プログラムの命令を解釈して，コンピュータ全体を制御．CPUの演算部分は，計算や演算処理を行う．特に，『算術論理演算装置（ALU：Arithmetic and Logic Unit）』とも呼ぶ． ・RAM（メインメモリ＋キャッシュメモリ） プログラムやデータを一時的に記憶し，コンピュータの電源を切るとこれらは消える． ・ROM プログラムやデータを長期的に記憶し，コンピュータの電源を切ってもこれらは消えない． ・ストレージ（HDD vs SSD） HDD：Hard Disk DriveとSSD：Solid State Driveがある． ・入力装置 コンピュータにデータを入力．キーボード，マウス，スキャナなど． ・出力装置 コンピュータからデータを出力．ディスプレイ，プリンタなど． 02. CPU（プロセッサ） IntelとAMDにおけるCPUの歴史（※2009年まで） クロック周波数 CPUの回路が処理と歩調を合わせるために用いる信号を，『クロック』と言う．一定時間ごとにクロックが起こる時，１秒間にクロックが何回起こるかを『クロック周波数』という．これは，Hzで表される．ちなみに，ワイのパソコンのクロック周波数は2.60GHzでした． （例1） 3Hz = 3 (クロック数／秒) （例2） 2.6GHz = 2.6×10^9 (クロック数／秒) MIPS：Million Instructions Per Second（×10^6 命令数／秒） CPUが1秒間に何回命令を実行するかを表す． （例題） (命令当たりの平均クロック数) = (4×0.3)＋(8×0.6)＋(10×0.1) = 7 (クロック周波数) ÷ (クロック当たりの命令数) = 700Hz (×10^6 クロック数／秒) ÷ 7 (クロック数／命令) = 100 (×10^6 命令数／秒) ・1命令当たりの実行時間 (秒／命令) の求め方 1 ÷ 100 (×10^6 命令／秒) = 10n (秒／命令) 03. 物理メモリ（RAM + ROM） 物理メモリの種類 『物理メモリ』は，RAMとROMに大きく分けられる． RAM：Read Access Memory RAMは，メインメモリとして使われる『Dynamic RAM』と，キャッシュメモリとして使われる『Static RAM』に分類される． ・Dynamic RAM メインメモリとして用いられる．よく見るやつ． ・Static RAM キャッシュメモリとして用いられる． ROM：Read Only Memory ・Mask ROM ・Programmable ROM Garbage collection プログラムが確保したメモリ領域のうち，不要になった領域を自動的に解放する機能． ・JavaにおけるGarbage collection Javaでは，JVM：Java Virtual Machine（Java仮想マシン）が，メモリ領域をオブジェクトに自動的に割り当て，また一方で，不要になったメモリ領域の解放を行う．一方で自動的に行う． 04. SRAM CPUから命令が起こるとき，CPU，DRAM，ストレージ間には，読み込みと書き出しの処理速度に差がある． キャッシュメモリとは ・一次キャッシュメモリと二次キャッシュメモリ** CPUとメインメモリの間に，キャッシュメモリを何段階か設置し，CPUとメインメモリの間の読み込みと書き出しの処理速度の差を緩和させる． キャッシュメモリの読み込み方法 ・ユーザー ➔ メインメモリ ➔ 二次キャッシュメモリ ➔ 一次キャッシュメモリ ユーザーが，パソコンに対して命令を与える． CPUは，命令をメインメモリに書き込む． CPUは，メインメモリから命令を読み出す． CPUは，二次キャッシュメモリに書き込む． CPUは，一次キャッシュメモリに書き込む． CPUは，命令を実行する． ・実例 タスクマネージャのパフォーマンスタブで，n次キャッシュメモリがどのくらい使われているのかを確認できる． キャッシュメモリへの書き込み方式の種類 ・Write-throught 方式 CPUは，命令をメインメモリとキャッシュメモリの両方に書き込む．常にメインメモリとキャッシュメモリの内容が一致している状態を確保できるが，メモリへの書き込みが頻繁に行われるので遅い． ・Write-back 方式 CPUは，キャッシュメモリのみに書き込む．次に，キャッシュメモリがメインメモリに書き込む．メインメモリとキャッシュメモリの内容が一致している状態を必ずしも確保できないが，メインメモリへの書き込み回数が少ないため速い 実効アクセス時間 05. アドレス空間管理の種類 前置き 言葉の使い方を，以下に統一する． 主記憶 ⇒ 物理メモリ（メインメモリ＋キャッシュメモリ） 補助記憶 ⇒ ストレージ 仮想記憶 ⇒ 仮想メモリ 物理メモリのアドレス空間管理 ・区画方式 後述の説明を参考にせよ． ・スワッピング方式 後述の説明を参考にせよ． ・オーバーレイ方式 後述の説明を参考にせよ． 仮想メモリのアドレス空間管理 ・ページング方式 後述の説明を参考にせよ． 05-02. 物理メモリのアドレス空間管理 固定区画方式（同じ大きさの区画に分割する方式） ・単一区画方式とは 物理メモリの領域を，一つの区画として扱い，プログラムに割り当てる方式．単一のプログラムしか読み込めず，余りのメモリ領域は利用できない． ・多重区画方式とは 物理メモリの領域を，複数の同じ大きさの区画に分割し，各区画にプログラムに割り当てる方式．複数のプログラムを読み込むことができるが，単一区画方式と同様に，余ったメモリ領域は利用できない． 可変区画方式（様々な大きさの区画に分割する方式） ・可変区画方式とは 物理メモリの領域を，プログラムの大きさに応じて，区画を様々な大きさの区画に分割し，プログラムに割り当てる方式．固定区画方式とは異なり，メモリ領域を有効に利用できる． スワッピング方式 ・スワッピング方式とは 物理メモリの領域を，優先度の高いプログラムに割り当て，反対に優先度が低いプログラムはストレージに退避させる方式．スワップ領域の作成方法については，CentOSのノートを参照． オーバーレイ方式 ・オーバーレイ方式とは GC：ガベージコレクション ・ガベージコレクションとは 確保された物理メモリのうち，解放可能なメモリをプログラムから解放する．物理メモリを使用しているオブジェクトが何かしらから参照されているかどうかを元に，解放するかどうかを判定する． ・アルゴリズム ガベージコレクションには様々なアルゴリズムがあり，採用されているアルゴリズムは言語ごとに異なる．Goのガベージコレクションについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/infrastructure_go.html 05-03. 仮想メモリのアドレス空間管理 ページング方式 ・ページング方式とは 仮想メモリの実装方法の一つ．仮想メモリのアドレス空間を『固定長』の領域（ページ），また物理メモリのアドレス空間を『固定長』の領域（ページフレーム）に分割し，管理する方式． ・ページイン／ページアウト 仮想メモリは，CPUの処理によって稼働したプログラムの要求を，物理メモリの代理として受け付ける．ストレージから物理メモリのページフレームにページを読み込むことを『Page-in』という．また，物理メモリのページフレームからストレージにページを追い出すことを『Page-out』という． ・仮想メモリとのマッピングによる大容量アドレス空間の実現 仮想メモリのアドレス空間を，物理メモリのアドレス空間とストレージにマッピングすることによって，物理メモリのアドレス空間を疑似的に大きく見せかけることができる． ちなみに，富士通の仮想メモリの容量は，以下の通り． セグメント方式 ・セグメント方式とは 仮想メモリの実装方法の一つ．仮想メモリのアドレス空間を『可変長』の領域（セグメント），また物理メモリのアドレス空間を『可変長』の領域（セグメント）に分割し，管理する方式． MMU：Memory Management Unit（メモリ管理ユニット） ・MMUにおける動的アドレス変換機構 MMUによって，仮想メモリのアドレスは，物理メモリのアドレスに変換される．この仕組みを，『動的アドレス変換機構』と呼ぶ． ・アドレス変換の仕組み（ページング方式型／セグメント方式型） 仮想メモリにおけるページの仮想アドレスを，ページ番号とページオフセットに分割する． ページテーブルを用いて，仮想アドレスのページ番号に対応する物理アドレスのページ番号を探す． 物理ページ番号にページオフセットを再結合し，物理メモリのページフレームの物理アドレスとする． ・ページテーブルにおける仮想ページ番号と物理ページ番号の対応づけ 05-04. メモリ，プロセス，スレッドの関係性 プロセス ・プロセスとは 参考：https://jpazamu.com/thread_process/#index_id5 スレッド ・スレッドとは ・マルチスレッド環境下での並列処理 言語 方法 PHP parallelライブラリを使用する．参考：https://github.com/krakjoe/parallel Go Goroutinesを使用する．参考：https://golang.org/doc/effective_go#concurrency Javascript WebWorkerを使用する．参考：https://developer.mozilla.org/ja/docs/Web/API/Web_Workers_API/Using_web_workersマルチスレッド環境下の並行処理と似て非なるものとして，シングルスレッド環境下での非同期処理がある．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_architecture.html 05-05. Page fault発生時の処理 Page faultとは ストレージから物理メモリのアドレス空間への割り込み処理のこと．CPUによって稼働したプログラムが，仮想メモリのアドレス空間のページにアクセスし，そのページが物理メモリのアドレス空間にマッピングされていなかった場合に，ストレージから物理メモリのアドレス空間に『ページイン』が起こる． Page Replacementアルゴリズム ページアウトのアルゴリズムのこと．方式ごとに，物理メモリのページフレームからストレージにページアウトするページが異なる． ・『FIFO方式：First In First Out』と『LIFO方式：Last In First Out』 ・『LRU方式：Least Recently Used』と『LFU方式：Least Frequently Used』 05-06. アドレス空間管理におけるプログラムの種類 Reusable（再使用可能プログラム） 一度実行すれば，再度，ストレージから物理メモリにページインを行わずに，実行を繰り返せるプログラムのこと． Reentrant（再入可能プログラム） 再使用可能の性質をもち，また複数のプログラムから呼び出されても，互いの呼び出しが干渉せず，同時に実行できるプログラムのこと． Relocatable（再配置可能プログラム） ストレージから物理メモリにページインを行う時に，アドレス空間上のどこに配置されても実行できるプログラムのこと． 06. ディスクメモリ CPU，メインメモリ，ストレージ間には，読み込みと書き出しの処理速度に差がある．（※再度記載） ディスクメモリの機能 メインメモリとストレージの間に，ディスクキャッシュを設置し，読み込みと書き出しの処理速度の差を緩和させる． 07. HDD Defragmentation 断片化されたデータ領域を整理整頓する． RAID：Redundant Arrays of Inexpensive Disks 複数のHDDを仮想的に一つのHDDであるかのようにして，データを管理する技術． ・RAID0（Striping） データを，複数のHDDに分割して書き込む． ・RAID1（Mirroring） データを，複数のHDDに同じように書き込む． ・RAID5（Striping with parity） データとパリティ（誤り訂正符号）を，3つ以上のHDDに書き込む． 08. GPUとVRAM GPUとVRAMの容量によって，扱うことのできる解像度と色数が決まる． 富士通PCのGPUとVRAMの容量は，以下の通り． 色数によって，１ドット当たり何ビットを要するが異なる． "},"public/hardware_embedded_system.html":{"url":"public/hardware_embedded_system.html","title":"▶ ︎組み込み機器","keywords":"","body":"組み込み機器 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 組み込み機器 組み込みシステムとは 組み込み機器（限定的な用途向けに特定の機能を果たす事を目的とした機器）を制御するシステムのこと． ※パソコンは、汎用機器（汎用的な用途向けに多様な機能を果たす事を目的とした機器）に分類される． マイクロコンピュータとは CPUとして、『マイクロプロセッサ』を用いたコンピュータのこと． センサによるアナログ情報の入力 外部のアナログ情報を計測し、マイコンに転送する． ＊具体例＊：温度センサ、加速度センサ、照度センサ、… A/D変換器によるアナログ情報からデジタル情報への変換 D/A変換器によるデジタル情報からアナログ情報への変換 Actuater 入力されたエネルギーもしくはコンピュータが出力した電気信号を物理的運動に変換する装置のこと． 組み込みシステムの制御方式の種類 ・シーケンス制御 決められた順序や条件に従って、制御の各段階を進めていく制御方式． ＊具体例＊ 洗濯機 ・フィードバック制御 その時の状況を定期的に計測し、目標値との差分を基に、出力を調節する制御方式． ＊具体例＊ エアコン 02. 入出力機器 キーボードからポインティングデバイス ・ジョイスティック 読み取り機器 ・イメージスキャナ ・Optical Character Reader 紙上の文字を文字データとして読み取る機器． ・Optical Mark Reader マークシートの塗り潰し位置を読み取る機器． ・キャプチャカード ・デジタルカメラ ディスプレイ ・CRTディスプレイ ・液晶ディスプレイ 電圧の有無によって液晶分子を制御．外部からの光によって画面を表示させる． ・有機ELディスプレイ 有機化合物に電圧を加えることによって発光させ、画面を表示させる． ・プラズマディスプレイ 2枚のガラスの間に、封入された希ガスに電圧をかけると放電し、紫外線が出る．そして、この紫外線が蛍光体を発光させることによって画面を表示する． 液晶ディスプレイとのシェア差が大きくなり、2014年に世界的に生産が終了された． ・LEDディスプレイ 2018年1月に開催された「CES 2018」でサムスンが発表した“マイクロLEDテレビ”「The Wall」は、従来の「液晶」や「有機EL」とは異なる新たな表示方式を採用したテレビとして、大きな話題となった． プリンタ ・ドットインパクトプリンタ ・インクジェットプリンタ ・レーザプリンタ ・プリンタの解像度 １インチ当たりのドット数（dpi）によって、解像度が異なる．復習ではあるが、PC上では、ドット数がどのくらいのビット数を持つかで、解像度が変わる． dpiが大きくなるにつれて、解像度は大きくなる． ・プリンタの印字速度 02-02. 入出力インターフェイス Serial interface vs. Parallel interface シリアルインターフェイスは、情報を1bitずつ転送する方式．パラレルインターフェイスは、複数のbitの情報を同時に転送する方式．パラレルインターフェイスは、同時にデータを送信し、同時に受信しなければならない．配線の形状や長さによって、信号の転送時間は異なる．動作クロックが速ければ速いほど、配線間の同時転送に誤差が生じてしまうため、現代の高スペックパソコンには向いていない． Serial interface が用いられている例 ・USB（Universal Serial Bus） ・IEEE1394 ビデオカメラとの接続に用いられるインターフェイス Parallel interface が用いられている例 ・IDE（Integrated Drive Electronics） ハードディスクとの接続に用いられるインターフェイス． ・SCSI（Small Computer System Interface） ハードディスク、CD-ROM、イメージスキャナなど、様々な周辺機器をデイジーチェーンするために用いるインターフェイス． 無線インターフェイス ・IrDA（infrared Data Assoiciation） 赤外線を使って、無線通信を行うためのインターフェイス． ・Bluetooth 2.4GHzの電波を使って無線通信を行うためのインターフェイス． "},"public/management_development_flow.html":{"url":"public/management_development_flow.html","title":"▶ ︎システム開発フローの全体像","keywords":"","body":"システム開発フローの全体像 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. システムの開発手法の種類 システム開発の要素 ・設計 ・実装 ・テスト ⇒ 15章と16章で解説していく． ウォーターフォール型開発 ・外部設計の詳細 外部設計では，ユーザ向けのシステム設計が行われる． プロトタイプ型開発 システム設計に入るまでに試作品を作り，要件定義をより正確にする開発方法． レビュー 各工程が完了した段階で，レビューを行う開発方法． RAD（Rapid Application Development） Visual Basicなどの開発支援ツールを用いて，短期間で設計～テストまでを繰り返す開発方法． スパイラル型開発 システムをいくつかのサブシステムに分割し，ウォーターフォール型開発で各サブシステムを開発していく方法． アジャイル型開発 スパイラルモデルの派生型．スパイラルモデルよりも短い期間で，設計～テストまでを繰り返す開発方法． CASEツール：Computer Aided Software Enginnering システム開発をサポートするツール群のこと． ・上流CASEツール データフロー図，ER図 ・下流CASEツール テスト支援ツール ・保守CASEツール リバースエンジニアリング 02. システム開発におけるプロジェクト管理 ウォーターフォール型開発（再掲） システム開発における様々な指標 『開発規模（か）』，『工数（こ）』，『生産性（せ）』の単位間の関係は，『みはじ』と同じである． ・開発規模（か） （プログラム本数による開発規模）＝（プログラム本数） （プログラム行数による開発規模）＝（ｋステップ行数） ・工数（こ） （人時による工数）＝（人数・時）＝（人数 × 時間） （人時による標準工数）＝（プログラム一本当たりの人数・時）＝（人数・時／本） 一期開発 外部設計 内部設計 開発 結合テスト 総合テスト 工数 42（時間） 70 140 52.5 42.0 配分月数 3（ヶ月） 3 5 2 3 A社動員数 12（人） 20 0 12 12 B社動員数 2（人） 4 28 15 2 ・生産性（せ） （プログラム本数の生産性） ＝（プログラム本数／人時） ＝（プログラム本数による開発規模）÷（工数） （kステップ行数の生産性） ＝（ｋステップ行数／人時） ＝（ｋステップ行数による開発規模）÷（工数） ・進捗率 Arrow ダイアグラム ・プロジェクトに必要な日数 全体的な工程に必要な日数は，所要日数が最も多い経路に影響される．この経路を，Critical Path という． ・最早結合点時刻 全体的な工程の中で，任意の結合点に取り掛かるために必要な最少日数のこと．Critical Path に影響されるので，注意． ・最遅結合点時刻 全体的な工程の中で，任意の結合点に取り掛かるために必要な最多日数のこと． "},"public/git.html":{"url":"public/git.html","title":"▶ ︎Git","keywords":"","body":"Gitの豆知識 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. トラブルシューティング 基点ブランチから二回派生するブランチマージする時の注意点 基点ブランチから，一つ目のブランチにマージし，これをpushする．ここでpushしないと，2番目のブランチが一つ目のブランチとの差分を検出してしまい，大量の差分コミットがgithubに表示されてしまう． 一つ目のブランチから二つ目のブランチにマージし．これをpushする． Conflictの解決方法とマージコミットの作成 git statusを行い，特定のファイルでのコンフリクトが表示される． Unmerged paths: (use \"git restore --staged ...\" to unstage) (use \"git add ...\" to mark resolution) both modified: XXX/YYY.twig コンフリクトしていたコード行を取捨選択する． 一度addを行い，コンフリクトの修正をGitに認識させる． $ git add XXX/YYY.twig git statusを行い，以下が表示される．コンフリクトが解決されたが，マージされていないと出力される．差分のファイルがたくさん表示される場合があるが，問題ない． All conflicts fixed but you are still merging. Changes to be committed: modified: XXX modified: XXX git commit（-mはつけてはいけない）を行い，vimエディタが表示される． Merge branch \"ブランチ名\" into ブランチ名 :wqでエディタを終了すれば，コンフリクトを解消したマージコミットが作成される． git statusを行う．場合によっては，差分のコミット数が表示されるが問題ない． Your branch is ahead of \"origin/feature/XXXX\" by 10 commits. pushする．この時，マージコミットを作成する時，基点ブランチ以外からマージしていると，差分のコミットが一つにまとまらず， 参考：http://www-creators.com/archives/1938 Commitの粒度 データベースからフロント出力までに至る実装をCommitする場合，以下の3つを意識する． データベースからCommit 関連性のある実装をまとめてCommit 一回のCommitがもつコード量が少なくなるようにCommit 誤って作成したプルリクの削除 不可能． 犯した罪は背負って生きていかなければならない． 参照：https://stackoverflow.com/questions/18318097/delete-a-closed-pull-request-from-github 02. Gitの準備 clone： ・clone 一番，クローンの速度が速く，コマンドの引数も簡単． $ git clone https://github.com//.git ・clone サーバ接続名は，，SSH接続の設定ファイル（~/.ssh/config）に記載されている．デフォルトでは，Githubの接続名は，「github.com」になっている． $ git clone git@:/.git config： ・ 設定の影響範囲の種類 影響範囲 意味 上書き順 設定ファイルの場所 system 全PCユーザの全リポジトリ 1 /etc/gitconfig global 現在のPCユーザーの全リポジトリ 2 ~/.gitconfig local 現在のリポジトリ 3 {リポジトリ名}/.git/config ・config -- --list 指定した影響範囲で適用されている設定値を表示する．--localで設定されていない項目は，--globalの設定値が適用される． $ git config --local --list Macでは，一つのPCで二つのGutHubアカウントを使用する場合に，キーチェーンという機能で設定が必要になる． リンク：https://sy-base.com/myrobotics/others/git-push_403error/ ・config -- user.name AuthorとCommitterの名前を設定する．localが一番最後に上書きされ，適用される． $ git config --local user.name \"hiroki-it\" ・config -- user.email AuthorとCommitterのメールアドレスを設定する．localが一番最後に上書きされ，適用される． $ git config --local user.email \"hasegawafeedshop@gmail.com\" Authorの情報は，コミット時に反映される．（Committerは表示されない） $ git log commit ee299250a4741555eb5027ad3e56ce782fe90ccb Author: hiroki-it Date: Sat Sep 12 00:00:00 2020 +0900 add ◯◯を実装した． ・config --global core.autocrlf 改行コードを，特定のタイミングで自動変換するように設定する．inputとしておくのが良い． $ git config --global core.autocrlf 設定値 チェックアウト時 コミット時 input 変換しない CRLF -> LF true LF -> CRLF CRLF -> LF false 変換しない 変換しない ・config --global core.editor gitのデフォルトエディタを設定する．ここでは，Vimをデフォルトとする． $ git config --global core.editor \"vim -c \"set fenc=utf-8\"\" remote： ・remote set-url origin プライベートリポジトリに接続する．configファイルに記述されたユーザ名と接続名を設定する．一つのPCで複数のGitHubアカウントを使用している場合，設定が必須である． $ git remote set-url origin @:/.git # リポジトリ１ Host User Port 22 HostName IdentityFile # リポジトリ２ Host User Port 22 HostName IdentityFile リポジトリに対してpushを実行してエラーが出た場合，異なる接続名が選ばれている場合は，URLの『接続名』の部分が正しく設定されているかを確認する． $ git push ERROR: Permission to hiroki-it/*****.git denied to Foo. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 03. Gitのコマンドメモ add： ・add --all 変更した全てのファイルをaddする． branch： ・branch --all 作業中のローカルブランチとリモート追跡ブランチを表示． ・branch --delete --force プッシュとマージの状態に関係なく，ローカルブランチを削除． ・branch --move 作業中のローカルブランチの名前を変更． ・branch --delete --remote origin/ リモート追跡ブランチを削除． （１）まず，branch --allで作業中のローカルブランチとリモート追跡ブランチを表示． $ git branch --all * master remotes/origin/2019/Symfony_Nyumon/master remotes/origin/master （２）remotes/origin/2019/Symfony_Nyumon/masterを削除． $ git branch -d -r origin/2019/Symfony_Nyumon/master Deleted remote-tracking branch origin/2019/Symfony_Nyumon/master (was 18a31b5). （３）再び，branch --allで削除されたことを確認． $ git branch --all * master remotes/origin/master ・branch checkout -b $ git checkout -b feature/3 d7e49b04 指定のコミットから新しいブランチを生やすことができる． cherry-pick ・cherry-pick -m 1 現在のブランチに対して，指定したコミットそれ単体をマージする． $ git cherry-pick 1d0ddeb9e52 プルリクのマージによるマージコミットを指定すると，そのプルリクで変更されたファイルのみがコミットの内容として取得できる．これにより，developブランチ上の必要な変更のみをリリースすることも可能である．ただし，マージコミットを指定する時はmオプションを有効化しないとエラーになることに注意する． # mオプションがないとエラー $ git cherry-pick d7e49b04 error: commit d7e49b04 is a merge but no -m option was given. fatal: cherry-pick failed # mオプションを有効化する $ git cherry-pick -m 1 d7e49b04 [master a9ebcb4] Merge pull request #276 from feature/123 Author: Hiroki Hasegawa Date: Wed Sep 15 00:00:00 2021 +0900 1 file changed, 7 insertions(+) stash： ・stashとは ファイルが，『インデックス』（=add）あるいは『HEAD』（=commit）に存在している状態で，異なるローカルブランチをcheckoutしようとすると，以下のエラーが出る． $ git checkout 2019/Symfony2_Ny umon/master error: Your local changes to the following files would be overwritten by checkout: app/config/config.yml src/AppBundle/Entity/Inquiry.php Please commit your changes or stash them before you switch branches. Aborting この場合，一度stashを行い，『インデックス』（=add）あるいは『HEAD』（=commit）を横に置いておく必要がある． ・stash -u --include-untracked トラッキングされていないファイルも含めて，全てのファイルを退避． git statusをしたところ，修正ファイルが３つ，トラックされていないファイルが１つある． $ git status On branch 2019/Symfony2_Nyumon/feature/6 Your branch is up to date with \"origin/2019/Symfony2_Nyumon/feature/6\". Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git checkout -- ...\" to discard changes in working directory) modified: app/Resources/views/Inquiry/index.html.twig modified: app/config/config.yml modified: src/AppBundle/Entity/Inquiry.php Untracked files: (use \"git add ...\" to include in what will be committed) app/Resources/views/Toppage/menu.html.twig no changes added to commit (use \"git add\" and/or \"git commit -a\") これを，stash -uする $ git stash -u Saved working directory and index state WIP on 2019/Symfony2_Nyumon/feature/6: 649995e update #6 xxx これらのファイルの変更点を一時的に退避できる． ・stash -- 特定のディレクトリやファイルのみstashすることができる． git stash -- src/... ・stash list 退避している『ファイル番号：ブランチ：親コミットとコミットメッセージ』を一覧で表示． $ git stash list stash@{0}: WIP on 2019/Symfony2_Nyumon/feature/6: 649995e update #6 xxx ・stash pop stash@{} 退避している指定のファイルを復元． $ git stash pop stash@{0} On branch 2019/Symfony2_Nyumon/feature/8 Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git checkout -- ...\" to discard changes in working directory) modified: app/Resources/views/Inquiry/index.html.twig modified: app/config/config.yml modified: src/AppBundle/Entity/Inquiry.php Untracked files: (use \"git add ...\" to include in what will be committed) app/Resources/views/Toppage/menu.html.twig no changes added to commit (use \"git add\" and/or \"git commit -a\") ・stash drop stash@{} 退避している指定のファイルを復元せずに削除． $ git stash drop stash@{0} Dropped refs/stash@{0} (1d0ddeb9e52a737dcdbff7296272080e9ff71815) ・stash clear 退避している全てのファイルを復元せずに削除． $ git stash clear revert： ・revertとは 作業中のローカルブランチにおいて，指定の履歴を削除． ・revert --no-edit 指定したコミットのみを打ち消す新しいコミットを作成する．コミットメッセージは，打ち消すコミットと同じものになる．リリース後に元に戻したい時に役立つ． $ git revert --no-edit ・revert --edit 指定したコミットのみを打ち消す新しいコミットを作成する．vimが起動するので，コミットメッセージを新しいものに変更する． $ git revert --edit ・revert -m 指定したマージコミットのみを打ち消す新しいコミットを作成する．コミットメッセージは，打ち消すコミットと同じものになる．マージナンバーを事前に確認しておく必要がある． $ git show commit xyz Merge: 1a1a1a 2b2b2b #ここに注目 Author: xxxx xxxx Date: Thu Jul 13 09:00:00 2017 +0000 Merge commit $ git revert -m 1 xyz reset： ・resetとは 作業中のローカルブランチにおいて，指定の履歴まで戻し，それ以降を削除． ・reset HEAD インデックスから，指定したファイルを削除． $ git reset HEAD ・reset --soft 作業中のローカルブランチにおいて，最新のHEAD（=commit後）を指定の履歴まで戻し，それ以降を削除する．commitのみを取り消したい場合はこれ． $ git reset --soft ・reset --mixed 作業中のローカルブランチにおいて，インデックス（=add後），HEAD（=commit後）を指定の履歴まで戻し，それ以降を削除．addとcommitを取り消したい場合はこれ． $ git reset --mixed ・reset --hard 作業中のローカルブランチにおいて，最新のワークツリー（=フォルダ），インデックス（=add後），HEAD（=commit後）を指定の履歴まで戻し，それ以降を削除． **ワークツリー（=フォルダ）内のファイルの状態も戻ってしまうので，取り扱い注意！！** $ git reset --hard ・resetの使用例 まず，logコマンドで，作業中のローカルブランチにおけるコミットIDを確認． $ git log commit f17f68e287b7d84318b4c49e133b2d1819f6c3db (HEAD -> master, 2019/Symfony2_Nyumon/master) Merge: 41cc21b f81c813 Author: Hiroki Hasegawa Date: Wed Mar 20 22:56:32 2019 +0900 Merge remote-tracking branch \"refs/remotes/origin/master\" commit 41cc21bb53a8597270b5deae3259751df18bce81 Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_2を追加 commit f81c813a1ead9a968c109671e6d83934debcab2e Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_1を追加 指定のコミットまで履歴を戻す． $ git reset --soft f81c813a1ead9a968c109671e6d83934debcab2e logコマンドで，正しく変更されているか確認． $ git log commit f81c813a1ead9a968c109671e6d83934debcab2e (HEAD -> master) Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add 新しいREADMEを追加 push --forceでローカルリポジトリの変更をリモートリポジトリに強制的に反映．**『強制的にpushした』というログも，リモート側には残らない．** $ git push --force Total 0 (delta 0), reused 0 (delta 0) To github.com:hiroki-it/Symfony2_Nyumon.git + f0d8b1a...f81c813 master -> master (forced update) rebase： ・rebaseとは（注意点あり） 作業中のローカルブランチにおいて，ブランチの派生元を変更．リモートブランチにpushした後は使ってはならず，他のコマンドを使う． ・rebase --interactive 派生元を変更する機能を応用して，過去のコミットのメッセージ変更，削除，統合などを行う． ＊コマンド例（コミットメッセージの変更）＊ まず，logコマンドで，作業中のローカルブランチにおけるコミットIDを確認． $ git log commit f17f68e287b7d84318b4c49e133b2d1819f6c3db (HEAD -> master, 2019/Symfony2_Nyumon/master) Merge: 41cc21b f81c813 Author: Hiroki Hasegawa Date: Wed Mar 20 22:56:32 2019 +0900 Merge remote-tracking branch \"refs/remotes/origin/master\" commit 41cc21bb53a8597270b5deae3259751df18bce81 Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_2を追加 commit f81c813a1ead9a968c109671e6d83934debcab2e Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_1を追加 指定した履歴の削除 $ git rebase --interactive 41cc21bb53a8597270b5deae3259751df18bce81 とすると，タブが表示され，指定のコミットIDの履歴が表示される pick b1b5c0f add #0 xxxxxxxxxx 『挿入モード』に変更し，この一行のpickをeditに変更．その後， :w として保存．その後，エディタ上で『Ctrl+C』を押し， :qa! で終了． commit --amendにmオプションを付けて，メッセージを変更． $ git commit --amend -m=\"\" rebase --continueを実行し，変更を反映させる． $ git rebase --continue Successfully rebased and updated refs/heads/develop. pushしようとすると，![rejected] develop -> develop (non-fast-forward)とエラーが出るので， $ git merge --allow-unrelated-histories で解決し，pushする． ＊コマンド例（Author名とCommiter名の変更）＊ ハッシュ値を指定して，rebaseコマンドを実行する． $ git rebase --interactive 41cc21bb53a8597270b5deae3259751df18bce81 commit --amendにreset-authorオプションを付けて，configで設定した名前をAuthor名とComitter名に適用する． $ git commit --amend --reset-author rebase --continueを実行し，変更を反映させる． $ git rebase --continue Successfully rebased and updated refs/heads/develop. 過去の全てのコミットに対して，Author名とCommitter名を適用するコマンドもある．しかし，危険な方法であるため，個人利用のリポジトリのみで使用するようにするべきである． #!/bin/bash git filter-branch -f --env-filter \" # Author名かCommitter名のいずれかが誤っていれば適用します． if [ ${GIT_AUTHOR_NAME}=\"Hiroki-Hasegawa\" -o ${GIT_COMMITTER_NAME}=\"Hiroki-Hasegawa\" ] ; then export GIT_AUTHOR_NAME=\"hiroki-it\" export GIT_AUTHOR_EMAIL=\"hasegawafeedshop@gmail.com\" export GIT_COMMITTER_NAME=\"hiroki-it\" export GIT_COMMITTER_EMAIL=\"hasegawafeedshop@gmail.com\" fi\" ・rebase --onto 作業中のローカルブランチの派生元を変更． $ git rebase --onto ・rebase --interactive --root 一番古い，最初の履歴を削除． （１）変更タブの表示 $ git rebase --interactive --root とすると，最初の履歴が記述されたタブが表示される pick b1b5c0f add #0 xxxxxxxxxx （２）pick b1b5c0f add #0 xxxxxxxxxxの行を削除して保存し，タブを閉じ，エディタ上で『Ctrl+C』を押す． :qa! ここで未知のエラー CONFLICT (modify/delete): README.md deleted in HEAD and modified in 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載 した. Version 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載した of README.md left in tree. error: could not apply 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載した Resolve all conflicts manually, mark them as resolved with \"git add/rm \", then run \"git rebase --continue\". You can instead skip this commit: run \"git rebase --skip\". To abort and get back to the state before \"git rebase\", run \"git rebase --abort\". Could not apply 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載した ・rebase --abort やりかけのrebaseを取り消し． 作業中のローカルブランチにおける(master|REBASE-i)が，(master)に変更されていることからも確認可能． hasegawahiroki@Hiroki-Fujitsu MINGW64 /c/Projects/Symfony2_Nyumon $ git rebase --interactive hasegawahiroki@Hiroki-Fujitsu MINGW64 /c/Projects/Symfony2_Nyumon (master|REBASE-i) $ git rebase --abort hasegawahiroki@Hiroki-Fujitsu MINGW64 /c/Projects/Symfony2_Nyumon (master) $ pull： ・コマンド組み合わせ 全てのリモートブランチをpullする． $ git branch -r | grep -v \"\\->\" | grep -v main | while read remote; do git branch --track \"${remote#origin/}\" \"$remote\"; done $ git fetch --all $ git pull --all push ： ・push -u origin ローカルで作成したブランチを，リモートにpushする．コミットは無くても良い． ・push origin :master トラウマコマンド ・push --delete origin リモートブランチのタグを削除する． $ git push --delete origin v1.0.0 なお，ローカルのタグは別に削除する必要がある． $ git tag -d v1.0.0 ・push --tags ローカルのコミットに付与したタグをリモートにpushする． show-branch： 作業ブランチの派生元になっているブランチを確認． $ git show-branch | grep \"*\" | grep -v \"$(git rev-parse --abbrev-ref HEAD)\" | head -1 | awk -F\"[]~^[]\" \"{print $2}\" filter-branch： ・filter-branch -f --env-filter 全てのコミットの名前とメールアドレスを上書きする． $ git filter-branch -f --env-filter \\ \"GIT_AUTHOR_NAME=\"hiroki-it\"; \\ GIT_AUTHOR_EMAIL=\"hasegawafeedshop@gmail.com\"; \\ GIT_COMMITTER_NAME=\"hiroki-it\"; \\ GIT_COMMITTER_EMAIL=\"hasegawafeedshop@gmail.com\";\" \\ HEAD ・filter-branch -f --tree-filter 全てのコミットに対して，指定した処理を実行する． ＊具体例＊ 全てのコミットに対して，特定のファイルを削除する処理を実行する．加えて，ローカルリポジトリに対してガーベジコレクションを実行すると，ローカルリポジトリから完全に削除できる． $ git filter-branch -f --tree-filter \\ 'rm -f ' HEAD # ガベージコレクションを実行 $ git gc --aggressive --prune=now "},"public/github.html":{"url":"public/github.html","title":"▶ ︎GitHub","keywords":"","body":"GitHub はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ テンプレート テンプレートの配置 リポジトリの直下に.githubディレクトリを配置し，ISSUE_TEMPLATE.mdやPULL_REQUEST_TEMPLATE.mdの名前でファイルを置く．Issueのテンプレートに関して，代わりにISSUE_TEMPLATEディレクトリを置き，任意の名前のmdファイルを置くと，複数のテンプレートを作成できる． 参考：https://qiita.com/nyamogera/items/3fe6985b45fbd5377184 project/ └── .github ├── ISSUE_TEMPLATE.md └── PULL_REQUEST_TEMPLATE.md project/ └── .github ├── ISSUE_TEMPLATE | ├── FIX.md | └── UPDATE.md | └── PULL_REQUEST_TEMPLATE.md Issue ・Issueの分割 一つのIssueとブランチにたくさんの実装をCommitすることは望ましくない．そこで，大きな対応を個々の対応に分割する．そして，大きな対応に関する基点Issueと基点ブランチを作成し，個々の対応に関連する子Issueと子ブランチを作成していく．個別の対応が終わったら，親ブランチへマージしていく． ・タイトル タイトルは『〇〇する．』とする．句読点の有無は好み． ・内容 内容は『背景』と『対応方針』さえ伝われば，文言自体はそのリポジトリのルールに合わせる． ＊具体例＊ # 背景 # 対応方針 PullReq ・タイトル タイトルは『〇〇した．』とする．句読点の有無は好み． ・WIP 実装途中のPullReqであり，実装方法などを質問したい場合に，タイトルに『WIP』とつけておく．レビューしてもらいたくなったら，これをはずす．レビュー修正時に，実装に時間がかかりそうであったら，再び付けても良い． ・内容 内容は『対応内容』と『レビューしてほしいところ』さえ伝われば，文言自体はそのリポジトリのルールに合わせる．もし，レビュー期限や動作確認手順を知らせる必要があれば『レビュー期限』『確認手順』の項目を設ける． ＊具体例＊ # リリース予定日 # 対応内容 # レビューしていただきたいところ レビューの方法 レビュー観点 ・ビジネスルールや仕様通りか 実装の条件文や，コメントから，ビジネスルールや仕様を理解する． 条件文でvar_dump() を行う． どういった入力がされた場合に，true として判断しているのかを確認．例えば，受注済区分値が設定されているときに，それが失注区分値に変わった場合に，値を返却しているならば，そこから，『失注』のビジネスルールが垣間見える． 定数に添えられたコメントから，仕様を理解． ・バリデーションは適切か empty() ，isset() などを正しく区別して使えているかを確認する ・冗長になっていないか 重複する処理をforeach()にまとめられないかを確認する．また，変数の格納が重複していないかを確認する． リリース hotfixブランチのリリース Issueを作成する． mainブランチから，『hotfix/』の名前でブランチを作成する． プルリクを作成し，マージの向き先をmainブランチとする． 速攻でapproveをもらい，mainブランチにマージする．この時，hotfixブランチは後でdevelopブランチにマージするため，削除しないようにする． パッチ番号を一つ増やしたタグを付与し，再リリースする． リリース後，エラーが解消されたら，ローカルPCでhotfixブランチをdevelopブランチにマージする． "},"public/backend_php_logic_algorithm.html":{"url":"public/backend_php_logic_algorithm.html","title":"▶ ︎アルゴリズムのロジック","keywords":"","body":"アルゴリズムのロジック はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 並び替えのアルゴリズム 例えば，次のような表では，どのような仕組みで「昇順」「降順」への並び替えが行われるのだろうか． 基本選択法（選択ソート） ・最小選択法 ＊実装例＊ 比較基準値を決める． 最初の数値を比較基準値とし，n個の中から最も小さい数字を探し，それと入れ替える． 次に，残りのn-1個の中から最も小さい数字を探し，それを2番目の数字と入れ替える． この処理をn-1回繰り返す． $array[$j]){ $position = $j; $min = $array[$j]; } } // 比較基準値の位置が更新されていなかった場合，親のfor文から抜ける． if($i == $position){ break; } // 親のfor文の最小値を更新． $array[$i] = $min; // 次に2番目を比較基準値とし，同じ処理を繰り返していく． } return $array; } ＊アルゴリズム解説＊ データ中の最小値を求め，次にそれを除いた部分の中から最小値を求める．この操作を繰り返していく． クイックソート ＊実装例＊ 適当な値を基準値（Pivot）とする （※できれば中央値が望ましい） Pivotより小さい数を前方，大きい数を後方に分割する． 二分割された各々のデータを，それぞれソートする． ソートを繰り返し実行する． ＊アルゴリズム解説＊ 適当な値を基準値（Pivot）とし，それより小さな値のグループと大きな値のグループに分割する．同様にして，両グループの中でPivotを選び，二つのグループに分割する．グループ内の値が一つになるまで，この処理を繰り返していく． 基本交換法（バブルソート） 隣り合ったデータの比較と入替えを繰り返すことによって，小さな値のデータを次第に端のほうに移していく方法． 基本挿入法（挿入ソート） 既に整列済みのデータ列の正しい位置に，データを追加する操作を繰り返していく方法． ヒープソート シェルソート 02. 配列内探索のアルゴリズム 線形探索法 今回は，配列内で「６」を探す． 二分探索法 前提として，ソートによって，すでにデータが整列させられているとする．今回は，配列内で「６」を探す． 03. グラフ探索のアルゴリズム（難し過ぎで記入途中） ダイクストラ法による最良優先探索 ＊実装例＊ 地点間の距離を表で表す．ただし，同地点間の距離は『0』，隣り合わない地点間の距離は『-1』とする． array(0, 2, 8, 4, -1, -1, -1), \"P1\" => array(2, 0, -1, -1, 3, -1, -1), \"P2\" => array(8, -1, 0, -1, 2, 3, -1), \"P3\" => array(4, -1, -1, 0, -1, 8, -1), \"P4\" => array(-1, 3, 2, -1, 0, -1, 9), \"P5\" => array(-1, -1, 3, 8, -1, 0, 3), \"P6\" => array(-1, -1, -1, -1, 9, 3, 0) ); ＊最短経路探索処理の解説＊ $startPoint = 0 $goalPoint = 6 とした時，出発地点（0）から1ステップ行ける地点までの距離（pDist）を取得し，確定させる． ＊アルゴリズム解説＊ 正のコストの経路のみの場合，用いることができる方法． 04. 誤り検出と訂正のアルゴリズム Check Digit Check バーコードやクレジットカードなどの読み取りチェックで使われている誤り検出方法． Check Digitを算出する． 算出されたCheck Digitが正しいかを検証する． Parity Check CRC：Cyclic Redundancy Check（巡回冗長検査） "},"public/statistic_analysis.html":{"url":"public/statistic_analysis.html","title":"▶ ︎統計解析","keywords":"","body":"統計解析 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ データ解析で気をつけること データ分析によって，何を明らかにしたいのか． 明らかにすることのために，どのデータ分析が必要なのか． 必要なデータ分析のために，どんな形式のデータを用意する必要があるのか． 01. 相関分析 データに，どの程度の直線的関係があるかを検出する分析手法．回帰分析を行うか否かの判断材料になる． ＊実装例＊ # データを読み込む． sample 02. 線形回帰分析 因果関係がありそうなデータに対して，横軸を原因，また縦軸を結果とし，最も当てはまりの良い線形モデルを推定する分析手法．モデルの精度が高ければ因果関係の証明になり，またモデルに原因を代入することで結果を予測できる． 単回帰分析 原因と結果が一つずつと仮定した時に，最も当てはまりの良い線形モデルを推定できる． ・回帰方程式 ＊実装例＊ # データを読み込む． sample |t|) # (Intercept) 1.099e+01 2.405e+00 4.571 3.11e-05 *** # 純広告 2.239e-05 2.927e-05 0.765 0.448 # // 純広告の回帰係数のp値 > 0.05 より，因果関係がない可能性． 重回帰分析 原因が二つ以上で結果が一つと仮定した時に，最も当てはまりの良い線形モデルを推定できる．ただし，グラフでは，モデルは平面で表される． ・回帰方程式 ＊実装例＊ # データを読み込む． sample |t|) # (Intercept) 8.857 1.007 8.797 1.69e-11 *** # days.月曜日 5.286 1.744 3.031 0.003957 ** # days.火曜日 4.893 1.670 2.930 0.005212 ** # days.水曜日 6.143 1.670 3.679 0.000601 *** # days.木曜日 5.893 1.670 3.529 0.000944 *** # days.金曜日 4.393 1.670 2.631 0.011479 * # // 月，水，金の回帰係数のp値 02-02. 非線形回帰分析 因果関係がありそうなデータに対して，横軸を原因，また縦軸を結果とし，最も当てはまりの良い非線形モデルを推定する分析手法．モデルの精度が高ければ因果関係の証明になり，またモデルに原因を代入することで結果を予測できる．非線形モデルを推定するためには，モデルを一般化し，一般化線形モデルとして処理する必要がある． ロジスティック回帰分析 説明変数が質的変数の場合に，最も当てはまりの良い非線形モデル（ロジスティック分布）を推定する． ・回帰方程式 ＊実装例＊ # データを読み込む． sample 03. 決定木分析 データに対して，最も当てはまりの良い決定木モデルを推定する分析手法． 分類木分析 決定木モデルを分類モデルとして用いる場合の決定木分析． ・図解例 赤い点：被験者が暑いと感じた日 青い点：被験者が暑くないと感じた日 ＊実装例＊ # データを読み込む． sample 04. 階層クラスタ分析 データを，似ている順に階層的にグループ化（クラスタリング）していく分析手法．データ間の同一性を明らかにすることができる． ＊実装例＊ # データを読み込む． sample1 05. グラフ生成関数 ggplot() ggplot()：グラフのキャンバスを準備 geom_XXX()：グラフをプロット theme()：グラフを追加加工 "}}