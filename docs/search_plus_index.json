{"./":{"url":"./","title":"📖 ︎このサイトについて","keywords":"","body":"このサイトについて サイトの作成方法 GitBookを使用して，mdファイルからHTMLを生成しております． 生成元のmdファイルは，hiroki-it/tech-notebook-gitbook リポジトリにて管理しております． 使い方 検索から スマホではなく，PCで使用します． 画面左上の検索フォームからキーワードを検索します． 検索結果が複数のノートにまたがる場合，ノートのタイトルを元に，参照するべきノートを判断します． ノートをクリックします． 検索結果からは，ノート内で一番最初に出現したキーワードにしかジャンプできません．そのため，ブラウザのキーワード機能を使用して，ノート内で改めてキーワードを検索します． 目次から スマホではなく，PCで使用します． 目次ページ を確認します． ノートをクリックします． サイトの目的 どこにでもいるエンジニアの 長谷川広樹 が，以下の目的のために使用しています． インプットしたことを自分の言葉で書き，アウトプットを行う． 誤った知識をその都度修正し，また体系的に整理する． インプットした内容を思い出すために閲覧する． そのため，誤った情報，誤った体系化，わかりにくい日本語，が多く散見されると思います． これらにつきましては，ご容赦いただけると幸いです． 学習方法 本サイトでは，以下を記載し，その概念を学習するようにしております． 定義づけ（演繹的な学習） 例（帰納的な学習） 概念図（視覚優位な学習） そのため，冗長な記載となることをご容赦いただけると幸いです． おわび このサイトで使われている説明や画像につきまして，様々な書籍やサイトから引用させていただいております． あくまで，上記の目的のためだけに使用させていただくという名目で，引用元を十分に記載しておりません． 深くお詫び申し上げます． "},"public/self_introduction.html":{"url":"public/self_introduction.html","title":"📖 ︎サイト管理者","keywords":"","body":"サイト管理者 経歴 長谷川広樹と申します． 2019年に理学修士を習得し，大学院を卒業後，バックエンドエンジニア としてキャリアをスタートいたしました． 現在は，SRE として働かさせていただいております． 詳しくは，以下のリンクまでご訪問いただけると幸いです． ▶ GitHub：https://github.com/hiroki-it ▶ Wantedly：https://www.wantedly.com/id/h_hasegawa ▶ Speaker Deck：https://speakerdeck.com/hiroki_hasegawa 関心のある技術領域 拡張性，保守性，可読性を高める技術に関心がございます． ドメイン駆動設計，アーキテクチャ，クラウドインフラ，IaC，コンテナ，CI/CD，Go，etc... "},"public/summary.html":{"url":"public/summary.html","title":"📖 ︎目次","keywords":"","body":"目次 ソフトウェア &#x1F4D6; ︎ソフトウェア 基本ソフトウェア（OS） &#x1F4D6; ︎ユーティリティ &#x1F4D6; ︎カーネル 言語プロセッサ &#x1F4D6; ︎言語プロセッサ &#x1F4D6; ︎言語別の処理方式 &#x1F4D6; ︎機械語と進数 ミドルウェア Web関連 &#x1F4D6; ︎Nginx &#x1F4D6; ︎Apache アプリケーション関連 &#x1F4D6; ︎PHP-FPM データベース関連 &#x1F4D6; ︎データベース &#x1F4D6; My︎SQL アプリケーションソフトウェア アーキテクチャ バックエンド &#x1F4D6; ︎マイクロサービスアーキテクチャ &#x1F4D6; ︎ドメイン駆動設計 &#x1F4D6; ︎クリーンアーキテクチャ &#x1F4D6; ︎CQRS フロントエンド &#x1F4D6; ︎フロントエンドアーキテクチャ アプリケーション間連携 &#x1F4D6; ︎JSON &#x1F4D6; ︎アプリケーション間通信 &#x1F4D6; ︎認証／認可 RESTful-API &#x1F4D6; ︎RESTful-API &#x1F4D6; ︎API仕様書 言語 &#x1F4D6; ︎オブジェクト指向型言語 PHP &#x1F4D6; PHPコマンドと設定 クラスベース &#x1F4D6; ︎クラス &#x1F4D6; ︎メソッド／データ &#x1F4D6; ︎データ構造 ロジック &#x1F4D6; ︎検証ロジック &#x1F4D6; ︎エラーとエラーハンドリング &#x1F4D6; ︎反復ロジック &#x1F4D6; ︎アルゴリズム フレームワーク &#x1F4D6; ︎Laravel &#x1F4D6; ︎Symfony パッケージ &#x1F4D6; ︎パッケージ管理 &#x1F4D6; ︎MySQLパッケージ &#x1F4D6; ︎その他パッケージ テスト &#x1F4D6; ︎テスト &#x1F4D6; ︎コードベースのテスト &#x1F4D6; ︎テスト仕様書ベースのテスト デバッグ &#x1F4D6; ︎デバッグ JavaScript プロトタイプベース &#x1F4D6; ︎プロトタイプ &#x1F4D6; ︎メソッド／データ ロジック &#x1F4D6; ︎検証ロジック &#x1F4D6; ︎非同期処理ロジック パッケージ／フレームワーク &#x1F4D6; ︎パッケージ &#x1F4D6; ︎Vue.js &#x1F4D6; ︎Nuxt.js デバッグ &#x1F4D6; ︎デバッグ ブラウザ &#x1F4D6; ︎ブラウザレンダリング 手続き型言語 Go &#x1F4D6; Goとは &#x1F4D6; Goコマンドと設定 ロジック &#x1F4D6; メソッド，データ パッケージ／フレームワーク &#x1F4D6; パッケージ &#x1F4D6; Gin ハードウェア &#x1F4D6; ︎ハードウェア &#x1F4D6; ︎メモリ &#x1F4D6; ︎組み込み機器 ネットワーク &#x1F4D6; ︎ネットワーク &#x1F4D6; ︎OSI参照モデル／TCP階層モデル セキュリティ &#x1F4D6; ︎サイバー攻撃 &#x1F4D6; ︎通信データの暗号化技術 クラウドコンピューティング &#x1F4D6; ︎クラウドコンピューティング AWS &#x1F4D6; ︎AWS &#x1F4D6; ︎API Gatewayへのymlインポート &#x1F4D6; ︎Lambda関数の実装 &#x1F4D6; ︎コスト管理 GCP &#x1F4D6; ︎GCP Infrastructure as Code &#x1F4D6; ︎Infrastructure as Code Terraform &#x1F4D6; ︎Terraform &#x1F4D6; ︎Terraformを用いたAWS構築Tips &#x1F4D6; ︎TerraformのCICDフロー 仮想化 &#x1F4D6; ︎仮想化 コンテナ Docker &#x1F4D6; ︎dockerコマンド &#x1F4D6; ︎Dockerfile コンテナオーケストレーション &#x1F4D6; ︎コンテナオーケストレーション Docker Compose &#x1F4D6; ︎docker-composeコマンド &#x1F4D6; ︎docker-compose.yml &#x1F4D6; ︎Kubernetes &#x1F4D6; ︎Docker Swarm ︎仮想サーバ（仮想マシン） &#x1F4D6; ︎仮想サーバ（仮想マシン） CICD &#x1F4D6; ︎CICD &#x1F4D6; ︎CircleCI &#x1F4D6; ︎Capistrano 可観測性／監視 &#x1F4D6; ︎可観測性 &#x1F4D6; ︎監視 Fluentd／FluentBit &#x1F4D6; ︎Fluentd／FluentBit &#x1F4D6; ︎FluentBit Datadog &#x1F4D6; ︎メトリクス収集 &#x1F4D6; ︎ログ収集 &#x1F4D6; 分散トレース収集 &#x1F4D6; テレメトリー間の紐付け &#x1F4D6; ︎監視 システム開発手法論 &#x1F4D6; ︎システム開発手法論 &#x1F4D6; ︎プロジェクト管理 Git &#x1F4D6; ︎GitHub &#x1F4D6; ︎Gitコマンド 統計解析 &#x1F4D6; ︎R言語 "},"public/software/software.html":{"url":"public/software/software.html","title":"📖 ︎ソフトウェア","keywords":"","body":"ソフトウェア はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ソフトウェアとは ユーザの操作による命令の流れ ユーザの操作による命令が，ソフトウェアを介して，ハードウェアに伝わるまで，を以下に示す． ソフトウェアの種類 1. アプリケーションソフトウェア（応用ソフトウェア） 2. ミドルウェア 3. 基本ソフトウェア（広義のOS） 4. Firmware 5. デバイスドライバ 02. アプリケーションソフトウェア（応用ソフトウェア） アプリケーションソフトウェアの一覧 ネイティブアプリ Webアプリとクラウドアプリ ハイブリッドアプリ 利用可能な通信状況 On／Off On On／Off ネイティブアプリケーション 端末のシステムによって稼働するアプリのこと．一度ダウンロードしてしまえば，インターネットに繋がっていなくとも，使用できる． ＊例＊ Office，BookLiveのアプリ版 Webアプリケーションとクラウドアプリケーション ・Webアプリケーション Webサーバ上でWebシステムをレンダリングすることによって稼働するアプリのこと．URLをWebサーバにリクエストすることで利用でき，随時，Webサーバとデータ通信を行う．全ての人が無料で利用できるものと，お金を払った人だけが利用できるものがある． ＊例＊ Googleアプリ，Amazon，BookLiveのブラウザ版，サイボウズ ・クラウドアプリケーション Webサーバ上のシステムによって稼働するアプリのうち，クラウドサービスを提供するもののこと． ＊例＊ Google Drive，Dropbox ハイブリッドアプリケーション 端末でWebviewを稼働させ，WebシステムのレンダリングなどをWebview上で行うアプリのこと． ＊例＊ クックパッド 03. ミドルウェア Webサーバのミドルウェア ・Apache 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_middleware_web_apache.html ・Nginx 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_middleware_web_nginx.html Appサーバのミドルウェア ・Apacheの拡張モジュール 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_middleware_web_apache.html ・PHP-FPM：PHP FastCGI Process Manager 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_middleware_application_php_fpm.html ・NGINX Unit WebサーバのNginxと組み合わせて使用できるミドルウェア． DBサーバのミドルウェア ・MySQL ・MariaDB 04. 基本ソフトウェア（広義のOS） 基本ソフトウェアの種類 ・Unix系OS Unixを源流として派生したOS．現在では主に，Linux系統（緑色），BSD系統（黄色），SystemV系統（青色）の三つに分けられる． ※ちなみに，MacOSはBSD系統 ・WindowsOS MS-DOSを源流として派生したOS．今では，全ての派生がWindows 10に集約された． 基本ソフトウェア ・基本ソフトウェアの構成 ・ユーティリティ ・言語プロセッサ ・制御プログラム（カーネル） 04-02. Unix系OS Linux系統 ・OSとバージョンの確認コマンド OSとバージョンが/etc/issueファイルに記載されている． $ cat /etc/issue Debian GNU/Linux 10 \\n \\l 現在，Linux系統のOSは，さらに3つの系統に分けられる． ・RedHat系統 RedHat，CentOS，Fedora ・Debian系統 Debian，Ubuntu， ・Slackware系統 Slackware BSD系統｜MacOS ・環境変数の確認 環境変数を確認する．全ての項目は，実際に実行して確認すること． $ export -p export EDITOR=vim export HOME=/Users/h.hasegawa export LANG=en_US.UTF-8 export SHELL=/bin/zsh export USER=h.hasegawa export VISUAL=vim ... 05. デバイスドライバ デバイスドライバとは 要勉強 06. Firmware Firmwareとは システムソフトウェア（ミドルウェア ＋ 基本ソフトウェア）とハードウェアの間の段階にあるソフトウェア．ROMに組み込まれている． BIOS：Basic Input/Output System UEFI：United Extensible Firmware Interface Windows 8以降で採用されている新しいFirmware 07. OSS：Open Source Software OSSとは 以下の条件を満たすソフトウェアをOSSと呼ぶ．アプリケーションソフトウェアから基本ソフトウェアまで，様々なものがある． 利用者は，無償あるいは有償で自由に再配布できる． 利用者は，ソースコードを入手できる． 利用者は，コードを自由に変更できる．また，変更後に提供する場合，異なるライセンスを追加できる． 差分情報の配布を認める場合には，同一性の保持を要求してもかまわない． ⇒ よくわからない 提供者は，特定の個人やグループを差別できない． 提供者は，特定の分野を差別できない． 提供者は，全く同じOSSの再配布において，ライセンスを追加できない． 提供者は，特定の製品でのみ有効なライセンスを追加できない． 提供者は，他のソフトウェアを制限するライセンスを追加できない． 提供者は，技術的に偏りのあるライセンスを追加できない． 種類 引用：https://openstandia.jp/oss_info/ "},"public/software/software_basic_utility.html":{"url":"public/software/software_basic_utility.html","title":"📖 ︎ユーティリティ","keywords":"","body":"ユーティリティ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ユーティリティの種類 Unixの場合 今回，以下に紹介するものをまとめる．RedHat系とDebian系のユーティリティが入り混じっているかもしれないため，要調査． ファイルシステム系 プロセス管理系 ネットワーク系 テキスト処理系 環境変数系 ハードウェア系 mkdir batch nslookup tail export df ls ps curl vim printenv free cp kill netstat grep timedatectl - find systemctl route history - - chmod cron ssh - - - rm - - - - - chown - - - - - ln - - - - - od - - - - - tar Windowsの場合 Windowsは，GUIでユーティリティを使用する．よく使うものを記載する． システム系 ストレージデバイス管理系 ファイル管理系 その他 マネージャ デフラグメントツール ファイル圧縮プログラム スクリーンセーバー クリップボード アンインストーラー - ファイアウォール レジストリクリーナ - - - アンチウイルス - - - ユーティリティのバイナリファイルの場所 バイナリファイルのディレクトリ バイナリファイルの種類 /bin Unixユーティリティのバイナリファイルの多く． /usr/bin 管理ユーティリティによってインストールされるバイナリファイルの多く． /usr/local/bin Unix外のソフトウェアによってインストールされたバイナリファイル．最初は空になっている． /sbin Unixユーティリティのバイナリファイルうち，sudo権限が必要なもの． /usr/sbin 管理ユーティリティによってインストールされたバイナリファイルのうち，sudo権限が必要なもの． /usr/local/sbin Unix外のソフトウェアによってインストールされたバイナリファイルのうち，sudo権限が必要なもの．最初は空になっている． # バイナリファイルが全ての場所で見つからないエラー $ which python3 which: no python3 in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin) # バイナリファイルの場所 $ which python3 /usr/bin/python3 02. 入力と出力 標準入出力 ・標準入出力とは 種類 説明 stddin（標準入力） キーボードからのコマンドに対して，データを入力するためのインターフェースのこと．プロセスごとに存在する． stdout（標準出力） コマンドからターミナルに対して，エラー以外のデータを出力するためのインターフェースのこと．プロセスごとに存在する． stderr（標準エラー出力） コマンドからターミナルに対して，エラーデータを出力するためのインターフェースのこと．プロセスごとに存在する． ・標準出力に出力 コマンド処理の後に，「>&1」を追加すると，処理の結果を，プロセスの標準出力に出力できる． ＊コマンド例＊ $ echo \"text\" >&1 また，プロセスの標準出力は/proc//fdディレクトリのファイルディスクリプタ番号（１番）で確認できる．プロセスIDはpsコマンドで事前に確認する． ＊コマンド例＊ PHP-FPMの稼働するアプリケーションの例 $ ps -aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.6 83736 25408 ? Ss 01:56 0:03 php-fpm: master process (/usr/local/etc/php-fpm.conf) www-data 2739 3.6 0.7 247968 29296 ? Sl 13:24 1:36 php-fpm: pool www www-data 2815 3.6 0.7 247968 29288 ? Sl 13:43 0:55 php-fpm: pool www www-data 2902 3.6 0.7 247968 29304 ? Sl 14:05 0:07 php-fpm: pool www root 2928 0.0 0.0 9732 3316 pts/0 R+ 14:08 0:00 ps -aux # 標準出力を確認 $ cat /proc/1/fd/1 参考：https://debimate.jp/2020/07/04/%e8%b5%b7%e5%8b%95%e6%b8%88%e3%81%bf%e3%83%97%e3%83%ad%e3%82%bb%e3%82%b9%ef%bc%88%e4%be%8b%ef%bc%9a%e3%83%87%e3%83%bc%e3%83%a2%e3%83%b3%e3%83%97%e3%83%ad%e3%82%bb%e3%82%b9%ef%bc%89%e3%81%ae%e6%a8%99/ ・標準エラー出力に出力 コマンド処理の後に，「>&2」を追加すると，処理の結果を，プロセスの標準エラー出力に出力できる． ＊コマンド例＊ $ echo \"text\" >&2 また，プロセスの標準出力は/proc//fdディレクトリのファイルディスクリプタ番号（２番）で確認できる．プロセスIDはpsコマンドで事前に確認する． ＊コマンド例＊ PHP-FPMの稼働するアプリケーションの例 $ ps -aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.6 83736 25408 ? Ss 01:56 0:03 php-fpm: master process (/usr/local/etc/php-fpm.conf) www-data 2739 3.6 0.7 247968 29296 ? Sl 13:24 1:36 php-fpm: pool www www-data 2815 3.6 0.7 247968 29288 ? Sl 13:43 0:55 php-fpm: pool www www-data 2902 3.6 0.7 247968 29304 ? Sl 14:05 0:07 php-fpm: pool www root 2928 0.0 0.0 9732 3316 pts/0 R+ 14:08 0:00 ps -aux # 標準エラー出力を確認 $ cat /proc/1/fd/2 参考：https://debimate.jp/2020/07/04/%e8%b5%b7%e5%8b%95%e6%b8%88%e3%81%bf%e3%83%97%e3%83%ad%e3%82%bb%e3%82%b9%ef%bc%88%e4%be%8b%ef%bc%9a%e3%83%87%e3%83%bc%e3%83%a2%e3%83%b3%e3%83%97%e3%83%ad%e3%82%bb%e3%82%b9%ef%bc%89%e3%81%ae%e6%a8%99/ ・標準出力とファイルに出力 パイプラインでteeコマンドを繋ぐと，標準出力とファイルの両方に出力できる． 参考：https://glorificatio.org/archives/2903 ＊コマンド例＊ $ echo \"text\" | tee stdout.log pipeline ・pipelineとは 「|」の縦棒記号のこと．複数のプログラムの入出力を繋ぐことができる． ・grepとの組み合わせ コマンドの出力結果をgrepコマンドに渡し，フィルタリングを行う． ＊コマンド例＊ 検索されたファイル内で，さらに文字列を検索する． $ find /* \\ -type f | xargs grep \"\" ・killとの組み合わせ コマンドの出力結果に対して，killコマンドを行う． ＊コマンド例＊ フィルタリングされたプロセスを削除する． $ sudo pgrep \\ -f | sudo xargs kill -9 ・awkとの組み合わせ コマンドの出力結果に対して，awkコマンドを行う． ＊コマンド例＊ 検索されたファイルの容量を合計する． $ find ./* -name \"*.js\" -type f -printf \"%s\\n\" | awk \"{ sum += $1; } END { print sum; }\" $ find ./* -name \"*.css\" -type f -printf \"%s\\n\" | awk \"{ sum += $1; } END { print sum; }\" $ find ./* -name \"*.png\" -type f -printf \"%s\\n\" | awk \"{ sum += $1; } END { print sum; }\" ・sortとの組み合わせ コマンドの出力結果に対して，並び順を変更する． ＊コマンド例＊ 表示された環境変数をAZ昇順に並び替える． $ printenv | sort -f 03. シェルスクリプト／Makefile シェルスクリプト ・シェルスクリプトとは ユーティリティの処理を手続き的に実装したファイル．最初の「#!」をシェバンという． ＊実装例＊ #!/bin/bash echo \"foo\" echo \"bar\" echo \"baz\" Makefile ・Makefileとは ユーティリティの処理を手続き的に実装したファイル．ターゲットごとに処理を実装する．複数のターゲット名を割り当てられる． foo: echo \"foo\" bar: echo \"bar\" baz qux: # 複数のターゲット名 echo \"baz\" ・ターゲット間依存関係 特定のターゲットの実行前に，他のターゲットを実行しておきたい場合，依存関係を定義できる．これは複数定義できる． foo: echo \"foo\" bar: foo # fooを事前に実行する． echo \"bar\" baz: foo baz # foo，bazを事前に実行する． echo \"baz\" シェルスクリプトの実行方法 ・source 現在開かれているインタラクティブで処理を実行する．そのため，シェルスクリプト内で定義した変数は，シェルスクリプトの実行後も維持される． $ source hello.sh ・bash 新しくインタラクティブを開き，処理を実行する．そのため，シェルスクリプト内で定義した変数は，シェルスクリプトの実行後に破棄される． $ bash hello.sh ・ドット $ . hello.sh ・パス指定 相対パスもしくは絶対パスでシェルスクリプトを指定する．実行するファイルをカレントディレクトリに置くことはできない． $ ./hello.sh Makefileの実行方法とオプション ・make Makefileが置かれた階層で，makeコマンドの引数としてターゲット名や環境変数を渡せる．Makefile内で環境変数のデフォルト値を定義できる． $ make = ＊実装例＊ $ make foo FOO=foo FOO=default foo: echo ${FOO} ロジック ・ヒアドキュメント ヒアドキュメントで作成したシェルスクリプトには，各行にechoが追加される． #!/bin/bash cat \"echo.sh\" #!/bin/bash hoge fuga EOF #!/bin/bash echo hoge echo fuga ・for ＊実装例＊ #!/bin/bash for i in 1 2 3 4 5 do echo \"$i\" done ・switch-case 変数に代入された値によって，処理を分ける．全ての場合以外をアスタリスクで定義する． ＊実装例＊ #!/bin/bash case \"$ENV\" in \"test\") VAR=\"XXXXX\" ;; \"stg\") VAR=\"YYYYY\" ;; \"prd\") VAR=\"ZZZZZ\" ;; *) echo \"The parameter ${ENV} is invalid.\" exit 1 ;; esac 04. ファイルシステム系 chmod：change mode ・ ファイルの権限を変更する．よく使用されるパーミッションのパターンは次の通り． $ chmod 600 ・-R ディレクトリ内のファイルに対して，再帰的に権限を付与する． $ chmod -R 600 ・100番刻みの規則性 所有者以外に全権限が与えられない． 数字 所有者 グループ その他 特徴 500 r-x --- --- 所有者以外に全権限なし 600 rw- --- --- 所有者以外に全権限なし 700 rwx --- --- 所有者以外に全権限なし ・111番刻みの規則性 全てのパターンで同じ権限になる． 数字 所有者 グループ その他 特徴 555 r-x r-x r-x 全てにWrite権限なし 666 rw- rw- rw- 全てにExecut権限なし 777 rwx rwx rwx 全てに全権限あり ・その他でよく使う番号 数字 所有者 グループ その他 特徴 644 rw- r-- r-- 所有者以外にWrite，Execute権限なし 755 rwx r-x r-x 所有者以外にWrite権限なし cp ・-Rp ディレクトリの属性情報も含めて，ディレクトリ構造とファイルを再帰的にコピー． $ cp -Rp // // # 隠しファイルも含めて，ディレクトリの中身を他のディレクトリ内にコピー # 「アスタリスク」でなく「ドット」にする $ cp -Rp // / ・-p 『ファイル名.YYYYmmdd』の形式でバックアップファイルを作成 $ cp -p .`date +\"%Y%m%d\"` echo ・オプション無し 定義されたシェル変数を出力する．変数名には$マークを付ける．ダブルクオートはあってもなくてもよい． $ = $ echo $ $ echo \"$\" file ・オプション無し ファイルの改行コードを確認する． # LFの場合（何も表示されない） $ file foo.txt foo.txt: ASCII text # CRLFの場合 $ file foo.txt foo.txt: ASCII text, with CRLF line terminators # CRの場合 $ file foo.txt foo.txt: ASCII text, with CR line terminators find ・-type ファイルを検索するためのユーティリティ．アスタリスクを付けなくとも，自動的にワイルドカードが働く． $ find /* -type f | xargs grep \"\" # パーミッションエラーなどのログを破棄して検索． $ find /* -type f | xargs grep \"\" 2> /dev/null ・-name 名前が .conf で終わるファイルを全て検索する． $ find /* -name \"*.conf\" -type f 名前が dir で終わるディレクトリを全て検索する． $ find /* -name \"*dir\" -type d ルートディレクトリ以下で， という文字をもち，ファイル名が .conf で終わるファイルを全て検索する． $ find /* -name \"*.conf\" -type f | xargs grep \"\" ln ・シンボリックリンクとは ファイルやディレクトリのショートカットのこと．シンボリックリンクに対する処理は，リンク元のファイルやディレクトリに転送される． ・-s カレントディレクトリに，シンボリックリンクを作成する．リンクの元になるディレクトリやファイルのパスを指定する． $ ln -s ls ・-l，-a 隠しファイルや隠しディレクトリも含めて，全ての詳細を表示する． $ ls -l -a mkdir ・-p 複数階層のディレクトリを作成する． $ mkdir -p // rm ・-R ディレクトリ自体と中のファイルを再帰的に削除する． $ rm -R od：octal dump ・オプション無し ファイルを8進数の機械語で出力する． $ od ・-Ad，-tx ファイルを16進数の機械語で出力する． $ od -Ad -tx set ・オプション無し 現在設定されているシェル変数を一覧で表示する． $ set ・-n シェルスクリプトの構文解析を行う． $ set -n ・-e 一連の処理の途中で0以外の終了ステータスが出力された場合，全ての処理を終了する． $ set -e ・-x 一連の処理をデバッグ情報として出力する． $ set -x ・-u 一連の処理の中で，未定義の変数が存在した場合，全ての処理を終了する． $ set -u ・-o pipefail パイプライン（|）内の一連の処理の途中で，エラーが発生した場合，その終了ステータスを出力し，全ての処理を終了する． $ set -o pipefail tar ・-x 圧縮ファイルを解凍する． $ tar -xf foo.tar.gz ・-f 圧縮ファイル名を指定する．これを付けない場合，テープドライブが指定される． $ tar -xf foo.tar.gz ・-v 解凍中のディレクトリ／ファイルの生成ログを表示する． $ tar -xvf foo.tar.gz ./ ./opt/ ./opt/foo/ ./opt/foo/bar/ ./opt/foo/bar/install.sh ./opt/foo/bar/baz/ ./opt/foo/bar/baz/init.sh ・-g gzip拡張子の圧縮ファイルを解凍する．ただし，標準で有効になっているため，オプションは付けないくても問題ない． $ tar -zxf foo.tar.gz unlink ・オプション無し カレントディレクトリのシンボリックリンクを削除する． $ unlink 04-02. ネットワーク系 curl ・オプション無し GETリクエストを送信する．jqコマンドを使用すると，レスポンスを整形できる． $ curl http://example.co.jp/foos/1 | jq . ・-X，-T，-d Content-Typeを指定して，POSTリクエストを送信する． $ curl -X POST -H \"Content-Type: application/json\" -d '{}' https://example.co.jp/foos ・-o（小文字） インストール後のファイル名を定義する．これを指定しない場合，-Oオプションを有効化する必要がある． $ curl -o https://example.co.jp ・-O（大文字） インストール後のファイル名はそのままでインストールする．これを指定しない場合，-oオプションを有効化する必要がある． ・-L 指定したURLでリダイレクトが行われても，リダイレクト後のURLからファイルをインストールする． $ curl -L https://example.co.jp/foos ssh：secure shell ・-l，-p，，-i，-T 事前に，秘密鍵の権限は「600」にしておく．tty（擬似ターミナル）を使用する場合は，-Tオプションをつける． $ ssh -l @ -p 22 -i -T ・-l，-p，，-i，-T，-vvv # -vvv：ログを出力する $ ssh -l @ -p 22 -i -T -vvv ・設定ファイル（~/.ssh/config） 設定が面倒なsshコマンドのオプションの引数を，~/.ssh/configファイルに記述しておく． # サーバ１ Host User Port 22 HostName IdentityFile # サーバ２ Host User Port 22 HostName IdentityFile これにより，コマンド実行時の値渡しを省略できる．tty（擬似ターミナル）を使用する場合は，-Tオプションをつける． # 秘密鍵の権限は，事前に「600」にしておく $ ssh -T 04-03. プロセス系 ps： process status ・-aux 稼働しているプロセスの詳細情報を表示するためのユーティリティ． # 稼働しているプロセスのうち，詳細情報に「xxx」を含むものを表示する． $ ps -aux | grep \"\" systemctl：system control（旧service） ・systemctlとは デーモンを起動するsystemdを制御するためのユーティリティ． ・list-unit-files デーモンのUnitを一覧で確認する． $ systemctl list-unit-files --type=service crond.service enabled # enable：自動起動する supervisord.service disabled # disable：自動起動しない systemd-reboot.service static # enable：他サービス依存 ・enable マシン起動時にデーモンが自動起動するように設定する． $ systemctl enable # 例：Cron，Apache $ systemctl enable crond.service $ systemctl enable httpd.service ・disable マシン起動時にデーモンが自動起動しないように設定する． $ systemctl disable # 例：Cron，Apache $ systemctl disable crond.service $ systemctl disable httpd.service ・systemd：system daemon のUnitの種類 各デーモンを，/usr/lib/systemd/systemや/etc/systemd/system下でUnit別に管理し，Unitごとに起動する．Unitは拡張子の違いで判別する． Unitの拡張子 意味 デーモン例 mount ファイルのマウントに関するデーモン． service プロセス起動停止に関するデーモン． httpd：http daemon socket ソケットとプロセスの紐付けに関するデーモン kill ・-9 指定したPIDのプロセスを削除する． $ kill -9 指定したコマンドによるプロセスを全て削除する． $ sudo pgrep -f | sudo xargs kill -9 cron ・cronとは 指定したスケジュールに従って，指定されたプログラムを定期実行する常駐プログラム． ・cronファイル ファイル名ディレクトリ名 利用者 主な用途 /etc/crontab root 毎時，毎日，毎月，毎週の自動タスクのメイン設定ファイル /etc/cron.hourly root 毎時実行される自動タスク設定ファイルを置くディレクトリ /etc/cron.daily root 毎日実行される自動タスク設定ファイルを置くディレクトリ /etc/cron.monthly root 毎月実行される自動タスク設定ファイルを置くディレクトリ /etc/cron.weekly root 毎週実行される自動タスク設定ファイルを置くディレクトリ ＊実装例＊ あらかじめ，各ディレクトリにcronファイルを配置しておく． cronとして登録するファイルを作成する．run-partsコマンドで，指定した時間に，各cronディレクトリ内のcronファイルを一括で実行するように記述しておく． # 設定 SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=\"example@gmail.com\" LANG=ja_JP.UTF-8 LC_ALL=ja_JP.UTF-8 CONTENT_TYPE=text/plain; charset=UTF-8 # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed # run-parts 1 * * * * root run-parts /etc/cron.hourly # 毎時・1分 5 2 * * * root run-parts /etc/cron.daily # 毎日・2時5分 20 2 * * 0 root run-parts /etc/cron.weekly # 毎週日曜日・2時20分 40 2 1 * * root run-parts /etc/cron.monthly # 毎月一日・2時40分 @reboot make clean html # cron起動時に一度だけ ・cron.dファイル 複数のcronファイルで全ての一つのディレクトリで管理する場合に用いる． ディレクトリ名 利用者 主な用途 /etc/cron.d root 上記以外の自動タスク設定ファイルを置くディレクトリ ・supervisorとの組み合わせ ユーザーが，OS上のプロセスを制御できるようにするためのプログラム． # インストール $ pip3 install supervisor # /etc/supervisor/supervisord.conf に設定ファイルを置いて起動． $ /usr/local/bin/supervisord 以下に設定ファイルの例を示す． ＊実装例＊ [supervisord] # 実行ユーザ user=root # フォアグラウンドで起動 nodaemon=true # ログ logfile=/var/log/supervisord.log # Pid pidfile=/var/tmp/supervisord.pid [program:crond] # 実行コマンド command=/usr/sbin/crond -n # プログラムの自動起動 autostart=true # プログラム停止後の再起動 autorestart=true # コマンドの実行ログ stdout_logfile=/var/log/command.log stderr_logfile=/var/log/command-error.log # コマンドの実行ユーザ user=root # コマンドの実行ディレクトリ directory=/var/www/tech-notebook crontab ・crontabとは cronデーモンの動作が定義されたcrontabファイルを操作するためのユーティリティ． ・オプション無し 作成したcronファイルを登録する．cron.dファイルは操作できない． $ crontab ・登録されたcronファイルの処理を確認 $ crontab -l # crontabコマンドで登録されたcronファイルの処理 1 * * * * rm foo ・cronファイルの登録手順 ＊実装例＊ １. 拡張子は自由で，時刻とコマンドが実装されたファイルを用意する．この時，最後に改行がないとエラー（premature EOF）になるため，改行を追加する． 参考： # cron-hourly.txt # 毎時・1分 1 * * * * root run-parts /etc/cron.hourly # cron-daily.txt # 毎日・2時5分 5 2 * * * root run-parts /etc/cron.daily # cron-monthly.txt # 毎週日曜日・2時20分 20 2 * * 0 root run-parts /etc/cron.weekly # cron-weekly.txt # 毎月一日・2時40分 40 2 1 * * root run-parts /etc/cron.monthly # cron起動時に一度だけ @reboot make clean html ２. このファイルをcrontabコマンドで登録する．cronファイルの実体はないことと，ファイルの内容を変更した場合は登録し直さなければいけないことに注意する． $ crontab /foo/cron-hourly.txt ３. 登録されている処理を確認する． $ crontab -l 1 * * * * root run-parts /etc/cron.hourly ４. ログに表示されているかを確認． $ cd /var/log $ tail -f cron ５. 改行コードを確認．改行コードが表示されない場合はLFであり，問題ない． $ file /foo/cron-hourly.txt foo.txt: ASCII text crond ・crondとは cronデーモンを起動するためのプログラム ・-n フォアグラウンドプロセスとしてcronを起動 $ crond -n 04-04. テキスト処理系 vim：Vi Imitaion，Vi Improved ・オプション無し vim上でファイルを開く． $ vim history ・オプション無し 履歴1000件の中からコマンドを検索する． $ history | grep tr #!/bin/bash cat ./src.txt | tr \"\\n\" \",\" > ./dst.txt 04-05. 環境変数系 export ・オプション無し 基本的な手順としては，シェル変数を設定し，これを環境変数に追加する． # シェル変数を設定 $ PATH=$PATH: # 環境変数に追加 $ export PATH シェル変数の設定と，環境変数への追加は，以下の通り同時に記述できる． # 環状変数として，指定したバイナリファイル（bin）のあるディレクトリへの絶対パスを追加． # バイナリファイルを入力すると，絶対パス $ export PATH=$PATH: # 不要なパスを削除したい場合はこちら # 環状変数として，指定したバイナリファイル（bin）のあるディレクトリへの絶対パスを上書き $ export PATH=/sbin:/bin:/usr/sbin:/usr/bin ・.bashrcへの追記 exportの結果は，OSの再起動で初期化されてしまう．そのため，再起動時に自動的に実行されるよう，/home/centos/.bashrcに追記しておく． # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific environment PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\" # xxxバイナリファイルのパスを追加 を追加 printenv ・オプション無し 全ての環境変数を表示する． $ printenv また，特定の環境変数を表示する． $ printenv VAR timedatactl ・set-timezone # タイムゾーンを日本時間に変更 $ timedatectl set-timezone Asia/Tokyo # タイムゾーンが変更されたかを確認 $ date 04-06. ハードウェア系 top ・オプション無し 各プロセスの稼働情報（ユーザ名，CPU，メモリ）を確認する． CPU使用率昇順に並べる $ top ・-a メモリ使用率昇順に並べる． $ top -a free ・-m，-total 物理メモリ，スワップ領域，の使用状況をメガバイトで確認する． # m：Mega Bytes # t: -total $ free -m -total df ・-h，-m，-t ストレージの使用状況をメガバイトで確認する． # h：--human-readable # t: -total $ df -h -m -t mkswap，swapon，swapoff ・スワッピング方式 物理メモリのアドレス空間管理の方法の一つ． ・スワップ領域の作成方法 # 指定したディレクトリをスワップ領域として使用 $ mkswap /swap_volume # スワップ領域を有効化 # 優先度のプログラムが，メモリからディレクトリに，一時的に退避されるようになる $ swapon /swap_volume # スワップ領域の使用状況を確認 $ swapon -s # スワップ領域を無効化 $ swapoff /swap_volume 05. 管理ユーティリティ 管理ユーティリティの種類 ・管理ユーティリティの対象 様々なレベルを対象にした管理ユーティリティがある． ・ライブラリ管理ユーティリティ ユーティリティ名 対象プログラミング言語 composer.phar：Composer PHP pip：Package Installer for Python Python npm：Node Package Manager Node.js maven：Apache Maven Java gem：Ruby Gems Ruby ・パッケージ管理ユーティリティ ユーティリティ名 対象OS 依存関係のインストール可否 Rpm：Red Hat Package Manager RedHat系 ✕ Yum：Yellow dog Updater ModifiedDNF：Dandified Yum RedHat系 〇 Apt：Advanced Packaging Tool Debian系 〇 Apk：Alpine Linux package management Alpine Linux 〇 ・言語バージョン管理ユーティリティ ユーティリティ名 対象プログラミング言語 phpenv PHP pyenv Python rbenv Ruby 05-02. ライブラリ管理ユーティリティ pip ・install 指定したライブラリをインストールする． # /usr/local 以下にインストール $ pip install --user # requirements.txt を元にライブラリをインストール $ pip install -r requirements.txt # 指定したディレクトリにライブラリをインストール pip install -r requirements.txt　--prefix=/usr/local ・freeze pipでインストールされたパッケージを元に，要件ファイルを作成する． $ pip freeze > requirements.txt ・show pipでインストールしたパッケージ情報を表示する． $ pip show sphinx Name: Sphinx Version: 3.2.1 Summary: Python documentation generator Home-page: http://sphinx-doc.org/ Author: Georg Brandl Author-email: georg@python.org License: BSD # インストール場所 Location: /usr/local/lib/python3.8/site-packages # このパッケージの依存対象 Requires: sphinxcontrib-applehelp, imagesize, docutils, sphinxcontrib-serializinghtml, snowballstemmer, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-jsmath, setuptools, packaging, Pygments, babel, alabaster, sphinxcontrib-qthelp, requests, Jinja2 # このパッケージを依存対象としているパッケージ Required-by: sphinxcontrib.sqltable, sphinx-rtd-theme, recommonmark npm ・入手方法 # リポジトリの作成 $ curl -sL https://rpm.nodesource.com/setup_.x | bash - # nodejsのインストールにnpmも含まれる $ yum install nodejs ・init package.jsonを生成する． $ npm init ・install ディレクトリにパッケージをインストール # ローカルディレクトリにパッケージをインストール $ npm install # グローバルディレクトリにインストール（あまり使わない） $ npm install -g 05-03. パッケージ管理ユーティリティ rpm ・-ivh パッケージをインストールまたは更新する．一度に複数のオプションを組み合わせて記述する．インストール時にパッケージ間の依存関係を解決できないので注意． # パッケージをインストール # -ivh：--install -v --hash $ rpm -ivh # パッケージを更新 # -Uvh：--upgrade -v --hash $ rpm -Uvh ・-qa インストールされた全てのパッケージの中で，指定した文字を名前に含むものを表示する． # -qa： $ rpm -qa | grep ・-ql 指定したパッケージ名で，関連する全てのファイルの場所を表示する． # -ql： $ rpm -ql ・-qi 指定したパッケージ名で，インストール日などの情報を表示する． # -qi： $ rpm -qi yum，dnf ・install，reinstall rpmと同様の使い方ができる．また，インストール時にパッケージ間の依存関係を解決できる． # パッケージをインストール $ yum install -y # 再インストールする時は，reinstallとすること $ yum reinstall -y ・list インストールされた全てのパッケージを表示する． # 指定した文字を名前に含むものを表示． $ yum list | grep ・EPELリポジトリ，Remiリポジトリ CentOS公式リポジトリはパッケージのバージョンが古いことがある．そこで，--enablerepoオプションを使用すると，CentOS公式リポジトリではなく，最新バージョンを扱う外部リポジトリ（EPEL，Remi）から，パッケージをインストールできる．外部リポジトリ間で依存関係にあるため，両方のリポジトリをインストールする必要がある． CentOSのEPELリポジトリをインストール．インストール時の設定ファイルは，/etc/yu.repos.d/* に配置される． # CentOS7系の場合 $ yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm # CentOS8系の場合 $ dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm # こちらでもよい $ yum install -y epel-release でもよい CentOSのRemiリポジトリをインストール．RemiバージョンはCentOSバージョンを要確認．インストール時の設定ファイルは，/etc/yu.repos.d/*に配置される． # CentOS7系の場合 $ yum install -y https://rpms.remirepo.net/enterprise/remi-release-7.rpm # CentOS8系の場合 $ dnf install -y https://rpms.remirepo.net/enterprise/remi-release-8.rpm 設定ファイルへは，インストール先のリンクなどが自動的に書き込まれる． [epel] name=Extra Packages for Enterprise Linux 6 - $basearch #baseurl=http://download.fedoraproject.org/pub/epel/6/$basearch mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-6&arch=$basearch failovermethod=priority enabled=0 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 [epel-debuginfo] name=Extra Packages for Enterprise Linux 6 - $basearch - Debug #baseurl=http://download.fedoraproject.org/pub/epel/6/$basearch/debug mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-6&arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=1 [epel-source] name=Extra Packages for Enterprise Linux 6 - $basearch - Source #baseurl=http://download.fedoraproject.org/pub/epel/6/SRPMS mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-6&arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 gpgcheck=1 Remiリポジトリの有効化オプションを永続的に使用できるようにする． # CentOS7の場合 $ yum install -y yum-utils # 永続的に有効化 $ yum-config-manager --enable remi-php74 # CentOS8の場合（dnf moduleコマンドを使用） $ dnf module enable php:remi-7.4 remiリポジトリを指定して，php，php-mbstring，php-mcryptをインストールする．Remiリポジトリを経由してインストールしたソフトウェアは/opt/remi/*に配置される． # CentOS7の場合 # 一時的に有効化できるオプションを利用して，明示的にremiを指定 $ yum install --enablerepo=remi,remi-php74 -y php php-mbstring php-mcrypt # CentOS8の場合 # リポジトリの認識に失敗することがあるのでオプションなし $ dnf install -y php php-mbstring php-mcrypt 再インストールする時は，reinstallとすること． # CentOS7の場合 # 一時的に有効化できるオプションを利用して，明示的にremiを指定 $ yum reinstall --enablerepo=remi,remi-php74 -y php php-mbstring php-mcrypt # CentOS8の場合 # リポジトリの認識に失敗することがあるのでオプションなし $ dnf reinstall -y php php-mbstring php-mcrypt 05-04. 言語バージョン管理ユーティリティ pyenv ・which # pythonのインストールディレクトリを確認 $ pyenv which python /.pyenv/versions/3.8.0/bin/python "},"public/software/software_basic_kernel.html":{"url":"public/software/software_basic_kernel.html","title":"📖 ︎カーネル","keywords":"","body":"制御プログラム（カーネル） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 制御プログラム（カーネル） （例）カーネル，マイクロカーネル，モノリシックカーネル 02. 通信管理 SELinux：Security Enhanced Linux Linuxに標準で導入されているミドルウェア．ただし，アプリケーションと他のソフトウェアの通信を遮断してしまうことがあるため，基本的には無効にしておく． SELinuxの状態を確認 $ getenforce # 有効の場合 Enforcing /etc/sellnux/configを修正する． # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled # OSを再起動 OSを再起動しないと設定が反映されない． 03 ジョブ管理 ジョブ管理とは クライアントは，マスタスケジュールに対して，ジョブを実行するための命令を与える． マスタスケジュラ，ジョブスケジュラ ジョブとは，プロセスのセットのこと．マスタスケジュラは，ジョブスケジュラにジョブの実行を命令する．データをコンピュータに入力し，複数の処理が実行され，結果が出力されるまでの一連の処理のこと．『Task』と『Job』の定義は曖昧なので，『process』と『set of processes』を使うべきとのこと． 引用：https://stackoverflow.com/questions/3073948/job-task-and-process-whats-the-difference/31212568 複数のジョブ（プログラムやバッチ）の起動と終了を制御したり，ジョブの実行と終了を監視報告するソフトウェア．ややこしいことに，タスクスケジューラとも呼ぶ． ・Reader ジョブ待ち行列に登録 ・Initiator ジョブステップに分解 ・Terminator 出力待ち行列に登録 ・Writer 優先度順に出力の処理フローを実行 Initiatorによるジョブのジョブステップへの分解 Initiatorによって，ジョブはジョブステップに分解される． 04. タスク管理 タスク管理とは タスクとは，スレッドに似たような，単一のプロセスのこと．Initiatorによるジョブステップから，タスク管理によって，タスクが生成される．タスクが生成されると実行可能状態になる．ディスパッチャによって実行可能状態から実行状態になる． 優先順方式 各タスクに優先度を設定し，優先度の高いタスクから順に，ディスパッチしていく方式． 到着順方式 待ち行列に登録されたタスクから順に，ディスパッチしていく方式． ＊例＊ 以下の様に，タスクがCPUに割り当てられていく． Round robin 方式 Round robinは，『総当たり』の意味．一定時間（タイムクウォンタム）ごとに，実行状態にあるタスクが強制的に待ち行列に登録される．交代するように，他のタスクがディスパッチされる． ＊例＊ 生成されたタスクの到着時刻と処理時間は以下のとおりである．強制的なディスパッチは，『20秒』ごとに起こるとする． タスクAが0秒に待ち行列へ登録される． 20秒間，タスクAは実行状態へ割り当てられる． 20秒時点で，タスクAは実行状態から待ち行列に追加される．同時に，待ち行列の先頭にいるタスクBは，実行可能状態から実行状態にディスパッチされる． 40秒時点で，タスクCは実行状態から待ち行列に追加される．同時に，待ち行列の先頭にいるタスクAは，実行可能状態から実行状態にディスパッチされる． 05. 入出力管理 入出力管理とは アプリケーションから低速な周辺機器へデータを出力する時，まず，CPUはスプーラにデータを出力する．Spoolerは，全てのデータをまとめて出力するのではなく，一時的に補助記憶装置（Spool）にためておきながら，少しずつ出力する（Spooling）． "},"public/software/software_basic_language_processor.html":{"url":"public/software/software_basic_language_processor.html","title":"📖 ︎言語プロセッサ","keywords":"","body":"言語プロセッサ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. プログラミング言語 言語の種類 プログラム言語のソースコードは，言語プロセッサによって機械語に変換された後，CPUによって実行される．そして，ソースコードに書かれた様々な処理が実行される． コンパイラ型言語 ・コンパイラ型言語とは コンパイラという言語プロセッサによって，コンパイラ方式で翻訳される言語． ・例 Go，C，C#，など． インタプリタ型言語 ・インタプリタ型言語とは インタプリタという言語プロセッサによって，インタプリタ方式で翻訳される言語をインタプリタ型言語という． ・例 PHP，Ruby，JavaScript，Python，など． 中間型言語 ・中間型言語とは Java仮想マシンによって，中間言語方式で翻訳される． 参考：https://kanda-it-school-kensyu.com/java-basic-intro-contents/jbi_ch01/jbi_0102/ ・例 Java，Scala，Groovy，Kotlin，など． 02. 言語プロセッサによる翻訳方式 アセンブラ方式 ・アセンブラ方式とは アセンブリ型言語を機械語に翻訳する方法のこと． コンパイラ方式 ・コンパイラ方式とは コンパイラ型言語を機械語に翻訳する方法のこと． インタプリタ方式 ・インタプリタ方式とは インタプリタ型言語を機械語に翻訳する方法のこと． 02-02. アセンブリ型言語の機械語翻訳 02-03. コンパイラ型言語の機械語翻訳 コンパイラ方式 ・機械語翻訳と実行 ソースコードをバイナリ形式のコードに翻訳した後，CPU上で命令が実行される．命令の結果はメモリに保管される． 参考： http://samuiui.com/2019/02/24/google-colaboratory%E3%81%A7python%E5%85%A5%E9%96%80/ https://qiita.com/tk_01/items/a84408b5436ec97bfbe1#%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%8C%E5%8B%95%E3%81%8F%E4%BB%95%E7%B5%84%E3%81%BF ・コンパイラによるビルド コンパイルによって，ソースコードは機械語からなるバイナリ形式のコードに変換される．その後，バイナリ形式のコードはリンクされ．exeファイルとなる．この一連のプロセスを『ビルド』という．また，ビルドによって生成されたファイルを『アーティファクト（成果物）』という． 仕組み （１）Lexical analysis（字句解析） ソースコードの文字列を言語の最小単位（トークン）の列に分解． 以下に，トークンの分類方法の例を示す． （２）Syntax analysis（構文解析） トークンの列をツリー構造に変換． （３）Semantics analysis（意味解析） ツリー構造を基に，ソースコードに論理的な誤りがないか解析． （４）Code optimization（コード最適化） ソースコードの冗長な部分を削除または編集．機械語をより短くするこができる． （５）Code generation（コード生成） 最適化されたコードをバイナリ形式のコードに変換． （６）リンク バイナリ形式のコードをリンクする． （７）命令の実行 リンクされたバイナリ形式のコードを基に，命令が実行される． makeによるビルド （１）パッケージをインストール # パッケージを公式からインストールと解答 $ wget $ tar # ビルド用ディレクトリの作成． $ mkdir build $ cd build （２）ビルドのルールを定義 configureファイルを元に，ルールが定義されたMakefileを作成する． # configureへのパスに注意． $ ../configure --prefix=\"\" （３）ビルド （コンパイル＋リンク） パッケージのソースコードからexeファイルをビルドする． # -j で使用するコア数を宣言し，処理の速度を上げられる． $ make -j4 任意で，exeファイルのテストを行える． $ make check （４）exeファイルの実行 生成されたソースコードのファイルを，指定したディレクトリにコピー． # installと命令するが，実際はコピー．sudoを付ける． $ sudo make install 元となったソースコードやバイナリ形式のコードを削除． $ make clean 02-04. インタプリタ型言語の機械語翻訳 インタプリタ方式 ・機械語翻訳と実行 ソースコードをバイナリ形式のコードに一行ずつ変換し，その都度，CPU上で命令が実行される．命令の結果はメモリに保管される． 参考： http://samuiui.com/2019/02/24/google-colaboratory%E3%81%A7python%E5%85%A5%E9%96%80/ https://qiita.com/tk_01/items/a84408b5436ec97bfbe1#%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%81%8C%E5%8B%95%E3%81%8F%E4%BB%95%E7%B5%84%E3%81%BF コマンドラインでそのまま入力し，機械語翻訳と実行を行うことができる． #=========== # PHPの場合 #=========== # PHPなので，処理終わりにセミコロンが必要 $ php -r \"\" # Hello Worldを出力 $ php -r \"echo \"Hello World\";\" # phpinfoを出力 $ php -r \"phpinfo();\" # （おまけ）phpinfoの出力をテキストファイルに保存 $ php -r \"phpinfo();\" > phpinfo.txt # php.iniの読み込み状況を出力 $ php --ini 仕組み （１）Lexical analysis（字句解析） ソースコードの文字列を言語の最小単位（トークン）の列に分解． 以下に，トークンの分類方法の例を示す． （２）Syntax analysis（構文解析） トークンの列をツリー構造に変換．ソースコードから構造体を構築することを構文解析といい，htmlを構文解析してDOMツリーを構築する処理とは別物なので注意． （３）Semantics analysis（意味解析） ツリー構造を基に，ソースコードに論理的な誤りがないか解析． （４）命令の実行 意味解析の結果を基に，命令が実行される． （５）１から４をコード行ごとに繰り返す 02-05. 中間型言語の機械語翻訳 中間言語方式 ・中間言語方式の機械語翻訳の流れ JavaまたはJVM型言語のソースコードを，Javaバイトコードを含むクラスファイルに変換する． JVM：Java Virtual Machine内で，インタプリタによって，クラスデータを機械語に翻訳する． 結果的に，OS（制御プログラム？）に依存せずに，命令を実行できる．（C言語） ・C言語とJavaのOSへの依存度比較 JVM言語 ソースコード "},"public/software/software_basic_language_processor_process_mode.html":{"url":"public/software/software_basic_language_processor_process_mode.html","title":"📖 ︎言語別の処理方式","keywords":"","body":"言語別の処理方式 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. エントリポイント エントリポイントとは プログラムを実行する時の起点となるファイル／関数のこと．エントリポイントのファイル／関数を起点として，そのプログラムの全てのファイルの処理が実行される． 参考：https://en.wikipedia.org/wiki/Entry_point 動的型付け型言語のエントリポイント ・特徴 動的型付け言語では，エントリポイントの定義方法が強制されず，指定したファイルの先頭行がエントリポイントになる．ただし慣例として，『index』という名前のファイルをエントリポイントとする言語が多い． ・PHPの場合 慣例としてindex.phpファイルをエントリポイントとすることになっている． 静的型付け型言語のエントリポイント ・特徴 静的型付け言語では，エントリポイントの定義方法が強制される．『main』という名前の関数でエントリポイントを定義させる言語が多い． ・Javaの場合 修飾子が『public static』，返却値型が『void』，引数名が『args』，引数型が『String[]』であるmain関数が，自動的にエントリポイントになる． import java.util.*; public class Main { // エントリポイントとなる関数 public static void main(String[] args) { // 他の全ファイルに繋がる処理 } } ・Goの場合 パッケージ名が『main』である`mainが，自動的にエントリポイントとなる． package main // エントリポイントとなる関数 func main() { // 他の全ファイルに繋がる処理 } 02. 並行処理（Concurrent processing） 並行処理とは プロセスでシングルスレッドが実行されている場合に，複数の処理を『独立的』に実行すること． 参考： https://techdifferences.com/difference-between-concurrency-and-parallelism.html https://moz.hatenablog.jp/entry/2018/04/10/175643 https://zenn.dev/hsaki/books/golang-concurrency/viewer/term 言語別の並行処理 03. 並列処理（Parallel processing） 並列処理とは プロセスでマルチスレッドが実行されている場合に，各スレッド上で複数の処理を『同時発生的』に実行すること．開始は同時であるが，終了はバラバラになる． 参考： https://techdifferences.com/difference-between-concurrency-and-parallelism.html https://moz.hatenablog.jp/entry/2018/04/10/175643 言語別の並列処理 ・PHPの場合 parallelライブラリを使用する． 参考： https://github.com/krakjoe/parallel https://qiita.com/WhiteGrouse/items/6fb906386b8fbabd6405 ・JavaScriptの場合 WebWorkerを使用する． 参考：https://developer.mozilla.org/ja/docs/Web/API/Web_Workers_API/Using_web_workers ・Goの場合 Goroutinesを使用する．ただし，実行環境によっては並列処理にならずに，並行処理になってしまうことがある．それが理由かどうかはわからないが，Goのドキュメントでは，Goroutinesはconcurrencyの項目に記載されている． 参考： https://medium.com/sprocket-inc/goroutine-concurrent-and-parallel-programming-669eaae55e73 https://golang.org/doc/effective_go#concurrency https://qiita.com/taigamikami/items/fc798cdd6a4eaf9a7d5e 04. 同期処理（Synchronous processing） 同期処理とは 完了を待ってから後続の処理が始まるような処理のこと． 05. 非同期処理（Asynchronous processing） 非同期処理とは 完了を待たずに後続の処理が始まり，後続の処理と同時に実行されるような処理のこと． 参考： https://qiita.com/kiyodori/items/da434d169755cbb20447 https://qiita.com/klme_u6/items/ea155f82cbe44d6f5d88 非同期処理の結果を用いる後続処理 ・後続処理の定義 後続の全処理が非同期処理と無関係であれば，そのままで問題は起こらない．しかし，後続の処理に非同期処理の結果を使用するものが含まれている場合，この処理だけは非同期処理の後に実行されるように定義する必要がある．言語別に，非同期処理の成否を管理し，後続する処理を定義できる機能が提供されている． ・JavaScriptの場合 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_js_logic_asynchronous_process.html "},"public/software/software_basic_language_processor_machine_language_and_radix.html":{"url":"public/software/software_basic_language_processor_machine_language_and_radix.html","title":"📖 ︎機械語と進数","keywords":"","body":"機械語と進数 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 機械語と2進数の関係 機械語とは あらゆる情報を『0』と『1』の2進数を機械語として，CPUに対して，命令が実行される． 様々な進数とbitの関係 しかし，人間が扱う上では8進数あるいは16進数に変換して表現することが適している．2進数1ケタが『1 bit』と定義されている．8進数の1ケタは2進数の3ケタ（＝3 bit）に相当し，16進数の1ケタは2進数の4ケタ（4 bit）に相当する． なぜ８bitを1Byteとするのか？（半角英数字とbitの関係） ８bitを一区切りとして，１Byteと表現する．これは，半角英数字一文字が８bitのデータ量を持つからである． Byte単位 1000 Byte = 1k Byte 一般的なCPUが扱える情報の種数 CPUでは，各データは2進法によって区別されている．CPUは4 ，8，16，32-bitバージョンと進歩し，2008年の後半からは 64-bitバージョンのCPUが普及し始めた．1-bitは2種類の情報を表すことができるため，32-bitのCPUでは2^32，64-bitでは2^64の種類の情報を扱う事ができる． 01-02. 機械語命令の種類 設定命令 ・実行アドレスをレジスタに設定する場合 ・実行アドレスが指す語の内容をレジスタに設定する場合 ・レジスタの内容を実行アドレスに格納する場合 シフト命令 計算命令 レジスタから取り出した値を別の値と足し，その結果を元のレジスタに設定すること． 論理演算命令 01-03. シフト命令 論理左シフト 最上位に正負を表す『符号bit』を設定せずに，シフトを行う． ２進数の場合… 左に１bitシフトすると『2倍』 左に１bitシフトし，元の値を足すを『3倍』 左に２bitシフトすると『4倍』 左に２bitシフトし，元の値を足すと『5倍』 左に２bitシフトし，元の値を足して『5倍』．さらに２bitシフトすると『10倍』 左に３bitシフトすると『8倍』 ・正の数の場合 ＊例＊ 00011100 ・負の数の場合 ＊例＊ 11100100 論理右シフト 最上位に正負を表す『符号bit』を設定せずに，シフトを行う． ２進数の場合… 右に１bitシフトすると『1/2』 右に２bitシフトすると『1/4』 右に３bitシフトすると『1/8』 ・正の数の場合 ＊例＊ 00011100 ・負の数の場合（計算はできない） ＊例＊ 11100100 負の数で論理右シフトを行う場合，間違った計算が行われてしまう．こういう場合，算術シフトが用いられる． 算術左シフト 最上位に正負を表す『符号bit』を設定し，シフトを行う． ２進数の場合… 左に１bitシフトすると『2倍』 左に１bitシフトし，元の値を足すを『3倍』 左に２bitシフトすると『4倍』 左に２bitシフトし，元の値を足すと『5倍』 左に２bitシフトし，元の値を足して『5倍』．さらに２bitシフトすると『10倍』 左に３bitシフトすると『8倍』 ・正の数の場合 ＊例＊ 00011100 ・負の数の場合 ＊例＊ 00011100 算術右シフト ２進数の場合… 最上位に正負を表す『符号bit』を設定し，シフトを行う． 右に１bitシフトすると『1/2』 右に２bitシフトすると『1/4』 右に３bitシフトすると『1/8』 ・正の数の場合 ＊例＊ 00011100 ・負の数の場合 01-04. 機械語命令の実行手順 実行手順 16進数が2進数に変換され，記号へ値が割り当てられる．（ビット分割） 記号の値を基に，実行アドレスの計算方法が選択され，実行される．（実行アドレスの計算） 実行アドレスを基に，機械語命令が実行され，値がレジスタやメモリに書き留められる．（機械語命令のトレース） （１）ビット分割 ＊例＊ 命令：20B3h ・16進数の2進数への変換 ・記号への値の割り当て （２）実効アドレスの計算 ・実行アドレスの計算方法の選択 『X＝2』，『I = 1』より，表の網掛けの計算式を選択． ・実効アドレスの計算の実行 ここに，レジスタ番号と内容の表を張る． (実効アドレス) = [adr + [X] ] = [1000h + [レジスタ2] ]（※配列のように，レジスタ2の値を参照） = [1000h + 0002h] = [1002h] = 1003h （３）機械語命令のトレース 01-05. 構文解析における数式の認識方法 逆ポーランド表記法（後置表記法） 演算子（＋，－，×，÷など）を被演算子（数値や変数，また計算の結果）の後ろに書くことで数式を表現する方法．ちなみに，人間が使っている表記方法は，『中置記法』という． ＊例＊ Y = ( A + B ) × ( C － ( D ÷ E ) ) 括弧は先に計算するので塊と見なす． ( A + B ) ⇒ AB+ 括弧は先に計算するので塊と見なす． ( D ÷ E ) ⇒ DE ÷ 括弧は先に計算するので塊と見なす． ( AB + ) × ( C － DE ÷ ) ⇒ ( AB + ) ( CDE ÷ －) × 括弧を外しても，塊はそのまま． 　　( AB + ) ( CDE ÷ －) × ⇒ AB+CDE÷－× 左辺と右辺をそれぞれ塊と見なす． 　　Y = AB+CDE÷－× ⇒ YAB+CDE÷－×= 01-06. CPUにおける小数の処理方法 固定小数点数 『この位置に小数点がある』な前提で数字を扱うことによって，小数点を含む数値を表現する方法． CPUは，数値に対し，特定の位置に小数点を打つ． 浮動小数点数 指数表記を用いることによって，小数点を含む数値を表現する方法． ・正規化した数式から浮動小数点数への変換 ・浮動小数点数から正規化した数式への変換 指数部と仮数部を調節して，できるだけ仮数部の上位桁に0が入らないようにして，誤差を少なくすること．例えば，ある計算の結果が0.012345×10^－3だった場合，仮数部を0.1～1の範囲に収めるために0.12345×10^－4に変更する． 01-07. 誤差 『誤差』：実際の数値とCPUが表現できる数値の間に生じるズレのこと． 無限小数 桁溢れ誤差 ＊例＊ 初代ドラクエ 初代のドラゴンクエストの経験値の上限は「65535」だった．これは，経験値が16bit（2 Byte）で表されており，桁溢れが起きることを防ぐために65535以上は計算しないようになっていた． 情報落ち 打切り誤差 円周率は，途中で計算を打ち切る． 桁落ち 丸め誤差 02. N 進数 ➔ 10進数（重み掛けを行う） 16進数 ➔ 10進数 ・整数 ＊例＊『CA125』 『(16^0 × 5) + (16^1 × 2) + (16^2 × 1) + (16^3 × A) + (16^4 × C) 』というように，下の位から，順に16^Nをかけていく．（AとCは，10進数に変換して『10』と『12』） (1×5) + (16×2) + (256×1) + (4096×10) + (65536×12) ＝ 827685 ・少数 2進数 ➔ 10進数 ・整数 『1101101』 『(2^0 × 1) + (2^1 × 0) + (2^2 × 1) + (2^3 × 1) + (2^4 × 0) + (2^5 × 1) + (2^6 × 1)』というように，下の位から，順に2^Nをかけていく． ・少数 02-02. 10進数 ➔ N 進数（Nで割り続ける） 10進数 ➔ 16進数 ・整数 ＊例＊『27』 27を16で割り続ける． 16進数で10～15は，A～Fで表記されるため，11をBで表記． 余りを並べ，答えは『1B』 ・少数 ＊例＊『0.1015625』 1.『0.1015625』に16をかけ，整数部分を取り出す．（0.1015625 × 16 = 1.625．『1』を取り出し，16進数に変換して『1』） 2．計算結果の少数部分に16をさらにかける．少数部分が0になるまで，これを繰り返す．（0.625 × 16 = 10.0より，『10』を取り出し，16進数に変換して『A』） 3．少数部分が0になったので，取り出した数を順に並べ，答えは『0.1A』 10進数 ➔ 2進数 ・整数 ＊例＊『109』 ・少数 02-03. X 進数 ➔ 10進数 ➔ Y 進数 一度，10進数に変換してから，任意の進数に変換する． 16進数 ➔ 2進数 ・整数 ＊例＊『20B3』 2，0，B，3を10進数に変換して，『(16^0 × 3) + (16^1 × 11) + (16^2 × 0) + (16^3 × 2) = 8371』 10と15を2進数に変換して，『0010』，『0000』，『1011』，『0011』 よって，AFは10進法に変換して『0010000010110011』 02-04. X 進数 ➔ 10 進数 ➔ Y 進数 ➔ 10 進数 16進数 ➔ 2進数 ・少数 ＊例＊ 2A.4C 整数部分の2Aを10進数に変換して， 42を2進数に変換して，『101010』．また，余り計算の時，余り１を2^Nに直しておく． 整数の場合，下位の桁から，『(2^0 × 0) + (2^1 × 1) + (2^2 × 0) + (2^3 × 1) + (2^4 × 0) + (2^5 × 1) + (2^6 × 0) + (2^7 × 0) + (2^8 × 0) 』 =『2^5＋2^3＋2^1』 （※16進数からの変換の場合，101010は，00101010として扱うことに注意） 76を2進数に変換して，『1001100』．また，余り計算の時，余り１を2^Nに直しておく． 少数部分の場合，上位の桁から，『(2^－1 × 0) + (2^－2 × 1) + (2^－3 × 0) + (2^－4 × 0) + (2^－5 × 1) + (2^－6 × 1) + (2^－7 × 0) + (2^－8 × 0) 』 =『 2^－2＋2^－5＋2^－6 』 （※16進数からの変換の場合，1001100は，01001100として扱うことに注意） したがって，『2^5＋2^3＋2^1＋2^－2＋2^－5＋2^－6』 03. 論理回路 論理式 以下のベン図では，集合Aと集合Bは入力が『1』の場合，外側は入力が『0』の場合を表している．演算方法を思い出すときには，ベン図を思い出せ． 否定回路（NOT回路），NOT演算，ベン図 丸い記号が否定を表す． 論理積回路（AND回路），AND演算，ベン図 ２つのbitを比較して，どちらも『1』なら『1』を出力． 否定論理積回路（NAND回路），NAND演算，ベン図 ２つのbitを比較して，どちらも『1』なら『0』を出力．ベン図では両方が『1』以外の場合を指しているが，回路の出力をうまく説明できない…． 論理和回路（OR回路），OR演算，ベン図 ２つのbitを比較して，どちらかが『1』なら『1』を出力． 排他的論理和回路（EOR回路／XOR回路），EOR演算，ベン図 ２つのbitを比較して，どちらかだけが『1』なら『1』を出力． 否定論理和回路（NOR回路），NOR演算，ベン図 ２つのbitを比較して，どちらも『0』なら『1』を出力． フリップフロップ回路 わかりやすい動画解説：https://www.youtube.com/watch?v=4vAGaWyGanU SRAMの電子回路に用いられている（6章を参照）．Set側に初期値『1』が入力される．入力を『0』に変えても，両方の出力結果は変わらず，安定している． Reset側に『1』を入力すると，両方の出力結果は変化する． 03-02. 論理演算命令 論理積 ＊例題＊ 16進数の『F』は，2進数で『0000 0000 0000 1111』で表される．よって，000Fを用いてAND演算した場合，下位4桁を変化させずに取り出すことができる． 1100 1101 1111 1000 0000 0000 0000 1111 ーーーーーーーーーーー 0000 0000 0000 1000 引用：https://ameblo.jp/kou05/entry-10883110086.html ＊例題＊ 16進数の『7F』は，2進数で『0000 0000 0111 1111』で表される．よって，7Fを用いてAND演算した場合，下位7桁を変化させずに取り出すことができる． 1100 1101 1111 1000 0000 0000 0111 1111 ーーーーーーーーーーー 0000 0000 0111 1000 ＊例題＊ 否定論理積 論理和 排他的論理和 否定論理和 ＊例題＊ XとYの否定論理積 X NAND Yは，NOT(X AND Y)として定義される．X OR YをNANDだけを使って表した論理式はどれか． ⇒X＝0，Y＝0のときにX OR Yが『0』になることから，『0』になる選択肢を探す． ・((X NAND Y) NAND X) NAND Y ((0 NAND 0)NAND 0)NAND 0 ＝(1 NAND 0) NAND 0 ＝1 NAND 0 ＝1 ・(X NAND X) NAND (Y NAND Y) (0 NAND 0)NAND(0 NAND 0) ＝1 NAND 1 ＝0 ・(X NAND Y) NAND (X NAND Y) (0 NAND 0)NAND(0 NAND 0) ＝1 NAND 1 ＝0 ・X NAND (Y NAND (X NAND Y)) 0 NAND(0 NAND(0 NAND 0)) ＝0 NAND (0 NAND 1) ＝0 NAND 1 ＝1 "},"public/software/software_middleware_web_nginx.html":{"url":"public/software/software_middleware_web_nginx.html","title":"📖 ︎Nginx","keywords":"","body":"Nginx はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Tips コマンドリファレンス ・nginx 参考：https://httpd.apache.org/docs/trunk/ja/programs/apachectl.html よく使うコマンド ・起動／停止 $ sudo systemctl start nginx $ sudo systemctl stop nginx ・設定ファイルのバリデーション $ sudo service nginx configtest # もしくはこちら $ sudo nginx -t ・設定ファイルの反映と安全な再起動 $ sudo systemctl reload nginx ・読み込まれた設定ファイルと設定値の一覧 読み込まれている全ての設定ファイル（includeディレクティブの対象も含む）の内容を展開して表示する． $ sudo nginx -T 02. 機能の種類 Webサーバ／コンテナのミドルウェアとして ・PHP-FPMとの組み合わせ 静的ファイルのリクエストが送信されてきた場合，Nginxはそのままレスポンスを返信する．動的ファイルのリクエストが送信されてきた場合，Nginxは，FastCGIプロトコルを介して，PHP-FPMにリクエストをリダイレクトする． # 設定ファイルのバリデーション $ php-fpm -t ＊実装例＊ #------------------------------------- # HTTPリクエスト #------------------------------------- server { listen 80; server_name example.com; root /var/www/example/public; index index.php index.html; include /etc/nginx/default/xxx.conf; #『/』で始まる全てのリクエストの場合 location / { try_files $uri $uri/ /index.php?$query_string; } #-------------------------------------------------- # FastCGIを用いたAppサーバ／コンテナへの転送，受信 # OSによって，fastcgi_paramsファイルの必要な設定が異なる #-------------------------------------------------- location ~ \\.php$ { # リダイレクト先のTCPソケット fastcgi_pass 127.0.0.1:9000; # もしくは，Unixソケット # fastcgi_pass unix:/run/php-fpm/www.sock; # リダイレクト先のURL（rootディレクティブ値+パスパラメータ） fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # 設定ファイルからデフォルト値を読み込む include fastcgi_params; } } ・/etc/nginx/fastcgi_paramsファイル アプリケーションで使用できる変数を定義する．nginx.confファイルによって読み込まれる．OSやそのバージョンによっては，変数のデフォルト値が書き換えられていることがある．実際にサーバ／コンテナ内に接続し，上書き設定が必要なものと不要なものを判断する必要がある．以下は，Debian 10のデフォルト値である． 参考：https://mogile.web.fc2.com/nginx_wiki/start/topics/examples/phpfcgi/ ＊実装例＊ #------------------------------------------------------- # OSによって，fastcgi_paramsファイルの必要な設定が異なる #------------------------------------------------------- fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; fastcgi_param DOCUMENT_ROOT $document_root; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param REQUEST_SCHEME $scheme; fastcgi_param HTTPS $https if_not_empty; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; # PHPだけで必要な設定 fastcgi_param REDIRECT_STATUS 200; ロードバランサ－のミドルウェアとして HTTPプロトコルで受信したリクエストを，HTTPSプロトコルに変換して転送する． ＊実装例＊ #------------------------------------- # HTTPリクエスト #------------------------------------- server { server_name example.com; listen 80; return 301 https://$host$request_uri; } #------------------------------------- # HTTPSリクエスト #------------------------------------- server { server_name example.com; listen 443 ssl http2; index index.php index.html; #------------------------------------- # SSL #------------------------------------- ssl on; ssl_certificate /etc/nginx/ssl/server.crt; ssl_certificate_key /etc/nginx/ssl/server.key; add_header Strict-Transport-Security \"max-age=86400\"; location / { proxy_pass http://app1; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Port $remote_port; } } リバースProxyのミドルウェアとして 前提として，ロードバランサ－から転送されたHTTPリクエストを受信するとする．静的コンテンツのリクエストは，リバースProxy（Nginx）でレスポンスを返信する．Webサーバは，必ずリバースProxyを経由して，動的リクエストを受信する． ＊実装例＊ #------------------------------------- # HTTPリクエスト #------------------------------------- server { server_name example.com; listen 80; return 301 https://$host$request_uri; #------------------------------------- # 静的ファイルであればNginxでレスポンス #------------------------------------- location ~ ^/(images|javascript|js|css|flash|media|static)/ { root /var/www/example/static; expires 30d; } #------------------------------------- # 動的ファイルであればWebサーバに転送 #------------------------------------- location / { proxy_pass http://127.0.0.1:8080; } } 03-01. Core機能 ブロック ・events 参考：https://nginx.org/en/docs/ngx_core_module.html#events ＊実装例＊ events { worker_connections 1024; } ディレクティブ ・user 本設定ファイルの実行ユーザとグループを設定する．グループ名を入力しなかった場合，ユーザ名と同じものが自動的に設定される． user www www; ・error_log error_log logs/error.log; ・include 共通化された設定ファイルを読み込む．アスタリスクによるワイルドカードに対応している． include /etc/nginx/conf.d/*.conf; ・pid pid logs/nginx.pid; ・worker_connections workerプロセスが同時に処理可能なコネクションの最大数を設定する． 参考：https://nginx.org/en/docs/ngx_core_module.html#worker_connections worker_connections 1024; ・worker_processes worker_processes 5; ・worker_rlimit_nofile worker_rlimit_nofile 8192; 設定ファイルの種類 ・/etc/nginx/conf.d/*.confファイル デフォルトの設定が定義されているいくつかのファイル．基本的には読み込むようにする．ただし，nginx.confファイルの設定が上書きされてしまわないかを注意する． include /etc/nginx/conf.d/*.conf; ・/etc/nginx/mime.typesファイル リクエストのContent-TypeのMIMEタイプとファイル拡張子の間の対応関係が定義されているファイル． include /etc/nginx/mime.types; ・/usr/share/nginx/modules/*.confファイル モジュールの読み込み処理が定義されているファイル． include /usr/share/nginx/modules/*.conf; 例えば，mod-http-image-filter.confファイルの内容は以下の通り． load_module \"/usr/lib64/nginx/modules/ngx_http_image_filter_module.so\"; 03-02. http_core_module ブロック ・http 全てのWebサーバに共通する処理を設定する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#http http { # Nginxのバージョンを表示するかどうか server_tokens off; # MIMEタイプを設定 include /etc/nginx/mime.types; default_type application/octet-stream; # ログのフォーマット log_format main \"$remote_addr - $remote_user [$time_local] \"$request\" \" \"$status $body_bytes_sent \"$http_referer\" \" \"\"$http_user_agent\" \"$http_x_forwarded_for\"\"; access_log /var/log/nginx/access.log main; # sendfileシステムコールを使用するかどうか sendfile on; # ヘッダーとファイルをまとめてレスポンスするかどうか tcp_nopush on; # keepaliveを維持する時間 keepalive_timeout 65; default_type application/octet-stream; include /etc/nginx/mime.types; include /etc/nginx/conf.d/*.conf; server { # ～ 中略 ～ } } ・location 個別のWebサーバ／コンテナにおける特定のURLの処理を設定する． https://nginx.org/en/docs/http/ngx_http_core_module.html#location ＊実装例＊ 各設定の優先順位に沿った以下の順番で実装した方が良い． # 1. ドキュメントルートを指定したリクエストの場合 location = / { } # 2. 『/images/』で始まるリクエストの場合 location ^~ /images/ { } # 3と4. 末尾が、『gif，jpg，jpegの形式』 のリクエストの場合 # バックスラッシュでドットをエスケープし，任意の文字ではなく『ドット文字』として認識できるようにする． location ~* \\.(gif|jpg|jpeg)$ { } # 5-1. 『/docs/』で始まる全てのリクエストの場合 location /docs/ { } # 5-2. 『/』で始まる全てのリクエストの場合 location / { } ルートの一致条件は，以下の通りである． 優先順位 prefix ルートの一致条件 ルート例 1 = 指定したルートに一致する場合． http://example.com/ 2 ^~ 指定したルートで始まる場合． http://example.com/images/foo.gif 3 ~ 正規表現（大文字・小文字を区別する）． http://example.com/images/FOO.jpg 4 ~* 正規表現（大文字・小文字を区別しない）． http://example.com/images/foo.jpg 5 なし 指定したルートで始まる場合． ・http://example.com/foo.html・http://example.com/docs/foo.html ・server 個別のWebサーバ／コンテナの処理を設定する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#server ＊実装例＊ server { # 80番ポートで受信 listen 80; # ホスト名 server_name example.com; root /var/www/example; index index.php index.html; location / { try_files $uri $uri/ /index.php?$query_string; } location ~ \\.php$ { fastcgi_pass unix:/run/php-fpm/www.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } ・リダイレクトとリライトの違い 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_api_restful.html ディレクティブ ・default_type Content-Typeヘッダーの値がmime.typesファイルにないMIME typeであった場合に適用するMIME typeを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#default_type ＊実装例＊ # application/octet-stream：任意のMIME type（指定なし）と見なして送信 default_type application/octet-stream ・listen HTTPリクエストを80番ポートでリクエストを受信する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#listen ＊実装例＊ listen 80; HTTPSリクエストを443番ポートでリクエストを受信する． ＊実装例＊ listen 443 ssl; ・sendfile クライアントへのレスポンス時に，ファイル送信のためにLinuxのsendfileシステムコールを使用するかどうかを設定する．ファイル返信処理をOS内で行うため，処理が速くなる．使用しない場合，Nginxがレスポンス時に自身でファイル返信処理を行う． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#sendfile ＊実装例＊ sendfile on; ・server_name パブリックIPアドレスに紐付くドメイン名を設定する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#server_name server_name example.com; パブリックIPアドレスを直接記述してもよい． server_name 192.168.0.0; ・ssl NginxでHTTPSプロトコルを受信する場合，sslプロトコルを有効にする必要がある． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#ssl ＊実装例＊ ssl on; ・ssl_certificate PEM証明書のパスを設定する． ＊実装例＊ ssl_certificate /etc/nginx/ssl/server.crt; ・ssl_certificate_key PEM秘密鍵のパスを設定する． ＊実装例＊ ssl_certificate_key /etc/nginx/ssl/server.key; ・tcp_nopush 上述のLinuxのsendfileシステムコールを使用する場合に，適用できる．クライアントへのレスポンス時，ヘッダーとファイルを，一つのパケットにまとめて返信するかどうかを設定する． ＊実装例＊ tcp_nopush on; ・try_files 指定されたパスのファイルを順に探してアクセスする．また，最後のパラメータで内部リダイレクトする．最後のパラメータでは，異なるパスまたはステータスコードを指定できる．もし，nginxとアプリケーションを別々のサーバ／コンテナで稼働させている場合，try_filesディレクティブがファイル探索の対象とする場所は，あくまでnginxの稼働するサーバ／コンテナ内になることに注意する．内部リダイレクトによって，nginx内でリクエストが再処理される．異なるパスに内部リダイレクトしていた場合は，パスに合ったlocationブロックで改めて処理される．内部リダイレクトは，URLを書き換えてリダイレクトせずに処理を続行する『リライト』とは異なることに注意する． 参考：https://nginx.org/en/docs/http/ngx_http_core_module.html#try_files location / { try_files file ... uri; } location / { try_files file ... =code; } ＊実装例＊ location / { # 1. 『/foo.html』のパスでサーバ／コンテナからファイルをレスポンス # 2. 『/foo.html/』のパスでサーバ／コンテナからファイルをレスポンス # 3. 『/index.php?query_string』のパスで内部リダイレクト try_files $uri $uri/ /index.php?query_string; } # 内部リダイレクト後は，『/index.php?foo=bar』のため，以下で処理される． location ~ \\.php$ { # php-fpmに転送される． fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } ヘルスチェックの受信 ・nginxによるレスポンス Webサーバ／コンテナのみヘルスチェックを受信する．ヘルスチェック用のserverブロックで，gifファイルのレスポンスを返信するようにlocationブロックを定義する．Nginxでアクセスログを出力する必要はないため，locationブロックではaccess_logを無効化する． ＊実装例＊ server { listen 80 default_server; listen [::]:80 default_server; root /var/www/example; index index.php index.html; location /healthcheck { empty_gif; access_log off; break; } } ・アプリケーションによるレスポンス Webサーバ／コンテナとアプリケーションの両方でヘルスチェックを受信する．アプリケーション側に200ステータスのレスポンスを返信するエンドポイントを実装したうえで，ヘルスチェック用のserverブロックで，アプリケーションにルーティングするようにlocationブロックを定義する．Nginxでアクセスログを出力する必要はないため，locationブロックではaccess_logを無効化する． ＊実装例＊ server { listen 80 default_server; listen [::]:80 default_server; root /var/www/example; index index.php index.html; location /healthcheck { try_files $uri $uri/ /index.php?$query_string; access_log off; } } 03-03. http_index_module ディレクティブ ・index リクエストのURLがトレイリングスラッシュで終わる全ての場合に，指定されたファイルをURLの末尾に追加する． 参考：https://nginx.org/en/docs/http/ngx_http_index_module.html ＊実装例＊ index index.php; 03-04. http_headers_module ディレクティブ ・add_header レスポンスヘッダーを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_headers_module.html#add_header ＊実装例＊ # Referrer-Policyヘッダーに値を設定する add_header Referrer-Policy \"no-referrer-when-downgrade\"; 03-05. http_upstream_module ブロック ・upstream 参考：https://nginx.org/en/docs/http/ngx_http_upstream_module.html#upstream ＊実装例＊ upstream big_server_com { server 127.0.0.3:8000 weight=5; server 127.0.0.3:8001 weight=5; server 192.168.0.1:8000; server 192.168.0.1:8001; } 03-06. http_fast_cgi_module ディレクティブ ・fastcgi_params FastCGIプロトコルを使用してAppサーバ／コンテナにリクエストを転送する場合に，転送先で使用する変数とその値を設定する． 参考：https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_param ＊実装例＊ fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; ・fastcgi_pass FastCGIプロトコルを使用してAppサーバ／コンテナにリクエストを転送する場合に，転送先のアドレスとポートを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_pass ＊実装例＊ fastcgi_pass 127.0.0.1:9000; 03-07. http_proxy_module ディレクティブ ・proxy_pass HTTPプロトコルを使用してAppサーバ／コンテナにリクエストを転送する場合に，転送先のアドレスとポートを設定する． 参考：https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass ＊実装例＊ proxy_pass http://127.0.0.1:8080/; "},"public/software/software_middleware_web_apache.html":{"url":"public/software/software_middleware_web_apache.html","title":"📖 ︎Apache","keywords":"","body":"Apache はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コマンド リファレンス ・httpd 参考：https://httpd.apache.org/docs/trunk/ja/programs/httpd.html ・apachectl 参考：https://httpd.apache.org/docs/trunk/ja/programs/apachectl.html コマンド ・ディレクティブの実装場所の一覧 特定のディレクティブを実装するべき設定ファイルを一覧で表示する． $ sudo httpd -L ・設定ファイルのバリデーション # systemctlコマンドでは実行不可能 $ sudo service httpd configtest $ sudo apachectl configtest $ sudo apachectl -t ・コンパイル済みモジュールの一覧 コンパイル済みのモジュールを一覧で表示する．表示されているからといって，読み込まれているとは限らない． $ sudo httpd -l ・読み込み済みモジュールの一覧 コンパイル済みのモジュールのうちで，実際に読み込まれているモジュールを表示する． $ sudo httpd -M ・読み込み済みconfファイルの一覧 読み込まれたconfファイルを一覧で表示する．この結果から，使われていないconfファイルもを検出できる． $ sudo httpd -t -D DUMP_CONFIG 2>/dev/null | grep \"# In\" | awk \"{print $4}\" ・読み込まれるVirtualHost設定の一覧 $ sudo httpd -S ・強制的な起動／停止／再起動 # 起動 $ sudo systemctl start httpd # 停止 $ sudo systemctl stop httpd # 再起動 $ sudo systemctl restart httpd ・安全な再起動 Apacheを段階的に再起動する．安全に再起動できる． $ sudo apachectl graceful 02. 機能の種類 Webサーバのミドルウェアとして Appサーバのミドルウェアとして mod_phpモジュールを読み込むことによって，Appサーバのミドルウェアとしても機能させることができる． 03. Coreにおける設定ディレクティブ ServerRoot ・ServerRootとは 他の設定ディレクティブで，相対パスが設定されている場合に適用される．そのルートディレクトリを定義する． ＊実装例＊ 通常であれば，etcディレクトリ以下にconfファイルが配置される． ServerRoot /etc/httpd CentOSのEPELリポジトリ経由でインストールした場合，Apacheのインストール後に，optディレクトリ以下にconfファイルが設置される． ServerRoot /opt/rh/httpd24/root/etc/httpd VirtualHost ・VirtualHostとは ディレクティブを囲うディレクティブの一つ．特定のホスト名やIPアドレスにリクエストがあった時に実行するディレクティブを定義する．VirtualHostという名前の通り，1 つのサーバ上で，仮想的に複数のドメインを扱うような処理も定義できる．複数のVirtualHostを設定した場合，一つ目がデフォルト設定として認識される． ＊実装例＊ Listen 80 NameVirtualHost *:80 # Defaultサーバとして扱う． DocumentRoot /www/foo ServerName www.example.com DocumentRoot /www/bar ServerName www.example.org ・IPベースVirtualHost 各ドメインに異なるIPアドレスを割り振るバーチャルホスト． ・名前ベースVirtualHost 全てのドメインに同じIPアドレスを割り振るバーチャルホスト． DocumentRoot ・DocumentRootとは ドキュメントのルートディレクトリを定義する．ドキュメントルートに『index.html』というファイルを置くと，ファイル名を指定しなくとも，ルートディレクトリ内のindex.htmlファイルが，エントリーポイントとして自動的に認識されて表示される． ＊実装例＊ DocumentRoot /www/foo: ServerName www.example.com index.html以外の名前をエントリーポイントにする場合，ファイル名を指定する必要がある． ＊実装例＊ DocumentRoot /www/foo:/start-up.html ServerName www.example.com Directory ・Directoryとは ディレクティブを囲うディレクティブの一つ．指定したディレクトリ内にリクエストがあった時に実行するディレクティブを定義する． ＊実装例＊ DirectoryIndex index.php AllowOverride All User，Group ・Userとは httpdプロセスのユーザ名を定義する．httpdプロセスによって作成されたファイルの所有者名は，このディレクティブで定義したものになる． ＊実装例＊ User apache ・Groupとは httpdプロセスのグループ名を定義する．httpdプロセスによって作成されたファイルのグループ名は，このディレクティブで定義したものになる． ＊実装例＊ Group apache KeepAlive，MaxKeepAliveRequests，KeepAliveTimeout ・KeepAliveとは HTTPプロトコルのリクエストのクライアントに対して，セッションIDを付与するかどうか，を定義する． ＊実装例＊ KeepAlive On ・KeepAliveTimeout セッションIDを付与中のクライアントにおいて，再びリクエストを送信するまでに何秒間空いたら，セッションIDを破棄するか，を定義する． ＊実装例＊ # KeepAliveがOnの時のみ KeepAliveTimeout 5 ・MaxKeepAliveRequests セッションIDを付与中のクライアントにおいて，リクエストのファイルの最大数を定義する． ＊実装例＊ # KeepAliveがOnの時のみ MaxKeepAliveRequests 1000 04. mod_soにおける設定ディレクティブ LoadModule ・LoadModule モジュールを読み込み，設定ディレクティブを宣言できるようにする． ＊実装例＊ 相対パスを指定し，ServerRootを適用させる．これにより，httpdディレクトリのmodulesディレクトリが参照される． # ServerRoot が /opt/rh/httpd24/root/etc/httpd だとする． LoadModule dir_module modules/mod_dir.so 04-02. mod_dirにおける設定ディレクティブ DirectoryIndex ・DirectoryIndexとは Directoryディレクティブによってリクエストされたディレクトリのインデックスファイルをレスポンスする． ＊実装例＊ DirectoryIndex index.html index.php ＊実装例＊ DirectoryIndex index.html DirectoryIndex index.php AllowOverride ・AllowOverrideとは 別に用意した.htaccessファイルにて，有効化するディレクティブを定義する． ＊実装例＊ DirectoryIndex index.php AllowOverride All ・All 別に用意した.htaccessファイルにて，実装可能なディレクティブを全て有効化する． ＊実装例＊ AllowOverride All ・None 別に用意した.htaccessファイルにて，実装可能なディレクティブを全て無効化する． ＊実装例＊ AllowOverride None ・Indexes 別に用意した.htaccessファイルにて，DirectoryIndexディレクティブを有効化する． ＊実装例＊ AllowOverride Indexes 04-03. mod_writeにおける設定ディレクティブ RewriteCond ・RewriteCondとは 条件分岐と，それによる処理を定義する． ＊実装例＊ RewriteCond %変数名 条件 ＊実装例＊ RewriteCond %{HTTP:X-Forwarded-Port} !^443$ RewriteRule ・リダイレクトとリライトの違い 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_api_restful.html ・RewriteRuleとは 条件分岐による処理を定義する． RewriteRule URL書換＆転送の記述 ＊実装例＊ リクエストをHTTPSプロトコルに変換して，リダイレクトする． RewriteRule ^(.*)?$ https://%{HTTP_HOST}$1 [R=301,L] 04-04. mod_setenvifにおける設定ディレクティブ SetEnvIf ・SetEnvIfとは 条件分岐と環境変数の設定を定義する． # クエリパラメータが以下の拡張子の場合に， SetEnvIf Request_URI \"\\.(gif|jpe?g|png|js|css)$\" object-is-ignore ・nolog ログを出力しない場合を設定できる． 04-05. mod_log_configにおける設定ディレクティブ LogFormat ・LogFormatとは アクセスログファイルの書式を定義する． ・アクセスログ形式と出力内容 アクセスログの出力先ログファイルとフォーマットを合わせて定義する． ＊実装例＊ # common形式 CustomLog logs/access_log common LogFormat \"%h %l %u %t \"%r\" %>s %b\" common # combine形式 CustomLog logs/access_log combined LogFormat \"%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"\" combined 以下のようなログになる． # common形式 118.86.194.71 - - [17/Aug/2011:23:04:03 +0900] \"GET /home/name/category/web HTTP/1.1\" 200 11815 # combine形式 118.86.194.71 - - [17/Aug/2011:23:04:03 +0900] \"GET /home/name/category/web HTTP/1.1\" 200 11815 \"http://naoberry.com/home/name/\" \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.112 Safari/535.1\" ・ログの変数一覧 変数 値 例 %h リモートホスト 118.86.194.71 %l リモートログ名（基本”-“になる） - %u リモートユーザ（Basic認証のユーザ） - %t リクエスト受付時刻 [17/Aug/2011:23:04:03 +0900] %r リクエストの最初の行 GET /home/name/category/web HTTP/1.1 %s ステータス 200 %b レスポンスのバイト数 11815 %{Referer}i リファラ http://naoberry.com/home/name/ %{User-Agent}i ユーザエージェント Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.112 Safari/535.1 ErrorLog ・ErrorLogとは エラーログファイルの書式を定義する． ・エラーログ形式と出力内容 エラーログの出力先を定義する． ＊実装例＊ ErrorLog /var/log/httpd/error_log LogLevel ・LogLevelとは どのレベルまでログを出力するかを定義する． ログレベル 意味 設定の目安 emerg サーバが稼動できないほどの重大なエラー alert critよりも重大なエラー crit 重大なエラー error エラー warn 警告 本番環境 notice 通知メッセージ info サーバ情報 ステージング環境 debug デバック用の情報 04-06. mod_sslにおける設定ディレクティブ SSLCertificateFile ・SSLCertificateFileとは PKIにおける公開鍵の検証に必要なSSLサーバ証明書のディレクトリを定義する．本番環境ではAWSのACM証明書を用いることが多いため，基本的な用途としては，ローカル開発でのオレオレ証明書読み込みのために用いる． ＊実装例＊ SSLCertificateFile /etc/httpd/conf.d/server.crt SSLCertificateKeyFile ・SSLCertificateKeyFileとは PKIにおける公開鍵の検証に必要な秘密鍵のディレクトリを定義する． ＊実装例＊ SSLCertificateKeyFile /etc/httpd/conf.d/server.key 04-07. mod_headersにおける設定ディレクティブ Header ・Headerとは レスポンスヘッダーを定義する．set，append，add，unset，echoオプションを設定できる．標準では2xxと3xxのステータスコードのみで設定が適用される．オプションとして，alwaysを設定することで，全てのステータスコードでヘッダーを設定する． ・set レスポンスヘッダーを追加する． ＊実装例＊ Referrer-Policyヘッダーを追加し，値をno-referrer-when-downgradeとする．ちなみに，Chrome85以降のReferrer-Policyヘッダー初期値の仕様変更については，以下を参考にせよ． 参考：https://www.chromestatus.com/feature/6251880185331712 Header set Referrer-Policy \"no-referrer-when-downgrade\" Header set Referrer-Policy \"no-referrer-when-downgrade\" always ・unset レスポンスヘッダーを削除する． ＊実装例＊ Referrer-Policyヘッダーを削除する Header unset Referrer-Policy \"no-referrer-when-downgrade Header unset Referrer-Policy \"no-referrer-when-downgrade\" always 05. htaccess 影響範囲 ・ルートディレクトリの場合 全てのファイルに対して，ディレクティブが適用される． ・それ以外のディレクトリの場合 設置したディレクトリ以下の階層のファイルに対して適用される． "},"public/software/software_middleware_application_php_fpm.html":{"url":"public/software/software_middleware_application_php_fpm.html","title":"📖 ︎PHP-FPM","keywords":"","body":"PHP-FPM：PHP FastCGI Process Manager はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. CGIについて ・CGIとは FastCGI：Fast Common Gateway Interface ・FastCGIとは CGIプロトコルのパフォーマンスを向上させたプロトコル仕様のこと． PHP-FPM ・PHP-FPMとは PHPのために実装されたFastCGIのこと．WebサーバとPHPファイルの間でデータ通信を行う． 参考：https://developpaper.com/shared-cgi-fastcgi-and-php-fpm-1/ 02. 設定 /etc/php-fpm.d/www.confファイル ・/etc/php-fpm.d/www.confファイルとは PHP-FPMの設定を定義する．php.iniファイルによって読み込まれる．php.iniファイルよりも優先されるので，設定項目が重複している場合は，こちらを変更する．Nginxからリクエストを受信する場合，/etc/php-fpm.d/www.confファイルと/etc/nginx/nginx.confファイルの両方で，プロセスのユーザ名を『www-data』とする必要がある．『www-data』はApacheプロセスのユーザ名の標準値である． 参考：https://www.php.net/manual/ja/install.unix.nginx.php ＊実装例＊ [www] # プロセスのユーザ名，グループ名 user = www-data group = www-data # UNIXドメインソケットを使用するために，sockファイルを指定 listen = /var/run/php-fpm/php-fpm.sock # 127.0.0.1:9000 # UNIXドメインソケットを使用するために，プロセスのユーザ名を変更 listen.owner = www-data listen.group = www-data listen.mode = 0660 # コメントアウト推奨 ;listen.acl_users = apache,nginx # TCPソケットのIPアドレス listen.allowed_clients = 127.0.0.1 # アクセスログを標準出力に出力する． access.log = /dev/stdout pm = dynamic pm.max_children = 50 pm.start_servers = 5 pm.min_spare_servers = 5 pm.max_spare_servers = 35 # システムログファイルの場所 slowlog = /var/log/php-fpm/www-slow.log # エラーログファイルの場所 # 開発環境では，エラーログファイル（/var/log/php-fpm/www-error.log）に出力 php_admin_value[error_log] = /dev/stderr php_admin_flag[log_errors] = on # セッションの保存方法．ここではredisのキーとして保存（デフォルト値はfiles） php_value[session.save_handler] = redis # セッションの保存場所（デフォルト値は，/var/lib/php/session） php_value[session.save_path] = \"tcp://foo-redis.*****.ng.0001.apne1.cache.amazonaws.com:6379\" php_value[soap.wsdl_cache_dir] = /var/lib/php/wsdlcache ・Dockerで使用する場合 PHP-FPMベースイメージにはzz-docker.confファイルが組み込まれており，このファイルにはPHP-FPMの一部の設定が実装されている．これに後勝ちするために，ホスト側ではwww.confファイルとして定義しておき，コンテナ側にコピーする時はzzz-www.confファイルとする． 参考：https://kengotakimoto.com/docker-laravel/#toc8 COPY ./php-fpm.d/www.conf /usr/local/etc/php-fpm.d/zzz-www.conf 04. ログ ログの種類 ・NOTICE [01-Sep-2021 00:00:00] NOTICE: fpm is running, pid 1 ・WARNING [01-Sep-2021 00:00:00] WARNING: [pool www] server reached pm.max_children setting (5), consider raising it ・Fatal Error Fatal error: Allowed memory size of xxxxx bytes exhausted (tried to allocate 16 bytes) "},"public/software/software_middleware_database.html":{"url":"public/software/software_middleware_database.html","title":"📖 ︎データベース","keywords":"","body":"データベース はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. RDB（関係データベース）とは RDBMS（関係データベース管理システム）の仕組み RDBは，データ同士がテーブル状に関係を持つデータ格納形式である．データはストレージに保存する． RDBMSとRDBの種類 ・MariaDB MariaDBデータベースを管理できるRDBMS ・MySQL MySQLデータベースを管理できるRDBMS ・PostgreSQL PostgreSQLデータベースを管理できるRDBMS RDBSにおけるデータベースエンジン RDBMSがデータベースに対してデータのCRUDの処理を行うために必要なソフトウェアのこと． ・InnoDB 01-02. NoSQL（非関係データベース）とは NoSQLは，データ同士が関係を持たないデータ格納形式である．データをメインメモリに保存する． NoSQLの種類 01-04. テーブル設計 ER図：Entity Relation Diagram 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_php_object_orientation_analysis_design_programming.html 正規化 ・正規化とは 繰り返し要素のある表を『正規形』，その逆を『非正規形』という．非正規形の表から，他と連動するカラムを独立させ，正規形の表に変更することを『正規化』という． ・方法 ＊例＊ まず，主キーが受注Noと商品IDの2つであることを確認．これらの主キーは，複合主キーではないとする． エクセルで表を作成 エクセルで作られた以下の表があると仮定． 第一正規化（繰り返し要素の排除） レコードを1つずつに分割． 第二正規化（主キーの関数従属性を排除） 主キーと特定のカラムが連動する（関数従属性がある）場合，カラムを左表として独立させる．今回，主キーが2つあるので，まず受注Noから関数従属性を排除していく．受注Noと他3カラムが連動しており，左表として独立させる．主キーと連動していたカラムを除いたものを右表とする．また，主キーが重複するローを削除する． 次に，商品IDの関数従属性を排除していく．商品IDと他2カラムに関数従属性があり，左表として独立させる．主キーと連動していたカラムを除いたものを右表とする．また，主キーが重複するローを削除する．これで，主キーの関数従属性の排除は終了． 第三正規化（主キー以外のカラムの関数従属性を排除） 次に主キー以外のカラムの関係従属性を排除していく．上記で独立させた3つの表のうち，一番左の表で，顧客IDと顧客名に関数従属性があるので，顧客IDを新しい主キーに設定し，左表として独立させる．主キーと連動していたカラムを除いたものを右表とする． まとめ 主キーの関係従属性の排除によって，受注表，商品表，数量表に分割できた．また，主キー以外の関係従属性の排除によって，顧客IDを新しい主キーとした顧客表に分割できた． ＊例＊ エクセルで表を作成 以下のような表の場合，行を分割し，異なる表と見なす． 第一正規化（繰り返し要素の排除） データの追加／削除 データを追加するあるいは削除する場合，カラムではなく，レコードの増減を行う．カラムの増減の処理には時間がかかる．一方で，レコードの増減の処理には時間がかからない． ＊例＊ 賞与を年1回から，2回・3回と変える場合，主キーを繰り返し，新しく賞与区分と金額区分を作る． テーブル命名規則 ・テーブル名は複数形 例えば，foosとする． カラム命名規則 ・プレフィクスは単数形テーブル名 例えば，foo_id，foo_name，foo_typeとする．ただし，子テーブルの外部キーと紐付くカラムがある場合，そのカラムのプレフィクスは，子テーブル名の単数形とする．例えば，bar_idとする．例外として，ActiveRecordパターンのフレームワーク（Laravelなど）では使用しない方がよいかもしれない．これらのフレームワークでは，単数形テーブル名のプレフィクスがないカラム名を想定して機能が備わっていることがある．この場合，DBとの連携で毎回カラム名を明示する必要があったり，標準ではないカラム名を使用することによる不具合が発生したり，不便なことが多かったりするため，おすすめしない． foo_id bar_id foo_name foo_type 1 1 foo 2 02. ACID ACIDとは トランザクションを実現するため必要な機能を略して『ACID』という． 参考： http://tooljp.com/jyosho/docs/ACID/ACID.html https://atmarkit.itmedia.co.jp/ait/articles/1801/31/news011.html Atomicity（不可分性） ・Atomicityとは トランザクションに含まれる全ての処理が成功することと，またはいずれかが失敗した場合には何も実行されていない状態に戻ることを保証する性質のこと．コミットメント制御によって実装される． Consistency（整合性） ・Consistencyとは トランザクションの実行前後であっても，データは常にDBのルールに則っている性質のこと．カラムの制約によって実装される． Isolation（独立性） ・Isolationとは トランザクションはお互いに独立し，影響を与え合わない性質のこと．排他制御によって実装される． Durability（永続性） ・Durabilityとは トランザクションの完了後は，たとえシステム障害があったとしても，データは失われない性質のこと．障害回復制御によって実装される． 02-02. コミットメント制御 RDBの書き込み系の操作 ・CREATE／UPDATE/DELETE処理の流れ ・RDBの操作と実際のメソッドの対応関係 RDBの書き込み系の操作 PDOでのメソッド名 ラッピング システム障害からの回復 更新前ログの記録 ↓ ↓ ↓ ↓ ↓ トランザクション開始 beginTransaction() execute()開始 ↓ ↓ ↓ ⬆︎ ・C／U／Dの処理・トランザクション終了 ・insert()・update()・delete() flush() ⬆︎　Roll back：rollBack() ↓ ↓ ↓ ⬆︎ Commitによる更新後ログの書き込み． commit()開始 ↓ ↓ ↓ ↓ ⬇︎ ↓ ↓ ↓ ⬇︎　Roll forward ↓ ↓ ↓ ⬇︎ Check Pointによる更新後ログのDB反映 commit()終了 execute()終了 ・PDOによるRDBの書き込み系の操作 PDOでは書き込み処理にexecメソッド，読み出し処理にqueryメソッドを使用する． ＊実装例＊ setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION); // トランザクションを開始． $db->beginTransaction(); // いくつかのSQLが実行される．※もし失敗した場合，ERRMODE_EXCEPTIONを実行． $db->exec(\"INSERT INTO movie(title, price) VALUES(\"ハリポタ\", 2000)\") $db->exec(\"INSERT INTO movie(title, price) VALUES(\"シスター\", 2000)\") // トランザクション内の一連のステートメントが成功したら，ログファイルにコミット． $db->commit(); } catch{ // 例外が発生したらロールバックし，エラーメッセージを出力． $db->rollBack(); print \"失敗しました．：{$e->getMessage()}\" } ・DoctrineによるRDBの書き込み系の操作 詳しくは，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_php_framework_symfony.html コミットによるログファイルへの更新前ログへの書き込み ・コミット トランザクション内の一連のステートメントを，ログファイルの更新前ログとして書き込む． ・二相コミット コミットを以下の二つの段階に分けて行うこと．ACIDのうち，原子性と一貫性を実装している． 他のサイトに更新可能かどうかを確認． 全サイトからの合意が得られた場合に更新を確定． チェックポイントにおけるデータファイルへの書き込み トランザクションの終了後，DBMSは，処理速度を高めるために，ログファイルの更新後ログをいったんメモリ上で管理する． そして，チェックポイントで，ログファイルの更新後ログをディスク上のデータファイルに反映させる．この時，チェックポイントは，自動実行または手動実行で作成する． 02-03. 障害回復制御 システム障害からの回復 データベースサーバのソフトウェア障害のこと．例えば，DBMSやOSのトラブル等によりシステム全体が停止する． ・ロールバック 障害によって，トランザクション内の一連のステートメントがすべて実行されなかった場合に，ログファイルの更新前ログを用いて，トランザクションの開始前の状態に戻す． ・ロールフォワード 障害によって，トランザクションの終了後に一連のステートメントの更新結果がディスクに反映されなかった場合に，ログファイルの更新後ログを用いて，ディスク上のデータファイルに更新結果を反映させる． ＊例＊ 『a』の値を更新するステートメントを含むトランザクションの後に，システムが異常終了した場合，ログファイルの更新後ログ『a = 5』を用いて，ディスク上のデータファイルに更新結果を反映させる．（ロールフォワード） 『b』の値を更新するステートメントを含むトランザクションの途中に，システムが異常終了した場合，ログファイルの更新前ログ『b = 1』を用いて，障害発生前の状態に戻す．（ロールバック） 媒体障害からの回復 データベースサーバのハードウェア障害のこと．例えば，ハードディスクの障害がある．ディスクを初期化／交換した後，バックアップファイルからデータベースを修復し，ログファイルの更新後ログ『a = 5』『b = 1』を用いて，修復できる限りロールフォワードを行う． ＊例＊ バックアップファイルの実際のコード -- -------------------------------------------------------- -- Host: xxxxx -- Server version: 10.1.38-MariaDB - mariadb.org binary distribution -- Server OS: Win64 -- HeidiSQL Version: 10.2.0.5611 -- -------------------------------------------------------- /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; /*!40101 SET NAMES utf8 */; /*!50503 SET NAMES utf8mb4 */; /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */; /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE=\"NO_AUTO_VALUE_ON_ZERO\" */; # データベース作成 -- Dumping database structure for kizukeba_pronami_php CREATE DATABASE IF NOT EXISTS `kizukeba_pronami_php` /*!40100 DEFAULT CHARACTER SET utf8 COLLATE utf8_unicode_ci */; USE `kizukeba_pronami_php`; # テーブルのデータ型を指定 -- Dumping structure for table kizukeba_pronami_php.mst_staff CREATE TABLE IF NOT EXISTS `mst_staff` ( `code` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(15) COLLATE utf8_unicode_ci NOT NULL, `password` varchar(32) COLLATE utf8_unicode_ci NOT NULL, PRIMARY KEY (`code`) ) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci; # レコードを作成 -- Dumping data for table kizukeba_pronami_php.mst_staff: ~8 rows (approximately) /*!40000 ALTER TABLE `mst_staff` DISABLE KEYS */; INSERT INTO `mst_staff` (`code`, `name`, `password`) VALUES (1, \"秦基博\", \"xxxxxxx\"), (2, \"藤原基央\", \"xxxxxxx\"); /*!40000 ALTER TABLE `mst_staff` ENABLE KEYS */; /*!40101 SET SQL_MODE=IFNULL(@OLD_SQL_MODE, \"\") */; /*!40014 SET FOREIGN_KEY_CHECKS=IF(@OLD_FOREIGN_KEY_CHECKS IS NULL, 1, @OLD_FOREIGN_KEY_CHECKS) */; /*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */; 02-04. 排他制御 UPDATE処理競合問題 ・UPDATE処理競合問題とは アプリケーションのレコードのUPDATE処理が，レコードの取得と更新からなるとする．システムのユーザAとBがおり，ユーザBがUPDATE処理時に取得しなければならないレコードの状態は，ユーザAがUPDATE処理を終えた後のものである．しかし，ユーザAがレコードを取得してから更新を終えるまでの間に，ユーザBが同じくレコードを取得してしまうことがある．結果として，ユーザBのUPDATE処理によって，ユーザAの処理が上書きされ，無かったことになってしまう． 参考：https://qiita.com/NagaokaKenichi/items/73040df85b7bd4e9ecfc ユーザAとユーザBのUPDATE処理が並行したとしても，ユーザAの処理が無かったことにならないよう保証する方法として，『排他制御』がある． 排他制御 ・種類 参考：https://qiita.com/momotaro98/items/5e37eefc62d726a30aee 種類 説明 共有／占有ロック DBによるロック機能． 楽観的／悲観的ロック アプリケーションまたはDBによるロック機能． ・UPDATE処理競合問題の許容 UPDATE処理競合問題を許容し，排他制御を使用しない選択肢もある． 共有／占有ロック ・共有ロック DBにおいて，CRUDのREAD処理以外の処理を実行不可能にする．レコードのREAD処理を実行する時に，他者によってUPDATE処理されたくない場合に用いる．「共有」の名の通り，共有ロックされているレコードに対して，他の人も共有ロックを行うことができる．MySQLでは，『SELECT ... LOCK IN SHARE MODE』を使用する． 参考：https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html ・占有ロック DBにおいて，CRUDの全ての処理を実行不可能にする．レコードのUPDATE処理を実行する時に，他者によってUPDATE／READ処理の両方を実行させない場合に用いる．MySQLでは，『SELECT ... FOR UPDATE』を使用する． 参考：https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html ・デッドロック現象 複数のトランザクションが，互いに他者が使いたいレコードをロックしてしまい，お互いのロック解除を待ち続ける状態のこと．もう一方のレコードのロックが解除されないと，自身のレコードのロックを解除できない時，トランザクションが停止する． 共有ロックの実行 占有ロックの実行 共有ロックされたレコード 〇 ✕ 占有ロックされたレコード ✕ ✕ 楽観的／悲観的ロック ・楽観的ロック DBのレコードにはバージョンに関するカラム値（最終更新日時など）が存在しているとする．UPDATE処理のためにユーザAがDBのレコードを取得した時に，バージョン値を一時的に保持しておく．続けて更新する直前に，DBからバージョンの値を改めて取得する．保持しておいたバージョン値とDBの値を比較し，DBの値の方がより新しいバージョンだった場合，UPDATE処理が失敗するようにする．競合によるエラーを表す409ステータスをレスポンスとして返信するとよい． 参考： https://e-words.jp/w/%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF-%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF.html https://medium-company.com/%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%A8%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%AE%E9%81%95%E3%81%84/ ・悲観的ロック ユーザAがDBのレコードを取得した時点でロックを起動し，ユーザBはレコードの取得すらできなくする．ユーザAが更新を終えてロックが解除され，そこで初めてユーザBはレコードを取得できるようになる．アプリケーションで悲観的ロックを実装することは難易度が高く，基本的にはDBが提供するロック機能を用いる． 参考： https://e-words.jp/w/%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF-%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF.html https://medium-company.com/%E6%82%B2%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%A8%E6%A5%BD%E8%A6%B3%E3%83%AD%E3%83%83%E3%82%AF%E3%81%AE%E9%81%95%E3%81%84/ ・ORMの楽観的ロックについて ORMが楽観的ロックの機能を持っている場合がある．PHPのORMであるDoctrineのロック機能については，以下のリンクを参考にせよ． 参考： https://www.doctrine-project.org/projects/doctrine-orm/en/2.9/reference/transactions-and-concurrency.html#locking-support https://qiita.com/tatsurou313/items/053cffdfe940a89d7f5a#or-%E3%83%9E%E3%83%83%E3%83%91%E3%83%BC%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%A5%BD%E8%A6%B3%E7%9A%84%E3%83%AD%E3%83%83%E3%82%AF%E3%81%AE%E5%AE%9F%E8%A3%85%E6%9C%89%E7%84%A1 ロックの粒度 DB ＞ テーブル ＞ レコード ＞ カラム の順に，粒度は大きい．ロックの粒度が細かければ，トランザクションの同時実行性が高くなって効率は向上する（複数の人がDBに対して作業できる）．しかし，ロックの粒度を細かくすればするほど，それだけベース管理システムのCPU負荷は大きくなる． "},"public/software/software_middleware_database_mysql.html":{"url":"public/software/software_middleware_database_mysql.html","title":"📖 My︎SQL","keywords":"","body":"MySQL はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 設定ファイル 元々の値をコメントアウトで示す [mysqld] skip-host-cache # 記述なし skip-name-resolve # 記述なし datadir = /var/lib/mysql socket = /var/lib/mysql/mysql.sock secure-file-priv = /var/lib/mysql-files user = mysql pid-file = /var/run/mysqld/mysqld.pid # character set / collation character_set_server = utf8mb4 # latin1 collation_server = utf8mb4_general_ci # latin1 # timezone default-time-zone = SYSTEM log_timestamps = SYSTEM # UTC # Error Log log-error = mysql-error.log # /var/log/mysqld.log # Slow Query Log slow_query_log = 1 # off slow_query_log_file = mysql-slow.log # host_name-slow.log long_query_time = 3 # 10 log_queries_not_using_indexes = 0 # off # General Log general_log = 1 # off general_log_file = mysql-general.log # host_name.log [mysql] default-character-set = utf8mb4 # utf8 [client] default-character-set = utf8mb4 # utf8 02. データベース MySQLの準備 ・CentOSにインストール mysqlコマンドのみをインストールしたい場合 $ dnf install -y mysql mysqlコマンド，データベースサーバ機能，をインストールしたい場合はこちら $ dnf install -y mysql-server ・DBに接続 DBに接続する．pオプションの値にはスペースが不要であることに注意する． $ mysql -u -p -h パラメータ ・パラメータの表示 データベースに登録されているグローバルパラメータとセッションパラメータを表示する． -- セッション／グローバルパラメータを表示 SHOW SESSION VARIABLES; SHOW GLOBAL VARIABLES; -- OSとDBのタイムゾーンに関するパラメータを表示 SHOW SESSION VARIABLES LIKE \"%time_zone\"; SHOW GLOBAL VARIABLES LIKE \"%time_zone\"; ・パラメータの設定 -- グローバルパラメータの場合 SET GLOBAL time_zone = \"Asia/Tokyo\"; -- セッションパラメータの場合 SET time_zone = \"Asia/Tokyo\"; 03. テーブル CREATE TABLE句 ・使い方 ＊実装例＊ -- 注文テーブル作成 CREATE TABLE order_data ( -- プライマリキー制約 order_id INT(10) PRIMARY KEY COMMENT \"注文ID\", -- Not Null制約 order_kbn INT(3) NOT NULL COMMENT \"注文区分\", system_create_date_time DATETIME NOT NULL COMMENT \"システム登録日時\", system_update_date_time DATETIME NOT NULL COMMENT \"システム更新日時\", delete_flg INT(1) DEFAULT 0 NOT NULL COMMENT \"0：通常，1：削除済\", -- 複合プライマリキー制約（これを指定する場合，上記のプライマリキー制約の記述は不要） PRIMARY KEY(order_id, order_kbn) -- 参照制約キー FOREIGN KEY order_kbn REFERENCES order_kbn_data ) CREATE VIEW句 ・使い方 ビューとはある表の特定のカラムや指定した条件に合致するレコードなどを取り出した仮想の表．また，複数の表を結合したビューを作成できる．ビューを作成することによりユーザに必要最小限のカラムやレコードのみにアクセスさせる事ができ，また結合条件を指定しなくても既に結合された表にアクセスできる． ⇒よくわからん… ＊実装例＊ CREATE VIEW { テーブル名 } AS SELECT * FROM { テーブル名 }; プライマリキー ・プライマリキーとは テーブルの中で，レコードを一意に識別できる値を『プライマリキー』の値と呼ぶ． ・プライマリキーとして使用可能なもの 一意に識別できるものあれば，何をプライマリキーとして使用しても問題なく，基本的に以下が使用される． 種類 説明 補足 MySQLのAuto Increment機能によって増加する番号カラム プライマリキー制約を課したカラムのAuto Increment機能を有効化しておく．CREATE処理でドメインモデルを作成する時に，『0』または『null』をモデルのID値として割り当てる．これにより，処理によって新しいレコードが追加される時に，現在の最新番号に＋１した番号が割り当てられるようになる．これはプライマリキー制約を満たす．参考：https://dev.mysql.com/doc/refman/8.0/en/example-auto-increment.html ・ドメインモデルとDBがより密結合になり，Active Recordパターンと相性がよい．MySQLの環境変数として『NO_AUTO_VALUE_ON_ZERO』を設定すると，『0』の割り当てによる自動連番が拒否されるようになる． UUID（例：3cc807ab-8e31-3071-aee4-f8f03781cb91） CREATE処理でモデルを作成する時に，アプケーションで生成したUUID値をドメインモデルのID値として割り当てる．UUID値が重複することは基本的に起こり得ないため，プライマリキー制約を満たす．UUID値の生成関数は言語の標準ライブラリとして用意されている． ・ドメインモデルとDBがより疎結合にでき，Repositoryパターンと相性がよい．UUID値は文字列として管理されるため，DBアクセス処理の負荷が高まってしまう．プライマリキーを使用してソートできない． ・複合プライマリキー プライマリキーは複数設定することができ，複合プライマリキーの場合，片方のフィールドの値が異なれば，異なるプライマリキーとして見なされる． ＊例＊ ユーザIDと期間開始日付を複合プライマリキーとすると，一人のユーザが複数の期間を持つことを表現できる． user_id period_start_date period_end_date fee_yen 1 2019-04-03 2019-05-03 200 1 2019-10-07 2019-11-07 400 2 2019-10-11 2019-11-11 200 ・採番テーブル 各テーブルのプライマリキーを統合的に管理するテーブルを採番テーブルという．各テーブルのプライマリキーは採番テーブルを元に割り当てられるため，連番ではなく飛び飛びになる． 参考：http://blog.livedoor.jp/sasata299/archives/51280681.html あらかじめ，最初のレコードのみ手動で挿入しておく． # 採番テーブルの作成する． CREATE TABLE id_sequence (id BIGINT NOT NULL); # 最初のレコードを手動で挿入する． INSERT INTO id_sequence VALUES (0); CREATE処理時には，事前に，採番テーブルに新しくプライマリキーを作成する．INSERT文のプライマリキーに『0』や『null』を割り当てるのではなく，採番テーブルから取得したIDを割り当てるようにする． # 新しくプライマリキーを作成する． UPDATE id_sequence SET id = LAST_INSERT_ID(id + 1); # プライマリキーを取得する． SELECT LAST_INSERT_ID(); 制約 ・制約とは DBにおいて，アプリケーションのCRUD処理に対するバリデーションのルールを定義する．しかし，必ずしも制約を使用する必要はなく，代わりのロジックをアプリケーション側で実装してもよい．その制約を，DBとアプリケーションのいずれの責務とするかを考え，使用するか否かを判断する． ・プライマリキー制約 プライマリキーとするカラムにはプライマリキー制約を課すようにする．プライマリキー制約によって，Unique制約とNot Null制約の両方が課される． ・Not Null制約 レコードに挿入される値のデータ型を指定しておくことによって，データ型不一致やNullのための例外処理を実装しなくてもよくなる． ・外部キー制約 親テーブルのカラムを参照する子テーブルのカラムを『外部キー』といい，この時に子テーブルに課す制約を『外部キー制約』という．子テーブルにおける外部キー制約によって，親子テーブル間に以下の整合性ルールが課される． 親テーブルの参照元カラムに存在しない値は，子テーブルに登録できない． 子テーブルの外部キーが参照する値が，親テーブルの参照元カラムに存在する場合，参照元カラムは削除できない． ＊例＊ 会社情報テーブル（親テーブル）と個人情報テーブル（子テーブル）があるとする．子テーブルの会社IDカラムを外部キーとして，親テーブルの会社IDカラムを参照する．親テーブルの参照元カラムに存在しないIDは，子テーブルの外部キーに登録できない．また，親テーブルの参照元カラムは外部キーに参照されているため，参照元カラムは削除できない． stored procedure ・stored procedureとは あらかじめ一連のSQL文をデータベースに格納しておき，Call文で呼び出す方式． ・使い方 ＊実装例＊ SELECT文のstored procedureを作成するとする． -- PROCEDUREを作成し，データベースへ格納しておく． CREATE PROCEDURE SelectContact AS SELECT { カラム名 } FROM { テーブル名 } -- PROCEDUREを実行 EXEC SelectContact エクスポート，インポート ・テーブルのエクスポート DBからテーブルをエクスポートする．エクスポートしたいテーブルの数だけ，テーブル名を連ねる $ mysqldump --force -u \"{ アカウント }\" -p -h \"{ DBのホスト }\" \"{ DB名 }\" \"{ テーブル名1 }\" \"{ テーブル名2 }\" > table.sql ・テーブルのインポート DBにテーブルをインポートする．forceオプションで，エラーが出ても強制的にインポート． $ mysql --force -u \"{ アカウント }\" -p -h \"{ DBのホスト }\" \"{ DB名 }\" データ型 ・数値型 整数値がどのくらい増えるかによって，3つを使い分ける．符号なし（Unsigned）を有効化した場合，マイナス値を使用しなくなった分，使用可能なプラス値が増える． データ型 値 符号なし（Unsigned）を有効化した場合 TINYINT -128~ +127 0~ +255 INT 2147483648~ +2147483647 0~ +4294967295 BIGINT -9223372036854775808~ +9223372036854775807 0~ +18446744073709551615 ・文字列型 文字数がどのくらい増えるかによって，3つを使い分ければ良い． データ型 最大バイト数 VARCHAR(M) 255 TEXT 65535 MEDIUMTEXT 16777215 Collation（照合順序） ・文字列型の照合順序とは 文字列型のカラムに関して，WHERE句の比較における値の特定，ORDER BY句における並び替えの昇順降順，JOIN句における結合，GROUP BYにおけるグループ化のルールを定義する．カラム／テーブル／DB単位で設定でき，比較するカラム同士では同じ照合順序が設定されている必要がある． 参考：https://johobase.com/sqlserver-where-collate/ ・種類 寿司とビールの絵文字が区別されないことを『寿司ビール問題』という．大文字Aと小文字aを区別しないことは，CI：Case Insensitiveと表現され，照合順序名にも特徴としてCIの文字が含まれている． 照合順序名 A／a ／:beer: は／ぱ／ば や／ゃ utf8mb4_unicode_ci = = = = utf8mb4_unicode_520_ci = ≠ = = utf8mb4_general_ci = = ≠ ≠ utf8mb4_bin ≠ ≠ ≠ ≠ 04. ユーザの管理 CREATE ・ユーザ作成 CREATE USER \"{ ユーザ名 }\" IDENTIFIED BY \"{ パスワード }\"; ・ユーザ一覧 ここで表示される特権と．ALL特権は異なる． SELECT * FROM mysql.user; DROP ・ユーザ削除 -- ユーザ別のホスト名の確認 SELECT * FROM mysql.user; -- ホストが「%」だった場合 DROP USER { ユーザ名 }@`%`; GRANT ・全ての操作権限を付与 データベース名は，シングルクオーテーションで囲う必要が無い．全権限を付与する場合，PRIVILEGESは省略できるが，厳密には省略しないようほうがよい． -- 全てのデータベースに関する権限を付与 GRANT ALL PRIVILEGES ON *.* TO \"{ ユーザ名 }\"; -- Amazon AuroraまたはRDSの場合はこちら GRANT ALL PRIVILEGES ON `%`.* TO \"{ ユーザー名 }\"; -- Amazon Auroraも同じく -- 特定のデータベースに関する全権限を付与 GRANT ALL PRIVILEGES ON {DB名}.* TO \"{ ユーザ名 }\"; ・一部の操作権限を付与 特定のデータベースに関する読み出し権限のみ付与する． GRANT SELECT ON {DB名}.* TO \"{ ユーザ名 }\"; ・ユーザ権限一覧 ユーザに付与されている権限を表示する． SHOW GRANTS FOR \"{ ユーザ名 }\"; 作成しただけで権限を何も付与してないユーザの場合，「データベースサーバ内の全データベースに関して，全権限なし」を表すUSAGEとして表示される． GRANT USAGE ON *.* TO \"{ ユーザー名 }\"; 特定のデータベースの操作権限を与えると，上記に加えて，付与したGRANT権限も表示されるようになる． REVOKE ・全権限削除 全権限を削除し，GRANT権限をUSAGEに戻す． -- Amazon AuroraまたはRDSの場合 REVOKE ALL PRIVILEGES ON `%`.* FROM \"{ ユーザ名 }\"; REVOKE ALL PRIVILEGES ON { DB名 }.* FROM \"{ ユーザ名 }\"; ・ユーザ名変更 RENAME USER \"{ 古いユーザ名 }\" TO \"{ 新しいユーザ名 }\"; 04-02. ユーザの準備手順 1. ユーザの作成 CREATEで以下の４種類を作成する．パスワードは，例えば8文字のパスワードを割り当てる． CREATE USER \"{ ユーザ名 }\" IDENTIFIED BY \"{ パスワード }\"; ユーザの種類 例 補足 ルートユーザ root DBの構築時にrootユーザが自動作成される場合は不要 アプリケーション foo_app 読み出し／書き込みユーザ foo_user 読み出しのみユーザ foo_readonly_user 2. ユーザへの権限付与 ・ルートユーザ ルートユーザには，最初から全てのDBに対して権限を付与されており不要． ・アプリケーション 使用するDBに対する全権限を付与する． -- DB名をクオーテーーションで囲う必要はない GRANT ALL PRIVILEGES ON {DB名}.* TO '{ ユーザー名 }' ・読み出し／書き込みユーザ 使用するDBに対する全権限を付与する． -- DB名をクオーテーションで囲う必要はない GRANT ALL PRIVILEGES ON {DB名}.* TO '{ ユーザー名 }' ・読み出しのみユーザ 使用するDBに対するSELECT権限を付与する． -- DB名をクオーテーションで囲う必要はない GRANT SELECT ON {DB名}.* TO '{ ユーザ名 }'; 05. レコードの読み出し：READ はじめに ・句の処理の順番 FROM ---> JOIN ---> WHERE ---> GROUP BY ---> HAVING ---> SELECT ---> ORDER BY SELECT句 ・なし 指定したカラムを取得する．MySQLでは，取得結果に標準の並び順が存在しないため，プライマリキーの昇順で取得したい場合は，ORDER BY句を使用して，明示的に並び替えるようにする． 参考：https://www.quora.com/What-is-the-default-order-of-records-for-a-SELECT-statement-in-MySQL SELECT * FROM { テーブル名 }; ・SUM関数 指定したカラムで，『フィールド』の合計を取得する． SELECT SUM({ カラム名 }) FROM { テーブル名 }; ・AVG関数 指定したカラムで，『フィールド』の平均値を取得する． SELECT AVG({ カラム名 }) FROM { テーブル名 }; ・MIN関数 指定したカラムで，『フィールド』の最小値を取得する． SELECT MIN({ カラム名 }) FROM { テーブル名 }; ・MAX関数 指定したカラムで，『フィールド』の最大値を取得する． SELECT MAX({ カラム名 }) FROM { テーブル名 }; ・COUNT関数 指定したカラムで，『フィールド』の個数を取得する． SELECT { カラム名 } COUNT(*) FROM { テーブル名 }; ※消去法の小技：集合関数を入れ子状にはできない ＊実装例＊ 集合関数を集合関数の中に入れ子状にすることはできない． -- SELECT AVG(SUM({ カラム名 })) FROM { テーブル名 }; 指定したカラムで，値無しも含む『フィールド』を取得する． SELECT { カラム名 } COUNT(*) FROM { テーブル名 }; 指定したカラムで，値無しを除いた『フィールド』を取得する． SELECT { カラム名 } COUNT(*); ・LAST_INSERT_ID関数 任意のテーブルに最後に挿入されたIDを読み出す．テーブル名を指定する必要はない． SELECT LAST_INSERT_ID(); ・MD5関数 文字列をハッシュ化 SELECT MD5(\"xxxxx\"); CASE句 カラム1がtrueだったら，カラム2を取得する．falseであったら，カラム3を取得する． SELECT CASE WHEN { エイリアス }.{ カラム名1 } = 1 THEN { エイリアス }.{ カラム名2 } ELSE { エイリアス }.{ カラム名3 } END AS name FROM { テーブル名 } AS { エイリアス }; FROM句 ・JOIN句の種類 ・LEFT JOIN（左外部結合） 『users』テーブルと『items』テーブルの商品IDが一致しているデータと，元となる『users』テーブルにしか存在しないデータが，セットで取得される． ・INNER JOIN（内部結合） 基本情報技術者試験では，内部結合（A∩B）しか出題されない． ・内部結合にWHEREを用いる場合 2つのWHERE文が，ANDで結びつけられている時，まず一つ目のWHEREを満たすレコードを取得した後，取得したレコードの中から，二つ目のWHEREを満たすレコードを取得する． ＊実装例＊ -- 『カラム』だけでなく，どの『表』なの物なのかも指定 SELECT { テーブル名1 }.{ カラム名1 }, -- 複数の表を指定 FROM { テーブル名1 }, { テーブル名2 }, -- まず，1つ目のフィールドと2つ目のフィールドが同じレコードを取得する． WHERE -- 次に，上記で取得したレコードのうち，次の条件も満たすレコードのみを取得する． { レコード名1 } = { レコード名2 } AND { レコード名2 } = { レコード名3 } ・内部結合にINNER JOIN ONを用いる場合 ＊実装例＊ -- 『カラム』だけでなく，どの『表』なの物なのかも指定 SELECT { テーブル名1 }.{ カラム名1 }, -- 複数の表を指定 FROM { テーブル名1 } -- 2つ目の表の『レコード』と照合 INNER JOIN { テーブル名2 } ON { テーブル名1 }.{ カラム名1 } = { テーブル名2 }.{ カラム名2 } -- 3つ目の表の『レコード』と照合 INNER JOIN { テーブル名3 } ON { テーブル名1 }.{ カラム名1 } = { テーブル名3 }.{ カラム名3 } ORDER BY句 ・使い方 ＊実装例＊ $order) { switch ($key) { case \"id\": return sprintf(\"ss.id %s\", $order); } } } // IN句順の場合 return sprintf(\"FIELD(ss.id, %s)\", $idList); }); $sql = IN句，ANY句の違い ・IN句の使い方 指定した値と同じ『フィールド』を取得する． ＊実装例＊ 指定したカラムで，指定した値の『フィールド』を取得する． SELECT * FROM { テーブル名 } WHERE { カラム名 } in (xxx, xxx,...); 指定したカラムで，指定した値以外の『フィールド』を取得する． SELECT * FROM { テーブル名 } WHERE { カラム名 } not in ({ レコード名1 }, { レコード名2 },...); 指定したカラムで，SELECTで読み出した値以外の『フィールド』を取得する． SELECT * FROM { テーブル名 } WHERE { カラム名 } not in ( -- SELECT { カラム名 } FROM { テーブル名 } WHERE { レコード名 } >= 160 ); 【IN句を使用しなかった場合】 SELECT * FROM fruit WHERE name = \"みかん\" OR name = \"りんご\"; 【IN句を使用した場合】 SELECT * FROM fruit WHERE name IN(\"みかん\", \"りんご\"); ・ANY句の使い方 書き方が異なるだけで，inと同じ出力 SELECT * FROM { テーブル名 } WHERE { カラム名 } = ANY(xxx, xxx, xxx); GROUP BY句 ・使い方 カラムをグループ化し，集合関数を使用して，フィールドの値を計算する． ＊実装例＊ 指定したカラムをグループ化し，フィールドの値の平均値を算出する． SELECT { カラム名1 }, AVG({ カラム名2 }) FROM { テーブル名 } GROUP BY { カラム名1 }; HAVING句 ・使い方 各句の処理の順番から考慮して，GROUP BYでグループ化した結果から，HAVINGで『フィールド』を取得する．SELECTにおける集計関数が，HAVINGにおける集計関数の結果を指定していることに注意せよ． ＊実装例＊ -- HAVINGによる集計結果を指定して出力． SELECT { カラム名1 }, COUNT({ カラム名2 }) FROM { テーブル名 } GROUP BY -- グループ化した結果を集計し，２個以上の『フィールド』を取得する． { カラム名1 } HAVING COUNT(*) >= 2; ※以下の場合，GROUP BY + HAVINGを使っても，WHEREを使っても，同じ出力結果になる． SELECT { カラム名 } FROM { テーブル名 } GROUP BY { カラム名 } HAVING { レコード名 }; SELECT { カラム名 } FROM { テーブル名 } WHERE { レコード名 } GROUP BY { カラム名 }; WILDCARD句 ・使い方 ＊実装例＊ SELECT * FROM { テーブル名 } WHERE { カラム名 } LIKE \"%営業\"; SELECT * FROM { テーブル名 } WHERE { カラム名 } LIKE \"_営業\"; BETWEEN句 ・使い方 ＊実装例＊ 指定したカラムで，1以上10以下の『フィールド』を取得する． SELECT * FROM { テーブル名 } BETWEEN 1 AND 10; SET句 ・使い方 ＊実装例＊ SET @A = { パラメータ値 }; SET @B = { パラメータ値 }; UPDATE { テーブル名 } SET { カラム名 } = @A, WHERE { カラム名 } = @B; サブクエリ ・使い方 掛け算と同様に，括弧内から先に処理を行う． ＊実装例＊ -- Main-query SELECT * FROM { テーブル名 } WHERE { カラム名 } != ( -- Sub-query SELECT max({ カラム名 }) FROM { テーブル名 } ); インデックス ・インデックスとは テーブルから特定のカラムだけを抜き出し，検索しやすいように並び替え，名前を付けて保存しておいたもの．インデックスとして保存されたカラムから特定のレコードを直接取得できるため，SQLの実行時間がカラム数に依存しなくなる．インデックスを使用しない場合，SQLの実行時に全てカラムを取得するため，実行時間がテーブルのカラム数に依存してしまう． ・クラスタインデックス プライマリキーあるいはユニークキーのカラムを抜き出して並び替えたインデックスのこと． ・セカンダリインデックス プライマリキーあるいはユニークキーではないカラムを抜き出して並び替えたインデックスのこと． ・複合インデックス 複数のカラムをひとまとめに抜き出して並び替えたインデックスのこと．対象としたカラムごとに異なる値のレコード数が計測され，この数が少ない（一意の値の多い）カラムが検出される．そして，カラムのレコードの昇順で並び替えられ，インデックスとして保存される． ＊例＊ 以下のようなテーブルがあり，nameカラムとaddressカラムをインデックスとして抜き出すとする． id name address old 1 Suzuki Tokyo 24 2 Yamada Osaka 18 3 Takahashi Nagoya 18 4 Honda Tokyo 16 5 Endou Tokyo 24 抜き出されたカラムごとに異なる値のレコード数が計測され，nameカラムはaddressカラムよりも一意のレコードが多いため，nameカラムの昇順（アルファベット順）に並び替えられ，インデックスとして保存される． name address Endou Tokyo Honda Tokyo Suzuki Tokyo Takahashi Nagoya Yamada Osaka EXPLAIN句 ・使い方 設定したSELECT句が仮に実行された場合に，いずれのテーブルのいずれのカラムを取得することになるか（実行計画）を表示する．また，想定実行時間も検出できるため，スロークエリの検出に役立つ． 参考：https://dev.mysql.com/doc/refman/5.7/en/explain-output.html EXPLAIN SELECT * FROM t1, t2 WHERE t1.c1 = 1 AND t1.c2 = t2.c3 *************************** 1. row *************************** id: 1 select_type: SIMPLE table: t1 type: ref possible_keys: index_t1_on_c1_and_c2 key: index_t1_on_c1_and_c2 key_len: 5 ref: const rows: 10 Extra: Using where; Using index *************************** 2. row *************************** id: 1 select_type: SIMPLE table: t2 type: ref possible_keys: index_t2_on_c3 key: index_t2_on_c3 key_len: 5 ref: sample.t1.c2 rows: 1 Extra: Using index ・select_type SQLの種類が表示される．サブクエリを含まないSQLはSIMPLEとなり，サブクエリを含むと，サブクエリの種類に応じて，PRIMARY，SUBQUERY，DEPENDENT SUBQUERY，UNCACHEABLE SUBQUERY，DERIVED，のいずれかが表示される． ・table 設定したSELECT句がアクセスするテーブル名が表示される． ・type 設定したSELECT句がテーブルにアクセスする時に，どの程度の数のカラムを検索するのかが表示される．検索するカラムが多いSQLほど，想定実行時間が長くなる． 種類 条件 検索するカラム数 補足 ALL ・インデックスを使用していない． 全てのカラム 全てのカラムを検索するため，実行時間が最も長く，改善する必要がある． index ・インデックスを使用していない． 全てのインデックスのカラム range ・セカンダリインデックスを使用している．・WHERE句に重複したレコード値，IN句，BETWEEN句を使用している． 特定の複数カラム ref ・セカンダリインデックスを使用している．・WHERE句に重複しないレコード値 特定の複数カラム eq_ref ・クラスタインデックスを使用している． 一つのカラム 一つのカラムしかfetchしないため，JOIN句を使用したアクセスの中で，実行時間が最も短い． const ・クラスタインデックスを使用している．・JOIN句を使用していない． 一つのカラム 一つのカラムしかfetchしないため，実行時間が最も短い． ・possible_keys インデックスとして設定されたカラムのうちで，実際に利用可能なものの一覧が表示される． Tips ・各データベース容量の確認 SELECT table_schema, sum(data_length) / 1024 / 1024 AS mb FROM information_schema.tables GROUP BY table_schema ORDER BY sum(data_length + index_length) DESC; ・カラムの検索 SELECT table_name, column_name FROM information_schema.columns WHERE column_name = { 検索したいカラム名 } AND table_schema = { 検索対象のデータベース名 } ・最適なインデックスの検出 レコードの突き合わせ処理アルゴリズム ・突き合わせ処理とは ビジネスの基盤となるマスタデータ（商品データ，取引先データなど）と，日々更新されるトランザクションデータ（販売履歴，入金履歴など）を突き合わせ，新しいデータを作成する処理のこと． ・アルゴリズム ・具体例 とある生命保険会社では，顧客の保険契約データを契約マスタテーブルで，またそれとは別に，保険契約データの変更点（異動事由）を異動トランザクションテーブルで，管理している．毎日，契約マスタテーブルと異動トランザクションテーブルにおける前日レコードを突き合わせ，各契約の異動事由に応じて，変更後契約データとして，新契約マスタテーブルに挿入する． 前処理として，契約マスタデータと異動トランザクションデータに共通する識別子が同じ順番で並んでいる必要がある． 契約マスタデータの1行目と，異動トランザクションデータの1行目の識別子を突き合わせる．『契約マスタデータ = 異動トランザクションデータ』の時，異動トランザクションデータを基に契約マスタデータを更新し，それを新しいデータとして変更後契約マスタデータに挿入する． 契約マスタデータの2行目と，異動トランザクションデータの2行目の識別子を突き合わせる．『マスタデータ マスタデータの3行目と，固定したままのトランザクションデータの2行目の識別子を突き合わせる．『マスタデータ = トランザクションデータ』の時，トランザクションデータを基にマスタデータを更新し，それを変更後データとして変更後マスタテーブルに挿入する． 『契約マスタデータ 最終的に，変更後マスタテーブルは以下の通りになる． "},"public/software/software_application_architecture_backend_microservice.html":{"url":"public/software/software_application_architecture_backend_microservice.html","title":"📖 ︎マイクロサービスアーキテクチャ","keywords":"","body":"マイクロサービスアーキテクチャ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. イントロダクション バックエンドのアーキテクチャの歴史 ・マイクロサービスアーキテクチャを取り巻く環境 参考；https://tech-blog.rakus.co.jp/entry/20201218/architecture 年代 アーキテクチャ 説明 1999 ～ モノリシックアーキテクチャ 1999年台，バックエンドのアーキテクチャとしてモノリシックアーキテクチャが台頭していた．しかし，モノリシックアーキテクチャは無秩序でつぎはぎだらけのアプリケーションになることが論文（『大きな泥だんご』）で指摘された．参考：https://ja.wikipedia.org/wiki/%E5%A4%A7%E3%81%8D%E3%81%AA%E6%B3%A5%E3%81%A0%E3%82%93%E3%81%94 2014 マイクロサービスアーキテクチャ 2014年にThoughtWorks社は，サービス指向アーキテクチャとドメイン駆動設計を統合し，アプリケーションを独立したサービスの集まりに分割するアーキテクチャを考案した．参考：・https://martinfowler.com/articles/microservices.html・https://atmarkit.itmedia.co.jp/ait/articles/2110/22/news006.html 2017 ミニサービスアーキテクチャ マイクロサービスアーキテクチャのサービス自体を独立したモノリスなアプリケーションと捉えると，その分だけ開発チーム（マネージャーとエンジニア）が必要になってしまう．2017年にCloud Elements社は，これに対処するためにミニサービスアーキテクチャを考案した．このアーキテクチャでは，マイクロサービスアーキテクチャとモノリスアーキテクチャの間をとった粒度で，アプリケーションを複数のサービスに分割する．この粒度を，マイクロサービスに対抗して『ミニサービス』または『MASA』とよぶ．参考：・https://blog.cloud-elements.com/pragmatic-microservices-architecture・https://atmarkit.itmedia.co.jp/ait/articles/2110/22/news006.html 2018 モジュラーモノリス ミニサービスアーキテクチャではサービスの粒度が大きくなったものの，複数のサービスが必要になることは変わらず，その分だけ開発チームが必要になる問題は解消されなかった．そこで，Root Insurance社はモジュラモノリスを考案した．モジュラモノリスでは，サービスの概念を取り入れずに，アプリケーションを細かいモジュールに分割する．参考：https://medium.com/@dan_manges/the-modular-monolith-rails-architecture-fb1023826fc4 ・モジュール／サービスの粒度の比較 参考：https://tech-blog.rakus.co.jp/entry/20201218/architecture モジュールの大きさ 種類 説明 一番大きい モノリシック アプリケーションのモジュールが分割されておらず，アプリケーションをデプロイの単位とする． モジュラー アプリケーションがモジュールに分割されており，アプリケーションをデプロイの単位とする． ミニサービス アプリケーションがサブドメイン（または境界付けられたコンテキスト）を単位としたサービスに分割されており，アプリケーションを構成するサービスのある程度のまとまりをデプロイの単位とする．また，DBを各サービスで共有する． 一番小さい マイクロ アプリケーションがサブドメイン（または境界付けられたコンテキスト）を単位としたサービスまたはルートエンティティに分割されており，アプリケーションを構成するサービスそれぞれをデプロイの単位とする．また，DBを各サービスで共有せずに，サービスごとに設置する． マイクロサービスアーキテクチャの特徴 ・ビジネスのスケーリングに強い ビジネスがスケーリングする時，サービスの新規実装または削除を行えば良いため，ドメイン層の激しい変化に強い． ・コンウェイの法則が働く マイクロサービスアーキテクチャにより，組織構造が小さなチームの集まりに変化することを期待できる． ・高頻度でリリース可能 各サービスを独立してデプロイできるため，高頻度でリリースできる． ・障害の影響が部分的 いずれかのサービスに障害が起こったとして，サーキットブレイカーを用いることにより，上流サービスへの障害の波及を食い止められる．そのため，障害の影響が部分的となり，アプリケーション全体が落ちてしまうことがない． ・複数の開発言語を使用可能 サービス間で，共通のデータ記述言語を使用してデータ通信を行えば，各サービスの開発言語が異なっていても問題ない． リポジトリの粒度 ・モノリポジトリ 全てのサービスを一つのリポジトリで管理する．Googleではモノリポジトリによるマイクロサービスアーキテクチャが採用されている． 参考：https://www.fourtheorem.com/blog/monorepo ・ポリレポジトリ 各サービスを異なるリポジトリで管理する． マイクロサービスアーキテクチャのフレームワーク ・dapr 参考： https://www.publickey1.jp/blog/19/dapr.html https://github.com/dapr/dapr 02. 各分散システムの粒度 サービス ・サービスとは マイクロサービスアーキテクチャにおけるバックエンドの分散システムのコンポーネントのこと．特定のサービスが他のサービスに侵食され，サービスの凝集度が低くならないようにするために，ACL：Anti Corruption Layer（腐食防止レイヤー）を設ける必要がある．腐食防止レイヤーは，異なるコンテキストから受信したデータを，そのサービスのコンテキストにあったデータ形式に変換する責務を持つ．CQRSでは，これはプロセスマネージャパターンとして知られている．一方でSagaパターンとも呼ばれるが，分散トランザクションでも同一の用語があるため，混乱を避けるためにプロセスマネージャパターンとする． 参考： https://github.com/czeslavo/process-manager https://www.oreilly.com/library/view/what-is-domain-driven/9781492057802/ch04.html https://docs.microsoft.com/ja-jp/previous-versions/msp-n-p/jj591569(v=pandp.10)?redirectedfrom=MSDN ・各サービスのアーキテクチャ 各サービスのアーキテクチャは自由である．この時，ドメイン駆動設計のアーキテクチャに基づいて実装することが可能である． ＊例＊ 参考：https://little-hands.hatenablog.com/entry/2017/12/07/bouded-context-implementation ECサイトがあり，これの商品販売ドメインを販売サブドメインと配送サブドメインに分割できるとする．この時，それぞれのサブドメインの問題を解決する販売コンテキストと配送コンテキストをサービスの粒度となり，オニオンアーキテクチャのアプリケーション間で同期通信／非同期通信を行う． サービスの分割手法 ・サービスの分割例 アプリケーション リンク 分割方法 サービスの種類 Eコマース https://github.com/GoogleCloudPlatform/microservices-demo ルートエンティティ カート，商品検索とインデックス，通貨の変換，クレジットカード，送料と発送，注文確認メール，注文フロー，レコメンド，広告，合成監視 Eコマース https://github.com/DataDog/ecommerce-workshop ルートエンティティ 広告，割引 ・サブドメイン，境界付けられたコンテキストを単位とした分割 サブドメインをサービスの粒度とする．ここでは，解決領域となる境界付けられたコンテキストがサブドメインの中に一つしか含まれていない場合を指しており，代わりに，境界付けられたコンテキストをサービスの粒度して考えても良い．サブドメインを粒度とすることを第一段階として，さらに小さな粒度に分割するために，次の段階としてルートエンティティを粒度とするとよい． 参考： https://microservices.io/patterns/decomposition/decompose-by-subdomain.html https://www.amazon.co.jp/dp/4873119316/ref=cm_sw_em_r_mt_dp_PVDKB4F74K7S07E4CTFF ・ルートエンティティを単位とした分割 ルートエンティティをサービスの単位とする．ただし，イベント駆動方式でアプリケーションを連携した場合に限り，従来のリクエスト方式でアプリケーションを連携する場合のルートエンティティを使用することはアンチパターンである．最良な解決策として，サービスのオブジェクトの状態管理方式として，従来のデータに着目したステートソーシングではなく，振る舞いに着目したイベントソーシングを使用する必要がある．また，各サービスを名詞ではなく動詞で命名するとよい．その他，各サービスでDBを完全に独立させることや，SAGAパターンを使用すること，がある． 参考： https://github.com/GoogleCloudPlatform/microservices-demo https://www.koslib.com/posts/entity-services-anti-pattern/ https://www.michaelnygard.com/blog/2018/01/services-by-lifecycle/ https://medium.com/transferwise-engineering/how-to-avoid-entity-services-58bacbe3ee0b 03. 分散システム間の連携 Orchestration（オーケストレーション） ・オーケストレーションとは 中央集権型システムとも言う．全てのサービスを制御する責務を持ったオーケストレーションプログラムを設置する設計方法．一つのリクエストが送信された時に，オーケストレーションプログラムは各サービスをコールしながら処理の結果を繋いでいく．マイクロサービスアーキテクチャだけでなく，サービス指向アーキテクチャでも使用される． 参考： https://news.mynavi.jp/itsearch/article/devsoft/1598 https://blogs.itmedia.co.jp/itsolutionjuku/2019/08/post_729.html https://www.fiorano.com/jp/blog/integration/integration-architecture/%E3%82%B3%E3%83%AC%E3%82%AA%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A3-vs-%E3%82%AA%E3%83%BC%E3%82%B1%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/ ・リクエストリプライ方式 オーケストレーションでは，個々のサービス間の連携方式にリクエストリプライ方式を採用する．この方式では，サービス間でRESTfulAPIを用いた同期通信を実行する． Choreography（コレオグラフィ） ・コレオグラフィとは 分散型システムとも言う．オーケストレーションとしてのプログラムは存在せず，各サービスで下流サービスに連携する責務を持たせる設計方法である．個々のサービス間の連携方式では，イベント駆動方式を採用する．一つのリクエストが送信された時に，サービスからサービスに処理が繋がっていく．マイクロサービスアーキテクチャでは，コレオグラフィによる連携が推奨されている． 参考： https://blogs.itmedia.co.jp/itsolutionjuku/2019/08/post_729.html https://www.fiorano.com/jp/blog/integration/integration-architecture/%E3%82%B3%E3%83%AC%E3%82%AA%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A3-vs-%E3%82%AA%E3%83%BC%E3%82%B1%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/ ・イベント駆動方式 コレオグラフィでは，上流／下流のサービス間の連携方式にイベントドリブン方式を採用する．この方式では，サービス間でメッセージキューを用いた非同期通信を行う．メッセージキューでは受信したメッセージを一方向にしか配信できないため，もしサービス間双方向に送信したい場合は，上流サービスからメッセージを受信するメッセージキューと．下流サービスから受信するメッセージキューを別々に設置する．メッセージキューはPub／Subデザインパターンで実装するか，またはAWS-SQSなどのツールを使用する． ・実装例 以下のリポジトリを参考にせよ． 参考：https://github.com/fedeoliv/microservices-transactions 04. データ永続化方式 ローカルトランザクション ・ローカルトランザクションとは 各サービスに独立したトランザクション処理が存在しており，一つのトランザクション処理によって，特定のサービスのデータベースのみを操作する設計方法．推奨である．このノートでは，ローカルトランザクションを用いたインフラストラクチャ層の連携を説明する． ・Sagaパターンとは ローカルトランザクションの時に，インフラストラクチャ層を実現する設計方法．上流サービスのデータベースの操作完了をイベントとして，下流サービスのデータベースの操作処理を連続的にコールする．ロールバック時には補償トランザクションが実行され，逆順にデータベースの状態が元に戻される． グローバルトランザクション ・グローバルトランザクションとは 分散トランザクションとも言う．一つのトランザクション処理が各サービスに分散しており，一つのトランザクション処理によて，各サービスのデータベースを連続的に操作する設計方法．非推奨である． 05. オブジェクトモデリング方式 イベントソーシング ・イベントソーシングとは ビジネスの出来事をモデリングし，データとして永続化する．現在の状態を取得する場合は，初期のデータに全ての出来事を適用する．CQRSと相性が良い． 参考： https://qiita.com/suin/items/f559e3dcde7c811ed4e1 https://martinfowler.com/articles/201701-event-driven.html ステートソーシング ・ステートソーシングとは ビジネスの現在の状態をモデリングし，データとして永続化する．過去の状態は上書きされる． 参考：http://masuda220.jugem.jp/?eid=435 06. 分散システムにおけるテスト CDCテスト：Consumer Drive Contract ・CDCテストとは サービスのコントローラがコールされてから，データベースの操作が完了するまでを，テストする．下流サービスのコールはモック化またはスタブ化する． 07. 運用 障害対策 ・サーキットブレイカーとは サービス間に設置され，他のサービスに連鎖する障害を吸収するプログラムのこと．下流サービスに障害が起こった時に，上流サービスにエラーを返してしまわないよう，直近の成功時の処理結果を返信する． 横断的な監視 ・分散トレーシングとは サービス間で分散してしまう各ログを，一意なIDで紐付ける方法． ・モニタリングサービス Datadogによる分散トレースの監視については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability_datadog_metrics.html "},"public/software/software_application_architecture_backend_domain_driven_design.html":{"url":"public/software/software_application_architecture_backend_domain_driven_design.html","title":"📖 ︎ドメイン駆動設計","keywords":"","body":"ドメイン駆動設計 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ドメイン駆動設計の全体像 戦略的設計の手順 戦略的設計では，ドメイン全体から境界付けられたコンテキストを明確にする． 参考：https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 ドメインエキスパートと話し合い，ドメイン全体の中からコアドメインとサブドメインを切り分ける． ドメインエキスパートの部署や業務フローの立ち位置によっては，同じ『単語』や『動詞』であっても，意味合い／定義づけが異なる場合がある．この時，それぞれを別々の名前からなるユビキタス言語として定義づける． ユビキタス言語を元に，境界付けられたコンテキストを定義づける． コンテキストマップを作成し，境界付けられたコンテキスト間の関係を明らかにする． 戦術的設計の手順 戦術的設計では，境界付けられたコンテキストをアーキテクチャやデザインパターンに落とし込む． ドメインエキスパートと話し合い，境界付けられたコンテキストに含まれる要件をヒアリングを行う．この時，ビジネスのルール／制約を十分にヒアリングする． 要件からユースケース図を作成する．この時，『システムが，〇〇を△△する．』と考えるとよい． 通常のオブジェクト指向分析／設計では，ユースケース図の後にクラス図を作成する．しかしドメイン駆動設計では，クラス図作成よりも先に集約の粒度を明確化するために，ユースケース図から『名詞』を抽出し，これを一つのドメインモデルとしたドメインモデル図を作成する．ドメインモデル図では，ビジネスのルール／制約を吹き出しに書き込む．各モデルのルール／制約に依存関係があり，データをセットで扱う必要があるような場合，これらを一つの集約として定義づけるとよい． 必要であればドメインエキスパートに再ヒアリングを行い，ドメインモデル図を改善する． ドメインモデル図を元に，クラス図を作成する．この時，モデルをエンティティや値オブジェクトを切り分けるようにする． アーキテクチャ（レイヤード型，ヘキサゴナル型，オニオン型，クリーンアーキテクチャ）を決め，クラス図を元にドメイン層を実装する． 運用後に問題が起こった場合，モデリングを修正する．場合によっては，デザインパターンに切り分ける． 02. 戦略的設計 ドメイン ・ドメインとは ビジネスモデル全体で見た時に，システム化の対象となる部分領域のこと．ビジネスモデル全体をいくつかのドメインを分割する方法として，一連の業務フローの中で，業務の担当者の属性が変化するタイミングに着目すると良い． ＊例＊ インターネット広告代理店の例．ビジネスモデルに基づく複数のドメインを示す．業務フローの担当者の変化として，まず問い合わせで注文を受けて広告アカウントを作成する『営業担当者』，制作した広告をアカウントに入稿する『制作担当者』，入稿された広告を運用して広告効果を高める『マーケティング担当者』，最後に広告の依頼者に料金を請求する『経理担当者』が挙げられる．これにより，インターネット広告代理店のビジネスモデルは，各担当者に対応するドメインに分割できる． 参考：https://labs.septeni.co.jp/entry/2021/04/15/130000 ＊例＊ 完全個室ジムを運営するハコジムの例．ビジネスモデルに基づく複数のドメインを示す．業務フローの担当者の変化として，まず個室ジムに適する物件を探す『物件担当者』，ジムのトレーナーを採用して会員に紹介する『採用担当者』，個室ジムの利用会員を獲得する『営業担当者』が挙げられる．これにより，ハコジムのビジネスモデルは，各担当者に対応するドメインに分割できる． 参考： https://hacogym.jp/ https://zenn.dev/hsshss/articles/e11efefc7011ab コアドメイン，サブドメイン，ドメインエキスパート ・コアドメイン，サブドメイン，ドメインエキスパートとは 各ドメインのドメインエキスパート（ビジネスルールに詳しい人）と，エンジニアが話し合いながら，ドメイン内の主要業務をコアドメイン，補助的な業務をサブドメインに分類する． 参考： https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 https://labs.septeni.co.jp/entry/2021/04/15/130000 ＊例＊ 完全個室ジムを運営するハコジムの例．ドメインのうちで，個室ジムドメインに基づくコアドメインとサブドメインを示す．コアドメインは予約ドメイン，それ以外はサブドメインとしている． 参考： https://hacogym.jp/ https://zenn.dev/hsshss/articles/e11efefc7011ab ＊例＊ ECサイトを運営するアスクルの例．ドメインのうちで，個人向け販売ドメイン（サイト名はLOHACO）に基づくサブドメインを示す．配送／注文／商品／ユーザ管理／在庫／受注をそれぞれサブドメインとしている（コアドメインは明言されていない）． 参考：https://speakerdeck.com/askul/ddd-and-clean-architecture-at-lohaco?slide=28 ユビキタス言語，境界付けられたコンテキスト ・ユビキタス言語とは ドメインエキスパート間で，特定の『単語』や『動詞』の意味合い／定義づけが異なる場合，これを別々の名前からなるユビキタス言語として定義づける． 参考：https://qiita.com/kmdsbng/items/bf415afbeec239a7fd63 ・境界付けられたコンテキストとは ドメインエキスパートの業務フローの立ち位置が異なれば，同じ『単語』や『動詞』であっても，異なる意味合い／定義づけのユビキタス言語が使用される．異なるユビキタス言語を元にして，境界付けられたコンテキストを定義する．この時，ユビキタス言語は，他の境界付けられたコンテキストでは通じないものであればあるほどよい．境界付けられたコンテキストそれぞれのユビキタス言語に合わせて，異なる名前でモデリングしていく．境界付けられたコンテキストを定義しない場合，異なるユビキタス言語をコアドメインやサブドメイン間で共有することとなり，それぞれの関心に無関係なデータを保持することになってしまう． ＊例＊ 本を販売するECサイトの例．コアドメインとサブドメインに基づいたユビキタス言語と境界付けられたコンテキストを示す．バイヤー（仕入れ）部，マーケティング部，在庫管理部のドメインエキスパートは，『本（商品）』という単語に対する意味合い／定義づけが異なる．そのため，それぞれを『本』『クーポン』『在庫』というユビキタス言語として定義でき，モデル名／データ名はそれぞれのユビキタス言語に合わせた名前になる．例えば，マーケの境界付けられたコンテキストでは，モデル名はCouponとなり，割引期間データを保持する必要があるが，仕入部や在庫部ではこのデータは不要である．一方，ISBNは全ての境界付けられたコンテキストのモデルに必要なデータである．境界付けられたコンテキストを定義しない場合，一つの商品モデルが全てのデータを保持することとなり，それぞれのドメインエキスパートが関心を持たないデータも保持することになってしまう． 参考：https://kenta-kosugi.medium.com/%E3%83%9E%E3%82%A4%E3%82%AF%E3%83%AD%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E4%B8%8A%E6%89%8B%E3%81%AA%E5%88%86%E5%89%B2-ff5bb01d1062 ＊例＊ 完全個室ジムを運営するハコジムの例．個室ジムドメインのコアドメインとサブドメインに基づく境界付けられたコンテキスト．認証コンテキスト，予約コンテキスト，顧客管理コンテキスト，銀行支払いコンテキスト，クレジットカード支払いコンテキストがある． 参考： https://hacogym.jp/ https://zenn.dev/hsshss/articles/e11efefc7011ab ＊例＊ 契約請求管理アプリを提供するアルプの例．コアドメインとサブドメインに基づいたユビキタス言語と境界付けられたコンテキストを示す．契約管理コンテキスト，商品管理コンテキスト，請求管理コンテキスト，がある．取り組みとして，週次でユビキタス言語の更新を行っている． 参考： https://note.com/alpinc/n/nab47ab9273c6 https://thealp.co.jp/ コンテキストマップ ・コンテキストマップとは 広義のドメイン全体の俯瞰する図のこと．コアドメイン，サブドメイン，境界付けられたコンテキストを定義した後，これらの関係性を視覚化する．異なるサブドメインの間で異なるユビキタス言語を使用する場合，境界付けられたコンテキストはサブドメインをまたがない．一方で，同じユビキタス言語を使用する場合，境界付けられたコンテキストは複数のサブドメインにまたがる．可能な限り，各境界付けられたコンテキストでは異なるユビキタス言語を使用し，境界付けられたコンテキストが複数のサブドメインにまたがないようにした方が良い（これ重要）． 参考：https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 ＊例＊ 完全個室ジムを運営するハコジムの例．個室ジムドメインのそれぞれの境界付けられたコンテキストに基づくモデリング．コアドメインの予約コンテキストとスマートロックコンテキストは，一つのマイクロサービスとして内製化している．一方で，それ以外の境界付けられたコンテキストは外製化している． 03. 戦術的設計 MVCからレイヤードアーキテクチャへの変遷 ・MVCと問題点 ドメイン駆動設計が考案される以前，MVCの考え方が主流であった．しかし，特にModelの役割が抽象的過ぎたため，開発規模が大きくなるにつれて，Modelに役割を集中させ過ぎてしまうことがあった． ・MVCからレイヤードアーキテクチャへの移行 ドメイン駆動設計が登場したことによって，MVCは発展し，M・V・Cそれぞれの役割がより具体的で精密になった．Modelの肥大化は，Modelがもつビジネスロジックをドメイン層，またCRUD処理をインフラストラクチャ層として分割することによって，対処された． DDDアーキテクチャ ・レイヤードアーキテクチャ 最初に考案された実現方法． 参考：https://www.amazon.co.jp/dp/4798121967/ref=cm_sw_r_tw_dp_ZD0VGXSNQMNZF7K1ME8J?_encoding=UTF8&psc=1 ・ヘキサゴナルアーキテクチャ 別名『ポートアンドアダプターアーキテクチャ』という．レイヤードアーキテクチャのインフラストラクチャ層に対して，依存性逆転を組み込んだもの．ドメイン層のオブジェクトは，ドメイン層の他のオブジェクトに依存する以外，何のオブジェクトにも外部ライブラリにも依存しない．逆に考えれば，これらに依存するものはドメイン層に置くべきではないと判断できる．本質的には，他の『オニオンアーキテクチャ』『クリーンアーキテクチャ』に同じである． 参考：https://www.amazon.co.jp/dp/B00UX9VJGW/ref=cm_sw_r_tw_dp_S20HJ24MHWTSED7T0ZCP ・オニオンアーキテクチャ レイヤードアーキテクチャのインフラストラクチャ層に対して，依存性逆転を組み込んだもの．ドメイン層のオブジェクトは，ドメイン層の他のオブジェクトに依存する以外，何のオブジェクトにも外部ライブラリにも依存しない．逆に考えれば，これらに依存するものはドメイン層に置くべきではないと判断できる．本質的には，他の『ヘキサゴナルアーキテクチャ』『クリーンアーキテクチャ』に同じである． 参考： https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/ https://little-hands.hatenablog.com/entry/2017/10/11/075634 ・クリーンアーキテクチャ レイヤードアーキテクチャのインフラストラクチャ層に対して，依存性逆転を組み込んだもの．ドメイン層のオブジェクトは，ドメイン層の他のオブジェクトに依存する以外，何のオブジェクトにも外部ライブラリにも依存しない．逆に考えれば，これらに依存するものはドメイン層に置くべきではないと判断できる．本質的には，他の『ヘキサゴナルアーキテクチャ』『オニオンアーキテクチャ』に同じである． 参考：https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html DDDデザインパターン ・DDDデザインパターン集 参考：https://www.ogis-ri.co.jp/otc/hiroba/technical/DDDEssence/chap1.html ドメインモデル ・コアドメインとサブドメインのモデル化 コアドメインとサブドメインを対象として，境界付けられたコンテキスト内のユビキタス言語に基づいてドメインモデルを設計する．コアドメインのシステムは内製である必要があるが，サブドメインのシステムは外製／内製のいずれでも問題ない． 参考：https://qiita.com/crossroad0201/items/875c5f76ed3794ed56c4 ・ドメインモデル図 クラス図よりも先に作成し，オブジェクト間のAggregation（集約）の粒度を明確にする．ユースケース図から『名詞』を抽出し，これをドメインモデルとして，クラス図と同じようにドメインモデル間の関係を表現する．ただし，クラス図とは異なり，クラスのメソッドは省略し，保持するデータのみに注目する．ドメインモデルを日本語で表現してよい．ドメインモデル図の作成手順については，以下を参考にせよ． 参考： https://www.eureka-moments-blog.com/entry/2018/12/29/145802 https://github.com/ShisatoYano/PlantUML/blob/master/DomainModelDiagram/DomainModelDiagram.pdf "},"public/software/software_application_architecture_backend_domain_driven_design_clean_architecture.html":{"url":"public/software/software_application_architecture_backend_domain_driven_design_clean_architecture.html","title":"📖 ︎クリーンアーキテクチャ","keywords":"","body":"クリーンアーキテクチャ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. アーキテクチャ概要 ・思想 DDDが適する機能要件の多いアプリケーションだけでなく，あらゆる種類のシステムに適用できる．クリーンアーキテクチャ原著の序文にて，著者は『私は，今まで色々な種類のシステムを作ってきたが，どのシステムもアーキテクチャもルールは同じだった．異なるシステムでも同じルールを共有する必要がある』というようなことを述べている． 参考：https://www.amazon.co.jp/dp/B07FSBHS2V ・構成 参考：https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html 02. インターフェース層（黄緑） コントローラ ・コントローラとは 入力／出力の処理時で，責務を以下のように分類できる．コントローラの責務をデザインパターンに切り分けても良い． 入力時／出力時 責務 補足 入力 インフラ層のルータから入力される認証情報を照合し，認証を実行する． 認証はインターフェース層あるいはユースケース層に実装する．参考：・https://github.com/little-hands/ddd-q-and-a/issues/173 インフラ層のルーターから入力されるパラメータをAPI仕様（必須，書式，など）と照らし合わせ，バリデーションを実行する． データの値がAPI仕様と比較して正しいかどうかを検証することに止まり，データの値が正しいかどうかの検証は，ユースケース層やドメイン層に実装する． インフラ層のルーターから入力されるパラメータをリクエストモデルに変換し，ユースケース層のインターラクターに入力する． リクエストモデル生成処理で，ドメイン層への依存が必要になる．リクエストモデル生成処理を切り分け，ユースケース層に置くと，コントローラがドメイン層に依存することを防げる． 出力 ユースケース層のインターラクターから出力されるレスポンスモデルを，JSONデータとしてフロントエンドにに返信する． バックエンドをAPIとして用いる場合，プレゼンターは不要である． ユースケース層のインターラクターから出力されるプレゼンターをビューモデルに変換し，バックエンドのテンプレートエンジンに出力する． バックエンドでテンプレートエンジンを用いてHTMLを生成する場合，プレゼンターが必要である． プレゼンター ・プレゼンターとは バックエンドからフロントエンドに出力するため，．バックエンドがテンプレートエンジンを持つフレームワークの時に，バックエンドからフロントエンドのロジックを分離するために用いる．一方で，バックエンドとフロントエンドを完全に分離し，バックエンドがJSONデータを返信するAPIとして機能する場合や，フロントエンドにテンプレートエンジンを組み込む場合は，プレゼンターを用いない．補足として，アウトプットバウンダリはプレゼンターのインターフェースのため，プレゼンターを用いなければ，アウトプットバウンダリも用いない． 参考： https://izumisy.work/entry/2019/12/12/000521 https://codezine.jp/article/detail/9749 バリデーションパターン ・バリデーションパターンとは デザインパターンの一つ．インターフェース層のバリデーションでは，データの必須や書式を検証する． ＊実装例＊ 日時データのフォーマットを検証する． validate($dateTime)) { return false; } return true; } } 03. ユースケース層（赤） 処理フロー インターフェース層からユースケース層までの処理の流れを示す． 参考：http://www.plainionist.net/Implementing-Clean-Architecture-Controller-Presenter/ インターラクター ・インターラクターとは 入力／出力の処理時で，責務を以下のように分類できる．ユースケースごとに異なるInteractorクラスを定義する方法と，全てのユースケースを責務としてもつInteractorクラスを定義する方法がある．また，Interactorインターフェースを用意して，インターフェース層のコントローラはこれを経由して，実装Interactorクラスのメソッドをコールするようにする． 入力時／出力時 責務 補足 入力 プレゼンテーション層のコントローラから入力されるリクエストパラメータを，システム上のルールと照らし合わせてバリデーションを実行する． データの値がシステム上あり得ないかどうかを検証する．ビジネス上あり得ない値かどうかはドメイン層にSpecificationパターンとして実装する． ドメイン層のメソッドを組み合わせて，ユーザの要求に対するシステムの振舞（ユースケース）を具現化する． プレゼンテーション層のコントローラから入力されるリクエストパラメータを，ドメイン層のインターフェースリポジトリに渡せるドメインモデルに変換する． 出力 ドメイン層のインターフェースリポジトリから出力されるドメインモデルをレスポンスモデルに変換し，インターフェース層のコントローラに出力する． バックエンドをAPIとして用いる場合，プレゼンターは不要である． ドメイン層のインターフェースリポジトリから出力されるドメインモデルをレスポンスモデルを経てプレゼンターに変換し，インターフェース層のコントローラに出力する． バックエンドでテンプレートエンジンを用いてHTMLを生成する場合，プレゼンターが必要である． ・ユースケースとメソッド名 インターラクターでは，ドメイン層を組み合わせてシステムの振舞（ユースケース）を具現化する．そのため，メソッド名はユースケースを適切に表現した自由な英単語を用いる．Laravelの基本的なメソッド名（index，store，create，show，update，）が参考になる．CREATE処理とUPDATE処理をSAVE処理としてまとめてもよい． メソッド名 引数型 返却値型 処理内容 indexFoo indexFooRequest indexFooResponse showFoo showFooRequest showFooResponse createFoo createFooRequest createFooResponse updateFoo updateFooRequest updateFooResponse saveFoo（upsertFoo） saveFooRequest（upsertFooRequest） saveFooResponse（upsertFooResponse） リポジトリのfindメソッドをコールして重複確認を実行し，その結果に応じてcreateメソッドまたはupdateメソッドをコールする．参考：https://github.com/little-hands/ddd-q-and-a/issues/241 deleteFoo deleteFooRequest deleteFooResponse ・ユースケース図 ユースケース図については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_php_object_orientation_analysis_design_programming.html ＊実装例＊ バックエンドをAPIとして用いる場合，プレゼンターは不要となる．この場合を示す． fooRepository = $fooRepository; } /** * @param CreateFooRequest $createFooRequest * @return CreateFooResponse */ public function createFoo(CreateFooRequest $createFooRequest): CreateFooResponse { $foo = $this->fooRepository->create( new Bar($createFooRequest->bar), new Baz($createFooRequest->baz) ); // 何らかの処理 } } fooRepository = $fooRepository; } /** * @param CreateFooRequest $createFooRequest * @return CreateFooResponse */ public function createFoo(CreateFooRequest $createFooRequest): CreateFooResponse { $foo = $this->fooRepository->create( new Bar($createFooRequest->bar), new Baz($createFooRequest->baz) ); // 何らかの処理 } /** * @param GetFooRequest $getFooRequest * @return GetFooResponse */ public function getFoo(GetFooRequest $getFooRequest): GetFooResponse { $foo = $this->fooRepository->findById( new FooId($getFooRequest->id) ); // 何らかの処理 } /** * @param UpdateFooRequest $updateFooRequest * @return UpdateFooResponse */ public function updateFoo(UpdateFooRequest $updateFooRequest): UpdateFooResponse { $foo = $this->fooRepository->update( new FooId($updateFooRequest->id), new Bar($updateFooRequest->bar), new Baz($updateFooRequest->baz) ); // 何らかの処理 } /** * @param DeleteFooRequest $deleteFooRequest * @return DeleteFooResponse */ public function deleteFoo(DeleteFooRequest $deleteFooRequest): DeleteFooResponse { $foo = $this->fooRepository->delete( new FooId($deleteFooRequest->id) ); // 何らかの処理 } } インプットバウンダリ ・インプットバウンダリとは インターラクターのインターフェースのこと．上位レイヤーにあるコントローラは，インターラクターインタフェースに依存する． ＊実装例＊ アウトプットバウンダリ ・アウトプットバウンダリとは 上位レイヤーのプレゼンターのインターフェースのこと．インターラクターは，レスポンスモデルではなく．アウトプットバウンダリをインターフェース層に出力する．ただし，アプリケーションをAPIとして用いる場合は，プレゼンターとアウトプットバウンダリが不要になり，これに伴い，インターラクターはレスポンスモデルを返却するようにする． リクエストモデル（インプットデータ） ・リクエストモデルとは インターフェース層のコントローラから入力されるリクエストパラメータをユースケース層に入力する時に，その入力構造を定義する．インターラクターのメソッドごとにリクエストモデルを用意するとよい． fooId = $fooId; $this->fooName = $fooName; } } レスポンスモデル（アウトプットデータ） ・レスポンスモデルとは ユースケース層のインターラクターから出力されるドメインモデルをインターフェース層に出力する時に，その出力構造を定義する．インターラクターのメソッドごとにレスポンスモデルを用意するとよい．またコントローラにて，フレームワーク依存のJSONレスポンスメソッドにレスポンスモデルを渡せるよう，クラス自身の構造を変換するメソッドを持たせるとよい．もし，クラス自身を渡して問題ないJSONレスポンスメソッドであれば，これは不要である． ＊実装例＊ ユースケース層のindexメソッドに対応するレスポンスモデル．JSONレスポンスメソッドが配列構造を引数に受け付けるため，これに渡せるよう，自身を配列構造に変換するメソッドを持たせる． foos = $foos; } /** * @return array */ public function toArray(): array { return [ \"foos\" => $this->foos ]; } } ユースケース層のcreateメソッドに対応するレスポンスモデル． fooId = $fooId; $this->fooName = $fooName; } /** * @return array */ public function toArray(): array { return [ \"id\" => $this->fooId, \"name\" => $this->fooName ]; } } アプリケーションサービス ・アプリケーションサービスとは ユースケース層において，他のオブジェクトを対象とした汎用的な振る舞いロジックを切り分けたもの．アプリケーションサービスは，他のオブジェクトにロジックをメソッドとして提供するだけで，自身の状態を変化させるメソッドは持たせないようにする．ちなみに，『サービス』の概念は全てのレイヤーに存在する．特定の機能を提供するアプリケーションをサービスとみなして連携すれば，マイクロサービスアーキテクチャにもなる． ・通知処理 ＊実装例＊ エンティティへの通知処理をアプリケーションサービスとして切り分ける． message = $message; } public function notify() { // SlackのAPIにメッセージを送信する処理 } } これを，ユースケース層でコールするようにする． notify(); } } 04. ドメイン層（黄） エンティティ ・エンティティとは 後述の説明を参照せよ． 値オブジェクト ・値オブジェクトとは 後述の説明を参照せよ． ドメインイベント ・ドメインイベントとは ドメイン層の中で，ビジネス的な『出来事』をモデリングしたもの．エンティティや値オブジェクトは『物』をモデリングするため，着眼点が異なる．エンティティデザインパターンの一つである『Pub／Subパターン』の概念を用いて，ドメインイベントとイベントリスナー（イベントハンドラー）の関連を表現する． Type Code（標準型） ・Type Codeとは Type Codeは概念的な呼び名で，実際は，標準的なライブラリとして利用できるEnumクラスに相当する．一意に識別する必要がないユビキタス言語の中でも，特に『区分』や『種類』などは，値オブジェクトとしてではなく，Enumクラスとしてモデリング／実装する．ただし，類似するパターンとして値オブジェクトのディレクトリ内に配置しても良い． ・色 ＊実装例＊ [\"name\" => \"レッド\"], self::BLUE => [\"name\" => \"ブルー\"] ]; /** * 値 */ private $value; /** * 色名 */ private $name; // インスタンス化の時に，『色の区分値』を受け取る． public function __construct(string $value) { // $kbnValueに応じて，色名をnameデータにセットする． $this->value = $value; $this->name = static::$set[$value][\"name\"]; } /** * 値を返却します． */ public function value(): int { return $this->value; } /** * 色名を返却します． */ public function name(): string { return $this->name; } } ・性別 ＊実装例＊ [\"name\" => \"男性\"], self::WOMAN => [\"name\" => \"女性\"], self::UNKNOWN => [\"name\" => \"不明\"], ]; /** * 値 */ private $value; /** * 名前 */ private $name; public function __construct($value) { $this->value = $value; $this->name = static::$set[$value][\"name\"]; } /** * 値を返却します． */ public function value(): int { return $this->value; } /** * 名前を返却します． */ public function name() { return $this->name; } } ・年号 ＊実装例＊ [\"name\" => \"明治\"], self::TAISHO => [\"name\" => \"大正\"], self::SHOWA => [\"name\" => \"昭和\"], self::HEISEI => [\"name\" => \"平成\"], self::REIWA => [\"name\" => \"令和\"], self::SEIREKI => [\"name\" => \"西暦\"], ]; private static $ymd = [ self::MEIJI => [ \"start\" => [ \"year\" => 1868, \"month\" => 1, \"day\" => 25, ], \"end\" => [ \"year\" => 1912, \"month\" => 7, \"day\" => 29, ], ], self::TAISHO => [ \"start\" => [ \"year\" => 1912, \"month\" => 7, \"day\" => 30, ], \"end\" => [ \"year\" => 1926, \"month\" => 12, \"day\" => 24, ], ], self::SHOWA => [ \"start\" => [ \"year\" => 1926, \"month\" => 12, \"day\" => 25, ], \"end\" => [ \"year\" => 1989, \"month\" => 1, \"day\" => 7, ], ], self::HEISEI => [ \"start\" => [ \"year\" => 1989, \"month\" => 1, \"day\" => 8, ], \"end\" => [ \"year\" => 2019, \"month\" => 4, \"day\" => 30, ], ], self::REIWA => [ \"start\" => [ \"year\" => 2019, \"month\" => 5, \"day\" => 1, ], \"end\" => [ \"year\" => 9999, \"month\" => 12, \"day\" => 31, ], ], ]; /** * 値 * * @var string */ private $value; /** * 年号名 * * @var string */ private $name; /** * 値を返却します * * @return string */ public function value(): string { return $this->value; } /** * @param $value */ public function __construct($value) { $this->value = $value; $this->name = static::$set[$value][\"name\"]; } /** * 年号名を返却します * * @return string */ public function name() { return $this->name; } } ドメインサービス ・ドメインサービスとは ドメイン層のエンティティに持たせるとやや不自然で，他のドメインオブジェクトを対象とした振る舞いロジックを切り分けたもの．ドメインサービスは，他のドメインオブジェクトにロジックをメソッドとして提供するだけで，自身の状態を変化させるメソッドは持たせないようにする．全てのメソッドを一つのドメインサービスにまとめて管理するよりも，動作の種類ごとに分けて管理した方が良い．この時，エンティティのビジネスロジックがドメインサービスに実装されすぎないように注意する．ちなみに，ドメイン層でリポジトリを用いることを嫌って，ドメインサービスの処理をユースケース層のアプリケーションサービスで定義しても問題ない． 参考： https://github.com/little-hands/ddd-q-and-a/issues/159 https://www.amazon.co.jp/dp/B082WXZVPC https://codezine.jp/article/detail/10318 ・重複確認 ドメイン層のリポジトリを用いて，該当の名前のエンティティがDBに存在するかどうかを検証する．ドメインサービスではなく，アプリケーションサービスとして定義しても良い． 参考： https://stackoverflow.com/questions/45007667/cqrs-ddd-how-to-validate-products-existence-before-adding-them-to-order https://www.amazon.co.jp/dp/B082WXZVPC https://github.com/little-hands/ddd-q-and-a/issues/573 ＊実装例＊ fooRepositoy = $fooRepositoy; } /** * エンティティがすでに存在しているかどうかを判定します． * * @param Foo $foo * @return bool */ public function exists(Foo $foo): bool { $foo = $this->fooRepository ->findByName($foo->name()); return $foo !== null; } } ・認可 ドメイン層のリポジトリを用いて，該当のIDのエンティティに対してアクセス可能かを検証する．ドメインサービスではなく，アプリケーションサービスとして定義しても良い． 参考： https://lessthan12ms.com/authorization-and-authentication-in-clean-architecture.html https://medium.com/@martinezdelariva/authentication-and-authorization-in-ddd-671f7a5596ac https://github.com/lezhnev74/ema/blob/master/src/Domain/Note/Commands/ModifyNote/ModifyNoteAuthorizer.php https://github.com/little-hands/ddd-q-and-a/issues/121 ＊実装例＊ fooRepositoy = $fooRepositoy; } /** * 更新処理を実行可能かを検証します． * * @param FooId $fooId * @param UserId $userId * @return bool */ public function canUpdateById(FooId $fooId, UserId $userId): bool { return $this->fooRepository ->findById($fooId) ->userId ->equals($userId); } } ・ドメイン例外 ドメイン層の例外処理をまとめた例外クラス． ＊実装例＊ Specificationパターン ・Specificationパターンとは デザインパターンの一つ．責務として，バリデーション，検索条件入力データを持つ．これらをエンティティや値オブジェクトのメソッド内部に持たせた場合，肥大化の原因となり，また埋もれてしまうため，可読性と保守性が悪い．そこで，こういったビジネスルールをSpecificationオブジェクトとして切り分けておく． ・ビジネスルールのバリデーション 真偽値メソッド（isFooメソッド）のように，オブジェクトのデータを検証して、仕様を要求を満たしているか、何らかの目的のための用意ができているかを調べる処理する． ＊実装例＊ isX) return false; if (!$entity->isY) return false; if (!$entity->isZ) return false; return true; } } ・検索条件入力データ リクエストのパスパラメータとクエリパラメータを引数として，検索条件のオブジェクトを生成する．ビジネスルールのバリデーションを行うSpecificationクラスと区別するために，Criteriaオブジェクトという名前としても用いられる． ＊実装例＊ id = $array[\"id\"]; } if (isset($array[\"name\"])) { $criteria->id = $array[\"name\"]; } if (isset($array[\"email\"])) { $criteria->id = $array[\"email\"]; } return $criteria; } } 04-02. ドメイン層のロジックの流出 ドメイン貧血症 ・ドメイン貧血症とは ドメイン層のドメインオブジェクトがビジネスロジックをほとんど持たない状態になっていること． ＊実装例＊ ドメインオブジェクトであるエンティティがゲッターとセッターしか持っていない．これは，ドメイン貧血症である． userId = $userId; $this->userName = $userName; } /** * @return UserId */ public function id() { return $this->userId; } /** * @return UserName */ public function userName() { return $this->userName; } } ドメイン層のドメインサービスへの流出 ドメイン層のロジックをドメインサービスに切り分けすぎると，同じくドメイン層のエンティティや値オブジェクトに実装するドメインロジックがなくなってしまい，ドメイン貧血症になる．そのため，ドメインサービス層の構築は控えめにする． ユースケース層のアプリケーションサービスへの流出 ドメイン層のロジックをユースケース層のユースケース層に実装してしまうと，ドメイン層のエンティティや値オブジェクトに実装するドメインロジックがなくなってしまい，ドメイン貧血症になる．ドメイン層とユースケース層のアプリケーションサービスのいずれに実装するべきかは，モデリングの対象がビジネスルールに基づくものなのか，システム利用者のユースケースに基づくものなのかである． 参考：https://www.amazon.co.jp/dp/B082WXZVPC 05-02. エンティティ エンティティとは 責務として，ビジネスのルールや制約の定義を持ち，値オブジェクトとは区別される．エンティティの責務をデザインパターンに切り分けても良い． 識別可能 ・識別可能とは オブジェクトが識別子（例：IDなど）を持ち，他のオブジェクトと同じ属性をもっていても，区別される．この識別子は，データベースのプライマリキーに対応している． type = $type; $this->name = $name; $this->number = $number; $this->priceVO = $priceVO; $this->colorVO = $colorVO; } /** * 犬用おもちゃ名（色）を返却します． * * @return string */ public function nameWithColor() { return sprintf( \"%s（%s）\", $this->name->value(), $this->colorVO->name() ); } } 識別子による等価性検証 ・識別子による等価性検証とは 等価性検証用のequalsメソッドを持つ．保持する識別子が，対象のエンティティと同じ場合，同一のものと見なされる． ・等価性の検証方法 全てのエンティティに等価性の検証メソッドを持たせると可読性が低い．そこで，全てのエンティティに等価性検証用のequalsメソッドを持たせることをやめ，継承元の抽象クラスのエンティティにこれを定義するとよい． id->equals($entity->id()); // IDオブジェクトの等価性 } /** * IDクラスを返却します． */ public function id(): Id { return $this->id; } } ・複合主キーへの対応（PHPでは不要） 以降の説明はJavaについて適用されるため，PHPでは不要である．複合主キーを持つオブジェクトに対応するために，主キーとなる方のオブジェクト側に，equalsメソッドとhashメソッドを定義する．これにより，言語標準搭載のequalsメソッドとhashメソッドをオーバーライドし，異なるセッションに渡ってオブジェクトを比較できるようにする．これらを定義しないと，オーバーライドされずに標準搭載のメソッドが用いられる．標準搭載のメソッドでは，異なるセッションに渡ったオブジェクトの比較では，必ず異なるオブジェクトであると判定してしまう． ＊実装例＊ PHPでは不要であるが，参考までに，PHPで実装した． id = $id; } /** * ハッシュ値を返却します． * * NOTE: 複合主キーを持つオブジェクトの等価性を正しく検証するために，標準の関数をオーバーライドします． * * @return string */ public function hash(): string { return $this->id; } /** * オブジェクトの等価性を検証します． * * NOTE: 複合主キーを持つオブジェクトの等価性を正しく検証するために，標準の関数をオーバーライドします． * * @param Id $id * @return bool */ public function equals(Id $id): bool { return ($id instanceof $this || $this instanceof $id) // IDオブジェクトのデータ型の等価性 && $this->hash() == $id->hash(); // ハッシュ値の等価性 } } データの可変性／不変性 ・可変性／不変性の実現方法（Mutable／Immutable） エンティティのデータは可変／不変データのいずれであってもよい．ただし，そもそもオブジェクトは不変である方が望ましいため，可変的なデータは最小限にする．変化させても問題ないプロパティに対してはセッターを定義し，不変的なデータに対してはコンストラクタインジェクションのみを許可するようにする．もちろん，セッター内ではドメインルールのバリデーションを実行する．不変性の実現方法については，後述の説明を参考にせよ． 05-03. 値オブジェクト 値オブジェクトとは 責務として，ビジネスのルールや制約の定義を持ち，エンティティと区別される．金額，数字，電話番号，文字列，日付，氏名，色などのユビキタス言語に関するデータと，一意で識別できるデータ（例えば，$idデータ）を持つ． 識別不可能 ・識別不可能とは 一意に識別できるデータをもたず，対象のユビキタス言語に関するデータをメソッドを持つ ・金額 金額データの計算をInteractor内処理やエンティティ内メソッドで行うのではなく，金額計算を行う値オブジェクトのメソッドとして分割する． ＊実装例＊ amount = (float) $amount; } /** * 金額を返却します * * @return float */ public function amount() { return $this->amount; } /** * 単位を返却します * * @return string */ public function unit() { return \"円\"; } /** * 足し算の結果を返却します * * @param Money $price * @return $this */ public function add(Money $price) { return new static($this->amount + $price->amount); } /** * 引き算の結果を返却します * * @param Money $price * @return $this */ public function substract(Money $price) { return new static($this->amount - $price->amount); } /** * 掛け算の結果を返却します * * @param Money $price * @return $this */ public function multiply(Money $price) { return new static($this->amount * $price); } } ・所要時間 所要時間データの計算をInteractorクラス内処理やエンティティ内メソッドで行うのではなく，所要時間計算を行う値オブジェクトのメソッドとして分割する． ＊実装例＊ distance = $distance; } /** * 徒歩または車のどちらを用いるかを判定します * * @return bool */ public function isMinuteByWalking(): bool { if ($this->distance * 1000 / self::WALKING_SPEED_PER_MINUTE distance * 1000 / self::WALKING_SPEED_PER_MINUTE; return ceil($minute); } /** * 車での所用時間を計算します * * @return float */ public function minuteByCar(): float { $minute = $this->distance * 1000 / self::CAR_SPEED_PER_MINUTE; return ceil($minute); } } ・住所 郵便番号データとその処理を値オブジェクトとして分割する． ＊実装例＊ city = $city; $this->zip = $zip; $this->address = $address; } /** * 郵便番号を生成し，返却します * * @return string */ public function zip() { return sprintf( \"〒%s-%s\", substr($this->zip, 0, 3), substr($this->zip, 3) ); } /** * 住所を生成し，返却します * * @return string */ public function address(): string { return sprintf( \"%s%s%s\", $this->city->prefecture->name ?? '', $this->city->name ?? '', $this->address ?? '' ); } } ・氏名 氏名，性別，データとその処理を値オブジェクトとして分割する． ＊実装例＊ lastName = $lastName; $this->firstName = $firstName; $this->lastKanaName = $lastKanaName; $this->firstKanaName = $firstKanaName; } /** * 氏名を作成します． */ public function fullName(): string { return $this->lastName . $this->firstName; } /** * カナ氏名を作成します． */ public function fullKanaName(): string { return $this->lastKanaName . $this->firstKanaName; } } データの不変性（Immutable） ・不変性の実現方法 値オブジェクトは不変的であり，インスタンスとして生成されて以降，データは変更されない．オブジェクトの不変性を実現するために，オブジェクトにセッターを定義しないようにし，データの設定にはconstructメソッドだけを用いるようにする． ＊実装例＊ propertyA = $propertyA; $this->propertyB = $propertyB; $this->propertyC = $propertyC; } } ・セッターでは不変的にならない理由 ＊実装例＊ Test01クラスインスタンスの$property01データに値を設定するためには，インスタンスからセッターを呼び出す．セッターは何度でも呼び出せ，その度にデータの値を上書きできてしまう． setProperty01(\"データ01の値\"); $test01->setProperty01(\"新しいデータ01の値\"); Test02クラスインスタンスの$property02データに値を設定するためには，インスタンスを作り直さなければならない．つまり，以前に作ったインスタンスの$property02の値は上書きできない．セッターを持たせずに，constructメソッドだけを持たせれば，不変的なオブジェクトとなる． ・過剰なゲッターへの対処法 不変的なデータはゲッターを用いなければアクセスできない．そのため，値オブジェクトにプロパティ値を返却するだけのゲッターが量産され，ファイルの見通しが悪くなってしまう．そこで，例えばPHPでは，マジックメソッドの__getメソッドを用いて，ゲッターの実装を省略できる．全ての値オブジェクトの基底クラスに，『コールされたゲッターがクラス内に存在していなければ，動的にプロパティにアクセスして返却する』処理を持った__getメソッドを定義しておく．すると，マジックメソッドのオーバーライド機能により，自身で定義した__getメソッドが代わりにコールされるようになり，ゲッターを定義する必要がなくなる． {$name}; } } class Foo { use ImmutableTrait; private $bar; public function __constructor($bar) { $this->bar = $bar } } $foo = new Foo() $foo->bar // __getメソッドが代わりにコールされ，プロパティ値が返却される． 概念的な統一体 交換可能性 オブジェクトが新しくインスタンス化された場合，以前に同一オブジェクトから生成されたインスタンスから新しく置き換える必要がある． 属性による等価性 ・属性による等価性検証とは 等価性を検証するメソッドを持つ．保持する全ての属性が，対象の値オブジェクトと同じ場合，同一のものと見なされる． ・等価性の検証方法 ＊実装例＊ 属性を一つだけ保持する場合，一つの属性のみを検証すれば良いため，以下の通りとなる． value = $value; } /** * @return string */ public function value(): string { return $this->value; } /** * 値オブジェクトの等価性を検証します． * * @param ValueObject $VO * @return bool */ public function equals(ValueObject $VO): bool { // 単一の属性を対象とする． return $this->value() === $VO->value(); } } 属性を複数保持する値オブジェクトの場合，全ての属性を検証する必要があるため，以下の通りとなる． paymentType = $paymentType; $this->contactMail = $contactMail; $this->price = $price; } /** * 値オブジェクトの等価性を検証します． * * @param ValueObject $VO * @return bool */ public function equals(ValueObject $VO): bool { // 複数の属性を対象とする． return $this->paymentType->value() === $VO->paymentType->value() && $this->contactMail->value() === $VO->contactMail->value() && $this->price->value() === $VO->price->value(); } } 全ての値オブジェクトに等価性の検証メソッドを持たせると可読性が低い．そこで，継承元の抽象クラスの値オブジェクトに定義するとよい．その時は，保持している属性を反復的に検証できるように実装するとよい． $value) { if ($this->__get($key) !== $VO->__get($key)) { return false; } } return true; } } 05-04. ルートエンティティとトランザクション ルートエンティティ ・ルートエンティティとは エンティティや値オブジェクトからなる集約の中で，最終的にユースケース層へレスポンスされる集約を，『ルートエンティティ』という． ＊実装例＊ dogToy = $dogToy; $this->dogFood = $dogFood; } /** * 犬用おもちゃを返却します． * * @return DogToy */ public function getDogToy(): DogToy { return $this->dogToy; } /** * 犬えさを返却します． * * @return DogFood */ public function getDogFood(): DogFood { return $this->dogFood; } } ・集約とは データをセットで扱う必要があるエンティティのまとまりのこと．依存関係の観点からみた集約については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_php_object_orientation_class.html トランザクションとの関係性 インフラ層のリポジトリでは，ルートエンティティの単位で，データの書き込み／読み出しのトランザクション処理を実行する．ルートエンティティを定義づける時の注意点として，集約の単位が大き過ぎると，一部分のエンティティのみトランザクションの対象とすれば良い処理であるのにも関わらず，ルートエンティティ全体まで対象としなければならなくなる．そのため，ビジネスロジックとしてのまとまりと，トランザクションとしてのまとまりの両方から，ルートエンティティの単位を定義づけるとよい． 参考：https://qiita.com/mikesorae/items/ff8192fb9cf106262dbf#%E5%AF%BE%E7%AD%96-1 06. インフラ層（青） インフラ層の依存性逆転 ・DIP（依存性逆転の原則）とは 参考：https://hiroki-it.github.io/tech-notebook-gitbook/?q=%E4%BE%9D%E5%AD%98%E6%80%A7%E9%80%86%E8%BB%A2 ・発表スライド リポジトリ ・リポジトリパターンとは デザインパターンの一つ．一例として，以下のメソッドを持つ．具体的な実装については，インターフェースリポジトリの実装を参考にせよ．CREATE処理とUPDATE処理をSAVE処理としてまとめてもよい． 参考： https://codewithshadman.com/repository-pattern-csharp/ https://sf9v.github.io/posts/generating-the-repository-pattern-in-go/#introduction https://terasolunaorg.github.io/guideline/public_review/ImplementationAtEachLayer/DomainLayer.html#repository-interface-label メソッド名 引数型 返却値型 処理内容 findById Id型 ドメインモデル型 ルートエンティティののドメインモデルを取得する． findAll なし ドメインモデル型を持つ配列 全てのドメインモデルを取得する． findAllByCriteria Criteria型 ドメインモデル型を持つ配列 条件に合致した全てのドメインモデルを取得する． create ルートエンティティのドメインモデル型 void型 ルートエンティティのドメインモデルを作成する． update ルートエンティティのドメインモデル型 void型 ルートエンティティのドメインモデルを更新する． save（upsert） ルートエンティティのドメインモデル型 void型 ルートエンティティのドメインモデルを作成／更新する．SELECT文のIN句を用いて，同じ識別子のエンティティをDBから取得できるかどうかを確認する．取得できない場合は，更新処理を実行する．参考：・https://github.com/little-hands/ddd-q-and-a/issues/241・https://github.com/little-hands/ddd-q-and-a/issues/129 delete Id型 void型 ルートエンティティのドメインモデルを削除する． ・他の類似するデザインパターンとの比較 デザインパターン 駆動の種類 ドメインモデルとテーブルの関連度合い 採用ライブラリ例 適所 補足 Active Record データベース駆動 ・非常に強い．・手順としてテーブル設計が先にあり，一つのドメインモデルが一つのテーブルに対応している．・テーブル間のリレーションシップによって，ドメインモデル間の依存関係が決まる． ・Eloquent（PHP）・Active Record（Ruby）・Hibernate（Java） ビジネスロジックが複雑でないアプリケーション参考：https://www.informit.com/articles/article.aspx?p=1398618&seqNum=3 DataMapperパターンと同じく，ORMの実装方法の一つである．参考：https://culttt.com/2014/06/18/whats-difference-active-record-data-mapper/ Data Mapper ドメイン駆動 ・弱い・Entityマネージャを用いて，ドメインモデルをDBに永続化する． Doctrine ビジネスロジックが複雑なアプリケーション参考：https://www.informit.com/articles/article.aspx?p=1398618&seqNum=3 ActiveRecordパターンと同じく，ORMの実装方法の一つである．参考：https://culttt.com/2014/06/18/whats-difference-active-record-data-mapper/ Repository ドメイン駆動 ・弱い・手順としてドメインモデルの依存関係の設計が先にあり，テーブル間の関係性は自由である．一つのドメインモデルが複数のテーブルを参照してもよい． ビジネスロジックが複雑なアプリケーション DB，RDMS，NoSQL，なんでもでもよい． なし なし 非常に弱い DBファサード ・実装リポジトリ リポジトリパターンを用いる．責務として，DBに対してデータの書き込み／読み出しのトランザクション処理を実行する．トランザクションはルートエンティティを単位として定義する必要があるため，リポジトリも同じくルートエンティティを単位として定義づけることになる．そのため，引数の型はルートエンティティのドメインモデル型になる．リポジトリではルートエンティティを意識して実装する必要がある一方で，DBのどのテーブルにデータが存在しているかを問わない．これにより，ルートエンティティとDBテーブルを別々に設計できる．ルートエンティティとトランザクションの関係性については，前述の説明を参考にせよ．DBテーブル設計については以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_middleware_database.html ・インターフェースリポジトリ 依存性逆転の原則を導入する場合に，ドメイン層にインターフェースリポジトリを配置する．インフラ層の実装リポジトリクラスと対応関係にある．実装リポジトリについては，後述の説明を参考にせよ． ＊実装例＊ ・DBに対する書き込み責務（Create，Update，Delete） DBに対する書き込み操作を行う． GET／POSTによって，ユースケース層から値が送信される． ファクトリによって，送信された値からエンティティや値オブジェクトを作成する．さらに，それらからルートエンティティを作成する． リポジトリにルートエンティティを渡す． ルートエンティティをレコードとしてDBに挿入する． 参考： https://www.doctrine-project.org/projects/doctrine-orm/en/2.8/reference/query-builder.htm https://github.com/doctrine/dbal/blob/2.12.x/lib/Doctrine/DBAL/Query/QueryBuilder.php ＊実装例＊ CREATE処理のため，DoctrineのQueryBuilderクラスのinsertメソッドを実行する． createQueryBuilder(); // SQLを定義する． $query->insert(\"dog_toy_table\") ->values([ // ルートエンティティの要素をカラム値として設定する．（IDはAutoIncrement） \"name\" => $dogToy->getName()->value(), \"type\" => $dogToy->getType()->value(), \"price\" => $dogToy->getPriceVO()->value(), \"color\" => $dogToy->getColorVO()->value(), ]); } } UPDATE処理のため，DoctrineのQueryBuilderクラスのupdateメソッドを実行する． createQueryBuilder(); // SQLを定義する． $query->update(\"dog_toy_table\", \"dog_toy\") // ルートエンティティの要素をカラム値として設定する． ->set(\"dog_toy.name\", $dogToy->getName()->value()) ->set(\"dog_toy.type\", $dogToy->getType()->value()) ->set(\"dog_toy.price\", $dogToy->getPriceVO()->value()) ->set(\"dog_toy.color\", $dogToy->getColorVO()->value()) ->where(\"dog_toy.id\", $dogToy->getId()->value(); return $query->getResult(); } } DELETE処理（論理削除）のため，DoctrineのQueryBuilderクラスのupdateメソッドを実行する． createQueryBuilder(); // SQLを定義する． $query->update(\"dog_toy_table\", \"dog_toy\") // 論理削除 ->set(\"dog_toy.is_deleted\", FlagConstant::IS_ON) ->where(\"dog_toy.id\", $dogToy->getId()->value(); return $query->getResult(); } } ・DBに対する読み出し責務（Read） DBに対する書き込み操作を行う． ユースケース層から集約がリクエストされる． DBからレコードを取得する． ファクトリによって，レコードからエンティティや値オブジェクトを作成する． リポジトリからルートエンティティを返却し，ユースケース層に渡す． 参考： https://www.doctrine-project.org/projects/doctrine-orm/en/2.8/reference/query-builder.htm https://github.com/doctrine/dbal/blob/2.12.x/lib/Doctrine/DBAL/Query/QueryBuilder.php ＊実装例＊ READ処理のため，DoctrineのQueryBuilderクラスのselectメソッドを実行する． createQueryBuilder(); // SQLを設定する． $query->select( \"dog_toy.id AS dog_toy_id\", \"dog_toy.name AS dog_toy_name\", \"dog_toy.type AS dog_toy_type\", \"dog_toy.price AS dog_toy_price\", \"dog_toy.color AS dog_toy_color\" ) ->from(\"dog_toy_table\", \"dog_toy\") // 論理削除されていないもののみ ->where(\"dog_toy.is_deleted\", FlagConstant::IS_OFF) ->getQuery(); // SQLを実行する． $entities = $query->getResult(); $dogToys = []; foreach($entities as $entity){ // 取得したエンティティをドメインモデルに変換する． $dogToys[] = $this->toDogToy($entity); } return $dogToys; } /** * ドメインモデルに変換します． */ private function toDogToy(array $entity): DogToy { $dogToy = new DogToy( new DogId($entity[\"dog_toy_id\"]), new DogName($entity[\"dog_toy_name\"]), new DogToyType($entity[\"dog_toy_type\"]), new PriceVO($entity[\"dog_toy_price\"], new ColorVO($entity[\"dog_toy_color\"] ); return $dogToy; } } ファクトリ ・ファクトリとは 責務として，新たな集約の作成や，既存の集約の再作成を実行する． ＊実装例＊ ルータ ・ルータとは コントローラにリクエストをルーティングする． ミドルウェア ・ミドルウェアとは ルーティング後にコントローラメソッドの前にコールされるBeforeMiddleと，レスポンスの実行時にコールされるAfterMiddlewareがある．最近のフレームワークでも搭載されている． イベントリスナー（イベントハンドラー） ・イベントリスナーとは ドメインイベントが発生した場合に，それに紐付く処理を実行する．フレームワークの機能に依存することになるため，実装の詳細をインフラ層におく． 参考： https://stackoverflow.com/questions/67148194/domain-driven-design-ddd-domain-event-handlers-where-to-place-them https://zenn.dev/fuuuuumin65/articles/2c96e8f0b29c01 ・命名規則 イベントでリスナーを使い回さずに，各イベントごとにリスナーを作成する．そのため，名前は『イベント名』＋Listener（Handler）となる． 参考：https://docs.microsoft.com/ja-jp/dynamicsax-2012/developer/naming-conventions-delegates-and-event-handlers#event-handler-naming-conventions インフラストラクチャサービス ・インフラストラクチャサービスとは インフラ層の中で，汎用的なロジックが切り分けられたもの．実装リポジトリと同様にして，ドメイン層にストラクチャサービスのインターフェースを設け，依存性逆転の原則を満たせるようにする． ・ロギング ・ファイル出力 ・ハッシュ化 パスワードのハッシュ化． 参考：https://dev.to/stevensunflash/using-domain-driven-design-ddd-in-golang-3ee5 07. アーキテクチャにおけるレイヤー別の例外スロー スローされた例外の扱い 各レイヤーでは例外をスローするだけに留まり，スローされた例外を対処する責務は，より上位レイヤーに持たせる．より上位レイヤーでは，そのレイヤーに合った例外に詰め替えて，これをスローする．最終的には，ユーザーインターフェース層まで持ち上げ，画面上のポップアップで警告文としてこれを表示する．例外スローの意義については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_php_logic_error_and_error_handling.html インターフェース層 ・例外 final class PresentationException extends Exception { } ユースケース層 ・例外 final class InteractorException extends Exception { } ドメイン層 ・例外 final class DomainException extends Exception { } インフラ層 ・例外 final class InfrastructureException extends Exception { } "},"public/software/software_application_architecture_backend_cqrs.html":{"url":"public/software/software_application_architecture_backend_cqrs.html","title":"📖 ︎CQRS","keywords":"","body":"CQRS：Command Query Responsibility Segregation はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. CQRS CQRSとは 『Command Query Responsibility Segregation（コマンドクエリ責務分離）』の略．リポジトリパターンにおける更新系と参照系の処理を分離する設計のこと．更新系のオブジェクトはそのままリポジトリとしてインフラ層に置く．一方で参照系のオブジェクトは，参照のユースケースに応じて『QueryServiceオブジェクト』として設計し，ユースケース層に置く（これ重要）．システムに部分的に組み込むことができる．N+1問題にも対処できる． 参考： https://vaadin.com/learn/tutorials/ddd/tactical_domain_driven_design https://little-hands.hatenablog.com/entry/2019/12/02/cqrs メリット 一覧画面に表示するデータは複数の集約からなるため，それぞれの集約に対応するリポジトリの参照系処理を順々にコールし，取得したデータを組み合わせる必要がある．そのため，一覧表示の度に複数のリポジトリをコールすることとなり，システムのパフォーマンスに悪影響が出る可能性がある．また，異なるリポジトリをまたいでWHERE句を用いることはできないため，複数の集約に渡る絞り込み検索を実装できない．しかしCQRSを用いると，更新系のオブジェクトはリポジトリ，一方で参照系のオブジェクトはユースケースに応じたQueryServiceオブジェクトとして設計することになる．そのため，更新系では集約の単位をそのままにして，集約とは無関係な参照系処理を設計できる． 参考：https://little-hands.hatenablog.com/entry/2019/12/02/cqrs 01-02. 処理系の種類 Command（更新系） ・Commandとは CREATE，UPDATE，DELETE処理を実行する処理フローのこと．今回，クリーンアーキテクチャを前提としてCQRSを説明する．概念や実装方法は以下のリンクを参考にせよ． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_architecture_backend_domain_driven_design_clean_architecture.html https://github.com/hiroki-it/ddd-api-with-laravel#ddd-api-with-laravel ・処理順序 インターフェース層のコントローラにて，リクエストパラメータからリクエストモデルを作成する． ユースケース層のインターラクターにて，リクエストモデルからデータを取り出し，ドメインモデルを作成する．これをインフラ層のリポジトリに渡す． インフラ層の書き込み／読み出しリポジトリにて，IDモデルのデータを用いて，読み出し／書き込みリポジトリでSELECT文を実行し，DBからレコードを配列として取得する．続けて，ドメインモデルからデータを取り出し，配列の値を上書きする．この配列でINSERT／UPDATE文を実行する．インフラ層の実装は，全てを自前で実装せずにORMで代用できる．void型をユースケース層のインターラクターに渡す． ユースケース層のインターラクターにて，リクエストモデルから作成した時に用いたドメインモデルを用いて，レスポンスモデルを作成する．レスポンスモデルをインタフェース層のコントローラに渡す． インターフェース層のコントローラにて，レスポンスモデルをJSONに変換し，レスポンスを返信する． Query（参照系） ・Queryとは READ処理を実行するオブジェクトのこと．今回，クリーンアーキテクチャを前提としてCQRSを説明する．Queryでは概念や実装方法は以下のリンクを参考にせよ． 参考： https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_architecture_backend_domain_driven_design_clean_architecture.html https://github.com/hiroki-it/ddd-api-with-laravel#ddd-api-with-laravel ・処理順序 インターフェース層のコントローラにて，リクエストパラメータからリクエストモデルを作成する． ユースケース層のインターラクターにて，リクエストモデルからデータを取り出し，QueryCriteriaオブジェクト（参照系検索条件）を作成する．ユースケースに応じたQueryServiceオブジェクトにおいて，QueryCriteriaオブジェクトを用いて，DBからレコードを配列として取得する．この配列からそのユースケースに対応するDTOを作成する．DTOをレスポンスモデルと見なし，そのままインタフェース層のコントローラに渡す． 参考： https://stackoverflow.com/questions/19620404/entity-vs-dto-in-cqrs https://softwareengineering.stackexchange.com/questions/378909/in-what-layer-are-the-dtos-stored-with-cqrs インターフェース層のコントローラにて，DTOをJSONに変換し，レスポンスを返信する． 02. CQRSに基づくイベント駆動アーキテクチャ CQRSとイベントソーシングの関係 イベントソーシングの実装方法は様々ある．イベントソーシングではDBアクセスの処理を更新系と参照系に分離することになるため，CQRSの方法論と相性が良い． 参考： https://little-hands.hatenablog.com/entry/2019/12/02/cqrs https://postd.cc/using-cqrs-with-event-sourcing/ "},"public/software/software_application_architecture_frontend.html":{"url":"public/software/software_application_architecture_frontend.html","title":"📖 ︎フロントエンドアーキテクチャ","keywords":"","body":"フロントエンドアーキテクチャ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. SPA：Single Page Application SPAとは ブラウザレンダリングのステップ 実行者 Loading ブラウザ Scripting ブラウザ Rendering ブラウザ Paiting ブラウザ 1つのWebページの中で，サーバとデータを非同期通信し，ブラウザ側で部分的に静的ファイルを生成する方法のこと．クライアント側でレンダリングを行うため，SSRと比較してCSR：Client Server side Renderingともいう．非同期通信は，Ajaxの手法を用いて実現される．また，静的ファイルの部分的な生成は，MVVMアーキテクチャによって実現する．SPAでは，ページ全体の静的ファイルをリクエストするのは最初のみで，それ以降はページ全体をリクエストすることはない．２回目以降は，ページ部分的にリクエストを行い，サーバ側からJSONを受け取っていく． 参考：https://developers.google.com/analytics/devguides/collection/analyticsjs/single-page-applications?hl=ja SPAの実装方法 ・MVVMアーキテクチャ View層とModel層の間にViewModel層を置き，View層とViewModel層の間で双方向にデータをやり取り（双方向データバインディング）することによって，View層とModel層の間を疎結合にするための設計手法の一つ．Vue.jsでは，意識せずにMVVMアーキテクチャで実装できるようになっている．詳しくは，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_js_framework_vuejs.html SPAと従来MPAの比較 ・処理速度 MPAと比較して，データを非同期的に通信できるため，1つのWebページの中で必要なデータだけを通信すればよく，レンダリングが速い． 02. SSR：Server Side Rendering 広義のSSRとは ブラウザ側ではなくサーバ側でJavaScriptを実行し，静的ファイルを生成する方法のこと．フレームワークのテンプレートエンジンやCGIを用いて，サーバ側で静的ファイルを生成すること，も含まれる． 参考： https://tadtadya.com/summary-of-the-web-site-display-process-flow/#index-list-8 https://ja.nuxtjs.org/docs/2.x/concepts/server-side-rendering ブラウザレンダリングのステップ 実行者 Loading サーバ Scripting サーバ Rendering サーバ Paiting ブラウザ 狭義のSSRとは 広義のSSRにSPAを取り入れた方法のこと．ブラウザ側ではなくサーバ側でJavaScriptを実行し，静的ファイルを生成する．ブラウザ側にレンダリングされた後，アイソモーフィックJavaScriptという仕組みでSPAとして動作する． 参考： https://qiita.com/rita0222/items/66fec6e7be5987bace3c https://qiita.com/kyrieleison/items/4ac5bcc331aee6394440#%E3%82%AF%E3%83%A9%E3%82%A4%E3%82%A2%E3%83%B3%E3%83%88%E3%82%B5%E3%82%A4%E3%83%89%E3%81%A8%E3%82%B5%E3%83%BC%E3%83%90%E3%82%B5%E3%82%A4%E3%83%89%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89%E5%85%B1%E6%9C%89 03. SSG：Static Site Generation SSGとは 事前にビルドを行って静的ファイルを生成しておく．そして，これをレンダリングし，静的サイトとして稼働させる．動的な要素（例：ランダム表示）を含む静的ファイルについては，該当の部分でAjaxを使用できるようにしておく． 04. ISR：Incremental Static Regeneration ISRとは SSGの発展型．SSGとは異なり，事前にビルドせず，静的ファイルを生成しない．その代わり，クライアントからリクエストがあって初めて，そのページのみビルドが実行され，レンダリングされる．クライアントから一回でもリクエストがあったページでは，初回時にビルドされた静的ファイルがその都度レンダリングされる． 参考：https://nextjs.org/docs/basic-features/data-fetching#incremental-static-regeneration 05. マイクロサービスアーキテクチャにおけるフロントエンド UI部品合成 ・UI部品合成とは フロントエンドのコンポーネントを，各サービスに対応するように分割する設計方法． BFFパターン：Backends For Frontends ・BFFパターンとは クライアントの種類（モバイル，Web，デスクトップ）に応じたAPIを構築し，このAPIから各サービスにルーティングする設計方法．BFFパターンを実装は可能であるが，AWSでいうAPI Gatewayで代用するとより簡単に実現できる． "},"public/software/software_application_collaboration_json.html":{"url":"public/software/software_application_collaboration_json.html","title":"📖 ︎JSON","keywords":"","body":"JSON はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. データ記述言語 データ記述言語の種類 ・JSON：JavaScript Object Notation 一番外側を波括弧で囲う． { \"account\": 200, \"fruit\": [ \"banana\", \"apple\" ] } ・YAML：YAML Ain\"t a Markup Language account: 200 fruit: - \"banana\" - \"apple\" ・マークアップ言語 詳しくは以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/frontend_browser_rendering.html ・CSV：Comma Separated Vector データ解析の入力ファイルとしてよく使うやつ． 02-01. JS型オブジェクト，JSON，PHP型オブジェクト JS型オブジェクト ・定義方法 キーはクオーテーションで囲う必要が無い． ＊実装例＊ const object = { \"account\": 200, \"fruit\": [ \"banana\", \"apple\" ] }; class Foo { constructor(fruit, account) { this.fruit = fruit; this.account = account; } } JSON ・定義方法 キーを，シングルクオーテーションではなく，クオーテーションで囲う必要がある． ＊実装例＊ const json = { \"account\": 200, \"fruit\": [ \"banana\", \"apple\" ] }; ・キーと値の変更方法 ＊実装例＊ // どんなデータを含むJSONなのかわかりやすい方法 const json = { \"age\": null, \"name\": null, \"tel\": null } json.age = 30; json.name = \"taro\"; json.tel = \"090-0123-4567\"; ＊実装例＊ const json = {} // areaというキーの値を追加 json.prefecture = \"Tokyo\"; // もしくは， json[\"prefecture\"] = \"Tokyo\"; // 以下は．undefined になる．二段階の定義はできない． //// json.prefecture.area = \"Shibuya\"; ＊実装例＊ const json = { \"age\": 30, \"name\": \"taro\", \"tel\": \"090-0123-4567\" } // areaというキーの値を追加 json.prefecture = \"Tokyo\"; // もしくは， json[\"prefecture\"] = \"Tokyo\"; ・キーの並び順 キーはアルファベット順に並べると良い．以下のサイトで並び替えられる． 参考：https://r37r0m0d3l.github.io/json_sort/ PHP型オブジェクト ・定義方法 ＊実装例＊ fruit = $fruit; $this->account = $account; } } 02-02. 相互パース（シリアライズ＋デシリアライズ） シリアライズ，デシリアライズとは ・バックエンドとフロントエンド間 データ送信のためにオブジェクト（JS型，PHP型）をJSONに変換する処理はシリアライズである．一方で，送信のためにJSONをオブジェクト（JS型，PHP型）に変換する処理はデシリアライズである． ・バックエンドとデータベース間 データ送信のためにオブジェクト（PHP型）をJSONに変換する処理はシリアライズである．一方で，送信のためにJSONをオブジェクト（PHP型）に変換する処理はデシリアライズである． フロントエンド ・シリアライズ：JS型からJSON JS型オブジェクトからJSONへの変換には，JSON.stringfyメソッドを使用する． ＊実装例＊ const object = { fruit: [\"banana\", \"apple\"], account: 200 }; // シリアライズ const json = JSON.stringify(object); console.log(json); // {\"fruit\":[\"banana\",\"apple\"],\"account\":200} ・デシリアライズ：JSONからJS型 JSONからJS型オブジェクトへの変換には，JSON.parseメソッドを使用する．レスポンスされたJSONはエスケープされていることに注意する． ＊実装例＊ const escapedJson = \"{\\\"fruit\\\":[\\\"banana\\\",\\\"apple\\\"],\\\"account\\\":200}\" console.log(escapedJson); // {\"fruit\":[\"banana\",\"apple\"],\"account\":200} // デシリアライズ const object = JSON.parse(escapedJson); console.log(object); // { fruit: [ 'banana', 'apple' ], account: 200 } ・相互パースメソッドを持つクラス ＊実装例＊ 以下でシリアライズとデシリアライズを行うクラスを示す． class StaffParser { // デシリアライズによるJS型データを自身に設定 constructor(properties) { this.id = properties.id; this.name = properties.name; } //-- デシリアライズ（JSONからJavaScriptへ） --// static deserializeStaff(json) { // JS型オブジェクトの定義方法 return new StaffParser({ id: json.id, name: json.name }); } //-- シリアライズ（JavaScriptからJSONへ） --// static serializeCriteria(criteria) { // JSONの定義 const json = { \"id\" : null, \"name\" : null } // ID if (criteria.id) { // JSONが生成される． json.id = _.trim(criteria.id); } // 氏名 if (criteria.name) { json.name = _.trim(criteria.name); } } } バックエンド ・デシリアライズ：JSONからPHP型 JSONからPHP型オブジェクトの変換には．json_decodeメソッドを使用する．第二引数がfalseの場合，object形式オブジェクトに変換する．リクエストで送信するJSONはエスケープする必要があることに注意する． // array(2) { // [0]=> // string(9) \"banana\" // [1]=> // string(9) \"apple\" // } // [\"account\"]=> // int(200) // } 第二引数がtrueの場合，連想配列形式に変換する． // array(2) { // [0]=> // string(9) \"banana\" // [1]=> // string(9) \"apple\" // } // [\"account\"]=> // int(200) // } ・シリアライズ：PHP型からJSON 03. JSONのクエリ言語 クエリ言語の種類 ・JMESPath ＊実装例＊ // ここに実装例 "},"public/software/software_application_collaboration_communication.html":{"url":"public/software/software_application_collaboration_communication.html","title":"📖 ︎アプリケーション間通信","keywords":"","body":"アプリケーション間通信 01. 同期通信 02. 非同期通信 非同期通信とは 非同期処理の一種である．そのため，通信の完了を待たずに後続の処理が始まる．後続の全処理が非同期通信と無関係であれば，そのままで問題は起こらない．しかし，後続の処理に非同期通信の結果を使用するものが含まれている場合，この処理だけは非同期通信の後に実行されるように定義する必要がある．特定の処理が非同期通信の後に実行されるように定義する方法については，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_js_logic_asynchronous_process.html 03. JavaScriptにおける非同期通信 Ajax：Asynchronous JavaScript + XML ・Ajaxとは JavaScriptで非同期通信を実現する手法のこと．JavaScript，HTML，XHTML，CSS，DOM，XML，XSLT，を組み合わせる． ・Ajaxの仕組み urlにアクセスすることにより，サーバからデータがレスポンスされる． DOMのマークアップ言語の解析により，Webページが構成される． ページ上で任意のイベント（ページング操作，フォーム入力など）が発火し，紐付くハンドラ関数が実行される． JavaScript型オブジェクトがJSONに変換される． 非同期通信により，バックエンドにリクエストを送信する． コントローラは，JSON型データを受信し，またそれを元にDBからオブジェクトをReadする． コントローラは，PHP型オブジェクトをJSONに変換し，レスポンスを返信する． 非同期通信メソッドがバックエンドからレスポンスを受信する． JSONがJavaScript型オブジェクトに変換される． オブジェクトがマークアップ言語に出力される． DOMを用いて，Webページを再び構成する． ・実装方法の種類 歴史的に，Ajaxを実装するための方法がいくつかある． 種類 提供 説明 補足 xhrオブジェクト ビルトインオブジェクト 今では使うことは少ないが，Ajaxが登場した初期の頃によく使われた． 参考：https://developer.mozilla.org/ja/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest fetchメソッド ビルトイン関数 参考：https://developer.mozilla.org/ja/docs/Web/API/Fetch_API/Using_Fetch JQueryオブジェクト JQueryパッケージ 参考：・https://api.jquery.com/category/ajax/shorthand-methods/・https://api.jquery.com/jquery.ajax axiosオブジェクト Axiosパッケージ 参考：https://github.com/axios/axios#request-method-aliases 03-02. 実装 xhrオブジェクトの場合 ・GET送信 参考：https://blog.capilano-fw.com/?p=6920#Ajax ＊実装例＊ // URL const url = 'https://example.co.jp/'; const xhr = new XMLHttpRequest(); // HTTPメソッドを指定 xhr.open('GET', url); // レスポンス受信後の処理 xhr.onload = () => { if(xhr.status === 200) { const data = JSON.parse(xhr.responseText); console.log(data); } }; // 最後に送信を実行 xhr.send(); ・POST送信 参考：https://blog.capilano-fw.com/?p=6920#Ajax ＊実装例＊ // URL const url = 'https://example.co.jp/'; // メッセージボディ const body = { name: 'Hiroki', email: 'example@gmail.com', password: 'password' }; const queries = []; for(const key in body) { const query = key +'='+ encodeURIComponent(params[key]); queries.push(query); } const queryString = queries.join('&'); const xhr = new XMLHttpRequest(); // HTTPメソッドを指定 xhr.open('POST', url); // 送信するデータ型 xhr.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded'); // レスポンス受信後の処理 xhr.onload = () => { if(xhr.status === 200) { const data = JSON.parse(xhr.responseText); console.log(data); } }; // 最後に送信を実行 xhr.send(queryString); JQueryオブジェクトの場合 ・GET送信 ＊実装例＊ const url = 'https://example.co.jp/'; $.get(url); ・POST送信 ＊実装例＊ const url = 'https://example.co.jp/'; const body = { name: 'Hiroki', email: 'example@gmail.com', password: 'password' }; $.post(url, params); ・任意のHTTPメソッド 任意のHTTPメソッド，URL，ヘッダー，メッセージボディなどを設定し，非同期的にデータを送受信する．Promiseオブジェクトを返却する． 参考：https://api.jquery.com/jquery.ajax ＊実装例＊ const id = 1; $.ajax({ // ################### // リクエストメッセージ // ################### // HTTPメソッド type: 'POST', // URL url: '/xxx/xxx/' + id + '/', // 送信するデータ型 contentType: 'application/json', // メッセージボディ data: { name: 'Hiroki', email: 'example@gmail.com', password: 'password' }, // ################### // レスポンスメッセージ // ################### // 受信するデータ型 dataType: 'json', }) Axiosオブジェクトの場合 ・GET送信 ＊実装例＊ const url = 'https://example.co.jp/'; axios.get(url); ・POST送信 ＊実装例＊ const url = 'https://example.co.jp/'; const body = { name: 'Hiroki', email: 'example@gmail.com', password: 'password' }; axios.post(url, params); "},"public/software/software_application_collaboration_authentication_authorization.html":{"url":"public/software/software_application_collaboration_authentication_authorization.html","title":"📖 ︎認証／認可","keywords":"","body":"Authenticate（認証）／Authorization（認可） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. HTTP認証 HTTP認証とは 認証時にHTTP通信の中で認証を行うこと．リクエストのauthorizationヘッダーとレスポンスのWWW-Authenticateヘッダーで認証スキームを指定する．認証スキームの種類には，『Basic認証』，『Digest認証』，『Bearer認証』などがある．認証情報の一時的な保存は，ブラウザのWebStoregeで行うため，認証解除（ログアウト）をサーバ側で完全に制御できない． 参考： https://www.iana.org/assignments/http-authschemes/http-authschemes.xhtml https://architecting.hateblo.jp/entry/2020/03/27/130535 https://developer.mozilla.org/ja/docs/Web/HTTP/Authentication#authentication_schemes Basic認証 ・Basic認証の仕組み 役割 説明 クライアント リクエスト送信元のアプリケーションのこと．文脈によっては，ブラウザがクライアントである場合とそうでない場合（例：OAuth認証）がある． ユーザ クライアントを使用している人物のこと． サーバ クライアントからリクエストを受信し，レスポンスを送信するアプリケーションのこと． 最初，クライアントは，認証後にアクセスできるページのリクエストをサーバに送信する． GET https://example.co.jp/foo-form HTTP/2 サーバは，これ拒否し，401ステータスで認証領域を設定し，レスポンスを送信する．これにより，認証領域の値をユーザに示して，ユーザ名とパスワードの入力を求めることができる．ユーザに表示するための認証領域には，任意の値を持たせることができ，サイト名が設定されることが多い． 401 Unauthorized WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" 『:』をBase64でエンコードした値をauthorizationヘッダーに割り当て，リクエストを送信する． POST https://example.co.jp/foo-form HTTP/2 authorization: Basic bG9naW46cGFzc3dvcmQ= サーバは，ユーザ名とパスワードを照合し，合致していれば，認証後ページのレスポンスを送信する．また，認証情報をブラウザのWebストレージに保存する． 200 OK WWW-Authenticate: Basic realm=\"\" 認証の解除時は，誤った認証情報をブラウザに意図的に送信させて認証を失敗させるようにする． 参考：https://stackoverflow.com/questions/4163122/http-basic-authentication-log-out POST https://example.co.jp/foo-form/logout HTTP/2 authorization: Basic サーバは，401ステータスでレスポンスを返信し，認証が解除される． 401 Unauthorized WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" Digest認証 ・Digest認証の仕組み 200 OK WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" POST https://example.co.jp/foo-form HTTP/2 authorization: Digest realm=\"\" nonce=\"\" algorithm=\"\" qoq=\"auth\" Bearer認証 ・Bearer認証とは 認証時にBearerトークンを使用する認証スキームのこと． ・Bearerトークン（署名なしトークン）とは 単なる文字列で定義されたアクセストークン．Bearer認証にて，トークンとして使用する．署名なしトークンとも呼ばれ，実際に認証された本人かどうかを判定する機能は無く，トークンを持っていればそれを本人として認可する．そのため，トークンの文字列が流出してしまわないよう，厳重に管理する必要がある．Bearerトークンを使用するBearer認証については，別項目の説明を参考にせよ． 参考：https://openid-foundation-japan.github.io/rfc6750.ja.html#anchor3 ・Bearer認証の仕組み 指定されたエンドポイントに対して，POSTリクエストを送信する．この時，Content-Typeヘッダーをapplication/x-www-form-urlencodedとする．必要なボディパラメータはAPIの提供元によって異なる．クライアントID，付与タイプ，などが必要なことが多い． 参考： https://developer.amazon.com/ja/docs/adm/request-access-token.html#request-format https://ja.developer.box.com/reference/post-oauth2-token/#request POST https://example.co.jp/foo HTTP/2 Content-Type: application/x-www-form-urlencoded # ボディ client_id=*****&grant_type=client_credentials&scope=messaging:push レスポンスボディにBearerトークンを含むレスポンスが返信される．他に，有効期限，権限のスコープ，指定可能な認証スキーマ，などが提供されることが多い． 参考： https://developer.amazon.com/ja/docs/adm/request-access-token.html#request-format https://ja.developer.box.com/reference/resources/access-token/ 200 OK X-Amzn-RequestId: d917ceac-2245-11e2-a270-0bc161cb589d Content-Type: application/json { \"access_token\":\"*****\", \"expires_in\":3600, \"scope\":\"messaging:push\", \"token_type\":\"Bearer\" } 発行されたBearerトークンを指定された認証スキーマでAuthorizationヘッダーに割り当て，リクエストを送信する．ここでは詳しく言及しないが，BearerトークンをForm認証のようにCookieヘッダーに割り当てることもある． 参考： https://stackoverflow.com/questions/34817617/should-jwt-be-stored-in-localstorage-or-cookie https://ja.developer.box.com/reference/post-oauth2-token/#response POST https://example.co.jp/foo HTTP/2 authorization: Bearer サーバは，Bearerトークンを照合し，合致していれば，認証後ページのレスポンスを送信する．無効なBearerトークンをブラックリストとしてRedis／DBで管理しておく．DBでブラックリストを管理すると，リクエストの度にDBアクセス処理が実行されることなってしまうため，Redisでこれを管理した方が良い． 200 OK WWW-Authenticate: Bearer realm=\"\" 認証の解除時は，Redis／DBでBearerトークンの状態を無効化する．またサーバは，401ステータスでレスポンスを返信し，認証が解除される． 参考： https://stackoverflow.com/questions/21978658/invalidating-json-web-tokens https://medium.com/devgorilla/how-to-log-out-when-using-jwt-a8c7823e8a6 401 Unauthorized WWW-Authenticate: Basic realm=\"\", charaset=\"UTF-8\" ・正常系／異常系レスポンス 参考：https://qiita.com/h_tyokinuhata/items/ab8e0337085997be04b1 成功の場合は，realm属性を空にしたレスポンスを返信する． 200 OK WWW-Authenticate: Bearer realm=\"\" 失敗の場合は，error属性にエラメッセージを割り当てたレスポンスを返信する． 400 Bad Request WWW-Authenticate: Bearer error=\"invalid_request\" 401 Unauthorized WWW-Authenticate: Bearer realm=\"token_required\" 403 Forbidden WWW-Authenticate: Bearer error=\"insufficient_scope\" ・Authorizationヘッダーのトークンのクライアント保持 不便ではあるが，AuthorizationヘッダーはCookieヘッダーとは異なり，ローカルPCに保存できない．その代わり，ブラウザの設定によって，ブラウザのWebStorageでも保持できる．Chromeでは，LocalStorage／SessionStorageに保持される．LocalStorageはSessionStorageと比べて保存期間が長いため，XSSの危険性がより高い．これらの確認方法については，以下のリンクを参考にせよ 参考： https://developer.chrome.com/docs/devtools/storage/localstorage/ https://developer.chrome.com/docs/devtools/storage/sessionstorage/ https://stackoverflow.com/questions/5523140/html5-local-storage-vs-session-storage OAuth認証 ・OAuth認証とは OAuthの項目を参考にせよ． 01-02. HTTP認証以外の認証方法 Form認証（Cookieベースの認証） ・Form認証とは 認証時にCookieヘッダーの値を使用する方法のこと．『`Cookieベースの認証』ともいう．Stateful化を行うため，HTTP認証には属していない．認証情報の一時的な保存は，サーバのセッションファイルで行うため，認証解除（ログアウト）をサーバ側で制御できる．Cookieヘッダーによる送受信では，CSRFの危険性がある． 参考： https://h50146.www5.hpe.com/products/software/security/icewall/iwsoftware/report/certification.html https://auth0.com/docs/sessions/cookies#cookie-based-authentication ・セッションIDを用いたForm認証の場合（セッションベース） セッションIDをCookieヘッダーに割り当て，リクエストを送信する． 最初，ユーザ作成の段階で，クライアントが認証情報をサーバに送信する．サーバは，認証情報をデータベースに保存する． POST https://example.co.jp/users HTTP/2 { \"email_address\": \"foo@gmail.com\", \"password\": \"foo\" } 次回の認証時に，再びユーザが認証情報を送信する． POST https://example.co.jp/foo-form HTTP/2 { \"email_address\": \"foo@gmail.com\", \"password\": \"foo\" } サーバは，データベースの認証情報を照合し，ログインを許可する．サーバは，セッションIDを生成し，セッションファイルに書き込む． # セッションファイル { sessionid: ***** } レスポンスのSet-Cookieヘッダーを使用して，セッションIDをクライアントに送信する． 200 OK Set-Cookie: sessionid= サーバは，セッションIDとユーザIDを紐付けてサーバ内に保存する．さらに次回のログイン時，クライアントは，リクエストのCookieヘッダーを使用して，セッションIDをクライアントに送信する．サーバは，保存されたセッションIDに紐付くユーザIDから，ユーザを特定し，ログインを許可する．これにより，改めて認証情報を送信せずに，素早くログインできるようになる． POST https://example.co.jp/foo-form HTTP/2 cookie: sessionid= 認証解除時，サーバでセッションファイルを削除する． 参考：https://blog.tokumaru.org/2013/02/purpose-and-implementation-of-the-logout-function.html ・トークンを用いたForm認証の場合（トークンベース） トークンをCookieヘッダーに割り当て，リクエストを送信する．この時のトークンの選択肢として，単なるランダムな文字列やJWTがある． 参考：https://scrapbox.io/fendo181/JWT(JSON_Web_Token)%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99%E3%82%8B%E3%80%82 ・Cookieヘッダーの値のクライアント保持 再利用のため，Cookieヘッダーに割り当てるための値（セッションID，トークン）は，ブラウザを通して，ローカルPCに有効期限に応じた間だけ保持できる．またはブラウザの設定によって，ブラウザのWebストレージでも保持できる．Chromeの場合は，Cookieストレージに保持される．確認方法については，以下のリンクを参考にせよ． 参考： https://developer.chrome.com/docs/devtools/storage/cookies/ https://qiita.com/cobachan/items/05fa537a4ffcb189d001 APIキー認証 ・APIキー認証とは 事前にAPIキーとなる文字列を配布し，認証フェースは行わずに認可フェーズのみでユーザを照合する方法のこと．API GatewayにおけるAPIキー認証については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws.html ・照合情報の送信方法 独自ヘッダーとして，x-api-keyヘッダーを定義する．これにAPIキーを割り当て，リクエストを送信する．リクエストヘッダへのパラメータの割り当てについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_api_restful.html GET https://example.co.jp/bar.php HTTP/2 x-api-key: Personal Access Tokenによる認証：PAT ・PATによる認証 クライアントがPersonal Access Token（個人用アクセストークン）の付与をリクエストし，認証フェースは行わずに認可フェーズのみでユーザを照合する方法のこと．AuthorizationヘッダーにPATを割りあてて，リクエストを送信する．作成時以降，アクセストークンを確認できなくなるため，クライアントがアクセストークンを管理する必要がある． 参考：https://www.contentful.com/help/personal-access-tokens/ GET https://example.co.jp/bar.php HTTP/2 authorization: サービス例 トークン名 説明 GitHub Personal access Token HTTPSを使用して，プライベートリポジトリにリクエストを送信するために必要．HTTPSを使用する場面として，アプリの拡張機能のGitHub連携，リポジトリのライブラリ化，などがある．参考：https://docs.github.com/ja/github/authenticating-to-github/creating-a-personal-access-token 01-03. 複数の認証の組み合わせ Two Step Verification（二段階認証） ・Two Step Verificationとは 認証時に段階的に二つの方法を設定し，クライアントを照合する方法のこと． 一段階目の認証例 二段階目の認証例 説明 備考 IDとパスワード IDとパスワード IDとパスワードによる方法の後，別のIDとパスワードによる方法を設定する． 秘密の質問 IDとパスワードによる方法の後，質問に対してあらかじめ設定した回答による方法を設定する． SMS IDとパスワードによる方法の後，SMS宛に送信した認証コードによる方法を設定する． 異なる要素のため，これは二要素認証でもある． 指紋 IDとパスワードによる方法の後，指紋の解析結果による方法を設定する． 異なる要素のため，これは二要素認証でもある． Two Factor Authorization（二要素認証） ・Two Factor Authorizationとは 二段階認証のうちで特に，認証時に異なる要素の方法を使用して，段階的にクライアントを照合すること方法のこと．後述するOAuth認証を組み込んでも良い． 一要素目の認証例 二要素目の認証例 IDとパスワード（知識） 事前登録された電話番号のSMSで受信したワンタイムパスワード（所持） 事前登録された電話番号のSMSで受信した認証コード（所持） OAuth認証（所持） 指紋（生体） 暗証番号（知識） キャッシュカード（所持） 02. 認可フェーズ 認証フェーズと認可フェーズ ・処理の違い 認証フェーズと認可フェーズでは，仕組みの中に，３つの役割が定義されている． クライアントが，HTTPリクエストにIDとパスワードを設定してリクエスト． IdP：Identity Providerが，IDを『認証』し，クライアント側にアクセストークンを発行． クライアントが，HTTPリクエストのヘッダーにアクセストークンを設定してリクエスト． アクセストークンが『認可』されれば，API側がデータをレスポンスする． 役割 説明 例 APIクライアント APIに対して，リクエストを送信したいサーバのこと． Ouath認証の仕組みにおけるクライアント． Identity Provider トークンを生成するサーバのこと． Ouath認証の仕組みにおける認可サーバ． APIサーバ クライアントに対して，リソースのレスポンスを送信するサーバのこと． Ouath認証の仕組みにおけるリソースサーバ． ・ステータスコードの違い 認証フェーズにて，誤ったトークンが発行されたことを表現したい場合，401ステータスを使用する．認可フェーズにて，正しいトークンが発行されたが，トークンの所有者に閲覧権限がないことを表現したい場合，403ステータスを使用する．ステータスコードについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_api_restful.html OAuthプロトコル，OAuth認証 ・OAuthプロトコル，OAuth認証とは 認証認可フェーズ全体の中で，認可フェーズにOAuthプロトコルを用いたクライアントの照合方法を『OAuth認証』と呼ぶ．認証フェーズと認可フェーズでは，３つの役割が定義されていることを説明したが，OAuthプロトコル2.0では，より具体的に４つの役割が定義されている． 役割 名称 説明 補足 APIクライアント クライアントアプリ リソースオーナに対するアクション機能を持つサーバのこと． OAuthの文脈では，ブラウザがクライアントと呼ばれないことに注意する．また，クライアントアプリとリソース間のデータ通信は，ブラウザを介したリダイレクトによって実現することに注意する． リソースオーナー クライアントを使用しているユーザのこと． Identity Provider 認可サーバ リソースサーバがリソースオーナーにアクセスできるトークンを生成するサーバのこと． 認可サーバがリダイレクト先のクライアントアプリのURLをレスポンスに割り当てられるように，クライアントアプリの開発者がURLを事前登録しておく必要がある．認可サーバを利用する開発者用に，コンソール画面が用意されていることが多い．参考：https://qiita.com/TakahikoKawasaki/items/8567c80528da43c7e844 APIサーバ リソースサーバ クライアントのアカウント情報を持っているサーバのこと． ユーザは，Facebookアカウントを使用してInstagramにログインしようとし，ブラウザはFacebookにリクエストを送信する．FacebookはInstagramにアカウント連携の承認ボタンをレスポンスとして返信する． ユーザが表示された承認ボタンを押し，ブラウザはFacebookにリクエストを送信する． アクセストークンを発行してもらうため，ブラウザはInstagram認可サーバにリクエストを送信する．Instagramは，アクセストークンを発行する．また，Facebookにリダイレクトできるように，LocationヘッダーにURLと認可レスポンスパラメータを割り当て，ブラウザにレスポンスを返信する．ブラウザはFacebookにリクエストを再送信し，Facebookは認可レスポンスパラメータを受け取る． 302 Found Location: https://example.com/foo.php?code=123&state=abc Facebookは，アクセストークンを割り当てたリクエストをInstagramのサーバに送信する． Instagramは，アクセストークンを認証し，データへのアクセスを許可する．また，Facebookにリダイレクトできるように，LocationヘッダーにURLを割り当て，ブラウザにレスポンスを返信する．ブラウザからFacebookにレスポンスがリダイレクトされる．ブラウザはFacebookにリクエストを再送信する． 参考： https://boxil.jp/mag/a3207/ https://qiita.com/TakahikoKawasaki/items/8567c80528da43c7e844 ・使用される認証スキーム OAuth認証では，認証スキーマとしてBearer認証が選ばれることが多く，AWSやGitHubは，独自の認証スキームを使用している．なお，認可サーバによって発行されたBearerトークンは，Authorizationヘッダー，リクエストボディ，クエリパラメータのいずれかに割り当てて送信できる． ・付与タイプ OAuth認証のトークンの付与方法には種類がある． 参考：https://oauth.net/2/grant-types/ 付与タイプ名 説明 使用例 Authorization Code Grant アプリケーションが他のAPIにアクセスする場合に使用する．推奨されている．参考：https://oauth.net/2/grant-types/authorization-code/ 他のSNSアプリとのアカウント連携 Client Credentials Grant 推奨されている．参考：https://oauth.net/2/grant-types/client-credentials/ Device Code 推奨されている．参考：https://oauth.net/2/grant-types/device-code/ Implicit Grant 非推奨されている．参考：https://oauth.net/2/grant-types/implicit/ Password Grant ユーザ名とパスワードを元に，トークンを付与する．非推奨されている．参考：・https://oauth.net/2/grant-types/password/・https://developer.okta.com/blog/2018/06/29/what-is-the-oauth2-password-grant#the-oauth-20-password-grant OpenID Connect ・OpenID Connectとは 要勉強． ・使用される認証スキーム 要勉強 03. JWT：JSON Web Token JWTとは 『ヘッダー』『ペイロード』『署名』のそれぞれのJSONデータをBase64urlによってエンコードし，ドットでつないだトークン．Bear認証やOauth認証のトークンとして使用できる．ランダムな文字列をこれら認証のトークンとするより，JWTを用いた方がより安全である． GET https://example.co.jp/bar.php HTTP/2 authorization: Bearer .. JWTをBearerトークンとして使用するBearer認証については，別項目の説明を参考にせよ． 参考： https://meetup-jp.toast.com/3511 https://dev.classmethod.jp/articles/json-signing-jws-jwt-usecase/ JWTの生成 ・JWT生成の全体像 JWTは以下のサイトから取得できる． 参考：https://jwt.io/ JWTの生成時に，例えばJavaScriptであれば，以下のような処理が実行されている． // .. const token = base64urlEncoding(header) + \".\" + base64urlEncoding(payload) + \".\" + base64urlEncoding(signature) ・ヘッダーのJSONデータの生成 ヘッダーは以下のJSONデータで定義される．署名のための暗号化アルゴリズムは，『HS256』『RS256』『ES256』『none』から選択できる． const header = { \"typ\" : \"JWT\" // JWTの使用 \"alg\" : \"HS256\", // 署名のための暗号化アルゴリズム } ・ペイロードのJSONデータの生成 ペイロードは以下のJSONデータで定義される．ペイロードには，実際に送信したいJSONを設定するようにする．必ず設定しなければならない『予約済みクレーム』と，ユーザ側が自由に定義できる『プライベートクレーム』がある． 予約済みクレーム名 役割 例 sub：Subject 一意な識別子を設定する． ユーザID iss：Issuer aud：Audience exp：Expiration Time JWTの有効期限を設定する． jti：JWT ID const payload = { \"sub\": \"foo\", \"aud\": \"foo\", \"iss\": \"https://example.com\", \"exp\": 1452565628, \"iat\": 1452565568 } ・署名のJSONデータの生成 例えばJavaScriptであれば，以下のような処理が実行されている． const signature = HMACSHA256( base64urlEncoding(header) + \".\" + base64urlEncoding(payload), secret ) JWTのクライアント保持 ・ 保持方法と安全度の比較 参考：https://qiita.com/Hiro-mi/items/18e00060a0f8654f49d6#%E6%97%A9%E8%A6%8B%E8%A1%A8 クライアント保持方法 組み合わせ おすすめ度 コメント localStorage △〜× XSSでJWTが盗まれる可能性がある． Cookieヘッダー プリフライトリクエスト △ Access-Control-Max-Ageの期間内だとCSRFでJWTが盗まれる可能性がある． Cookieヘッダー CSRFトークン ◯ SameSiteCookie ◯ SPAとAPIが同一オリジンの必要がある． "},"public/software/software_application_collaboration_api_restful.html":{"url":"public/software/software_application_collaboration_api_restful.html","title":"📖 ︎RESTful-API","keywords":"","body":"RESTful-API はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. RESTとRESTfulとは REST ・RESTとは 分散型アプリケーションを構築する時に，それぞれアプリケーションを連携させるのに適したアーキテクチャスタイルをRESTという．RESTは，以下の特徴を持つ． ・RESTfulとRESTful APIとは RESTに基づいた設計をRESTfulという．RESTful設計が用いられたWebAPIをRESTful APIという．例えば，RESTful APIの場合，DBにおけるUserInfoのCRUDに対して，一つの『/UserInfo』というURIを対応づけている． RESTの４原則 ・Stateless クライアントに対してレスポンスを返信した後に，クライアントの情報を保持せずに破棄する仕組みのこと．擬似的にStatefulな通信を行う時は，キャッシュ，Cookie，セッションIDを用いて，クライアントの情報を保持する． Statelessプロトコル Statefulプロトコル HTTP SSH HTTPS TLS/SSL - SFTP ・Connectability ・Uniform Interface HTTPプロトコルを使用したリクエストを，『リソースに対する操作』とらえ，リクエストにHTTPメソッドを対応づけるようにする． ・Addressability エンドポイントによって，特定のリソースを操作できること． 02. エンドポイント エンドポイントとは 特定のリソースを操作するための固有のURIのこと．エンドポイント は，リソース1つごと，あるいはまとまりごとに割り振られる． HTTPメソッド，エンドポイント，ユースケースの関係 RESTfulAPIでは，全てのHTTPメソッドの内，主に以下の4つを使用して，データ処理の方法をリクエストする．それぞれが，APIのユースケースに対応する．ユースケースごとのメソッド名については，Laravelを参考にする． 参考：https://noumenon-th.net/programming/2020/01/30/laravel-crud/ HTTPメソッド エンドポイント ユースケース メソッド名の例 GET https://example.co.jp/users ・全データのインデックス取得・条件に基づくデータの取得 index https://example.co.jp/users/{id} IDに基づくデータの取得 show POST https://example.co.jp/users ・データの作成・PDFの作成・ファイルデータの送信・ログイン／ログアウト create，store PUT` https://example.co.jp/users/{id} データの更新（置換） update DELETE https://example.co.jp/users/{id} データの削除 delete，destroy POST送信とPUT送信の重要な違いについてまとめる．データを作成するユースケースの時はPOST送信，または更新する時はPUT送信を使用する．ただしもっと正確には，ユースケースが『作成』or『更新』ではなく，『非冪等』or『冪等』で判断したほうが良い． 参考： https://stackoverflow.com/a/2691891/12771072 https://restfulapi.net/rest-put-vs-post/ POST送信 PUT送信 データ作成の冪等性 リクエスト1つにつき，1つのデータを作成（非冪等的） リクエスト数に限らず，1つのデータを作成する（冪等的）．古いデータを新しいデータに置換する行為に近い． リクエストパラメータの場所 メッセージボディにJSONデータなどを割り当てる． パスパラメータにidなど，またメッセージボディにJSONデータなどを割り当てる． エンドポイントの命名 ・動詞を使用しないこと すでにHTTPメソッド自体に動詞の意味合いが含まれるため，エンドポイントに動詞を含めないようにする．この時，アクセスするリソース名がわかりやすいような名詞を使用する． 参考： https://cloud.google.com/blog/products/api-management/restful-api-design-nouns-are-good-verbs-are-bad https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-design/#h-use-nouns-instead-of-verbs-in-endpoint-paths ただし慣例として，認証のエンドポイントが動詞（login，logout，register）になることは許容されている． 参考： https://stackoverflow.com/questions/7140074/restfully-design-login-or-register-resources https://www.developer.com/web-services/best-practices-restful-api ＊悪い実装例＊ GET https://example.co.jp/show-user/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 GET https://example.co.jp/users/hiroki_hasegawa ＊認証の場合＊ 動詞を許容するのであればloginやlogoutとし，名詞を採用するのであればsessionとする． GET https://example.co.jp/login GET https://example.co.jp/session ・短くすること ＊悪い実装例＊ ここで，service，api，といったキーワードは，なくても問題ない． GET https://example.co.jp/service/api/users/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 ・略称を使わないこと ＊悪い実装例＊ ここで，Usersを意味する『u』といった略称は，当時の設計者しかわからないため，不要である． GET https://example.co.jp/u/12345 ＊良い実装例＊ 略称を使わずに，『users』とする． GET https://example.co.jp/users/12345 ・小文字を使うこと ＊悪い実装例＊ GET https://example.co.jp/Users/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 ・ケバブケースを使うこと ＊悪い実装例＊ GET https://example.co.jp/users_id/12345 ＊良い実装例＊ スネークケースやキャメケースを使わずに，ケバブケースを使用する． GET https://example.co.jp/users-id/12345 ただ，そもそもケバブ方式も利用せずに，スラッシュで区切ってしまうのも手である GET https://example.co.jp/users/id/12345 ・複数形を使用すること ＊悪い実装例＊ Usersという集合の中に，Idが存在しているため，単数形は使わない． GET https://example.co.jp/user/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 ・システムの設計方法がバレないURIにすること ＊悪い実装例＊ 悪意のあるユーザに，脆弱性を狙われる可能性があるため，システムの設計方法がばれないアーキテクチャにすること．ミドルウェアにCGIプログラムが使用されていることや，phpを使用していることがばれてしまう． GET https://example.co.jp/cgi-bin/get_users.php ＊良い実装例＊ GET https://example.co.jp/users/12345 ・HTTPメソッドの名前を使用しないこと ＊悪い実装例＊ メソッドから，処理の目的はわかるので，URIに対応する動詞名を実装する必要はない． GET https://example.co.jp/users/get/12345 POST https://example.co.jp/users/create/12345 PUT https://example.co.jp/users/update/12345 DELETE https://example.co.jp/users/delete/12345 ＊良い実装例＊ GET https://example.co.jp/users/{id} POST https://example.co.jp/users PUT https://example.co.jp/users/{id} DELETE https://example.co.jp/users/{id} ・数字，バージョン番号を可能な限り使用しないこと ＊悪い実装例＊ ここで，alpha，v2，といったキーワードは，当時の設計者しかわからないため，あまり良くない．ただし，利便上，使う場合もある． GET https://example.co.jp/v2/users/12345 ＊良い実装例＊ GET https://example.co.jp/users/12345 URLにバージョンを表記しない代わりに，リクエストヘッダーのX-api-Versionにバージョン情報を格納する方法がより良い． X-Api-Version: 1 ・異なるHTTPメソッドの間でルールを統一すること ＊悪い実装例＊ GET送信とPOST送信の間で，IDパラメータのHTTPメソッドが統一されていない． GET https://example.co.jp/users/?id=12345 POST https://example.co.jp/users/12345/messages ＊良い実装例＊ 以下のように，異なるHTTPメソッドの間でも統一する． GET https://example.co.jp/users/12345 POST https://example.co.jp/users/12345/messages エンドポイントのパラメータ ・パス，クエリストリングへの割り当て URIの構造のうち，パスまたはクエリストリングにパラメータを割り当てて送信する．それぞれ，パスパラメータまたはクエリパラメータという． GET https://example.co.jp:80/users/777?text1=a&text2=b 完全修飾ドメイン名 送信先のポート番号（80の場合は省略可） ルート パスパラメータ ？ クエリパラメータ（GET送信時のみ） https://example.co.jp 80 users {id} ? text1=a&text2=b ・使い分け（再掲） データの送信対象 パスパラメータ クエリパラメータ 単一条件で決まる検索処理 ◯ △ 複数条件で決まる検索処理 ✕ ◯ フィルタリング処理 ✕ ◯ ソーティング処理 ✕ ◯ ・メッセージボディへの割り当て JSON型データ内に定義し，メッセージボディにパラメータを割り当てて送信する． POST https://example.co.jp HTTP/2 # メッセージボディ { \"id\": 1, \"name\": \"foo\", } ・リクエストヘッダーへの割り当て リクエストヘッダーにパラメータを割り当てて送信する．送信時のヘッダー名は大文字でも小文字でもいずれでも問題ないが，内部的に小文字に変換されるため，小文字が推奨である．APIキーのヘッダー名の頭文字に『X』を付けるのは，独自ヘッダーの頭文字に『X』を付ける慣習があったためである．ただし，現在は非推奨である． 参考：https://developer.mozilla.org/ja/docs/Web/HTTP/Headers POST https://example.co.jp HTTP/2 # Authorizationヘッダー authorization: Bearer ${Token} # APIキーヘッダー x-api-key: ***** エンドポイントのレスポンス形式 ・ステータスコード 参考：https://qiita.com/unsoluble_sugar/items/b080a16701946fcfce70 コード 概要 説明 200 成功 正しいリクエストである． 401 認証エラー 誤ったリクエストである．認証プロセスで正しいトークンが発行されず，認可プロセスのリクエストでこの誤ったトークンを送信したことを表している．認可の失敗ではなく，認証の失敗であることに注意する． 403 認可エラーによるトークン所有者の認可スコープ外 誤ったリクエストである．APIに認証プロセスが存在し，トークンの発行が必要だとする．認証プロセスにて正しいトークンが発行されたが，認可プロセスにてトークンの所有者の認可スコープ外と判定されたことを表している． 送信元IPアドレスの閲覧禁止 誤ったリクエストである．APIに認証認可プロセスが存在せず，トークン発行と閲覧権限検証が不要だとする．送信元IPアドレスに閲覧権限がないと判定されてことを表している． 404 ページが見つからない 誤ったリクエストである．存在しないデータをリクエストしていることを表している． 409 競合エラー 誤ったリクエストである．CREATE処理やUPDATE処理によって，新しいデータと現在のDBのデータの間で競合が起こっていることを表している．一意な識別子として用いているデータの重複や，楽観的ロックによる排他制御が起こる場合に使用する．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_middleware_database.html 412 リソースアクセスエラー 誤ったリクエストである．リソースへのアクセスに失敗したことを表している． 422 バリデーションエラー 誤ったリクエストである．送信されたパラメータが誤っていることを示している． 500 サーバエラー サーバーの処理でランタイムエラーが起こっている．エラーの種類については，以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_authentication_authorization.html 503 ビジネスロジックエラー エラーは起こらないが，ビジネス上ありえないデータをリクエストしていることを表す． ・リダイレクトとリライトの違い リダイレクトでは，リクエストされたURLをサーバ側で新しいURLに書き換えてブラウザに返信し，ブラウザがリクエストを再送信する．そのため，クライアント側は新しいURLで改めてリクエストを送信することになる．一方で，リライトでは，リクエストされたURLをサーバ側で異なるURLに書き換え，サーバがそのままリクエストを送信する．そのため，クライアント側は古いURLのままリクエストを送信することになる．その他の違いについては，以下を参考にせよ． 参考：https://blogs.iis.net/owscott/url-rewrite-vs-redirect-what-s-the-difference ・リライトとフォワードの違い リライトでは異なるサーバにリクエストを送信できるが，フォワードでは同一サーバ内の異なるファイルにアクセスすることしかできない． 03. メッセージ メッセージとは アプリケーション層で生成されるデータを，メッセージという．リクエスト時にクライアント側で生成されるメッセージをリクエストメッセージ，レスポンス時にサーバ側で生成されるメッセージをレスポンスメッセージという． HTTPコンテキスト ・HTTPコンテキスト 特定のリクエストメッセージ／レスポンスメッセージに関するあらゆる情報（リクエストパラメータ，セッション，その他フレームワーク固有の情報など）を扱うための仕組みのこと．特にフレームワークやパッケージにおいてよく使われる用語である． ・.NET Frameworkの場合 .NETのフレームワーク．コンテキストクラスが用意されている． 参考：https://docs.microsoft.com/en-us/dotnet/api/system.web.routing.requestcontext?view=netframework-4.8 ・Ginの場合 Goのフレームワーク．コンテキスト構造体が用意されている． 参考：https://pkg.go.dev/github.com/gin-gonic/gin#Context ・Nuxt.jsの場合 JavaScriptのフレームワーク．コンテキストオブジェクトが用意されている． 参考：https://nuxtjs.org/ja/docs/internals-glossary/context/ ・Lambdaの場合 フレームワークでなはいが，Lambdaの場合にパラメータとしてcontextオブジェクトが用意されている． 03-02. リクエストメッセージ 構造 ・GET送信の場合 クエリパラメータに送信するデータを記述する方法．リクエストメッセージは，以下の要素に分類できる．以下では，Web APIのうち，特にRESTfulAPIに対して送信するためのリクエストメッセージの構造を説明する． GET https://example.co.jp/bar-form.php?text1=a&text2=b HTTP/2 # リクエストされたドメイン名 Host: example.co.jp Connection: keep-alive Upgrade-Insecure-Requests: 1 # ブラウザキャッシュの最大有効期限（リクエストヘッダーとレスポンスヘッダーの両方で定義可能） Cache-Control: max-age=31536000 # ブラウザのバージョン情報等 User-Agent: Mozzila/5.0 (Windows NT 10.0; Win64; x64) Ch # レスポンス返信してほしいMIMEタイプ Accept: text/html, application/xhtml+xml, application/xml; q=0 # レスポンスで返信してほしいエンコーディング形式 Accept-Encondig: gzip, deflate, br # レスポンスで返信してほしい言語 Accept-Language: ja, en-US; q=0.9, en; q=0.8 # 遷移元のページ Referer: https://foo.co.jp/ # 送信元IPアドレス # ※プロキシサーバ（ALBやCloudFrontなども含む）を経由している場合に，それら全てのIPアドレスも順に設定される X-Forwarded-For: , , ・POST送信の場合 クエリパラメータを，URLに記述せず，メッセージボディに記述してリクエストメッセージを送る方法．以下では，Web APIのうち，特にRESTfulAPIに対して送信するためのリクエストメッセージの構造を説明する．メッセージボディに情報が記述されるため，履歴では確認できない．また，SSLによって暗号化されるため，傍受できない．リクエストメッセージは，以下の要素に分類できる． POST https://example.co.jp/bar-form.php HTTP/2 # リクエストされたドメイン名 Host: example.co.jp Connection: keep-alive Content-Length: 15 # ブラウザキャッシュの最大有効期限（リクエストヘッダーとレスポンスヘッダーの両方で定義可能） Cache-Control: no-store # オリジン（プロトコル＋ドメイン＋ポート番号） Origin: https://example.co.jp Upgrade-Insecure-Requests: 1 # リクエストで送信するMIMEタイプ Content-Type: application/x-www-firm-urlencoded # ブラウザのバージョン情報等 User-Agent: Mozzila/5.0 (Windows NT 10.0; Win64; x64) Ap # レスポンス返信してほしいMIMEタイプ Accept: text/html, application/xhtml+xml, application/xml; q=0 # レスポンスで返信してほしいエンコーディング形式 Accept-Encondig: gzip, deflate, br # レスポンスで返信してほしい言語 Accept-Language: ja, en-US; q=0.9, en; q=0.8 # 遷移元のページ Referer: https://foo.co.jp/ # 各Cookieの値（二回目のリクエスト時に設定される） Cookie: sessionid=; csrftoken=; _gat=1 # 送信元IPアドレス # ※プロキシサーバ（ALBやCloudFrontなども含む）を経由している場合に，それら全てのIPアドレスも順に設定される X-Forwarded-For: , , # ボディ．（SSLによって暗号化されるため閲覧不可） text=a&text2=b ・例外として，ボディを持つGET送信の場合 GET送信ではあるが，ボディにクエリパラメータを記述して送信する方法がある． POSTMANで，GET送信にメッセージボディを含めることについて： https://github.com/postmanlabs/postman-app-support/issues/131 送信例 ・PHPの場合 URL, // HTTPメソッド CURLOPT_CUSTOMREQUEST => \"GET\", // SSL証明書の検証 CURLOPT_SSL_VERIFYPEER => false, // 文字列型で受信 CURLOPT_RETURNTRANSFER => true ] ); // リクエストの実行 $messageBody = (curl_exec($curl)) ? curl_exec($curl) : []; // curlセッションを閉じる curl_close($curl); 03-03. レスポンスメッセージ 構造 ＊例＊ 200 OK # レスポンスで送信するMIMEタイプ Content-Type: text/html;charset=UTF-8 Transfer-Encoding: chunked Connection: close # Webサーバ（nginx，apache，AmazonS3などが表示される） Server: nginx Date: Sat, 26 Sep 2020 04:25:08 GMT # リファラポリシー（nginx，apache，などで実装可能） Referrer-Policy: no-referrer-when-downgrade x-amz-rid: ***** # セッションIDを含むCookie情報 Set-Cookie: session-id=*****; Domain=.amazon.co.jp; Expires=Sun, 26-Sep-2021 04:25:08 GMT; Path=/ Set-Cookie: session-id-time=*****; Domain=.amazon.co.jp; Expires=Sun, 26-Sep-2021 04:25:08 GMT; Path=/ Set-Cookie: i18n-prefs=JPY; Domain=.amazon.co.jp; Expires=Sun, 26-Sep-2021 04:25:08 GMT; Path=/ Set-Cookie: skin=noskin; path=/; domain=.amazon.co.jp Accept-CH: ect,rtt,downlink Accept-CH-Lifetime: 86400 X-UA-Compatible: IE=edge Content-Language: ja-JP # ブラウザキャッシュの最大有効期限（リクエストヘッダーとレスポンスヘッダーの両方で定義可能） Cache-Control: no-cache # ブラウザキャッシュの最大有効期限（レスポンスヘッダーのみで定義可能） Expires: Wed, 21 Oct 2015 07:28:00 GMT Pragma: no-cache X-XSS-Protection: 1; X-Content-Type-Options: nosniff Vary: Accept-Encoding,User-Agent,Content-Type,Accept-Encoding,X-Amzn-CDN-Cache,X-Amzn-AX-Treatment,User-Agent Strict-Transport-Security: max-age=*****; includeSubDomains; preload X-Frame-Options: SAMEORIGIN # CloudFrontのキャッシュにヒットしたかどうか X-Cache: Miss from cloudfront Via: 1.1 *****.cloudfront.net (CloudFront) X-Amz-Cf-Pop: SEA19-C2 X-Amz-Cf-Id: *****== # 言語のバージョン（※ php.ini にて，expose_php = Off と設定することで非表示にできる） X-Powered-By: PHP/7.3.22 # ボディ ここにサイトのHTMLのコード 04. オブジェクトデータ オブジェクトデータ ・オブジェクトデータとは リクエスト（POST）／レスポンスにて，メッセージボディに割り当てて送信／返信するデータのこと． ・MIME type（Content type） POST／PUT送信において，ボディパラメータのデータ形式を表現する識別子のこと．リクエストヘッダー／レスポンスヘッダーのContent-Typeヘッダーに割り当てると，オブジェクトデータのデータ型を定義できる．GET送信には不要である． 参考：https://stackoverflow.com/questions/5661596/do-i-need-a-content-type-header-for-http-get-requests トップレベルタイプ サブレベルタイプ 意味 application octet-stream 任意のMIME type（指定なし）を示す． javascript json x-www-form-urlencoded POST送信のデータ zip text html HTMLテキスト css CSSテキスト plane プレーンテキスト image png jpeg gif ・データ型の指定方法 最も良い方法は，リクエストのContent-Typeヘッダーに，『application/json』を設定することである． POST https://example.co.jp/users/12345 # ヘッダー Content-Type: application/json 他に，URIでデータ型を記述する方法がある． POST https://example.co.jp/users/12345?format=json リクエスト（POST，PUT） 正常系レスポンスで返信するオブジェクトデータと同じ． 正常系レスポンスの場合 ・POST／PUTでは処理後データをレスポンス POST／PUTメソッドでは，処理後のデータを200レスポンスとして返信する．もし処理後のデータを返信しない場合，改めてGETリクエストを送信する必要があり，余分なAPIコールが必要になってしまう． 参考： https://developer.ntt.com/ja/blog/741a176b-372f-4666-b649-b677dd23e3f3 https://qiita.com/wim/items/dbb6def4e207f6048735 ・DELETEではメッセージのみをレスポンス DELETEメソッドでは，メッセージのみを200レスポンスとして返信する．空ボディ204レスポンスとして返信してもよい． 参考： https://stackoverflow.com/questions/25970523/restful-what-should-a-delete-response-body-contain/50792918 https://qiita.com/fukuma_biz/items/a9e8d18467fe3e04068e#4-delete---%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%81%AE%E5%89%8A%E9%99%A4 ・ステータスコードは不要 正常系レスポンスの場合，オブジェクトデータへのステータスコードの割り当ては不要である． { \"name\": \"Taro Yamada\" } ・フラットなデータ構造にすること JSONの場合，階層構造にすると，データ容量が増えてしまう． ＊例＊ { \"name\": \"Taro Yamada\", \"age\": 10, \"interest\": { \"sports\":[\"soccer\", \"baseball\"], \"subjects\": \"math\" } } そこで，できるだけデータ構造をフラットにする．ただし，見やすさによっては階層構造も許容される． 参考：https://www.amazon.co.jp/Web-API-The-Good-Parts/dp/4873116864 ＊例＊ { \"name\": \"Taro Yamada\", \"age\": 10, \"sports\":[\"soccer\", \"baseball\"], \"subjects\": \"math\" } あるいは，Content-Typeヘッダーに『application/hal+json』『application/vnd.api+json』『application/vnd.collection+json』といったよりJSONベースの強い制約のフォーマットを利用する． ・日付データの形式に気をつけること RFC3339（W3C-DTF）形式でオブジェクトデータに含めて送受信すること． ＊例＊ 2020-07-07T12:00:00+09:00 ただし，日付をリクエストパラメータで送受信する時，RFC3339（W3C-DTF）形式を正規表現で設定する必要があるので注意． ＊例＊ GET https://example.co.jp/users/12345?date=2020-07-07T12:00:00%2B09:00 異常系レスポンスの場合 { \"code\": 400 \"errors\": [ \"〇〇は必ず入力してください．\", \"□□は必ず入力してください．\" ] \"url\" : \"https://example-api-doc.co.jp\" } 参考：https://qiita.com/suin/items/f7ac4de914e9f3f35884#%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%AC%E3%82%B9%E3%83%9D%E3%83%B3%E3%82%B9%E3%81%A7%E8%80%83%E6%85%AE%E3%81%97%E3%81%9F%E3%81%84%E3%81%93%E3%81%A8 種類 必要性 データ型 説明 エラーメッセージ 必須 文字列型 複数のエラーメッセージを返信できるように，配列として定義する． ステータスコード 任意 整数型 エラーの種類がわかるステータスコードを割り当てる． エラーコード（例外コード） 任意 文字列型 APIドキュメントのエラーの識別子として，エラコード（例外コード）を割り当てる． APIドキュメントのURL 任意 文字列型 外部に公開するAPIの場合に，エラーの解決策がわかるAPIドキュメントのURLを割り当てる． 05. Statelessプロトコルにおける擬似Stateful化 Cookie，Cookie情報（キー名／値） ・Cookie，Cookie情報とは クライアントからの次回のリクエスト時でも，Cookie情報（キー名／値のセット）を用いて，同一クライアントと認識できる仕組みをCookieという．HTTPはStatelessプロトコルであるが，Cookie情報により擬似的にStatefulな通信を行える． ・Cookie情報に関わるヘッダー 最初，サーバからのレスポンス時，Set-Cookieヘッダーを用いて送信される．反対に，クライアントからのリクエスト時，Cookie情報は，Cookieヘッダーを用いて送信される． HTTPメッセージの種類 ヘッダー名 属性 内容 レスポンスメッセージ Set-Cookie Name Cookie名と値 Expires Cookieの有効期限（日数） Max-Age Cookieの有効期限（秒数） Domain クライアントがリクエストする時のCookie送信先ドメイン名． Path クライアントがリクエストする時のCookie送信先ディレクトリ Secure クライアントからのリクエストでSSLプロトコルが使用されている時のみ，リクエストを送信できるようにする． HttpOnly クライアント側で，JavaScriptがCookieを使用できないようにする．XSS攻撃の対策になる． リクエストメッセージ Cookie セッションIDなどのCookie情報 クライアントから送信されてきたリクエストメッセージのCookieヘッダーの内容は，グローバル変数に格納されている． \"値\"] ・仕組み 最初，ブラウザはリクエストでデータを送信する． サーバは，レスポンスヘッダーのSet-CookieヘッダーにCookie情報を埋め込んで送信する． ブラウザは，そのCookie情報を保存する． 2回目以降のリクエストでは，ブラウザは，リクエストヘッダーのCookieヘッダーにCookie情報を埋め込んでサーバに送信する．サーバは，Cookie情報に紐付くクライアントのデータをReadする． セッション ・セッション，セッションIDとは 特定のサイトを訪問してから，離脱するまでの一連のユーザ操作を『セッション』という．この時，セッションIDを用いると，セッションの各リクエストの送信元を同一クライアントとして識別できる．HTTPはStatelessプロトコルであるが，セッションIDにより擬似的にStatefulな通信を行える．例えばセッションIDにより，ログイン後にページ遷移を行っても，ログイン情報を保持でき，同一ユーザからのリクエストとして認識できる．セッションIDは，Cookie情報の一つとして，CookieヘッダーとSet-Cookieヘッダーを使用して送受信される． # リクエストヘッダーの場合 Cookie: sessionid=; csrftoken=u32t4o3tb3gg43; _gat=1 # レスポンスヘッダーの場合 Set-Cookie: sessionId= セッション数はGoogleコンソールで確認できる．GoogleConsoleにおけるセッションについては，以下のリンクを参考にせよ． 参考：https://support.google.com/analytics/answer/6086069?hl=ja ・セッションIDの発行，セッションファイルの生成 セッションは，session_startメソッドを用いることで開始される．また同時に，クライアントにセッションIDを発行する．グローバル変数にセッションIDを代入することによって，セッションIDの記載されたセッションファイルを作成する．セッションIDに紐付くその他のデータはこのセッションファイルに書き込まれていく．セッションファイルの名前は，sess_*****ファイルとなっており，セッションファイル名を元にしてセッションIDに紐付くデータを参照する．もしクライアントに既にセッションIDが発行されている場合，セッションファイルを参照するようになる． ＊実装例＊ ・セッションファイルの保存場所 セッションファイルの保存場所は/etc/php.iniファイルで定義できる． # /etc/php.ini ### ファイル形式 session.save_handler = files ### 保存場所 session.save_path = \"/tmp\" セッションファイルは，サーバ外（PHP Redis，ElastiCache Redisなど）に保存することもできる．/etc/php-fpm.d/www.confファイルではなく，/etc/php.iniファイルにて保存先の指定が必要である．ElastiCache Redisについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws.html # /etc/php.ini ## Redis形式 session.save_handler = redis ## Amazon RedisのOrigin session.save_path = \"tcp://foo-redis.*****.ng.0001.apne1.cache.amazonaws.com:6379\" なお，PHP-FPMを使用している場合は，/etc/php-fpm.d/www.confファイルにて，セッションファイルの保存先を指定する必要がある． # /etc/php-fpm.d/www.conf ## Redis形式 php_value[session.save_handler] = redis ## Amazon RedisのOrigin php_value[session.save_path] = \"tcp://foo-redis.*****.ng.0001.apne1.cache.amazonaws.com:6379\" ・セッションの有効期限と初期化確率 セッションの有効期限を設定できる．これにより，画面遷移時にログイン情報を保持できる秒数を定義できる． # 24時間 session.gc_maxlifetime = 86400 ただし，有効期限が切れた後にセッションファイルを初期化するかどうかは確率によって定められている．確率は， 『gc_probability÷gc_divisor』 で計算される． 参考：https://www.php.net/manual/ja/session.configuration.php#ini.session.gc-divisor # 有効期限後に100%初期化されるようにする． session.gc_probability = 1 session.gc_divisor = 1 ・仕組み 最初，ブラウザはリクエストでデータを送信する．セッションIDを発行し，セッションIDごとにsess_*****ファイルを生成． サーバは，レスポンスヘッダ情報のCookieヘッダーを使用して，セッションIDを送信する． ブラウザは，そのセッションIDを保存する． 2回目以降のリクエストでは，ブラウザは，リクエストヘッダ情報のCookieヘッダーを使用して，セッションIDをサーバに送信する．サーバは，セッションIDに紐付くクライアントのデータをReadする． "},"public/software/software_application_collaboration_api_restful_api_specification.html":{"url":"public/software/software_application_collaboration_api_restful_api_specification.html","title":"📖 ︎API仕様書","keywords":"","body":"API仕様書 01. OpenAPI仕様 OpenAPI仕様とは RESTful APIの仕様を実装により説明するためのフォーマットのこと．JSON型またはYAML型で実装できる．いくつかのフィールドから構成されている． 参考：https://spec.openapis.org/oas/v3.1.0#fixed-fields openapi: # openapiフィールド info: # infoフィールド servers: # serversフィールド paths: # pathsフィールド webhooks: # webhooksフィールド components: # componentsフィールド security: # securityフィールド tags: # tagsフィールド externalDocs: # externalDocsフィールド API Gatewayによるインポート API GatewayによるOpenAPI仕様のインポートについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws_api_gateway_import.html フィールド ・openapiフィールド（必須） OpenAPI仕様のバージョンを定義する． ＊実装例＊ openapi: 3.0.0 ・infoフィールド（必須） API名，作成者名，メールアドレス，ライセンス，などを定義する． ＊実装例＊ info: title: Foo API # API名 description: The API for Foo. # APIの説明 termsOfService: https://www.foo.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.foo.com/support # 連絡先に関するURL email: support@foo.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン ・serversフィールド API自体のURL，などを定義する． ＊実装例＊ servers: - url: https://{env}.foo.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www ・pathsフィールド（必須） APIのエンドポイント，HTTPメソッド，ステータスコード，などを定義する． paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: # GETメソッドを指定する． tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # リクエスト #=========================== parameters: [] #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # path itemオブジェクト #=========================== post: # POSTメソッドを指定する． tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # リクエスト #=========================== parameters: [] requestBody: # メッセージボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type foo: # メッセージボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # スキーマとして，正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type foo: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # スキーマとして，異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # リクエスト #=========================== parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string foo: # パスパラメータ例 userId=1 #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type foo: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type foo: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type foo: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # リクエスト #=========================== parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string foo: # パスパラメータ例 userId=1 #=========================== # レスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # Content-Type foo: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # Content-Type foo: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # Content-Type foo: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． ・componentsフィールド（必須） スキーマなど，他の項目で共通して利用するものを定義する． components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type foo: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"APIキーの認可に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # Basic認証 basicAuth: description: Basic認証 type: http scheme: basic # Bearer認証 bearerAuth: description: Bearer認証 type: http scheme: bearer # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # ヘッダ名は『x-api-key』とする．小文字が推奨である． in: header ＊実装例＊ ・securityフィールド componentsフィールドで定義した認証方法を宣言する．ルートで宣言すると，全てのパスに適用できる． ＊実装例＊ security: - apiKeyAuth: [] ・tagsフィールド 各項目に付けるタグを定義する．同名のタグをつけると，自動的にまとめられる． ＊実装例＊ tags: - name: ユーザ情報取得エンドポイント description: | ・externalDocsフィールド APIを説明するドキュメントのリンクを定義する． ＊実装例＊ externalDocs: description: 補足情報はこちら url: https://foo.com スキーマ ・スキーマとは APIに対して送信されるリクエストメッセージのデータ，またはAPIから返信されるレスポンスメッセージのデータについて，データ型や必須データを，JSON型またはYAML型で実装しておいたもの．リクエスト／レスポンス時のデータのバリデーションに用いる． ・スキーマによるバリデーション データ型や必須データにより，リクエスト／レスポンスのデータのバリデーションを行う． 参考：https://spec.openapis.org/oas/v3.1.0#data-types ＊実装例＊ 例えば，APIがレスポンス時に以下のようなJSON型データを返信するとする． { \"id\": 1, \"name\": \"Taro Yamada\", \"age\": 10, \"sports\":[\"soccer\", \"baseball\"], \"subjects\": \"math\" } ここで，スキーマを以下のように定義しておき，APIからデータをレスポンスする時のバリデーションを行う． { \"$schema\": \"https://json-schema.org/draft-04/schema#\", \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"integer\", \"minimum\": 1 }, \"name\": { \"type\": \"string\" }, \"age\": { \"type\": \"integer\", \"minimum\": 0 }, \"sports\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } }, \"subjects\": { \"type\": \"string\" } }, \"required\": [\"id\"] } ・API Gatewayにおけるスキーマ設定 API Gatewayにて，バリデーションのためにスキーマを設定できる．詳しくは，以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws.html "},"public/hardware/hardware.html":{"url":"public/hardware/hardware.html","title":"📖 ︎ハードウェア","keywords":"","body":"ハードウェア はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ハードウェアとは ハードウェアの種類 ・ユーザの操作が，ソフトウェアを介して，ハードウェアに伝わるまで ・CPU（プロセッサ） CPUは制御と演算を行う．CPUの制御部分は，プログラムの命令を解釈して，コンピュータ全体を制御．CPUの演算部分は，計算や演算処理を行う．特に，『算術論理演算装置（ALU：Arithmetic and Logic Unit）』とも呼ぶ． ・RAM（メインメモリ＋キャッシュメモリ） プログラムやデータを一時的に記憶し，コンピュータの電源を切るとこれらは消える． ・ROM プログラムやデータを長期的に記憶し，コンピュータの電源を切ってもこれらは消えない． ・ストレージ（HDD vs SSD） HDD：Hard Disk DriveとSSD：Solid State Driveがある． ・入力装置 コンピュータにデータを入力．キーボード，マウス，スキャナなど． ・出力装置 コンピュータからデータを出力．ディスプレイ，プリンタなど． 02. CPU（プロセッサ） IntelとAMDにおけるCPUの歴史（※2009年まで） クロック周波数 CPUの回路が処理と歩調を合わせるために用いる信号を，『クロック』と言う．一定時間ごとにクロックが起こる時，１秒間にクロックが何回起こるかを『クロック周波数』という．これは，Hzで表される．ちなみに，ワイのパソコンのクロック周波数は2.60GHzでした． （例1） 3Hz = 3 (クロック数／秒) （例2） 2.6GHz = 2.6×10^9 (クロック数／秒) MIPS：Million Instructions Per Second（×10^6 命令数／秒） CPUが1秒間に何回命令を実行するかを表す． （例題） (命令当たりの平均クロック数) = (4×0.3)＋(8×0.6)＋(10×0.1) = 7 (クロック周波数) ÷ (クロック当たりの命令数) = 700Hz (×10^6 クロック数／秒) ÷ 7 (クロック数／命令) = 100 (×10^6 命令数／秒) ・1命令当たりの実行時間 (秒／命令) の求め方 1 ÷ 100 (×10^6 命令／秒) = 10n (秒／命令) 03. メモリ 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/hardware/hardware_memory.html 04. ディスクメモリ CPU，メインメモリ，ストレージ間には，読み込みと書き出しの処理速度に差がある．（※再度記載） ディスクメモリの機能 メインメモリとストレージの間に，ディスクキャッシュを設置し，読み込みと書き出しの処理速度の差を緩和させる． 05. HDD Defragmentation 断片化されたデータ領域を整理整頓する． RAID：Redundant Arrays of Inexpensive Disks 複数のHDDを仮想的に一つのHDDであるかのようにして，データを管理する技術． ・RAID0（Striping） データを，複数のHDDに分割して書き込む． ・RAID1（Mirroring） データを，複数のHDDに同じように書き込む． ・RAID5（Striping with parity） データとパリティ（誤り訂正符号）を，3つ以上のHDDに書き込む． 06. GPUとVRAM GPUとVRAMの容量によって，扱うことのできる解像度と色数が決まる． 富士通PCのGPUとVRAMの容量は，以下の通り． 色数によって，１ドット当たり何ビットを要するが異なる． "},"public/hardware/hardware_memory.html":{"url":"public/hardware/hardware_memory.html","title":"📖 ︎メモリ","keywords":"","body":"メモリ はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 物理メモリ（RAM + ROM） 物理メモリの種類 『物理メモリ』は，RAMとROMに大きく分けられる． RAM：Read Access Memory RAMは，メインメモリとして使われる『Dynamic RAM』と，キャッシュメモリとして使われる『Static RAM』に分類される． ・Dynamic RAM メインメモリとして用いられる．よく見るやつ． ・Static RAM キャッシュメモリとして用いられる． ROM：Read Only Memory ・Mask ROM ・Programmable ROM Garbage collection プログラムが確保したメモリ領域のうち，不要になった領域を自動的に解放する機能． ・JavaにおけるGarbage collection Javaでは，JVM：Java Virtual Machine（Java仮想マシン）が，メモリ領域をオブジェクトに自動的に割り当て，また一方で，不要になったメモリ領域の解放を行う．一方で自動的に行う． 02. SRAM CPUから命令が起こるとき，CPU，DRAM，ストレージ間には，読み込みと書き出しの処理速度に差がある． キャッシュメモリとは ・一次キャッシュメモリと二次キャッシュメモリ** CPUとメインメモリの間に，キャッシュメモリを何段階か設置し，CPUとメインメモリの間の読み込みと書き出しの処理速度の差を緩和させる． キャッシュメモリの読み込み方法 ・ユーザー ➔ メインメモリ ➔ 二次キャッシュメモリ ➔ 一次キャッシュメモリ ユーザーが，パソコンに対して命令を与える． CPUは，命令をメインメモリに書き込む． CPUは，メインメモリから命令を読み出す． CPUは，二次キャッシュメモリに書き込む． CPUは，一次キャッシュメモリに書き込む． CPUは，命令を実行する． ・実例 タスクマネージャのパフォーマンスタブで，n次キャッシュメモリがどのくらい使われているのかを確認できる． キャッシュメモリへの書き込み方式の種類 ・Write-throught方式 CPUは，命令をメインメモリとキャッシュメモリの両方に書き込む．常にメインメモリとキャッシュメモリの内容が一致している状態を確保できるが，メモリへの書き込みが頻繁に行われるので遅い． ・Write-back方式 CPUは，キャッシュメモリのみに書き込む．次に，キャッシュメモリがメインメモリに書き込む．メインメモリとキャッシュメモリの内容が一致している状態を必ずしも確保できないが，メインメモリへの書き込み回数が少ないため速い 実効アクセス時間 03. アドレス空間管理の種類 前置き 言葉の使い方を，以下に統一する． 主記憶 ⇒ 物理メモリ（メインメモリ＋キャッシュメモリ） 補助記憶 ⇒ ストレージ 仮想記憶 ⇒ 仮想メモリ 物理メモリのアドレス空間管理 ・区画方式 後述の説明を参考にせよ． ・スワッピング方式 後述の説明を参考にせよ． ・オーバーレイ方式 後述の説明を参考にせよ． 仮想メモリのアドレス空間管理 ・ページング方式 後述の説明を参考にせよ． 03-02. 物理メモリのアドレス空間管理 固定区画方式（同じ大きさの区画に分割する方式） ・単一区画方式とは 物理メモリの領域を，一つの区画として扱い，プログラムに割り当てる方式．単一のプログラムしか読み込めず，余りのメモリ領域は利用できない． ・多重区画方式とは 物理メモリの領域を，複数の同じ大きさの区画に分割し，各区画にプログラムに割り当てる方式．複数のプログラムを読み込むことができるが，単一区画方式と同様に，余ったメモリ領域は利用できない． 可変区画方式（様々な大きさの区画に分割する方式） ・可変区画方式とは 物理メモリの領域を，プログラムの大きさに応じて，区画を様々な大きさの区画に分割し，プログラムに割り当てる方式．固定区画方式とは異なり，メモリ領域を有効に利用できる． スワッピング方式 ・スワッピング方式とは 物理メモリの領域を，優先度の高いプログラムに割り当て，反対に優先度が低いプログラムはストレージに退避させる方式． オーバーレイ方式 ・オーバーレイ方式とは GC：ガベージコレクション ・ガベージコレクションとは 確保された物理メモリのうち，解放可能なメモリをプログラムから解放する．物理メモリを使用しているオブジェクトが何かしらから参照されているかどうかを元に，解放するかどうかを判定する． ・アルゴリズム ガベージコレクションには様々なアルゴリズムがあり，採用されているアルゴリズムは言語ごとに異なる．Goのガベージコレクションについては，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_procedural_language_go_logic.html 03-03. 仮想メモリのアドレス空間管理 ページング方式 ・ページング方式とは 仮想メモリの実装方法の一つ．仮想メモリのアドレス空間を『固定長』の領域（ページ），また物理メモリのアドレス空間を『固定長』の領域（ページフレーム）に分割し，管理する方式． ・ページイン／ページアウト 仮想メモリは，CPUの処理によって稼働したプログラムの要求を，物理メモリの代理として受け付ける．ストレージから物理メモリのページフレームにページを読み込むことを『Page-in』という．また，物理メモリのページフレームからストレージにページを追い出すことを『Page-out』という． ・仮想メモリとのマッピングによる大容量アドレス空間の実現 仮想メモリのアドレス空間を，物理メモリのアドレス空間とストレージにマッピングすることによって，物理メモリのアドレス空間を疑似的に大きく見せかけることができる． ちなみに，富士通の仮想メモリの容量は，以下の通り． セグメント方式 ・セグメント方式とは 仮想メモリの実装方法の一つ．仮想メモリのアドレス空間を『可変長』の領域（セグメント），また物理メモリのアドレス空間を『可変長』の領域（セグメント）に分割し，管理する方式． MMU：Memory Management Unit（メモリ管理ユニット） ・MMUにおける動的アドレス変換機構 MMUによって，仮想メモリのアドレスは，物理メモリのアドレスに変換される．この仕組みを，『動的アドレス変換機構』と呼ぶ． ・アドレス変換の仕組み（ページング方式型／セグメント方式型） 仮想メモリにおけるページの仮想アドレスを，ページ番号とページオフセットに分割する． ページテーブルを用いて，仮想アドレスのページ番号に対応する物理アドレスのページ番号を探す． 物理ページ番号にページオフセットを再結合し，物理メモリのページフレームの物理アドレスとする． ・ページテーブルにおける仮想ページ番号と物理ページ番号の対応づけ 03-04. プロセス プロセスとは プログラムは，メモリ上の特定のアドレス範囲に割り当てられている．プログラム自体を『プロセス』という．プロセスの代わりに『タスク』ということもある．プロセスとして割り当てられたプログラムはCPUに参照され，CPUのコア上で処理が実行される．シングルプロセスとマルチプロセスがあり，現代のハードウェアのほとんどがマルチプロセスの機能を持つ． 参考： https://jpazamu.com/thread_process/#index_id5 http://staff.miyakyo-u.ac.jp/~m-yasu/curri-ex/os/txt/os5.html プロセシングの種類 ・シングルプロセシング 単一のメモリ上において，単一のプロセスがアドレスに割り当てられる仕組みのこと． ・マルチプロセシング 単一のメモリ上において，複数のプロセスがアドレスに割り当てられる仕組みのこと．優先度の低いプロセスからCPUを切り離し，優先度の高いプロセスにCPUを割り当てる，といった仕組みを持つ． 参考：https://linuxjf.osdn.jp/JFdocs/The-Linux-Kernel-5.html 03-05. スレッド スレッドとは メモリ上ではプログラムがプロセスとして割り当てられており，プログラムはCPUのコア上で実行される．CPUのコアと紐付くプロセスの実行単位を『スレッド』という． 参考：https://atmarkit.itmedia.co.jp/ait/articles/0503/12/news025.html スレッディングの種類 ・シングルスレッディング メモリ上の特定のプロセスにおいて，単一のスレッドを実行できる仕組みのこと． ・マルチスレッディング メモリ上の特定のプロセスにおいて，複数のスレッドを実行できる仕組みのこと．各スレッドがプロセスに割り当てられているアドレスを共有して使う． マルチスレッディングについて ・通常のマルチスレッド CPUのコアが単一のスレッドが紐付くようなマルチスレッドのこと． 参考：https://milestone-of-se.nesuke.com/sv-basic/architecture/hyper-threading-smt/ ・同時マルチスレッド CPUのコアが複数のスレッドが紐付くようなマルチスレッドのこと． 参考：https://milestone-of-se.nesuke.com/sv-basic/architecture/hyper-threading-smt/ 03-05. Page fault発生時の処理 Page faultとは ストレージから物理メモリのアドレス空間への割り込み処理のこと．CPUによって稼働したプログラムが，仮想メモリのアドレス空間のページにアクセスし，そのページが物理メモリのアドレス空間にマッピングされていなかった場合に，ストレージから物理メモリのアドレス空間に『ページイン』が起こる． Page Replacementアルゴリズム ページアウトのアルゴリズムのこと．方式ごとに，物理メモリのページフレームからストレージにページアウトするページが異なる． ・『FIFO方式：First In First Out』と『LIFO方式：Last In First Out』 ・『LRU方式：Least Recently Used』と『LFU方式：Least Frequently Used』 03-06. アドレス空間管理におけるプログラムの種類 Reusable（再使用可能プログラム） 一度実行すれば，再度，ストレージから物理メモリにページインを行わずに，実行を繰り返せるプログラムのこと． Reentrant（再入可能プログラム） 再使用可能の性質をもち，また複数のプログラムから呼び出されても，互いの呼び出しが干渉せず，同時に実行できるプログラムのこと． Relocatable（再配置可能プログラム） ストレージから物理メモリにページインを行う時に，アドレス空間上のどこに配置されても実行できるプログラムのこと． "},"public/hardware/hardware_embedded_system.html":{"url":"public/hardware/hardware_embedded_system.html","title":"📖 ︎組み込み機器","keywords":"","body":"組み込み機器 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 組み込み機器 組み込みシステムとは 組み込み機器（限定的な用途向けに特定の機能を果たす事を目的とした機器）を制御するシステムのこと． ※パソコンは、汎用機器（汎用的な用途向けに多様な機能を果たす事を目的とした機器）に分類される． マイクロコンピュータとは CPUとして、『マイクロプロセッサ』を用いたコンピュータのこと． センサによるアナログ情報の入力 外部のアナログ情報を計測し、マイコンに転送する． ＊例＊：温度センサ、加速度センサ、照度センサ、… A/D変換器によるアナログ情報からデジタル情報への変換 D/A変換器によるデジタル情報からアナログ情報への変換 Actuater 入力されたエネルギーもしくはコンピュータが出力した電気信号を物理的運動に変換する装置のこと． 組み込みシステムの制御方式の種類 ・シーケンス制御 決められた順序や条件に従って、制御の各段階を進めていく制御方式． ＊例＊ 洗濯機 ・フィードバック制御 その時の状況を定期的に計測し、目標値との差分を基に、出力を調節する制御方式． ＊例＊ エアコン 02. 入出力機器 キーボードからポインティングデバイス ・ジョイスティック 読み取り機器 ・イメージスキャナ ・Optical Character Reader 紙上の文字を文字データとして読み取る機器． ・Optical Mark Reader マークシートの塗り潰し位置を読み取る機器． ・キャプチャカード ・デジタルカメラ ディスプレイ ・CRTディスプレイ ・液晶ディスプレイ 電圧の有無によって液晶分子を制御．外部からの光によって画面を表示させる． ・有機ELディスプレイ 有機化合物に電圧を加えることによって発光させ、画面を表示させる． ・プラズマディスプレイ 2枚のガラスの間に、封入された希ガスに電圧をかけると放電し、紫外線が出る．そして、この紫外線が蛍光体を発光させることによって画面を表示する． 液晶ディスプレイとのシェア差が大きくなり、2014年に世界的に生産が終了された． ・LEDディスプレイ 2018年1月に開催された「CES 2018」でサムスンが発表した“マイクロLEDテレビ”「The Wall」は、従来の「液晶」や「有機EL」とは異なる新たな表示方式を採用したテレビとして、大きな話題となった． プリンタ ・ドットインパクトプリンタ ・インクジェットプリンタ ・レーザプリンタ ・プリンタの解像度 １インチ当たりのドット数（dpi）によって、解像度が異なる．復習ではあるが、PC上では、ドット数がどのくらいのビット数を持つかで、解像度が変わる． dpiが大きくなるにつれて、解像度は大きくなる． ・プリンタの印字速度 02-02. 入出力インターフェイス Serial interface vs. Parallel interface シリアルインターフェイスは、情報を1bitずつ転送する方式．パラレルインターフェイスは、複数のbitの情報を同時に転送する方式．パラレルインターフェイスは、同時にデータを送信し、同時に受信しなければならない．配線の形状や長さによって、信号の転送時間は異なる．動作クロックが速ければ速いほど、配線間の同時転送に誤差が生じてしまうため、現代の高スペックパソコンには向いていない． Serial interface が用いられている例 ・USB（Universal Serial Bus） ・IEEE1394 ビデオカメラとの接続に用いられるインターフェイス Parallel interface が用いられている例 ・IDE（Integrated Drive Electronics） ハードディスクとの接続に用いられるインターフェイス． ・SCSI（Small Computer System Interface） ハードディスク、CD-ROM、イメージスキャナなど、様々な周辺機器をデイジーチェーンするために用いるインターフェイス． 無線インターフェイス ・IrDA（infrared Data Assoiciation） 赤外線を使って、無線通信を行うためのインターフェイス． ・Bluetooth 2.4GHzの電波を使って無線通信を行うためのインターフェイス． "},"public/network/network.html":{"url":"public/network/network.html","title":"📖 ︎ネットワーク","keywords":"","body":"ネットワーク はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ネットワークの全体像 インターネット，WAN，LAN ネットワークには，『インターネット』『WAN』『LAN』がある．家庭内LAN，学内LAN，企業内LAN，企業WANなど，さまざまなネットワークがあり，インターネットは，それぞれのネットワークを互いに接続しているネットワークである． WAN，LANの例 例えば，LANとしてEthernet，WANとしてデジタル専用線を用いる． WANの種類と歴史 グローバルネットワークとプライベートネットワーク ルータを境に，プライベートネットワークとグローバルネットワークに分けられる．ややこしいが，ルータにはグローバルIPアドレスが割り当てられている． 02. プライベートネットワークへのデータ送信 データ通信方法の種類 ・回線交換方式 少数対少数でデータ通信を行うため，送信時に，送信者と受信者の宛先情報は必要ない． ・パケット交換方式 通信するデータをパケット化する．多数対多数でデータ通信を行うため，送信時に，送信者と受信者の宛先情報が必要になる． URLとメールアドレス ・構造 URLとメールアドレスは完全修飾ドメイン名を持つ． また，完全修飾ドメイン名は，ドメイン名の子関係にあるサブドメイン名を持てる．ホスト名（以下では省略されている）と，ドメイン名の間につける． ・完全修飾ドメイン名によるサーバ指定 完全修飾ドメイン名は，所属ネットワークを指すドメイン名と，そのネットワークにおける具体的なサーバを指すホスト名からなる．ただし，サーバのホスト名が『www』である場合，クライアントはURLの指定時にホスト名を省略できる．例えば，『www.example.co.jp』という完全修飾ドメイン名をURLで指定する場合，『example.co.jp』としてもよい． セグメント ・セグメントの種類 プライベートネットワークは，外部公開用ネットワーク，非武装地帯，内部ネットワークに分類される． ・非武装地帯のサーバの種類 攻撃の影響が内部ネットワークに広がる可能性を防ぐために，外部から直接リクエストを受ける．そのため，『DNSサーバ』『プロキシサーバ』『Webサーバ』『メールサーバ』は，非武装地帯に設置される． ・内部ネットワークのサーバの種類 外部から直接リクエストを受けない．そのため，『DBサーバ』は，内部ネットワークに設置される． 03. Webシステムを構成する主要な3層構造 Webシステムとは Webサーバ，Appサーバ，DBサーバによるネットワークの仕組みをWebシステムという．ソフトウェアとハードウェアのノートも参考にせよ． Webサーバ ・Webサーバの役割 ミドルウェア（Apache，Nginxなど）がインストールされている．また，Web兼Appサーバのミドルウェアとして機能する（NGINX Unit）がインストールされていることもある． Webサーバ → Appサーバ → DBサーバ 静的コンテンツ 静的レス ー ー 静的コンテンツ＋動的コンテンツ 静的レス 動的レス データ管理 ブラウザから静的コンテンツのみのリクエストがあった場合，静的コンテンツをレスポンスする．また，静的コンテンツと動的コンテンツの両方のリクエストがあった場合に，アプリケーションサーバに動的コンテンツのリクエストを行う．アプリケーションサーバからレスポンスを受け取り，ブラウザにレスポンスを行う． Appサーバ ・Appサーバの役割 ミドルウェア（PHPならPHP-FPM，JavaならTomcat）がインストールされている． Webサーバ → Appサーバ → DBサーバ 静的コンテンツ 静的レス ー ー 静的コンテンツ＋動的コンテンツ 静的レス 動的レス データ管理 Webサーバから動的コンテンツのリクエストがあった場合に，プログラミング言語を言語プロセッサで翻訳し，DBサーバにリクエストを行う．DBサーバからのレスポンスを受け取り，Webサーバに動的なコンテンツのレスポンスを行う． DB管理システムを持つDBサーバ ・DBサーバの役割 DB管理システムがインストールされている．DBの情報が保存されている． サーバの処理能力向上 ・垂直スケーリング（スケールアップ ⇔ スケールダウン） サーバ自体のスペックをより高くすることで，サーバ当たりの処理能力を向上させる．その逆は，スケールダウン．設定で，仮想サーバのスペックを上げることも，これに該当する． ・水平スケーリング（スケールアウト ⇔ スケールイン） サーバの台数を増やすことで，サーバ全体の処理能力を向上させる．その逆は，スケールイン． 03-02. Webシステムの構成方法 Dualシステム 同じ処理を行う2つのシステムからなるシステム構成のこと．随時，処理結果を照合する．いずれかが故障した場合，異常が発生したシステムを切り離し，残る片方で処理を続けることによって，故障を乗り切る． Duplexシステム オンライン処理を行う主系システムと，バッチ処理を行う従系システムからなるシステム構成のこと．主系システムが故障した場合，主系システムのオンライン処理を従系システムに引き継ぎ，処理を続けることによって，故障を乗り切る． 従系システムの待機方法には２つの種類がある． ・ホットスタンバイ ・コールドスタンバイ システムの稼働率 並列システムの場合，両方の非稼働率をかけて，全体から引く． ＊例＊ １－(1－0.81) × (1－0.64) = 0.9316 04. フォワード／リバースプロキシサーバ 役割 ・代理リクエスト機能（セキュリティのノートも参照） 代理でリクエストを送るフォワードプロキシサーバと，レスポンスを送るリバースプロキシサーバに分類できる． ・キャッシュ機能 リバースプロキシサーバに，Webページのコンテンツをキャッシュとして保存することによって，Webサーバのアクセス負荷を抑える．ちなみに，ブラウザもキャッシュ機能を持っている． 設置場所 ・物理サーバの場合 フォワードプロキシサーバはプロバイダの会社に，リバースプロキシサーバはリクエスト先の社内ネットワークに設置されている． ・クラウド上の場合 クラウドの場合も，サーバが仮想的に構築される違いだけで，設置場所は同じである． リバースプロキシサーバの実現方法 ・Nginx Webサーバとしてではなく，リバースプロキシサーバとして使用し，代理リクエストやキャッシュを行わせることが可能． 04-02. プロキシサーバ，DNSサーバによる名前解決 （1）完全修飾ドメイン名に対応するIPアドレスのレスポンス ・仕組み クライアントPCは，完全修飾ドメイン名を，フォワードプロキシサーバ（キャッシュDNSサーバ）にリクエスト． フォワードプロキシサーバは，完全修飾ドメイン名を，リバースプロキシサーバに代理リクエスト． リバースプロキシサーバは，完全修飾ドメイン名を，DNSサーバ（ネームサーバ）に代理リクエスト． DNSサーバは，完全修飾ドメインにマッピングされるIPv4アドレスを取得し，リバースプロキシサーバにレスポンス． | 完全修飾ドメイン名 | ⇄ | IPv4アドレス | | :--------------------------: | :--: | :-------------------: | | http://www.example.com | | 203.142.205.139 | リバースプロキシサーバは，IPv4アドレスを，フォワードプロキシサーバに代理レスポンス．（※NATによるIPv4アドレスのネットワーク間変換が起こる） フォワードプロキシサーバは，IPv4アドレスを，クライアントPCに代理レスポンス． ・プロキシサーバ（キャッシュDNSサーバ）におけるDNSキャッシュ ルートサーバは世界に13機しか存在しておらず，世界中の名前解決のリクエストを全て処理することは現実的に不可能である．そこで，IPアドレスとドメイン名の関係をキャッシュするプロキシサーバ（キャッシュDNSサーバ）が使用されている．基本的には，プロキシサーバとDNSサーバは区別される．ただし，Amazon Route53のように，プロキシサーバとDNSサーバの機能を両立しているものもある． （2）IPアドレスに対応するWebページのレスポンス ・仕組み クライアントPCは，レスポンスされたIPv4アドレスを基に，Webページを，リバースプロキシサーバにリクエスト． リバースプロキシサーバは，Webページを，Webサーバに代理リクエスト． Webサーバは，Webページを，リバースプロキシサーバにレスポンス． リバースプロキシサーバは，Webページを，クライアントPCに代理レスポンス． 06. ネットワーク速度の指標 一覧 レスポンスタイム リクエストを送信してから，サーバが処理を実行し，レスポンスが返信されるまでに要する時間のこと． レイテンシー リクエストを送信してから，レスポンスが返信されるまで要する時間のこと．サーバの処理時間は含まない． Connection Time（接続時間） リクエストを送信する前に，サーバとのTCP接続の確立に要する時間のこと． リクエストとレスポンスの送受信の前後に行われるTCP接続の確立を「スリーウェイハンドシェイク」という． Bandwidth（帯域幅） 一度に送受信できるデータの最大容量のこと． スループット（伝送速度） 単位時間当たりの送信できる最大のデータ容量のこと． 他からの影響を受けた実際のスループットを「実効スループット」という． スループット（伝送速度） ・伝送とは サーバからクライアントPCにデータを送信すること．相互の送信は，通信と呼ぶ． ・スループットとは 単位時間当たりの送信できる最大のデータ容量のこと．実際には，スループットは，『プロバイダ』，『光回線』，『自宅の有線／無線』の三つに影響されるため，スループットで期待されるデータ容量を満たせないことが多い．実際のスループットを「実効スループット」という． ・伝送秒数の求め方 (伝送秒数) = データ容量(bit) ÷ スループット(bit/s) × 伝送効率 ・トラフィックとは とあるネットワーク地点でのスループットのこと． 参考：https://xtech.nikkei.com/it/article/Keyword/20070222/262872/ 総務省のデータで，日本のブロードバンド大手5社の総トラフィックを年次でグラフ化したものがある． 参考：https://xtech.nikkei.com/atcl/nxt/column/18/00525/112900001/ "},"public/network/network_osi_tcp_model.html":{"url":"public/network/network_osi_tcp_model.html","title":"📖 ︎OSI参照モデル／TCP階層モデル","keywords":"","body":"OSI参照モデル／TCP階層モデル はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. OSI参照モデルとTCP階層モデル データがパケットになるまで アプリケーション層でデータが作成される． トランスポート層でTCPヘッダが追加される． インターネット層でIPヘッダが追加される． ネットワークインターフェース層でEthernetヘッダが追加される． パケットとして送信される． OSI参照モデル ・各概念層のヘッダ情報追加 TCP階層モデル ・プロトコルの分類と扱われる階層 TCP/IPモデルで用いられるプロトコルのうち，最も代表的な「TCP」と「IP」から名前をとって「TCP/IP」と名付けられた．プロトコルとしての暗号化技術である『セキュアプロトコル』は，赤色で示してある． 02-02. 通信機器におけるヘッダ情報認識 各概念層と通信機器の間の対応関係 プライベートネットワークにクライアントPCがある． クライアントPCにて，WebブラウザのアプリケーションのプロセスがTCPアプリケーション層（OSIアプリケーション層＋プレゼンテーション層＋セッション層）で稼働している．ここで，パケットが作成される． パケットは，クライアントPCのTCPトランスポート層（OSIトランスポート層），TCPインターネット層（OSIネットワーク層），TCPネットワークインターフェース層（OSIデータリンク層＋OSI物理層）を経る．各層で，パケットにヘッダー情報が追加される． PCからルータにパケットが送信される． ルータはTCPインターネット層（OSIネットワーク層）に属するため，より上層に一度戻ることになる． グローバルネットワークを経て，送信先のプライベートネットワークのルータに到達する． ルータからサーバにパケットが送信される． パケットは，サーバのCPネットワークインターフェース層（OSIデータリンク層＋OSI物理層），TCPインターネット層（OSIネットワーク層），TCPトランスポート層（OSIトランスポート層），を経る． サーバにて，アプリケーションのプロセスが特定のポート番でリッスンしている．アプリケーションによってパケットが処理される． ・ネットワーク層 ・データリンク層 ・物理層 NIC：Network Interface Card（例：LANアダプタ，LANボード，LANカード），リピータ，LANケーブル 各概念層のヘッダ情報認識 送信元で作成されたパケットは，非カプセル化されながら，通信機器に認識される． 参考：https://ja.wikipedia.org/wiki/%E3%83%AB%E3%83%BC%E3%82%BF%E3%83%BC 03. TCPアプリケーション層 アプリケーション層とは 各アプリケーションがプロセスとして稼働しており，それぞれがデータ（メッセージ）を作成する．各プロセスは特定のポート番号をリッスンする． 参考：https://netdekagaku.com/netstat-command/ ちなみに，指定したポート番号でリッスンしているプロセスを特定できる． $ sudo lsof -i: 03-02. メールデータの作成 メールデータの送受信 ・仕組み クライアント（メール送信可能なアプリケーション）から送信されたメールは，送信側のメールサーバに送信される． 送信側のメールサーバは，メールを受信側のメールサーバに転送する． 受信側のアプリケーションは，各々が指定したプロトコルに応じて，受信側のメールサーバからメールデータを取得する． 参考：https://xtech.nikkei.com/it/pc/article/basic/20120312/1043605/ ・送信側のメールサーバのモック メールデータの送信機能を開発するときに，送信テストを行う必要があり，この内容は公開したくない．そこで，送信側のメールサーバのモックを提供するサービスを利用する．この送信側メールサーバモックは，クライアントから送信されたメールのテストデータを受信側のメールサーバに転送しないため，安全に送信テストを実行できる．Mailtrapがおすすめである． 参考：https://mailtrap.io/ SMTP：Simple Mail Transfer Protocol ・SMTPとは メールデータを送信するためのプロトコルのこと． ・SMTP-AUTH：SMTP AUTHentication SMTPに認証を組み込んだ仕組みのこと．クライアント（メール送信可能なアプリケーション）からメールサーバにメールデータをSMTP送信する時，メールサーバがクライアントに対して認証を実行する． POP3：Post Official Protocol version 3 ・POP3とは メールサーバに届いたメールを，受信機器にダウンロードし，受信機器で閲覧するプロトコル．メールの既読未読状況は，他の受信機器と共有される． IMAP4：Internet Message Access Protocol version 4 ・IMAP4とは メールサーバに届いたメールを，受信機器にダウンロードせず，メールサーバに置いたまま閲覧するプロトコル．メールの既読未読状況は，他の受信機器と共有されない． ＊例＊ GmailでPOPかIMAPを設定可能 APOP：Authenticated POP ・APOPとは メール受信の際に，チャレンジレスポンス方式の認証を行うことで平文の認証情報がネットワークに流れるのを防止するプロトコル 04. TCPトランスポート層 トランスポート層とは ・全体像 クライアントからのリクエスト時に，ネットワーク層から渡されたパケットのポート番号情報を元に，アプリケーション層の特定のプロセスにパケットを渡す．また反対に，レスポンス時にアプリケーション層のプロセスから出力されたパケットに情報を付加し，ネットワーク層に渡す．この時，各アプリケーションはプロセスとして稼働していることに留意する． ・クライアントからのリクエスト時（図の 「→」 ） まず，ネットワーク層でプライベートIPアドレスを用いて，リクエスト先のパソコンを識別する．その後，トランスポート層で，ポート番号を元にして，アプリケーション層のプロセスにパケットを送信する． ＊例＊ ローカル環境のnginxプロセスのリッスンするポート番号を8080と設定した場合，リクエスト時に以下のようにポート番号を指定すると，nginxプロセスにリクエストを送信できる． GET http://localhost:8080/ ・クライアントへのレスポンス時（図の 「←」 ） アプリケーション層から送信されてきたパケットの通過したポート番号をヘッダ情報として追加する．これを，ネットワーク層へ送信する． ・ソケット，ソケット接続とは トランスポート層に存在し，受信した通信をアプリケーション層の各プロセスに振り分ける受け口をソケットという．送信元のサーバが送信先に対して，『192.168.1.1:50001（送信元IPアドレス:送信ポート）』『10.0.0.1:80（宛先IPアドレス:宛先ポート）』といったように，IPアドレスとポート番号の組合せで指定する．オリジンとは似て非なるものなので注意．サーバ間のソケット間のネットワーク接続をソケット接続という． ポート番号 ・ポート番号とは アプリケーションのプロセスへのパケット送受信に，プロセスを区別するために各プロセスに割り当てられる番号．アプリケーションには，それぞれポート番号が割り当てられており，トランスポート層で，ポート番号を元にして，特定のプロセスにパケットを送信する． ・Well known ポート番号（0 ～ 1023） IANA：Internet Assigned Numbers Authority（インターネット割当番号公社）によって管理されているポート番号．Webサーバがリクエストを受信する時，またレスポンスを送信する時に使用される．ホストOSとゲスト（仮想サーバ）との通信では，80番（HTTP）の受信に関する様々な設定が必要になる． ・登録済みポート番号（1024 ～ 49151） IANAが登録申請を受けて公開しているポート番号．企業が作成した独自のアプリなどに対して割り当てられる．クライアントがリクエストを送信する時，またレスポンスを受信する時に使用される． ・動的／非公式ポート番号（49152 ～ 65535） 自由に使用できるポート番号．クライアントがリクエストを送信する時，またレスポンスを受信する時に使用される． ・ポートフォワーディング（ポート転送） サーバ内の特定のポート番号のアプリケーションに対して，パケットが送信されてきた時，これを異なるポート番号のアプリケーションに転送すること．SSHプロトコルと組み合わせると，SSHポートフォワーディングを実現できる． ポートスキャナ ・ポートスキャナとは ポートスキャナを用いることによって，各ポート番号にアクセスし，応答があるかどうかや，どのようなソフトウェアが応答するかを調べ，一覧表示できる． 05. TCPインターネット層 インターネット層とは IPパケットのヘッダ情報を用いて，宛先認識する． PC-Aは，構成したIPパケットをEthernetに乗せて，ルータAに送信． ルータAは，IPパケットをデジタル専用線に乗せて，ルータBに送信． ルータBは，構成したIPパケットをEthernetに乗せて，Webサーバに送信． IPv4アドレスの種類 ・プライベートIPアドレス LAN内で使用される．異なるプライベートネットワーク間では，同じIPv4アドレスが存在する．プライベートIPアドレスは，『10.0.0.0 ～ 10.255.255.255』，『172.16.0.0 ～ 172.31.255.255』，『192.168.0.0 ～ 192.168.255.255』で表される． ・グローバルIPアドレス プロバイダが提供するIPv4アドレスである．パブリックネットワーク内に同じIPv4アドレスは存在せず，Network Information Centerへの使用申請が必要．プライベートIPアドレスの番号でなければ，グローバルIPアドレスである．NATはグローバルIPアドレスを持っており，プライベートネットワークとプライベートネットワーク間の双方向への通信時に，プライベートIPアドレスと相互変換する． プライベート／グローバルIPアドレスとbitとの関係 例えば，プライベートIPアドレスの４つのオクテット（第一オクテットから第四オクテットまで）が１Byteの容量をもち，IPアドレス全体で４Byteの容量を持つ．ちなみに，172から始まるIPアドレスは，クラスBである．　 プライベート／グローバルIPアドレスのネットワーク部とホスト部 ・クラスによるホスト部とネットワーク部の定義 IPアドレスをクラスとして分類し，各クラスでIPアドレスのネットワーク部とホスト部を定義する方法．設定したIPアドレスの属するクラスによって，使用できるIPアドレスの範囲が決まってしまう．ホスト部とネットワーク部の定義方法が4種類しかないため，IPアドレスのパターン数（最大パソコン数）が多すぎたり，少なすぎたりしてしまう． 使用可能なIPアドレスの範囲 クラス ネットワーク部のオクテット ホスト部のオクテット 二進数で見た時（n：ネ，h：ホ） IPアドレスのパターン数（最大パソコン数） 備考 0.0.0.0 〜 127.255.255.255 A 第一のみ 第二から第四 0nnnnnnn.hhhhhhhh.hhhhhhhh.hhhhhhhh 2^24（16777216）個 128.0.0.0 〜 191.255.255.255 B 第一から第二 第三から第四 10nnnnnn.nnnnnnnn.hhhhhhhh.hhhhhhhh 2^16（65536）個 よく使う 192.0.0.0 〜 223.255.255.255 C 第一から第三 第四のみ 110nnnnn.nnnnnnnn.nnnnnnnn.hhhhhhhh 2^8（256）個 224.0.0.0 〜 239.255.255.255 D - - 1110xxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx - 240.0.0.0 〜 255.255.255.255 E - - 1111xxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx - ・サブネットマスクよるネットワーク部とホスト部の定義 『1』あるいは『0』で，IPアドレスのネットワーク部とホスト部を定義し，IPアドレスの後ろに記述する方法（＊例＊192.168.42.23/24）．設定したIPアドレスに対して，使用可能なIPアドレスの範囲を自由に定義できる．ネットワーク部を『1』，ホスト部を『0』で表現する．サブネットマスクの表記方法には，二進数形式，IPアドレス形式，1の個数で表すCIDR形式による表現方法がある． 二進数形式 IPアドレス形式 CIDR形式 IPアドレスのパターン数（最大PC数） 備考 /10000000.00000000.00000000.00000000 /128.0.0.0 /1 /11000000.00000000.00000000.00000000 /192.0.0.0 /2 ... ... ... /11111111.00000000.00000000.00000000 /255.0.0.0 /8 2^24（16777216）個 ... ... ... /11111111.11111110.00000000.00000000 /255.254.0.0 /15 /11111111.11111111.00000000.00000000 /255.255.0.0 /16 2^16（65536）個 よく使う範囲 ... ... /11111111.11111111.11111110.00000000 /255.255.254.0 /23 /11111111.11111111.11111111.00000000 /255.255.255.0 /24 2^8（256）個 ... ... ... /11111111.11111111.11111111.11111110 /255.255.255.254 /31 /11111111.11111111.11111111.11111111 /255.255.255.255 /32 1個 よく使う範囲 ＊例＊ プライベートIPアドレスが192.168.0.0（11000000.10101000.00000000.00000000）で，使いたいIPアドレスのパターン数が65536個，または16777216個の場合に，サブネットマスクの表記，使用可能なIPアドレスの範囲は以下のようになる． 使いたいIPアドレスのパターン数 二進数形式による表記 IPアドレス形式 CIDR形式 使用可能なIPアドレスの範囲 16777216個 192.168.0.0/11111111.00000000.00000000.00000000 192.168.0.0/255.0.0.0 192.168.0.0/24 ⇒ 192.168.0.1 〜 192.168.0.254 65536個 192.168.0.0/11111111.11111111.00000000.00000000 192.168.0.0/255.255.0.0 192.168.0.0/16 ⇒ 192.168.0.1 〜 192.168.255.254 1個 192.168.0.0/11111111.11111111.11111111.11111111 192.168.0.0/255.255.255.255 192.168.0.0/32 ⇒ 192.168.0.0 DNSサーバとhostsファイルの役割 ・完全修飾ドメイン名とグローバルIPアドレスのマッピング 例えば，外部WebサーバのグローバルIPアドレスが『203.142.205.139』であると知っている場合，URLのプロトコル部分以下を『203.142.205.139』としてリクエストすれば，外部Webサーバが提供するウェブサイトにアクセスできる．しかし，グローバルIPアドレスは数字の羅列であるため，人間には覚えにくい．そこで，グローバルIPアドレスの代わりに，完全修飾ドメイン名をURLの一部として用いる． ・hostsファイル DNSサーバよりも先に参照されるマッピングファイル．WebサーバのIPアドレスがDNSサーバに登録されていない時，またDNSサーバが不具合の時に，DNSサーバの代わりとして用いる． 05-02. ルータ NAT（静的NAT）：Network Address TranslationによるIPアドレスv4の変換 一つのグローバルIPアドレスに対して，一つのプライベートIPアドレスを紐付けられる．グローバルIPアドレスを持ち，グローバルネットワークとプライベートネットワークの双方向への通信時に，IPアドレスを変換できる． ・リクエスト時のルータにおける変換 プライベートネットワークから出る時に，パケットのヘッダ情報における『送信元』のプライベートIPアドレスをグローバルIPアドレスに変換する． ＊例＊ 例えば，GoogleでWebページを見ながら，Gmailアプリを起動している場合，リクエストにおけるパケット情報として… 送信元プライベートIPアドレス ⇄ 送信元グローバルIPアドレス 192.168.1.1 200.1.1.1 『送信元プライベートIPアドレス』『送信先グローバルIPアドレス』『メールサーバの待ち受けポート番号110（POP3）』を指定して，メールサーバにリクエスト． GET http://www.example.co.jp:110/ 『送信元プライベートIPアドレス』『送信先グローバルIPアドレス』『Webサーバの待ち受けポート番号80（HTTP）』を指定して，Webサーバにリクエスト．ただし．80は，省略可能． GET http://www.example.co.jp:80/ 『送信元プライベートIPアドレス』『送信先グローバルIPアドレス』『DNSサーバの待ち受けポート番号53（DNS）』を指定して，DNSサーバにリクエスト GET http://www.example.co.jp:53/ これらの『送信元プライベートIPアドレス』が，NATルータで，グローバルIPアドレスに変換される． ・レスポンス時の変換 プライベートネットワークに入る時に，パケットのヘッダ情報における『宛先』のグローバルIPアドレスをプライベートIPアドレスに変換する． NAPT（動的NAT）：Network Address Port TranslationによるIPアドレスとポート番号の変換 一つのグローバルIPアドレスに対して，複数のプライベートIPアドレスを紐付けられる．グローバルネットワークとプライベートネットワークの双方向への通信時に，IPアドレスを変換できる． ・リクエスト時の変換 プライベートネットワークから出る時に，パケットのヘッダ情報における『送信元』のプライベートIPアドレスをグローバルIPアドレスに変換する．ただし，異なるプライベートIPアドレスが同じグローバルIPに変換されてしまうため，これを識別するために，ポート番号を複数の異なるポート番号に変換し，グローバルIPアドレスに付け加える． ＊例＊ 送信元プライベートIPアドレス 変換前ポート番号 ⇄ 送信元グローバルIPアドレス 変換後ポート番号 192.168.2.1 50011 130.X.X.X:50011 50011 192.168.3.1 50011 130.X.X.X:50012 50012 ・レスポンス時の変換 プライベートネットワークに入る時に，付け加えられたポート番号を元に，パケットのヘッダ情報における『宛先』のグローバルIPアドレスを，異なるプライベートIPアドレスに変換し分ける． "},"public/security/security_cyber_attacks.html":{"url":"public/security/security_cyber_attacks.html","title":"📖 ︎サイバー攻撃","keywords":"","body":"サイバー攻撃 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. サイバー攻撃からの防御方法 防御方法の種類 ファイアウォール ・Proxyサーバによるアプリケーションゲートウェイ型ファイアウォール Proxyサーバ上で，SSLサーバ証明書の認証，セキュリティ系のソフトウェアの稼働，を行い，ファイアウォールとして用いる．Proxyサーバセキュリティ精度を重視する場合はこちら． ・パケットフィルタリング型ファイアウォール パケットのヘッダ情報に記載された送信元IPアドレスやポート番号などによって，パケットを許可するべきかどうかを決定する．速度を重視する場合はこちら．ファイアウォールとWebサーバの間には，NATルータやNAPTルータが設置されている．これらによる送信元プライベートIPアドレスから送信元グローバルIPアドレスへの変換についても参考にせよ． ＊例＊ Win10における設定画面 Detection Systemとは ・Detection Systemとは ネットワーク上を流れるトラフィックを監視し，不正アクセスと思われるパケットを検出した時に，管理者に通知するシステム．あくまで通知するだけで，攻撃を防御することはしない． IPS：Intrusion Prevention Systemとは ・IPSとは ネットワーク上を流れるトラフィックを監視し，不正アクセスと思われるパケットを検出した時に，管理者に通知し，さらにパケットの侵入を防ぐシステム． WAF：Web Application Firewallとは ・WAFとは Webアプリケーション自体を保護するシステム． 02. Malware の種類と特徴 Malware の語源 『malicious（悪意のある）＋software（ソフトウェア）』 Macroウイルス ・Macroウイルスとは Wordなどのワープロアプリや，Excelなどの表計算アプリに感染 Worm ・Wormとは 自己複製し，1つのコンピュータから，4つの経路（ネットワーク，メール，共有フォルダ，USB）を辿って，他のコンピュータに感染を広げていく．パソコンがグローバルIPで直接インターネットに接続していると感染しやすい．ワームを防ぐためには，パソコンにプライベートIPアドレスを設定し，NATやNAPTなどを介して，インターネットに接続させる必要がある． ＊例＊ 共有フォルダ経由での感染拡大 トロイの木馬 ・トロイの木馬とは ＊例＊ Google play で，過去にアプリとして忍び込んでいたトロイの木馬 感染方法がギリシャ神話上のトロイの木馬に似ていることに由来する．有用なプログラムであるように見せかけて，パソコン利用者に実行させることで感染．裏で不正な処理を行う． ※トロイの木馬はギリシャ神話に登場する．ギリシャ軍は難攻不落のトロイ城を陥落させるため，中に精鋭部隊を忍び込ませた木馬をトロイ城の近くに置いて帰った．戦利品だと勘違いしたトロイ軍は，城内に木馬を持ち帰った．夜中，木馬の中に隠れた精鋭部隊が自軍の兵士をトロイ城に引き入れ，城を制圧した． Spyware ・Spywareとは パソコン利用者の個人情報を収集し，外部に送信する． Bot ・Botとは あらかじめBot化させておいたパソコンを踏み台として，攻撃者の命令通りに動かす． ・パソコンがボット化するまでのプロセス ・スマホがボット化するまでのプロセス ・Bot の使われ方 まず，攻撃対象のネットワーク内にあるパソコンをBot化させる．攻撃者は，Bot化したパソコンを踏み台としてサーバーを攻撃させるように，C&Cサーバーに命令を出す． 03. サイバー攻撃／その対策 CSRF：Cross-Site Request Forgeries ・CSRFとは ユーザがとあるフォームからログイン後，セッションIDを保持したまま悪意のあるサイトにアクセスしたとする．悪意のあるサイトのサーバは，ユーザのセッションIDを使用して，元々ログインしていたサイトのサーバを攻撃する．サーバは，正しいフォームからのリクエストと誤認してしまい，攻撃を許容してしまう． 参考：https://www.ipa.go.jp/security/vuln/websecurity-HTML-1_6.html ・【対策】ワンタイムトークン 認証時に，セッションIDだけでなく，ワンタイムトークンも併用する．認証フォームがリクエストされた時，サーバ側では，ワンタイムトークンを発行し，これをSet-Cookieヘッダーのcsrftokenパラメータ（フレームワークによっては，これに相当するパラメータ）や独自ヘッダーに割り当てて，レスポンスを返信する． 200 OK Set-Cookie: csrftoken= # 独自ヘッダー X-CSRF-TOKEN: ブラウザではレスポンスヘッダーからワンタイムトークンを取り出し，認証フォームのinputタグのhidden属性に割り当てる．他に，metaタグにトークンを割り当てることもある． \"> \"> 認証のためのPOSTリクエスト時に，リクエストボディや独自ヘッダーにトークンを割り当て，リクエストを送信する．どちらを使用するかは，バックエンド側の仕様によって異なる． POST https://example.co.jp/bar-form.php HTTP/2 # 独自ヘッダー x-csrf-token: { _token= } サーバ側では，POSTリクエストによって送信されたトークンとワンタイムトークンを比較し，認証を実行する．以降，POSTリクエストの場合はそのワンタイムトークンを使い回し，GETリクエストの場合は使用しない．トークンが変更されていれば，誤った入力フォームからのリクエストとして判定し，401ステータスを返却する． 参考： https://terasolunaorg.github.io/guideline/5.2.0.RELEASE/ja/Security/CSRF.html#spring-securitycsrf https://qiita.com/Nsystem/questions/1bd6d30748957e1b6700 https://qiita.com/mpyw/items/0595f07736cfa5b1f50c#%E3%83%88%E3%83%BC%E3%82%AF%E3%83%B3%E3%81%AE%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95 ・【対策】CORS XSSの説明を参考にせよ セッションID固定化 ・セッションID固定化とは 参考：https://www.ipa.go.jp/security/vuln/websecurity-HTML-1_4.html Directory traversal ・Directory traversalとは traversalは，横断する（ディレクトリの構造を乗り越える）の意味．パス名を使ってファイルを指定し，管理者の意図していないファイルを不正に閲覧またはダウンロードする． DoS攻撃：Denial of Service ・DoS攻撃，DDos攻撃とは アクセスが集中することでWebサーバーがパンクすることを利用し，悪意を持ってWebサーバーに大量のデータを送りつける手法．リクエストの送信元が一つの場合はDos攻撃，複数の場合はDDos攻撃という． ・【対策】POSTリクエストのリクエスト数制限 php.iniファイルにて，一度に受信できるPOSTリクエストの上限値を設定できる． max_input_vars = 1000 ・【対策】同一送信元のリクエスト制限 同じ送信元からの一分間あたりのリクエスト数を制限する．例えば，WAF，API Gatewayの機能を使用する． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws.html SQL Injection ・SQL Injectionとは データベースのSQLクエリのパラメータとなる入力に，不正な文字列を入力して不正なSQLクエリを実行させ，データベースの情報を抜き取る手法．ただし，近年は減少傾向にある． ・【対策】特殊な文字の無効化 データベースのSQLクエリのパラメータとなる入力では，『シングルクオーテーション』や『バックスラッシュ』などはSQLで特別な意味を持つ．そのため，これらのパラメータが割り当てられているリクエストメッセージを拒否する．例えば，WAFの機能を使用する． 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/aws-managed-rule-groups-list.html ・【対策】プレースホルダー プリペアードステートメントのSQL中にパラメータを設定し，値をパラメータに渡した上で，SQLとして発行する方法．処理速度が速い．また，パラメータに誤ってSQLが渡されても，これを実行できなくなるため，SQLインジェクションの対策になる．プレースホルダーについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_php_package_mysql.html XSS：Cross Site Scripting ・XSSとは WebアプリケーションによるHTML出力のエスケープ処理の欠陥を悪用し，利用者のWebブラウザで悪意のあるスクリプトを実行させる ． ・【対策】CORS：Cross-Origin Resource Sharing（オリジン間リソース共有） 異なるドメインで表示されるページからのリクエストを許可する仕組みのこと．標準では，異なるドメインで表示されるページからのリクエストは拒否されるようになっている．異なるドメインで表示されるページからのリクエストを許可したい場合は，ページからのリクエストメッセージとサーバからのレスポンスメッセージの両方で対応が必要である． 参考：https://developer.mozilla.org/ja/docs/Glossary/Origin ＊実装例＊ まず，リクエストメッセージのOriginヘッダーに送信元オリジンを設定する．加えて，Cookieヘッダーを持つリクエストメッセージを送信したい場合は，JavaScriptの実装でwithCredentialsにtrueを割り当てる．JavaScriptのライブラリによってオプション名が異なるため注意する． 参考：https://qiita.com/tomoyukilabs/items/81698edd5812ff6acb34#%E3%82%B7%E3%83%B3%E3%83%97%E3%83%AB%E3%81%AB%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF%E3%82%92%E8%A8%B1%E5%8F%AF%E3%81%97%E3%81%9F%E3%81%84%E5%A0%B4%E5%90%88 GET https://foo.com/bar HTTP/2 # 送信元オリジン Origin: https://example.com import axios from 'axios' const client = axios.create({ baseURL: \"https://foo.co.jp\", withCredentials: true, // オプションの有効化 }) return new Promise((resolve, reject) => { client.get('/bar') .then((data) => { resolve(data) }) .catch((err) => { reject(err) }) }) 次に，レスポンスメッセージのAccess-Control-Allow-Originヘッダーに，許可された送信元オリジンを割り当てて返信する．Cookieヘッダーを持つリクエストメッセージを許可する場合，同じくレスポンスメッセージのAccess-Control-Allow-Credentialsヘッダーにtrueを割り当てる．その他，許可するHTTPメソッドやHTTPヘッダーを定義できる．例えば，許可されていないHTTPメソッドを使用して，異なるオリジンにリクエストを送信すると，405ステータスでエラーレスポンスが返信される． 参考： https://developer.mozilla.org/ja/docs/Web/HTTP/Headers/Access-Control-Allow-Credentials https://stackoverflow.com/questions/24687313/what-exactly-does-the-access-control-allow-credentials-header-do 200 OK # 許可された送信元オリジン Access-Control-Allow-Origin: https://example.co.jp # リクエストメッセージがCookieヘッダーを持つことを許可する場合 Access-Control-Allow-Credentials: true # 許可するHTTPメソッド Access-Control-Allow-Methods: GET,POST,HEAD,OPTIONS # その他，許可するHTTPヘッダー Access-Control-Allow-Headers: Content-Type ちなみに，Cookieヘッダーを持つリクエストメッセージを許可しない場合に限り，全てのオリジンやヘッダーを許可できる． 200 OK # 全てのオリジンを許可 Access-Control-Allow-Origin: * Access-Control-Allow-Headers: * ・【対策】Set-CookieヘッダーのDomain属性 リクエストメッセージがCookieヘッダーを持つことを許可した場合に，サブドメインのオリジンにもCookieヘッダーの送信を許可するかどうかを制御できる．サブドメインレスポンスメッセージのSet-Cookieヘッダーにて，Domain属性にドメインが割り当てなかった場合は，ページを表示するサーバのドメインにのみCookieヘッダーを持つリクエストを許可でき，サブドメインへの送信を拒否できる．一方で，ドメインが割り当てた場合は，そのページからサブドメインに対しても，Cookieヘッダーを持つリクエストを許可できる．ドメインではなく，オリジンであることに注意する． 参考： https://zenn.dev/agektmr/articles/f8dcd345a88c97 https://azisava.sakura.ne.jp/programming/0017.html#sec4-1 ＊実装例＊ Domain属性にexample.co.jpが割り当てられていたとする．最初にドットがついているドメイン（.example.co.jp）でも，同じ値として認識される．この場合，example.co.jpに加えて，サブドメイン（foo.example.co.jp）に対しても，Cookieヘッダーを持つリクエストを送信できる． 200 OK Set-Cookie: domain=example.co.jp POST http://foo.example.co.jp/bar-form.php HTTP/2 # 送信元オリジン Origin: http://example.co.jp Cookie: sessionid=; csrftoken= ・【対策】Set-CookieヘッダーのHttpOnly属性 これを有効化した場合，Set-CookieヘッダーにHttpOnly属性が割り当てられるようになる．JavaScriptからCookieヘッダーにアクセスできなくできる． 200 OK Set-Cookie: HttpOnly ・【対策】Set-CookieヘッダーのsameSite属性 種類 説明 None 異なるドメインから送信された全てのリクエストがCookieヘッダーを持つことを許可する． Lax 異なるドメインから送信された一部のリクエストがCookieヘッダーを持つことを許可する． Strict 異なるドメインから送信された全てのリクエストがCookieヘッダーを持つことを拒否する． 異なるドメインからのリクエストがCookieヘッダーを持つことを許可／拒否する．ここでリクエストを制御しているのは，オリジンではなく，ドメインであることに注意する． 参考：https://zenn.dev/agektmr/articles/f8dcd345a88c97 200 OK Set-Cookie: SameSite=None ・【対策】Set-CookieヘッダーのSecure属性 これを有効化した場合，Set-CookieヘッダーにSecure属性が割り当てられるようになる．HTTPSプロトコルを使用した場合のみ，リクエストメッセージにCookieヘッダーを割り当てられるようになる． 200 OK Set-Cookie: Secure パスワードリスト攻撃 ・パスワードリスト攻撃とは 漏洩したパスワードを用いて，正面から正々堂々とアクセスする手法． Brute-force攻撃とReverse Brute-force攻撃 ・Brute-force攻撃とReverse Brute-force攻撃とは Brute-forceは力ずくの意味．IDを固定して，パスワードを総当たりで試す手法．例えば，5桁数字のパスワードなら，9の5乗通りの組み合わせを試す．一方で，Reverse Brute-forceは，パスワードを固定して，IDを総当たりで試す手法． ・パスワードのパターン数 レインボー攻撃 ・レインボー攻撃とは レインボーテーブルの文字列とハッシュ値の対応関係を元にして，ハッシュ化された暗号からパスワードを推測する手法． ・【対策】BCryptによるハッシュ化 BCryptを使用して，Blowfish方式に基づく暗号化を実行する．Blowfish方式では，同じパスワードの文字列であっても異なるハッシュ値が生成されるため，レインボー攻撃を防げる．Blowfish方式で生成されたハッシュ値は，異なるルールで生成された複数のハッシュ値の組み合わせである． 参考： https://medium-company.com/%E3%82%B9%E3%83%88%E3%83%AC%E3%83%83%E3%83%81%E3%83%B3%E3%82%B0/ https://medium-company.com/bcrypt/ # + + + $2y$10$1QVmWNzk.TsaZQLQ/zeI9OAZL02AWP.VdFPPyAc9hSc2Cp4yOXKtG 文字列 説明 $2y$（4文字） 暗号化アルゴリズムのバージョンを表す．他に，2，2a，2b，2xがある． $10$（4文字） ストレッチング（ハッシュ化の反復）の回数を表す．10とした場合は，2^10回反復でハッシュ化を実行する． 1QVmWNzk.TsaZQLQ/zeI9O（22文字） ソルト（ランダムな文字列）を表す． AZL02AWP.VdFPPyAc9hSc2Cp4yOXKtG（31文字） パスワードそのもののハッシュ値を表す． 04. その他のサイバー攻撃 ソーシャルエンジニアリング ・ソーシャルエンジニアリングとは 技術的な手法ではなく，物理的な手法（盗み見，盗み聞き，成りすまし，詐欺など）によってパスワードを取得し，アクセスする手法． 踏み台攻撃 ・踏み台攻撃とは 対象のインターネット内のパソコンに攻撃プログラムを仕込んで置き，攻撃者からの命令でサーバを攻撃させる手法（※ボットを用いた攻撃など） ・パソコンがボット化するまでのプロセス（再掲） ・スマホがボット化するまでのプロセス（再掲） ・Bot の使われ方（再掲） DNS Cache Poisoning ・DNS Cache Poisoningとは キャッシュDNSサーバーがもつIPアドレスを偽のIPアドレスに変え，偽のWebサイトに強制的にアクセスさせる手法． Back Door ・Back Doorとは 例えば，Webサイトのカード決済画面やサーバに潜ませることによって，カード情報を第三者に送信する手法． "},"public/security/security_encryption_technology.html":{"url":"public/security/security_encryption_technology.html","title":"📖 ︎通信データの暗号化技術","keywords":"","body":"通信データの暗号化技術 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 通信データを暗号化する目的 盗聴（通信データの盗み取り）を防ぐため 『共通鍵暗号方式』や『公開鍵暗号方式』によって実現される．暗号アルゴリズムに基づく暗号方式を用いてデータを暗号化することによって，通信データの盗聴を防ぐ． 改竄（通信データの書き換え）を防ぐため 『デジタル署名』や『ハッシュ関数』によって実現される．相手に送ったデータと相手が受け取ったデータが同じかどうかを確認することによって，通信データの改竄を防ぐ． 成りすましを防ぐため 『デジタル署名』によって実現される．正しい相手であることを証明することによって，成りすましを防ぐ． 01-02. 暗号アルゴリズム 通信データの暗号化のほとんどは，『共通鍵暗号方式』や『公開鍵暗号方式』によって実現される．それらの方式は，以下のアルゴリズムによって実装される． 共通鍵暗号アルゴリズム 共通鍵暗号方式を実装するためのアルゴリズム ・DES 暗号：Data Encryption Standard ・AES 暗号：Advanced Encryption Standard 公開鍵暗号アルゴリズム 公開鍵暗号方式を実装するためのアルゴリズム ・RSA 暗号：Rivest-Shamir-Adleman cryptosystem 01-03. 暗号アルゴリズムに基づく暗号方式 暗号方式の種類一覧 共通鍵暗号方式 公開鍵暗号方式 暗号化アルゴリズム 共通鍵暗号アルゴリズム 公開鍵暗号アルゴリズム アルゴリズムの種類 RC4、DES、3DES、AES RSA、ElGamal 暗号化に要する時間 より短い より長い 生成される暗号鍵 共通鍵 秘密鍵、公開鍵 鍵の配布方法 メール（盗聴に気を付ける） メール、PKI 鍵の再利用 再利用するべきではない 再利用してもよい 共通鍵暗号方式 ・共通鍵暗号方式とは サーバから受信者（クライアント）にあらかじめ秘密鍵を渡しておく．鍵の受け渡しを工夫しないと，共通鍵が盗聴される可能性がある（鍵配送問題）． ＊例＊ エクセルのファイルロック 長所：処理が速い 短所：鍵の配布が大変 ・共通鍵の再利用の可否 各受信者（クライアント）は，サーバから，受信者ごとに生成された共通鍵をもらう．鍵の再利用をするべきではない． 公開鍵暗号方式 ・公開鍵暗号方式とは 公開鍵暗号方式でも記載の通り，共通鍵暗号方式の鍵配送問題を解決すべく開発された．『RSA暗号』などによって実装される．受信者（クライアント）の公開鍵で暗号化した場合，受信者の秘密鍵でのみ復号可能．すなわち，第三者に復号（解読）されることはないと判断可能． ＊サーバが行うこと＊ サーバは，受信者（クライアント）から公開鍵をもらう． 公開鍵を用いて，情報を暗号化する． ＊受信者（クライアント）が行うこと＊ 受信者（クライアント）は，秘密鍵で情報を復号する． ・公開鍵の再利用の可否 各受信者（クライアント）は，サーバから，異なるサーバで再利用される公開鍵をもらう．ただし，サーバごとに異なる秘密鍵と公開鍵を用いてもよい． ハイブリッド暗号方式 共通鍵暗号方式と公開鍵暗号方式を組み合わせた暗号方式．両方の方式の長所と短所を補う． 02. 暗号化方式に基づくセキュアプロトコル セキュアプロトコルの種類と扱われる階層 プロトコルとしての暗号化技術である『セキュアプロトコル』は，赤色で示してある． セキュアプロトコルで扱われる通信データ ・通信データの種類 Webコンテンツデータ，メールデータ，その他 ・通信データの作成，ヘッダ情報追加，カプセル化 パケット交換方式におけるパケットのヘッダ情報は，パソコンの各概念層のプロトコルによって追加されていく． 02-02. アプリケーション層におけるメールデータの暗号化技術 S/MIME：Secure MIME ・S/MINEとは 暗号化ダイジェスト（デジタル署名）を含むデジタル証明書をメールに添付することによって，公開鍵の成りすましを防ぐセキュリティ技術． ・S/MIMEにおけるデジタル証明書 デジタル証明書をS/MIMEに用いる場合，特にS/MIME証明書という．詳しくは，暗号ダイジェスト（デジタル署名）を参照． 02-03. アプリケーション層におけるリモート接続／操作やファイル転送の暗号化技術 SSH：Secure Shell ・SSHとは 公開鍵暗号方式に基づくセキュアプロトコル．公開鍵暗号方式と，公開鍵認証方式やパスワード認証方式の技術を用いて，インターネットを経由して，サーバのリモート接続／操作を行う．物理Webサーバであっても，仮想Webサーバであっても，SSHによるリモート接続／操作の仕組みは同じである． ・SSH接続／操作する側に必要なソフトウェア 『OpenSSH』，『TeraTerm』，『Putty』がある． ・SSH接続／操作される側に必要なソフトウェア 『OpenSSH』，『Apache MINA/SSHD』 ・SSHポートフォワーディング（SSHポート転送） ローカルサーバと踏み台サーバのSSH接続と，ポートフォワーディングを組み合わせることによって，外部ネットワークのプライベートネットワーク内リモートサーバのアプリケーションに間接的に通信を行う方法． ＊例＊ 踏み台サーバ（例：EC2）を用いて，ローカルサーバ（例：自身のパソコン）の20000番ポートが割り当てられたアプリケーションと，リモートサーバ（例：Aurora）の3306番が割り当てられたアプリケーションをマッピングできるようになる．DBMSクライアントソフトでは，リモートにあるDBサーバに接続するために，この仕組みがよく用いられる． # ローカルの20000番ポートが割り当てられたアプリケーションに対する通信を，RDSの3306番ポートのアプリケーションに転送． [local pc] $ ssh -L20000:xxxx.rds.amazonaws.com:3306 username@fumidai.com ＊例＊ このリモートサーバが仮想サーバ／コンテナの場合もあり，ホストOSと仮想サーバ／コンテナの接続でもSSHポートフォワーディングが用いられている．ホスト外部のパソコンから，ホストOS上の仮想サーバ／コンテナに接続したい場合，SSHポートフォワーディングを用いることによって，ホストOSを踏み台とした仮想サーバ／コンテナへの接続が行えるようになる． SCP：Secure Copy Protocol ・SCPとは SSHを介して，ファイル転送を行う．SSHの機能をより拡張したプロトコルである． クライアントは，リモート接続先のサーバにファイル送信を命令する． サーバは，Shellを用いてSCPプログラムを起動し，クライアントにファイルを送信する． ・ファイルを要求する側に必要なソフトウェア 『WinSCP』，『Filezilla』 ・ファイルを送信する側に必要なソフトウェア SFTP：SSH File Transfer Protocol ・SFTPとは SSHを介して，ファイル転送を行う．SSHとFTPを組み合わせたプロトコルではなく，SSHの機能をより拡張したものである． ・ファイル要求側のクライアントソフトウェア 『WinSCP』，『Filezilla』 ・ファイル送信側のクライアントソフトウェア 02-04. トランスポート層におけるヘッダ情報の暗号化技術 SSL/TLS：Secure Sockets Layer / Transport Layer Security ・SSL/TLSとは ハイブリッド暗号方式に基づくセキュアプロトコル．トランスポート層で，パケットのヘッダ情報の暗号化を担う．具体的には，HTTPプロトコルで，GET送信のヘッダ部分，またPOST送信のヘッダ部分とボディ部分を暗号化する． ＊例＊ Chromeでは，HTTPSにおいて，SSLサーバ証明書に不備がある（例えば，オレオレ証明書を用いている）と，以下のような警告が表示される．SSLサーバ証明書については，公開鍵基盤の説明を参照せよ． ・SSL/TLSにおけるデジタル証明書とドメイン認証 デジタル証明書をSSLに用いる場合，特にSSLサーバ証明書という．提供される秘密鍵と組み合わせて，ドメインの認証に用いられる．詳しくは，暗号ダイジェスト（デジタル署名）を参照． VPN：Virtual Private Network（仮想プライベートネットワーク） ・VPNとは 異なるネットワーク間で安全な通信を行うための仕組み．IPsecやSSL/TLSによって実現される． ・インターネットVPNでのSSL/TLS通信の利用 VPNゲートウェイとのSSL/TLS通信によって，インターネットVPNを実現できる． 02-05. 暗号ダイジェスト（デジタル署名）について 暗号ダイジェスト（デジタル署名）を用いた暗号化技術 ・暗号ダイジェスト（デジタル署名）とは 『公開鍵暗号方式とは逆の仕組み（※つまり，公開鍵暗号方式ではない）』と『ハッシュ関数』を利用した暗号化．『成りすまし』と『改竄』を防げる． ＊サーバが行うこと＊ サーバは，受信者（クライアント）にあらかじめ公開鍵を配布しておく． 平文をハッシュ化し，ダイジェストにする． ダイジェストを秘密鍵で暗号化し，暗号ダイジェスト（デジタル署名）を作成する． 『平文』，『暗号ダイジェスト（デジタル署名）』を送信する． ＊受信者（クライアント）が行うこと＊ 受信者（クライアント）は，『平文』と『暗号ダイジェスト（デジタル署名）』を受信する． 平文をハッシュ化し，ダイジェストにする． 上記２つのダイジェストが同一なら，『成りすまし』と『改竄』が行われていないと判断 ・暗号ダイジェスト（デジタル署名）のメリット 1．改竄を防げる サーバから送られた『平文』と『暗号ダイジェスト』のどちらかが，通信の途中で改竄された場合，これらのダイジェストが同じになることは確率的にありえない．したがって，確かに改竄されていないと判断可能． 2．成りすましを防げる 特定の秘密鍵を持つのは，特定のサーバだけ．したがって，確かにサーバによって暗号化されたものだと判断可能． ・暗号ダイジェスト（デジタル署名）のデメリット ★★公開鍵の成りすましを防ぐことができない★★ 二者間だけのやり取りでは，あらかじめ受信者に渡される公開鍵が偽の送信者のものであっても，確かめる術がない．これを保障する仕組みに，PKI（公開鍵基盤）がある． 暗号ダイジェスト（デジタル署名）と公開鍵暗号方式を用いた暗号化技術 『成りすまし』と『改竄』を防げるデジタル署名に，『盗聴』を防げる公開鍵暗号方式を組み込んだ暗号化技術． ハッシュ関数によるハッシュ化 何かのデータを入力すると，規則性のない一定の桁数の値を出力する演算手法． PKI：Public Key Infrastructure（公開鍵基盤）による公開鍵の検証 ・ドメインの正当性の検証 秘密鍵とデジタル証明書はドメインの正当性（偽サイトではないこと）を担保するものである．デジタル署名に用いた秘密鍵に対応する公開鍵は，成りすました人物による偽の公開鍵である可能性がある．第三者機関の認証局によって，公開鍵を検証するインフラのことを，公開鍵基盤という． ・公開鍵の検証の仕組み 多くの場合，サーバの提供会社が中間認証局をもっている．中間認証局とルート認証局の関係については，認証局そのもののなりすましの防止策を参照． ＊例＊ サーバ提供者 自社の中間認証局名 ルート認証局名 AWS Amazon Trust Services Starfield社 GCP Google Trust Services ＊サーバが行うこと＊ サーバは，公開鍵と秘密鍵を作り，認証局に公開鍵とデジタル署名を提出． 認証局から，暗号ダイジェスト（デジタル署名）を含むデジタル証明書（S/MIME証明書，SSLサーバ証明書）を発行してもらう．デジタル証明書が，公開鍵の本人証明になる．デジタル証明書は，S/MIMEで用いる場合には，『S/MIME証明書』，SSL/TLSで用いる場合には，『SSLサーバ証明書』という． 受信者（クライアント）にメール，暗号ダイジェスト（デジタル署名）を含むデジタル証明書を送信． ＊受信者（クライアント）が行うこと＊ 受信者（クライアント）は，暗号ダイジェスト（デジタル署名）を含むデジタル証明書（S/MIME証明書，SSLサーバ証明書）を受信． 認証局からもらった公開鍵を用いて，デジタル証明書の暗号ダイジェスト（デジタル署名）部分を復号し，ハッシュ値が同じなら，認証局そのものが成りすましでないと判断する． ・認証局そのものの成りすましの防止策 デジタル証明書（S/MIME証明書，SSLサーバ証明書）を発行する認証局そのものが，成りすましの可能性がある．そこで，認証局をランク付けし，ルート認証局が下位ランクの認証局に権限を与えることで，下位の認証局の信頼性を持たせている．なお，ルート認証局は専門機関から厳しい審査を受けているため，ルート認証局自体がなりすましである可能性は非常に低い． 02-06. ネットワーク層におけるヘッダ情報の暗号化技術 IPsec：Internet Protocol Security ・IPSecとは 共通鍵暗号方式に基づくセキュアプロトコル．ネットワーク層で，パケットのヘッダ情報の暗号化を担う．例えば，リモートワーク時に，自宅PCと会社のネットワークをVPN接続するために用いられる．VPN接続されると，自宅PCからのTCPプロトコルのリクエストが会社のルーターを通過するため，送信元IPアドレスが会社のものにかわる．盗聴を防げる． ・IPsecによるパケットのカプセル化 VPN：Virtual Private Network（仮想プライベートネットワーク） ・VPNとは 異なるネットワーク間で安全な通信を行うための仕組み．使用されているセキュアプロトコルに基づいて，『PPTP-VPN』，『SSL/TLS-VPN』，『IPsec-VPN』がある． ・PPTP-VPNの例 『PPTP』 ・SSL/TLS-VPNの例 『OpenVPN』 ・IPsec-VPNの例 『L2TP/IPSec』 03. その他のセキュリティ技術 メール受信におけるセキュリティ ・OP25B（Outbound Port 25 Blocking） ・SPF（Sender Policy Framework） パスワードの保存方法 平文で保存しておくと，流出した時に勝手に使用されてしまうため，ハッシュ値で保存するべきである． 生体認証 Web beacon webページに，サーバに対してHTTPリクエストを送信するプログラムを設置し，送信されたリクエストを集計するアクセス解析方法．例えば，1x1の小さなGif「画像」などを設置する． Penetration テスト 既知のサイバー攻撃を意図的に行い，システムの脆弱性を確認するテストのこと． ＊例＊ 株式会社LACによるPenetration テストサービス "},"public/cloud_computing/cloud_computing.html":{"url":"public/cloud_computing/cloud_computing.html","title":"📖 ︎クラウドコンピューティング","keywords":"","body":"クラウドコンピューティング はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. オンプレミスとクラウドコンピューティングの種類 オンプレミスとは ベンダーは関わらず，ユーザの設備によって，システムを運用すること． クラウドコンピューティングとは インターネットを経由して，ベンダーのサーバに自身のデータを保存し，利用すること．ベンダーが，システムを稼働させるために必要なソフトウェアとハードウェアをどこまで提供するかによって，サービスの名称が異なる． 02. オンプレミス 03. クラウドコンピューティング IaaS：Infrastructure as a Service ＊例＊ アプリケーション名 提供 Amazon Web Service Amazon Google Cloud Platform Google Microsoft Azure Microsoft IBM Cloud IBM PaaS：Platform as a Service ＊例＊ アプリケーション名 提供 Google App Engine Google Windows Azure Microsoft GitHub Pages GitHub FaaS：Platform as a Service ユーザ側は関数プログラムの実装のみを行い，それ以外はベンダー側に管理してもらうサービスのこと． ＊例＊ Lambda SaaS：Software as a Service 従来はパッケージとして提供していたアプリケーションを，Webアプリケーションとして提供するサービスのこと． ＊例＊ Google Apps（Google Map，Google Cloud，Google Calender など） "},"public/cloud_computing/cloud_computing_aws.html":{"url":"public/cloud_computing/cloud_computing_aws.html","title":"📖 ︎AWS","keywords":"","body":"AWS：Amazon Web Service はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ALB：Application Load Balancing ALBとは クラウドリバースプロキシサーバ，かつクラウドロードバランサーとして働く．リクエストを代理で受信し，インスタンスへのアクセスをバランスよく分配することによって，サーバへの負荷を緩和する． 設定項目 ・概要 設定項目 説明 補足 リスナー ALBに割り振るポート番号お，受信するプロトコルを設定する．リバースプロキシかつロードバランサ－として，これらの通信をターゲットグループにルーティングする． セキュリティポリシー リクエストの送信者が使用するSSL/TLSプロトコルや暗号化方式のバージョンに合わせて，ALBが受信できるこれらのバージョンを設定する． ・リクエストの送信者には，ブラウザ，APIにリクエストを送信する外部サービス，転送元のAWSリソース（CloudFrontなど），などを含む．・参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/create-https-listener.html#describe-ssl-policies ルール リクエストのルーティングのロジックを設定する． ターゲットグループ ルーティング時に使用するプロトコルと，ルーティング先のアプリケーションに割り当てられたポート番号を指定する． ターゲットグループ内のターゲットのうち，トラフィックはヘルスチェックがOKになっているターゲットにルーティングされる． ヘルスチェック ターゲットグループに属するプロトコルとアプリケーションのポート番号を指定して，定期的にリクエストを送信する． ・ターゲットグループ ターゲットの指定方法 補足 インスタンス ターゲットが，EC2でなければならない． IPアドレス ターゲットのパブリックIPアドレスが，静的でなければならない． Lambda ターゲットが，Lambdaでなければならない． ルール ・ルールの設定例 ユースケース ポート IF THEN リクエストがポート80を指定した時に，443にリダイレクトしたい． 80 それ以外の場合はルーティングされないリクエスト リダイレクト先：https://#{host}:443/#{path}?#{query}ステータスコード：HTTP_301 リクエストがポート443を指定した時に，ターゲットグループに転送したい． 443 それ以外の場合はルーティングされないリクエスト 特定のターゲットグループ Webサーバ，アプリケーションにおける対応 ・問題 ALBからEC2へのルーティングをHTTPプロトコルとした場合，アプリケーション側で，HTTPSプロトコルを用いた処理ができなくなる．そこで，クライアントからALBに対するリクエストのプロトコルがHTTPSだった場合，Webサーバまたはアプリケーションにおいて，ルーティングのプロトコルをHTTPSと見なすように対処する． ・Webサーバにおける対処方法 ALBを経由したリクエストの場合，リクエストヘッダーにX-Forwarded-Protoヘッダーが付与される．これには，ALBに対するリクエストのプロトコルの種類が，文字列で代入されている．これが『HTTPS』だった場合，WebサーバへのリクエストをHTTPSであるとみなすように対処する．これにより，アプリケーションへのリクエストのプロトコルがHTTPSとなる（こちらを行った場合は，以降のアプリケーション側の対応不要）． ＊実装例＊ SetEnvIf X-Forwarded-Proto https HTTPS=on ・アプリケーションにおける対処方法 ALBを経由したリクエストの場合，リクエストヘッダーにHTTP_X_FORWARDED_PROTOヘッダーが付与される．これには，ALBに対するリクエストのプロトコルの種類が．文字列で代入されている．これが『HTTPS』だった場合，アプリケーションへのリクエストをHTTPSであるとみなすように，index.phpに追加実装を行う． ＊実装例＊ その他の留意事項 ・割り当てられるプライベートIPアドレス範囲 ALBに割り当てられるIPアドレス範囲には，VPCのものが適用される．そのため，EC2のSecurity Groupでは，VPCのIPアドレス範囲を許可するように設定する必要がある． ・ALBのセキュリティグループ Route53から転送されるパブリックIPアドレスを受信できるようにしておく必要がある．パブリックネットワークに公開するWebサイトであれば，IPアドレスは全ての範囲（0.0.0.0/0と::/0）にする．社内向けのWebサイトであれば，社内のプライベートIPアドレスのみ（n.n.n.n/32）を許可するようにする． 02. Amplify Amplifyとは サーバレスアプリケーションを構築するためのクラウドインフラストラクチャのフレームワーク．SSGの場合，静的ファイルをデプロイしさえすれば，アプリケーションとしての要件が全て整う．SPAの場合，サーバレスのバックエンドを自動構築してくれ，フロントエンドをデプロイしさえすれば，要件が全て整う．これのAWSリソースはCloudFormationによって構築されるが，Amplify経由でしか設定を変更できず，各AWSリリースのコンソール画面を見ても，非表示になっている．ただし，Route53の設定は表示されており，Amplifyが追加したレコードをユーザが編集できるようになっている． 参考：https://d1.awsstatic.com/webinars/jp/pdf/services/20200520_AWSBlackBelt_Amplify_A.pdf 役割 使用されているAWSリソース 認証 Gognito 静的サイトホスティング CloudFront，S3 API API Gateway，AppSync GraphQL バックエンドロジック Lambda DB DynamoDB ストレージ S3 全文検索 Elastic Search リアルタイム通知 AppSync，IoT Core 設定項目 項目 説明 補足 本番稼働ブランチ 基点ブランチを設定する． Amplifyを本番運用しない場合は，developブランチを設定すればよい． Branch autodetection ブランチの自動検出を有効化する． ワイルドカードを組み込む場合，アスタリスクを二つ割り当てないと，ブランチが検知されないことがある． 手動ビルド＆デプロイ ・開発環境で擬似再現 サーバレスアプリケーションを開発環境で再現する． $ amplify mock api ・開発環境から直接ビルド&デプロイ 開発／ステージング／本番環境に切り替える必要がある． # アプリケーションの設定 $ amplify add hosting # ビルド&デプロイ $ amplify publish 自動ビルド&デプロイ ・連携可能なバージョン管理システム 参考：https://docs.aws.amazon.com/ja_jp/amplify/latest/userguide/getting-started.html#step-1-connect-repository ・対応するリポジトリ構造 種類 ビルド開始ディレクトリ 非モノリポジトリ リポジトリ名からなるディレクトリ モノリポジトリ モノリポジトリの各アプリケーションディレクトリ ・amplify.ymlファイル リポジトリのルートにamplify.ymlファイルを配置する．Next.jsではSSG／SSRの両モードでビルド＆デプロイが可能である．package.jsonファイルで使用されるnextコマンドに応じて，SSGまたはSSRのいずれかのインフラが構築され，デプロイされる．SSGの場合，裏側ではS3，CloudFront，Route53などが構築され，静的ホスティングが実行される．SSRの場合，フロントエンドだけでなくバックエンドの稼働環境が必要になるため，LambdaやCogniteが構築される． 参考： https://docs.aws.amazon.com/ja_jp/amplify/latest/userguide/build-settings.html https://docs.aws.amazon.com/ja_jp/amplify/latest/userguide/server-side-rendering-amplify.html#deploy-nextjs-app version: 1 #===================== # 環境変数 #===================== env: variables: key: # 環境変数のハードコーディング #===================== # バックエンドのCI/CD #===================== backend: phases: preBuild: commands: - # コマンド build: commands: - # コマンド postBuild: commands: - # コマンド #===================== # フロントエンドのCI/CD #===================== frontend: phases: preBuild: commands: - npm install # 環境変数として登録したエンコード値をデコード - echo $ENV | base64 -di > .env - cat .env build: commands: - nuxt generate --fail-on-error - ls -la ./dist artifacts: # デプロイ対象のディレクトリ files: # 全てのディレクトリ - \"**/*\" discard-paths: yes # ビルドのアーティファクトを配置するディレクトリ baseDirectory: dist # キャッシュとして保存するディレクトリ cache: paths: - node_modules/**/* #===================== # テスト #===================== test: phases: preTest: commands: - # コマンド test: commands: - # コマンド postTest: commands: - # コマンド artifacts: # デプロイ対象のディレクトリ files: # 全てのディレクトリ - \"**/*\" configFilePath: *location* # ビルドのアーティファクトのディレクトリ baseDirectory: *location* 03. API Gateway API Gatewayとは 異なるクライアントからのリクエストを受信して差分を吸収し，適切なAPIに振り分けられる． 設定項目 ・概要 API Gatewayは，メソッドリクエスト，統合リクエスト，統合レスポンス，メソッドレスポンス，から構成される． 設定項目 説明 補足 リソース エンドポイント，HTTPメソッド，転送先，などを設定する． 構築したAWSリソースのパスが，API Gatewayのエンドポイントになる． ステージ API Gatewayをデプロイする環境を定義する． オーソライザー LambdaまたはCognitoによるオーソライザーを使用して，認可プロセスを定義する． ゲートウェイのレスポンス モデル リクエスト／レスポンスのスキーマを設定する．これらのバリデーションのために使用できる． OpenAPI仕様におけるスキーマについては，以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_api_restful.html リソースポリシー ポリシーを使用して，API Gatewayにセキュリティを定義づける． ドキュメント ダッシュボード APIの設定 使用量プラン 有料サービスとしてAPIを公開し，料金体系に応じてリクエスト量を制限するために使用する．APIキーにリクエスト量のレートを設定する． 有料サービスとして使用しないAPIの場合は，レートを設定する必要はない． APIキー APIキー認証を設定する． ・その他のアクセス制御の方法として，以下がある．参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/apigateway-control-access-to-api.html・APIキー認証については，以下のリンクを参考にせよ．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_authentication_authorization.html クライアント証明書 SSLサーバ証明書をAPI Gatewayに割り当てる． APIが，API Gatewayから転送されたリクエストであること識別できるようになる． CloudWatchログの設定 API GatewayがCloudWatchログにアクセスできるよう，ロールを設定する． 一つのAWS環境につき，一つのロールを設定すればよい． リソース ・リソース 順番 処理 説明 補足 1 メソッドリクエスト クライアントから送信されたデータのうち，実際に転送するデータのフィルタリングを行う． 2 統合リクエスト メソッドリクエストから転送された各データを，マッピングテンプレートのJSONに紐付ける． 3 統合レスポンス 統合リクエストでプロキシ統合を使用する場合，統合レスポンスを使用できなくなる． 4 メソッドレスポンス レスポンスが成功した場合，クライアントに送信するステータスコードを設定する． ・メソッドリクエスト 設定項目 説明 補足 認可 定義したLambdaまたはCognitoによるオーソライザーを有効化する． リクエストの検証 『URLクエリ文字列パラメータ』『HTTPリクエストヘッダー』『リクエスト本文』のバリデーションを有効化する． APIキーの必要性 リクエストヘッダーにおけるAPIキーのバリデーションを行う．リクエストのヘッダーに『x-api-key』を含み，これにAPIキーが割り当てられていることを強制する． ヘッダー名は大文字でも小文字でも問題ないが，小文字が推奨．参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_api_restful.html URLクエリ文字列パラメータ リクエストされたURLのクエリパラメータのバリデーションを行う． HTTPリクエストヘッダー リクエストヘッダーのバリデーションを行う． リクエスト本文 リクエストボディのバリデーションを行う． SDK設定 ・統合リクエスト 設定項目 説明 補足 統合タイプ リクエストの転送先を設定する． URLパスパラメータ メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのパスパラメータに紐付ける．または紐付けずに，新しいデータを転送しても良い． URLクエリ文字列パラメータ メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのクエリパラメータに紐付ける．または紐付けずに，新しいデータを転送しても良い． HTTPヘッダー メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのヘッダーに紐付ける．または紐付けずに，新しいデータを転送しても良い． 値はシングルクオートで囲う必要がある． マッピングテンプレート メソッドリクエストから転送されたデータを，API Gatewayから転送するリクエストのメッセージボディに紐付ける．または紐付けずに，新しいデータを転送しても良い． ・テスト 設定項目 設定例 補足 クエリ文字 ヘッダー X-API-Token: test 波括弧，スペース，クオーテーションは不要． リクエスト本文 {test:\"test\"} 改行タグやスペースが入り込まないようにする． ・OpenAPI仕様のインポート 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws_api_gateway_import.html ・CORSの有効化 CORSを有効化し，異なるオリジンによって表示されたページからのリクエストを許可する．以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/how-to-cors.html プライベート統合 ・プライベート統合とは API GatewayとVPCリンクの間で，リクエスト／レスポンスのJSONデータを自動的にマッピングする機能のこと． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-private-integration.html また，VPCリンクの設定によって，VPCエンドポイントサービスが構築される．VPCエンドポイントサービスについては，VPCエンドポイントサービスの説明を参考にせよ． 設定項目 説明 統合タイプ VPCリンクを選択する． プロキシ統合の使用 VPCリンクとのプロキシ統合を有効化する． メソッド HTTPメソッドを設定する． VPCリンク VPCリンク名を設定する． エンドポイントURL NLBのDNS名をドメイン名として，転送先のURLを設定する． デフォルトタイムアウトの使用 ・メソッドリクエストと統合リクエストのマッピング Lambdaプロキシ統合 ・Lambdaプロキシ統合とは API GatewayとLambdaの間で，リクエスト／レスポンスのJSONデータを自動的にマッピングする機能のこと．プロキシ統合を使用すると，Lambdaに送信されたリクエストはハンドラ関数のeventオブジェクトに代入される．プロキシ統合を使用しない場合，LambdaとAPI Gatewayの間のマッピングを手動で行う必要がある． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-lambda-integrations.html 設定項目 説明 統合タイプ Lambda関数を選択する． Lambdaプロキシ統合の使用 Lambdaとのプロキシ統合を有効化する． Lambdaリージョン 実行したLambda関数のリージョンを設定する． Lambda関数 実行したLambda関数の名前を設定する． 実行ロール 実行したいLambda関数へのアクセス権限がアタッチされたロールのARNを設定する．ただし，Lambda側にAPI Gatewayへのアクセス権限をアタッチしてもよい． 認証情報のキャッシュ デフォルトタイムアウトの使用 ・リクエスト時のマッピング API Gateway側でプロキシ統合を有効化すると，API Gatewayを経由したクライアントからのリクエストは，ハンドラ関数のeventオブジェクトのJSONデータにマッピングされる． { \"resource\": \"Resource path\", \"path\": \"Path parameter\", \"httpMethod\": \"Incoming request's method name\", \"headers\": { String containing incoming request headers }, \"multiValueHeaders\": { List of strings containing incoming request headers }, \"queryStringParameters\": { query string parameters }, \"multiValueQueryStringParameters\": { List of query string parameters }, \"pathParameters\": { path parameters }, \"stageVariables\": { Applicable stage variables }, \"requestContext\": { Request context, including authorizer-returned key-value pairs }, \"body\": \"A JSON string of the request payload.\", \"isBase64Encoded\": \"A boolean flag to indicate if the applicable request payload is Base64-encoded\" } ・レスポンス時のマッピング API Gatewayは，Lambdaからのレスポンスを，以下のJSONデータにマッピングする．これ以外の構造のJSONデータを送信すると，API Gatewayで『Internal Server Error』のエラーが起こる． { \"isBase64Encoded\": true | false, \"statusCode\": httpStatusCode, \"headers\": { \"headerName\": \"headerValue\", ... }, \"multiValueHeaders\": { \"headerName\": [ \"headerValue\", \"headerValue2\", ... ], ... }, \"body\": \"Hello Lambda\" } API Gatewayは上記のJSONデータを受信した後，bodyのみ値をレスポンスのメッセージボディに持たせ，クライアントに送信する． \"Hello Lambda\" ステージ ・設定 設定項目 説明 キャッシュ設定 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-caching.html デフォルトのメソッドスロットリング １秒当たりのリクエスト数制限を設定する．参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-request-throttling.html WAF 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/apigateway-control-access-aws-waf.html クライアント証明書 紐付けるWAFを設定する． ・ステージ変数 デプロイされるステージ固有の環境変数を設定できる．Lambda関数名，エンドポイントURL，パラメータマッピング，マッピングテンプレートで値を出力できる．以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/aws-api-gateway-stage-variables-reference.html ・SDKの生成 ・Canary 設定項目 説明 ステージのリクエストディストリビューション Canaryのデプロイ Canaryステージ変数 キャッシュ ログの種類 ・実行ログ CloudWatchログにAPI Gatewayの実行ログを送信するかどうかを設定できる．リクエスト／レスポンスの構造もログに出力するようにした方が良い．　 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-logging.html ・カスタムアクセスログ CloudWatchログにAPI Gatewayのアクセスログを送信するかどうかを設定できる．アクセスログを構造化ログとして出力できる． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/set-up-logging.html 分散トレースの収集 X-Rayを用いて，API Gatewayを起点とした分散トレースを収集する．まず，API GatewayでトレースIDが生成される．その後，各AWSリソースでスパンを取得し，スパンを紐付けることより，分散トレースを表現できる．なおX-Rayでは，親スパンをセグメント，子スパンをサブセグメントと呼ぶ． 参考：https://docs.aws.amazon.com/ja_jp/xray/latest/devguide/xray-concepts.html#xray-concepts-traces APIの設定 ・エンドポイントタイプ 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html 種類 説明 リージョン API Gatewayのエンドポイントへのリクエストを，リージョン内の物理サーバで受け付ける． プライベート API Gatewayのエンドポイントへのリクエストを，VPC内からのみ受け付ける． エッジ最適化 API Gatewayのエンドポイントへのリクエストを，CloudFrontのエッジサーバで受け付ける． 04. Auto Scaling Auto Scalingとは アプリケーションのメトリクスの閾値を基準として，自動水平スケーリングを自動的に実行する． 設定項目 ・起動設定 スケーリングの対象となるAWSリソースを定義する． ・スケーリンググループ スケーリングのグループ構成を定義する．各グループで最大最小必要数を設定できる． ・スケーリングポリシー スケーリングの方法を定義する． 種類 説明 補足 シンプルスケーリング 特定のメトリクスに単一の閾値を設定し，それに応じてスケーリングを行う． ステップスケーリング 特定のメトリクスに段階的な閾値を設定し，それに応じて段階的にスケーリングを実行する． （例）CPU平均使用率に段階的な閾値を設定する．・40%の時にインスタンスが１つスケールアウト・70%の時にインスタンスを２つスケールアウト・90%の時にインスタンスを３つスケールアウト ターゲット追跡スケーリング 特定のメトリクス（CPU平均使用率やMemory平均使用率）にターゲット値を設定し，それに収束するように自動的にスケールインとスケールアウトを実行する． ターゲット値を設定できるリソースの例・ECSサービスのタスク数・RDSクラスターのAuroraのリードレプリカ数・Lambdaのスクリプト同時実行数 05. Certificate Manager 設定項目 設定項目 説明 ドメイン名 認証をリクエストするドメイン名を設定する． 検証の方法 DNS検証かEmail検証かを設定する． 認証局 認証局であるATSによって認証されたSSLサーバ証明書を管理できる． 自社の中間認証局名 ルート認証局名 ATS：Amazon Trust Services Starfield社 ドメインの承認方法 ・DNS検証 CNAMEレコードランダムトークンを用いて，ドメイン名の所有者であることを証明する方法．ACMによって生成されたCNAMEレコードランダムトークンが提供されるので，これをRoute53に設定しておけば，ACMがこれを検証し，証明書を発行してくれる． 証明書 ・セキュリティポリシー 許可するプロトコルを定義したルールこと．SSL/TLSプロトコルを許可しており，対応できるバージョンが異なるため，ブラウザがそのバージョンのSSL/TLSプロトコルを使用できるかを認識しておく必要がある． Policy-2016-08 Policy-TLS-1-1 Policy-TLS-1-2 Protocol-TLSv1 〇 ✕ ✕ Protocol-TLSv1.1 〇 〇 ✕ Protocol-TLSv1.2 〇 〇 〇 ・SSLサーバ証明書の種類 DNS検証またはEメール検証によって，ドメイン名の所有者であることが証明されると，発行される．証明書は，PKIによる公開鍵検証に用いられる． 証明書の種類 説明 ワイルドカード証明書 証明するドメイン名にワイルドカードを用いたもの． ・SSLサーバ証明書の設置場所パターン AWSの使用上，ACM証明書を設置できないAWSリソースに対しては，外部の証明書を手に入れて設置する．HTTPSによるSSLプロトコルを受け付けるネットワークの最終地点のことを，SSLターミネーションという． パターン（Route53には必ず設置） SSLターミネーション（HTTPSの最終地点） 補足 Route53 → ALB(+ACM証明書) → EC2 ALB Route53 → CloudFront(+ACM証明書) → ALB(+ACM証明書) → EC2 ALB CloudFrontはバージニア北部で，またALBは東京リージョンで，証明書を構築する必要がある．CloudFrontに送信されたHTTPSリクエストをALBにルーティングするために，両方に紐付ける証明書で承認するドメインは，一致させる必要がある． Route53 → CloudFront(+ACM証明書) → EC2 CloudFront Route53 → CloudFront(+ACM証明書) → S3 CloudFront Route53 → ALB(+ACM証明書) → EC2(+外部証明書) EC2 Route53 → NLB → EC2(+外部証明書) EC2 Route53 → EC2(+外部証明書) EC2 Route53 → Lightsail(+ACM証明書) Lightsail 証明書の確認方法 ・ブラウザからの確認 Chromeを例に挙げると，SSLサーバ証明書はURLの鍵マークから確認できる． ＊例＊ CircleCIのサイトは，SSLサーバ証明書のためにACMを使用している． 06. Chatbot Chatbotとは SNSを経由して，CloudWatchからの通知をチャットアプリに転送するAWSリソース． 設定項目 ・slack通知の場合 クライアントをSlackとした場合の設定を以下に示す． 設定項目 説明 Slackチャンネル 通知の転送先のSlackチャンネルを設定する． アクセス許可 SNSを介して，CloudWatchにアクセスするためのロールを設定する． SNSトピック CloudWatchへのアクセス時経由する，SNSトピックを設定する． ・サポート対象のイベント AWSリソースのイベントを，EventBridge（CloudWatchイベント）を用いて，Chatbotに転送できるが，全てのAWSリソースをサポートしているわけではない．サポート対象のAWSリソースは以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/chatbot/latest/adminguide/related-services.html#cloudwatchevents ・インシデント ４大シグナルを含む，システム的に良くない事象のこと． ・オンコール インシデントを通知するようにし，通知を受けて対応すること． 07. CloudFront CloudFrontとは クラウドリバースプロキシサーバとして働く．VPCの外側（パブリックネットワーク）に設置されている．オリジンサーバ（コンテンツ提供元）をS3とした場合，動的コンテンツへのリクエストをEC2に振り分ける．また，静的コンテンツへのリクエストをCacheし，その上でS3へ振り分ける．次回以降の静的コンテンツのリンクエストは，CloudFrontがレンスポンスを行う． 設定項目 ・概要 設定項目 説明 Distributions Reports & analytics Distributions ・Distributions 参考になったサイト 設定項目 説明 補足 General Origin and Origin Groups コンテンツを提供するAWSリソースを設定する． Behavior オリジンにリクエストが行われた時のCloudFrontの挙動を設定する． ErrorPage 指定したオリジンから，指定したファイルのレスポンスを返信する． Restriction Invalidation CloudFrontに保存されているCacheを削除できる． ・General 設定項目 説明 補足 Price Class 使用するエッジロケーションを設定する． Asiaが含まれているものを選択． AWS WAF CloudFrontに紐付けるWAFを設定する． CNAME CloudFrontのデフォルトドメイン名（xxxxx.cloudfront.net.）に紐付けるRoute53レコード名を設定する． ・Route53からルーティングする場合は必須．・複数のレコード名を設定できる． SSL Certificate HTTPSプロトコルでオリジンに転送する場合に設定する． 上述のCNAMEを設定した場合，SSL証明書が別途必要になる．また，Certificate Managerを使用する場合，この証明書は『バージニア北部』で申請する必要がある． Security Policy リクエストの送信者が使用するSSL/TLSプロトコルや暗号化方式のバージョンに合わせて，CloudFrontが受信できるこれらのバージョンを設定する． ・リクエストの送信者には，ブラウザ，APIにリクエストを送信する外部サービス，転送元のAWSリソース，などを含む．・参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/secure-connections-supported-viewer-protocols-ciphers.html Default Root Object オリジンのドキュメントルートを設定する． ・何も設定しない場合，ドキュメントルートは指定されず，Behaviorで明示的にルーティングする必要がある．・index.htmlを設定すると，『/』でリクエストした時に，オリジンのルートディレクトリにあるindex,htmlファイルがドキュメントルートになる． Standard Logging CloudFrontのアクセスログをS3に生成するかどうかを設定する． ・Origin and Origin Groups 設定項目 説明 補足 Origin Domain Name CloudFrontをリバースプロキシとして，AWSリソースのエンドポイントやDNSにルーティングする． ・例えば，S3のエンドポイント，ALBのDNS名を設定する．・別アカウントのAWSリソースのDNS名であってもよい． Origin Path オリジンのルートディレクトリを設定する． ・何も設定しないと，デフォルトは『/』のなる．Behaviorでは，『/』の後にパスが追加される．・『/var/www/app』を設定すると，Behaviorで設定したパスが『/var/www/app/xxxxx』のように追加される． Origin Access Identity リクエストの転送先となるAWSリソースでアクセス権限のアタッチが必要な場合に設定する．転送先のAWSリソースでは，アクセスポリシーをアタッチする． CloudFrontがS3に対して読み出しを行うために必要． Origin Protocol Policy リクエストの転送先となるAWSリソースに対して，HTTPとHTTPSのいずれのプロトコルで転送するかを設定する． ・ALBで必要．ALBのリスナーのプロトコルに合わせて設定する．・HTTP Only：HTTPで転送・HTTPS Only：HTTPSで転送・Match Viewer：両方で転送 HTTPポート 転送時に指定するオリジンのHTTPのポート番号 HTTPSポート 転送時に指定するオリジンのHTTPSのポート番号 ・Behavior 何に基づいたCacheを行うかについては，★マークの項目で制御できる．★マークで，各項目の全て値が，過去のリクエストに合致した時のみ，そのリクエストと過去のものが同一であると見なす仕組みになっている．キャッシュ判定時のパターンを減らし，HIT率を改善するために，★マークで可能な限り『None』を選択した方が良い．最終的に，対象のファイルがCloudFrontのCacheの対象となっているかは，レスポンスのヘッダーに含まれる『X-Cache:』が『Hit from cloudfront』，『Miss from cloudfront』のどちらで，Cacheの使用の有無を判断できる．その他の改善方法は，以下リンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/cache-hit-ratio.html#cache-hit-ratio-query-string-parameters 設定項目 説明 補足 Precedence 処理の優先順位． 最初に構築したBehaviorが『Default (*)』となり，これは後から変更できないため，主要なBehaviorをまず最初に設定する． Path Pattern Behaviorを行うファイルパスを設定する． Origin or Origin Group Behaviorを行うオリジンを設定する． Viewer Protocol Policy HTTP／HTTPSのどちらを受信するか，またどのように変換して転送するかを設定 ・HTTP and HTTPS：両方受信し，そのまま転送・Redirect HTTP to HTTPS：両方受信し，HTTPSで転送・HTTPS Only：HTTPSのみ受信し，HTTPSで転送 Allowed HTTP Methods リクエストのHTTPメソッドのうち，オリジンへの転送を許可するものを設定 ・パスパターンが静的ファイルへのリクエストの場合，GETのみ許可．・パスパターンが動的ファイルへのリクエストの場合，全てのメソッドを許可． ★Cache Based on Selected Request Headers（★については表上部参考） リクエストヘッダーのうち，オリジンへの転送を許可し，またCacheの対象とするものを設定する． ・各ヘッダー転送の全拒否，一部許可，全許可を設定できる．・全拒否：全てのヘッダーの転送を拒否し，Cacheの対象としない．動的になりやすい値を持つヘッダー（Accept-Datetimeなど）を一切使用せずに，それ以外のクエリ文字やCookieでCacheを判定するようになるため，同一と見なすリクエストが増え，HIT率改善につながる．・一部転送：指定したヘッダーのみ転送を許可し，Cacheの対象とする．・全許可：全てのヘッダーがCacheの対象となる．しかし，日付に関するヘッダーなどの動的な値をCacheの対象としてしまうと．同一と見なすリクエストがほとんどなくなり，HITしなくなる．そのため，この設定でCacheは実質無効となり，『対象としない』に等しい． Whitelist Header Cache Based on Selected Request Headers を参考にせよ． ・Accept-xxxxx：アプリケーションにレスポンスして欲しいデータの種類（データ型など）を指定．・ CloudFront-Is-xxxxx-Viewer：デバイスタイプのBool値が格納されている． Object Caching CloudFrontにコンテンツのCacheを保存しておく秒数を設定する． ・Origin Cache ヘッダーを選択した場合，アプリケーションからのレスポンスヘッダーのCache-Controlの値が適用される．・カスタマイズを選択した場合，ブラウザのTTLとは別に設定できる． TTL CloudFrontにCacheを保存しておく秒数を詳細に設定する． ・Min，Max，Default，の全てを0秒とすると，Cacheを無効化できる．・『Cache Based on Selected Request Headers = All』としている場合，Cacheが実質無効となるため，最小TTLはゼロでなければならない． ★Farward Cookies（★については表上部参考） Cookie情報のキー名のうち，オリジンへの転送を許可し，Cacheの対象とするものを設定する． ・Cookie情報キー名転送の全拒否，一部許可，全許可を設定できる．・全拒否：全てのCookieの転送を拒否し，Cacheの対象としない．Cookieはユーザごとに一意になることが多く，動的であるが，それ以外のヘッダーやクエリ文字でCacheを判定するようになるため，同一と見なすリクエストが増え，HIT率改善につながる．・リクエストのヘッダーに含まれるCookie情報（キー名／値）が変動していると，CloudFrontに保存されたCacheがHITしない．CloudFrontはキー名／値を保持するため，変化しやすいキー名／値は，オリジンに転送しないように設定する．例えば，GoogleAnalyticsのキー名（_ga）の値は，ブラウザによって異なるため，１ユーザがブラウザを変えるたびに，異なるCacheが生成されることになる．そのため，ユーザを一意に判定することが難しくなってしまう．GoogleAnalyticsのキーはブラウザからAjaxでGoogleに送信されるもので，オリジンにとっても基本的に不要である．・セッションIDはCookieヘッダーに設定されているため，フォーム送信に関わるパスパターンでは，セッションIDのキー名を許可する必要がある． ★Query String Forwarding and Caching（★については表上部参考） クエリストリングのうち，オリジンへの転送を許可し，Cacheの対象とするものを設定する． ・クエリストリング転送とCacheの，全拒否，一部許可，全許可を選択できる．全拒否にすると，Webサイトにクエリストリングをリクエストできなくなるので注意．・異なるクエリパラメータを，別々のCacheとして保存するかどうかを設定できる． Restrict Viewer Access リクエストの送信元を制限するかどうかを設定できる． セキュリティグループで制御できるため，ここでは設定しなくてよい． Compress Objects Automatically レスポンス時にgzipを圧縮するかどうかを設定 ・クライアントからのリクエストヘッダーのAccept-Encodingにgzipが設定されている場合，レスポンス時に，gzip形式で圧縮して送信するかどうかを設定する．設定しない場合，圧縮せずにレスポンスを送信する．・クライアント側のダウンロード速度向上のため，基本的には有効化する． ・Invalidation TTL秒によるCacheの自動削除を待たずに，手動でCacheを削除できる．全てのファイルのCacheを削除したい場合は『/*』，特定のファイルのCacheを削除したい場合は『/』，を指定する．CloudFrontに関するエラーページが表示された場合，不具合を修正した後でもCacheが残っていると，エラーページが表示されてしまうため，作業後には必ずCacheを削除する． ・オリジンに対するリクエストメッセージの構造 CloudFrontからオリジンに送信されるリクエストメッセージの構造例を以下に示す． GET /foo/ # リクエストされたドメイン名 Host: foo.com User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1 Authorization: Bearer X-Amz-Cf-Id: XXXXX Via: 2.0 77c20654dd474081d033f27ad1b56e1e.cloudfront.net (CloudFront) # 各Cookieの値（二回目のリクエスト時に設定される） Cookie: sessionid=; __ulfpc=; _ga=; _gid= # 送信元IPアドレス # ※プロキシサーバ（ALBやCloudFrontなども含む）を経由している場合，それら全てのIPアドレスも順に設定される X-Forwarded-For: , , Accept-Language: ja,en;q=0.9 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate, br pragma: no-cache cache-control: no-cache upgrade-insecure-requests: 1 sec-fetch-site: none sec-fetch-mode: navigate sec-fetch-user: ?1 sec-fetch-dest: document # デバイスタイプ CloudFront-Is-Mobile-Viewer: true CloudFront-Is-Tablet-Viewer: false CloudFront-Is-SmartTV-Viewer: false CloudFront-Is-Desktop-Viewer: false # リクエストの送信元の国名 CloudFront-Viewer-Country: JP # リクエストのプロトコル CloudFront-Forwarded-Proto: https ・CloudFrontとオリジン間のHTTPS通信 CloudFrontとオリジン間でHTTPS通信を行う場合，両方にドメイン証明書を割り当てる必要がある．割り当てたとしても，以下の条件を満たさないとHTTPS通信を行うことはできない．CLoudFronからオリジンにHostヘッダーを転送しない設定の場合，オリジンが返却する証明書に『Origin Domain Name』と一致するドメイン名が含まれている必要がある．一方で，Hostヘッダーを転送しない場合，オリジンが返却する証明書に『Origin Domain Name』と一致するドメイン名が含まれているか，またはオリジンが返却する証明書に，Hostヘッダーの値と一致するドメイン名が含まれている必要がある． ・キャッシュの時間の決まり方 キャッシュの時間は，リクエストヘッダー（Cache-Control，Expires）の値とCloudFrontの設定（最大最小デフォルトTTL）の組み合わせによって決まる．ちなみに，CloudFrontの最大最小デフォルトTTLを全て０秒にすると，キャッシュを完全に無効化できる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#ExpirationDownloadDist Reports & analytics ・Cache statistics リクエストに関連する様々なデータを，日付別に集計したものを確認できる． ・Popular objects リクエストに関連する様々なデータを，オブジェクト別に集計したものを確認できる． エッジロケーションとエッジサーバ ・Point Of Presence CloudFrontは世界中に設置される『Point Of Presence（エッジロケーション＋中間層キャッシュ）』にデプロイされる． 参考：https://aws.amazon.com/jp/cloudfront/features/?whats-new-cloudfront.sort-by=item.additionalFields.postDateTime&whats-new-cloudfront.sort-order=desc ・エッジロケーションにおける全エッジサーバのIPアドレス CloudFrontには，エッジロケーションの数だけエッジサーバがあり，各サーバにIPアドレスが割り当てられている．以下のコマンドで，全てのエッジサーバのIPアドレスを確認できる． $ curl https://ip-ranges.amazonaws.com/ip-ranges.json \\ | jq \".prefixes[]| select(.service==\"CLOUDFRONT\") | .ip_prefix\" もしくは，以下のリンクを直接参考し，『\"service\": \"CLOUDFRONT\"』となっている部分を探す． 参考：https://ip-ranges.amazonaws.com/ip-ranges.json ・エッジロケーションの使用中サーバのIPアドレス CloudFrontには，エッジロケーションがあり，各ロケーションにサーバがある．以下のコマンドで，エッジロケーションにある使用中サーバのIPアドレスを確認できる． $ nslookup .cloudfront.net カスタムエラーページ ・カスタムエラーページとは オリジンに該当のファイルが存在しない場合，オリジンはCloudFrontに以下の403ステータスのレスポンスを返信する．カスタムエラーページを設定しない場合，CloudFrontはこの403ステータスをそのままレスポンスしてしまうため，オリジンに配置したカスタムエラーページを404ステータスでレスポンスするように設定する． This XML file does not appear to have any style information associated with it. The document tree is shown below. AccessDenied Access Denied ***** ***** ・設定方法 オリジンからカスタムエラーページをレスポンスするパスパターンを定義する．Lamnda@Edgeを使用したCloudFrontの場合は，Lambda@Edgeを経由して，カスタムエラーページをレスポンスする必要がある． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/HTTPStatusCodes.html 08. CloudTrail CloudTrailとは IAMユーザによる操作や，ロールのアタッチの履歴を記録し，ログファイルとしてS3に転送する．CloudWatchと連携することもできる． 09. CloudWatch CloudWatchエージェント ・CloudWatchエージェントとは インスタンス内で稼働する常駐システムのこと．インスタンス内のデータを収集し，CloudWatchに対して送信する． ・CloudWatchエージェントの設定 セクションの種類 説明 補足 agentセクション CloudWatchエージェント全体を設定する． ・ウィザードを使用した場合，このセクションの設定はスキップされる．・実装しなかった場合，デフォルト値が適用される． metricsセクション ・ウィザードを使用した場合，このセクションの設定はスキップされる．・実装しなかった場合，何も設定されない． logsセクション CloudWatchエージェントは，/opt/aws/amazon-cloudwatch-agent/bin/config.jsonファイルの定義を元に，実行される．設定ファイルは分割できる．設定後，amazon-cloudwatch-agent-ctlコマンドで設定ファイルを読み込ませる．CloudWatchエージェントを使用して，CloudWatchにログファイルを送信するだけであれば，設定ファイル（/opt/aws/amazon-cloudwatch-agent/bin/config.json）にはlogセッションのみの実装で良い．run_as_userには，プロセスのユーザ名（例：cwagent）を設定する． ＊実装例＊ { \"agent\": { \"run_as_user\": \"cwagent\" }, \"logs\": { \"logs_collected\": { \"files\": { \"collect_list\": [ { \"file_path\": \"/var/log/nginx/error.log\", \"log_group_name\": \"/foo-www/var/log/nginx/error_log\", \"log_stream_name\": \"{instance_id}\" }, { \"file_path\": \"/var/log/php-fpm/error.log\", \"log_group_name\": \"/foo-www/var/log/php-fpm/error_log\", \"log_stream_name\": \"{instance_id}\" } ] } } } } ・ログ送信権限 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html ・操作コマンド ＊コマンド例＊ # EC2内にある設定ファイルを，CloudWatchエージェントに読み込ませる（再起動を含む） $ /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \\ -a fetch-config \\ -m ec2 \\ -s \\ -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json # プロセスのステータスを確認 $ /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl \\ -m ec2 \\ -a status # 設定ファイルが読み込まれたかを確認 ### CloudWatchエージェントのプロセスのログファイル $ tail -f /opt/aws/amazon-cloudwatch-agent/logs/amazon-cloudwatch-agent.log ### 設定ファイルの構文チェックのログファイル $ tail -f /opt/aws/amazon-cloudwatch-agent/logs/configuration-validation.log ### OS起動時にデーモンが稼働するように設定されているかを確認 $ systemctl list-unit-files --type=service 09-02. CloudWatchメトリクス CloudWatchメトリクスとは AWSリソースで発生したデータポイントのメトリクスを収集する． データポイント，メトリクス 以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability.html メトリクスの分類名 ・ディメンション，名前空間，メトリクス名 分類群 説明 ディメンション インスタンスを単位とした分類名．インスタンスIDで命名される． 名前空間 AWSリソースを単位とした分類名．AWSリソース名で表現される． メトリクス名 集計対象のデータポイントの発生領域を単位とした分類名．データポイントの発生領域名で表現される． 参考： https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html https://www.slideshare.net/AmazonWebServicesJapan/20190326-aws-black-belt-online-seminar-amazon-cloudwatch CloudWatchメトリクス上では，以下のように確認できる． CloudWatch Synthetics ・CloudWatch Syntheticsとは 合成監視を行えるようになる． 09-03. CloudWatchログ CloudWatchログ クラウドログサーバとして働く．AWSリソースで生成されたログを収集できる．ログについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability.html 設定項目 ・概要 設定項目 説明 補足 ロググループ ログストリームをグループ化して収集するかどうかを設定する． 基本的に，ログファイルはグループ化せずに，一つのロググループには一つのログストリームしか含まれないようにする． メトリクスフィルター フィルターパターンに合致した文字列を持つログをトリガーとして，データポイントを発生させる．これを収集するメトリクスを設定する． サブスクリプションフィルター ・フィルターパターン ログ内で検知する文字列を設定する．大文字と小文字を区別するため，網羅的に設定する必要がある． 参考：https://qiita.com/shimajiri/items/81a4ed0fe39fe337fedb ＊例＊ OR条件で大文字小文字を考慮し，『:』が含まれるログを検出する．ここでコロンを含まているのは，ログに含まれるファイル名やメソッド名が誤って検知されないようするためである． ?\"WARNING:\" ?\"Warning:\" ?\"ERROR:\" ?\"Error:\" ?\"CRITICAL:\" ?\"Critical:\" ?\"EMERGENCY:\" ?\"Emergency:\" ?\"ALERT:\" ?\"Alert:\" ＊例＊ OR条件で大文字小文字を考慮し，『 message』が含まれるログを検出する． ?\"WARNING message\" ?\"Warning message\" ?\"ERROR message\" ?\"Error message\" ?\"CRITICAL message\" ?\"Critical message\" ?\"EMERGENCY message\" ?\"Emergency message\" ?\"ALERT message\" ?\"Alert message\" ＊例＊ 『error:』が含まれ，かつ『Foo』が含まれないログを検知する．OR条件と除外条件を組み合わせようとすると，OR条件が認識されずに除外条件だけが適用されてしまう．そのため，ここではOR条件を使用していない． 参考：https://dev.classmethod.jp/articles/cloudwatch-metricsfilter-filterpattern/ \"error:\" -Foo CloudWatchログエージェント（非推奨） ・CloudWatchログエージェントとは インスタンス内で稼働する常駐システムのこと．インスタンス内のデータを収集し，CloudWatchログに対して送信する．2020/10/05現在は非推奨で，CloudWatchエージェントへの設定の移行が推奨されている． ・awslogs.confファイル インスタンス内のetcディレクトリ下にawslogs.confファイルを，設置する．OS，ミドルウェア，アプリケーション，の各層でログを収集するのがよい． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/logs/AgentReference.html#agent-configuration-file ＊実装例＊ ############################# # /var/awslogs/awslogs.conf ############################# # ------------------------------------------ # CentOS CloudWatch Logs # ------------------------------------------ [/var/log/messages] # タイムスタンプ #（例）Jan 1 00:00:00 datetime_format = %b %d %H:%M:%S #（例）2020-01-01 00:00:00 # datetime_format = %Y-%m-%d %H:%M:%S # 収集したいログファイル．ここでは，CentOSのログを指定する． file = /var/log/messages # 文字コードutf_8として送信する．文字コードが合わないと，CloudWatchログの画面上で文字化けする． encoding = utf_8 # 要勉強 buffer_duration = 5000 initial_position = start_of_file # インスタンスID log_stream_name = {instance_id} # AWS上で管理するロググループ名 log_group_name = /var/log/messages # ------------------------------------------ # Nginx CloudWatch Logs # ------------------------------------------ [/var/log/nginx/error.log] file = /var/log/nginx/error.log buffer_duration = 5000 log_stream_name = {instance_id} initial_position = start_of_file log_group_name = /var/log/nginx/error_log.production # ------------------------------------------ # Application CloudWatch Logs # ------------------------------------------ [/var/www/project/app/storage/logs/laravel.log] file = /var/www/project/app/storage/logs/laravel.log buffer_duration = 5000 log_stream_name = {instance_id} initial_position = start_of_file log_group_name = /var/www/project/app/storage/logs/laravel_log.production ############################# # /var/awslogs/awscli.conf ############################# [plugins] cwlogs = cwlogs [default] region = ap-northeast-1 ・コマンド 設定後，awslogsコマンドでプロセスを起動する． ＊コマンド例＊ # CloudWatchエージェントの再起動 # 注意: restartだとCloudWatchに反映されない時がある． $ service awslogs restart # もしくは $ service awslogs stop $ service awslogs start # ログが新しく生成されないと変更が適用されないことがあるため，ログファイルに適当な文字列行を増やしてみる． Logインサイト ・Logインサイトとは クエリを使用してログを抽出する． ・クエリ例 汎用的なクエリを示す． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html ＊例＊ 小文字と大文字を区別せずに，WarningまたはErrorを含むログを検索する． fields @timestamp, @message, @logStream | filter @message like /(?i)(Warning|Error)/ | sort @timestamp desc | limit 100 CLI ・ログ収集量を確認 ＊コマンド例＊ 全てのロググループに対して，一日当たりの収集量をstart-timeからend-timeの間で取得する．--dimensionsオプションを使用して，特定のディメンション（ロググループ）に対して集計を実行することもできる．（ただ，やってみたけどうまくいかず） 参考：https://docs.aws.amazon.com/cli/latest/reference/cloudwatch/get-metric-statistics.html $ aws cloudwatch get-metric-statistics \\ --namespace AWS/Logs \\ --metric-name IncomingBytes \\ --start-time \"2021-08-01T00:00:00\" \\ --end-time \"2021-08-31T23:59:59\" \\ --period 86400 --statistics Sum | jq -r \".Datapoints[] | [.Timestamp, .Sum] | @csv\" | sort 09-04. CloudWatchアラーム 設定項目 ・ログが対象の場合 設定項目 説明 補足 名前空間 紐付くロググループが属する名前空間を設定する．CloudWatchログが，設定した名前空間に対して，値を発行する． メトリクス 紐付くロググループが属する名前空間内のメトリクスを設定する．CloudWatchログが，設定したメトリクスに対して，値を発行する． メトリクス値 フィルターパターンでログが検知された時に，データポイントとして発生させる値のこと． 例えば『検出数』を発行する場合は，『１』を設定する． ・メトリクスが対象の場合 ・条件 設定項目 説明 補足 閾値の種類 アラームを実行するデータポイント アラートを発生させるデータポイント数を設定する． 欠落データの処理 データポイントが発生しないことをどう判定するかを設定する． データポイントが発生しないことを正常と見なす場合は『notBreaching』とし，発生しないことを異常とする場合は，『breaching』とする．参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html#alarms-and-missing-data CLI ・CloudWatchアラームの状態変更 ＊コマンド例＊ CloudWatchアラームの状態を変更する． $ aws cloudwatch set-alarm-state \\ --alarm-name \"prd-foo-alarm\" \\ --state-value ALARM \\ --state-reason \"アラーム!!\" 10. Code系サービス CodePipeline ・CodePipelineとは CodeCommit，CodeBuild，CodeDeployを連携させて，AWSに対するCI/CD環境を構築する．CodeCommitは，他のソースコード管理サービスで代用できる． ・CodeCommitとは ソースコードをバージョン管理する． ・CodeBuildとは ビルドフェーズとテストフェーズを実行する． ・CodeDeployとは デプロイフェーズを実行する． CodeBuild ・buildspec.ymlファイル CodeBuildの設定を行う．ルートディレクトリの直下に配置しておく． 参考：https://docs.aws.amazon.com/ja_jp/codebuild/latest/userguide/build-spec-ref.html version: 0.2 phases: install: runtime-versions: docker: 18 preBuild: commands: # ECRにログイン - $(aws ecr get-login --no-include-email --region ${AWS_DEFAULT_REGION}) # イメージタグはGitHubコミットのハッシュ値を使用 - IMAGE_TAG=$CODEBUILD_RESOLVED_SOURCE_VERSION # ECRのURLをCodeBuildの環境変数から作成 - REPOSITORY_URI=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${IMAGE_REPO_NAME} build: commands: # タグ付けしてイメージをビルド - docker build -t REPOSITORY_URI:$IMAGE_TAG -f Dockerfile . postBuild: commands: # ECRにイメージをプッシュ - docker push $REPOSITORY_URI:$IMAGE_TAG # ECRにあるデプロイ対象のイメージの情報（imageDetail.json） - printf \"{\"Version\":\"1.0\",\"ImageURI\":\"%s\"}\" $REPOSITORY_URI:$IMAGE_TAG > imageDetail.json # デプロイ対象とするビルドのアーティファクト artifacts: files: imageDetail.json ・ビルド時に作成すべきデプロイ設定ファイル デプロイ対象となるイメージを定義するために，標準デプロイアクションの場合にはimagedefinitions.jsonファイル，またはBlue/Greenデプロイメントの場合にはimageDetail.jsonファイルを用意する必要がある．これはリポジトリに事前に配置するのではなく，ビルド時に自動的に作成するようにした方がよい． 参考：https://docs.aws.amazon.com/ja_jp/codepipeline/latest/userguide/file-reference.html CodeDeployによるBlue/Greenデプロイメント ・Blue/Greenデプロイメントとは 以下の手順でデプロイを行う． ECRのイメージを更新 タスク定義の新しいリビジョンを構築． サービスを更新． CodeDeployによって，タスク定義を基に，現行の本番環境（Prodブルー）のタスクとは別に，テスト環境（Testグリーン）が構築される．ロードバランサーの接続先を，本番環境（Prodブルー）のターゲットグループ（Primaryターゲットグループ）に加えて，テスト環境（Testグリーン）にも向ける． 社内からテスト環境（Testグリーン）のALBに，特定のポート番号でアクセスし，動作を確認する． 動作確認で問題なければ，Console画面からの入力で，ロードバランサーの接続先をテスト環境（Testグリーン）のみに設定する． テスト環境（Testグリーン）が新しい本番環境としてユーザに公開される． 元々の本番環境（Prodブルー）は削除される． ・appspec.ymlファイル CodeDeployの設定を行う．ルートディレクトリの直下に配置しておく．仕様として，複数のコンテナをデプロイできない．タスク定義名をとすると，自動補完してくれる． 参考：https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-resources.html version: 0.0 Resources: - TargetService: # 使用するAWSリソース Type: AWS::ECS::Service Properties: # 使用するタスク定義 TaskDefinition: \"\" # 使用するロードバランサー LoadBalancerInfo: ContainerName: \"\" ContainerPort: \"80\" PlatformVersion: \"1.4.0\" ・taskdef.jsonファイル デプロイされるタスク定義を実装し，ルートディレクトリの直下に配置する．CodeDeployは，CodeBuildから渡されたimageDetail.jsonファイルを検知し，ECRからイメージを取得する．この時，taskdef.jsonファイルのイメージ名をとしておくと，ECRから取得したイメージ名を使用して，自動補完してくれる． { \"family\": \"\", \"requiresCompatibilities\": [ \"FARGATE\" ], \"networkMode\": \"awsvpc\", \"taskRoleArn\": \"\", \"executionRoleArn\": \"\", \"cpu\": \"512\", \"memory\": \"1024\", \"containerDefinitions\": [ { \"name\": \"\", \"image\": \"\", \"essential\": true, \"portMappings\": [ { \"containerPort\": 80, \"hostPort\": 80, \"protocol\": \"tcp\" } ], \"secrets\": [ { \"name\": \"DB_HOST\", \"valueFrom\": \"/ecs/DB_HOST\" }, { \"name\": \"DB_DATABASE\", \"valueFrom\": \"/ecs/DB_DATABASE\" }, { \"name\": \"DB_PASSWORD\", \"valueFrom\": \"/ecs/DB_PASSWORD\" }, { \"name\": \"DB_USERNAME\", \"valueFrom\": \"/ecs/DB_USERNAME\" }, { \"name\": \"REDIS_HOST\", \"valueFrom\": \"/ecs/REDIS_HOST\" }, { \"name\": \"REDIS_PASSWORD\", \"valueFrom\": \"/ecs/REDIS_PASSWORD\" }, { \"name\": \"REDIS_PORT\", \"valueFrom\": \"/ecs/REDIS_PORT\" } ], \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"\", # スタックトレースのログを紐付けられるように，日付で区切るようにする． \"awslogs-datetime-format\": \"\\\\[%Y-%m-%d %H:%M:%S\\\\]\", \"awslogs-region\": \"\", \"awslogs-stream-prefix\": \"\" } } } ] } CodeDeployによるインプレースデプロイメント 11. EBS：Elastic Block Storage EBSとは クラウド内蔵ストレージとして働く． 設定項目 ・ストレージの種類とボリュームタイプ ストレージの種類 ボリューム名 SSD 汎用SSD SSD プロビジョンド IOPS SSD HDD スループット最適化 HDD HDD Cold HDD ・最小ボリューム 踏み台サーバを構築する時，できるだけ最小限のボリュームを選択し，ストレージ合計を抑える必要がある． OS 仮想メモリ ボリュームサイズ Amazon Linux t2.micro 8 CentOS t2.micro 10 12. EC2：Elastic Computer Cloud EC2とは クラウドサーバとして働く．注意点があるものだけまとめる．ベストプラクティスについては，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/ec2-best-practices.html 設定項目 ・概要 設定項目 説明 補足 AMI：Amazonマシンイメージ OSを選択する． ベンダー公式のものを選択すること．（例：CentOSのAMI一覧 https://wiki.centos.org/Cloud/AWS） インスタンスの詳細設定 EC2インスタンスの設定する． ・インスタンス自動割り当てパブリックにて，EC2に動的パブリックIPを割り当てる．EC2インスタンス構築後に有効にできない．・終了保護は必ず有効にすること． ストレージの追加 EBSボリュームを設定する． 一般的なアプリケーションであれば，20～30GiBでよい．踏み台サーバの場合，最低限で良いため，OSの下限までサイズを下げる．（例：AmazonLinuxの下限は8GiB，CentOSは10GiB） キーペア EC2の秘密鍵に対応した公開鍵をインストールできる． キーペアに割り当てられるフィンガープリント値を調べることで，公開鍵と秘密鍵の対応関係を調べることができる． インスタンスのダウンタイム ・ダウンタイムの発生条件 以下の条件の時にEC2にダウンタイムが発生する．EC2を冗長化している場合は，ユーザに影響を与えずに対処できる．ダウンタイムが発生する方のインスタンスを事前にALBのターゲットグループから解除しておき，停止したインスタンスが起動した後に，ターゲットグループに再登録する． 変更する項目 ダウンタイムの有無 補足 インスタンスタイプ あり インスタンスタイプを変更するためにはEC2を停止する必要がある．そのため，ダウンタイムが発生する． ホスト物理サーバのリタイアメント あり AWSから定期的にリタイアメントに関する警告メールが届く．ルートデバイスタイプが『EBS』の場合，ホスト物理サーバの引っ越しを行うためにEC2の停止と起動が必要である．そのため，ダウンタイムが発生する．なお，再起動では引っ越しできない． スペック ・インスタンスタイプ 『世代』と『大きさ』からなる名前で構成される．世代の数字が上がるにつれて，より小さな世代と同じ大きさであっても，パフォーマンスと低コストになる．AMIのOSのバージョンによっては，新しく登場したインスタンスタイプを適用できないことがあるため注意する．例えば，CentOS 6系のAMIでは，t3.smallを選択できない． 参考：https://aws.amazon.com/marketplace/pp/prodview-gkh3rqhqbgzme?ref=cns_srchrow 種類 世代 t2，t3，t3a，t4g，a1 大きさ nano，small，medium，large，xlarge，2xlarge ・ストレージ EBSの説明を参考にせよ． ・CPUバーストモード バーストモードのインスタンスタイプの場合，一定水準のベースラインCPU使用率を提供しつつ，これを超過できる．CPU使用率がベースラインを超えたとき，超過した分だけEC2はCPUクレジットを消費する．CPUクレジットは一定の割合で回復する．蓄積できる最大CPUクレジット，クレジットの回復率，ベースラインCPU使用率は，インスタンスタイプによって異なる．詳しくは以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/burstable-performance-instances.html キーペア ・キーペアのフィンガープリント値 ローカルに置かれている秘密鍵が，該当するEC2に置かれている公開鍵とペアなのかどうか，フィンガープリント値を照合して確認する方法 $ openssl pkcs8 \\ -in .pem \\ -inform PEM \\ -outform DER \\ -topk8 \\ -nocrypt | openssl sha1 -c ・EC2へのSSH接続 クライアントのSSHプロトコルのパケットは，まずインターネットを経由して，インターネットゲートウェイを通過する．その後，Route53，ALBを経由せず，そのままEC2へ向かう． 13. ECR ECRとは AWSが提供するDockerイメージのレジストリサービス 設定項目 ・概要 設定項目 説明 補足 可視性 リポジトリをパブリックアクセス／プライベートアクセスにするかを設定する． 様々なベンダーがパブリックリポジトリでECRイメージを提供している．参考：https://gallery.ecr.aws/ タグのイミュータビリティ 同じタグ名でイメージがプッシュされた場合に，イメージタグを上書き可能／不可能かを設定できる． プッシュ時にスキャン イメージがプッシュされた時に，イメージにインストールされているライブラリの脆弱性を検証し，一覧表示する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECR/latest/userguide/image-scanning.html 暗号化設定 ライフサイクル ・ライフサイクルポリシー ECRのイメージの有効期間を定義できる． 設定項目 説明 補足 ルールの優先順位 順位の大きさで，ルールの優先度を設定できる． 数字は連続している必要はなく，例えば，10，20，90，のように設定しても良い． イメージのステータス ルールを適用するイメージの条件として，タグの有無や文字列を設定できる． 一致条件 イメージの有効期間として，同条件に当てはまるイメージが削除される閾値を設定できる． 個数，プッシュされてからの期間，などを閾値として設定できる． イメージタグ ・タグ名のベストプラクティス Dockerのベストプラクティスに則り，タグ名にlatestを使用しないようにする．その代わりに，イメージのバージョンごとに異なるタグ名になるようハッシュ値（例：GitHubのコミットID）を使用する． 参考：https://matsuand.github.io/docs.docker.jp.onthefly/develop/dev-best-practices/ 14-01. ECS ECSとは コンテナオーケストレーションを実行する環境を提供する．VPCの外に存在している．ECS，EKS，Fargate，EC2の対応関係は以下の通り． Control Plane（コンテナオーケストレーション環境） Data Plane（コンテナ実行環境） 説明 ECS：Elastic Container Service Fargate，EC2 単一のOS上でコンテナオーケストレーションを実行する． EKS：Elastic Kubernetes Service EC2 複数のOS上それぞれでコンテナオーケストレーションを実行する． 14-02. ECS on EC2 EC2起動タイプのコンテナ ・タスク配置戦略 タスクをインスタンスに配置する時のアルゴリズムを選択できる． 戦略 説明 Spread タスクを各場所にバランスよく配置する Binpack タスクを一つの場所にできるだけ多く配置する． Random タスクをランダムに配置する． 14-03. ECS on Fargate：Elastic Container Service クラスター ・クラスターとは サービス ・サービスとは タスク数の維持管理や，タスクへのロードバランシング，リリースの成否の管理を行う機能のこと． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/service_definition_parameters.html 設定項目 説明 補足 タスク定義 サービスで維持管理するタスクの定義ファミリー名とリビジョン番号を設定する． 起動タイプ タスク内のコンテナの起動タイプを設定する． プラットフォームのバージョン タスクの実行環境のバージョンを設定する． バージョンによって，連携できるAWSリソースが異なる． サービスタイプ タスクの必要数 非スケーリング時またはデプロイ時のタスク数を設定する． 最小ヘルス率と最大率の設定値に影響する． 最小ヘルス率 タスクの必要数の設定を100%とし，新しいタスクのデプロイ時に，稼働中タスクの最低合計数を割合で設定する． 例として，タスク必要数が４個だと仮定する．タスクヘルス最小率を50%とすれば，稼働中タスクの最低合計数は２個となる．デプロイ時の既存タスク停止と新タスク起動では，稼働中の既存タスク／新タスクの数が最低合計数未満にならないように制御される．参考：https://toris.io/2021/04/speeding-up-amazon-ecs-container-deployments 最大率 タスクの必要数の設定を100%とし，新しいタスクのデプロイ時に，稼働中／停止中タスクの最高合計数を割合で設定する． 例として，タスク必要数が４個だと仮定する．タスク最大率を200%とすれば，稼働中／停止中タスクの最高合計数は８個となる．デプロイ時の既存タスク停止と新タスク起動では，稼働中／停止中の既存タスク／新タスクの数が最高合計数を超過しないように制御される．参考：https://toris.io/2021/04/speeding-up-amazon-ecs-container-deployments ヘルスチェックの猶予期間 デプロイ時のALB／NLBのヘルスチェックの状態を確認するまでの待機時間を設定する．猶予期間を過ぎても，ALB／NLBのヘルスチェックが失敗していれば，サービスはタスクを停止し，新しいタスクを再起動する． ALB／NLBではターゲットを登録し，ヘルスチェックを実行するプロセスがある．特にNLBでは，これに時間がかかる．またアプリケーションによっては，コンテナの構築に時間がかかる．そのため，NLBのヘルスチェックが完了する前に，ECSサービスがNLBのヘルスチェックの結果を確認してしまうことがある．例えば，NLBとLaravelを使用する場合は，ターゲット登録とLaravelコンテナの築の時間を加味して，330秒以上を目安とする．例えば，ALBとNuxtjs（SSRモード）を使用する場合は，600秒以上を目安とする．なお，アプリケーションのコンテナ構築にかかる時間は，ローカル環境での所要時間を参考にする． タスクの最小数 スケーリング時のタスク数の最小数を設定する． タスクの最大数 スケーリング時のタスク数の最大数を設定する． ロードバランシング ALBでルーティングするコンテナを設定する． タスクの数 タスクの構築数をいくつに維持するかを設定する． タスクが何らかの原因で停止した場合，空いているAWSサービスを使用して，タスクが自動的に補填される． デプロイメント ローリングアップデート，Blue/Greenデプロイがある． ・ターゲット追跡スケーリングポリシー 設定項目 説明 補足 ターゲット追跡スケーリングポリシー 監視対象のメトリクスがターゲット値を超過しているか否かに基づいて，タスク数のスケーリングが実行される． ECSサービスメトリクス 監視対象のメトリクスを設定する． 『平均CPU』，『平均メモリ』，『タスク当たりのALBからのリクエスト数』を監視できる．SLIに対応するCloudWatchメトリクスも参考にせよ． ターゲット値 タスク数のスケーリングが実行される収束値を設定する． ターゲット値を超過している場合，タスク数がスケールアウトされる．反対に，ターゲット値未満（正確にはターゲット値の９割未満）の場合，タスク数がスケールインされる． スケールアウトクールダウン期間 スケールアウトを発動してから，次回のスケールアウトを発動できるまでの時間を設定する． ・期間を短くし過ぎると，ターゲット値を超過する状態が断続的に続いた場合に，余分なスケールアウトが連続して実行されてしまうため注意する．・期間を長く過ぎると，スケールアウトが不十分になり，ECSの負荷が緩和されないため注意する． スケールインクールダウン期間 スケールインを発動してから，次回のスケールインを発動できるまでの時間を設定する． スケールインの無効化 ターゲット値の設定に応じて，自動的にスケールアウトやスケールインが起こるシナリオ例を示す． 最小タスク数を2，必要タスク数を4，最大数を6，CPU平均使用率を40%に設定するとする． 平常時，CPU使用率40%に維持される． リクエストが増加し，CPU使用率55%に上昇する． タスク数が6つにスケールアウトし，CPU使用率40%に維持される． リクエスト数が減少し，CPU使用率が20%に低下する． タスク数が2つにスケールインし，CPU使用率40%に維持される． ・マイクロサービスアーキテクチャ風 マイクロサービスアーキテクチャのアプリケーション群を稼働させる時，Kubernetesを使用し，またインフラとしてEKSを使用するのが基本である．ただし，モノリスなアプリケーションをECSサービスで分割し，Fargateで稼働させることにより，マイクロサービスアーキテクチャ風のインフラを構築できる． 参考：https://tangocode.com/2018/11/when-to-use-lambdas-vs-ecs-docker-containers/ タスク ・タスク グルーピングされたコンテナ群のこと ・タスク定義とは 各タスクをどのような設定値に基づいて構築するかを設定できる．タスク定義は，バージョンを示す『リビジョンナンバー』で番号づけされる．タスク定義を削除するには，全てのリビジョン番号のタスク定義を登録解除する必要がある． ・タスクのライフサイクル 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/task-lifecycle.html#lifecycle-states ・タスクサイズ 設定項目 説明 タスクメモリ タスク当たりのコンテナの合計メモリ使用量 タスクCPU タスク当たりのコンテナの合計CPU使用量 ・新しいタスクを一時的に実行 現在起動中のECSタスクとは別に，新しいタスクを一時的に起動する．CI/CDツールで実行する以外に，ローカルから手動で実行する場合もある．起動時に，overridesオプションを使用して，指定したタスク定義のコンテナ設定を上書きできる．正規表現で設定する必要があり，さらにJSONでは『\\』を『\\\\』にエスケープしなければならない．コマンドが実行された後に，タスクは自動的にStopped状態になる． ＊実装例＊ LaravelのSeederコマンドやロールバックコマンドを，ローカルPCから実行する． #!/bin/bash set -x echo \"Set Variables\" SERVICE_NAME=\"stg-foo-ecs-service\" CLUSTER_NAME=\"stg-foo-ecs-cluster\" TASK_NAME=\"stg-foo-ecs-task-definition\" SUBNETS_CONFIG=$(aws ecs describe-services \\ --cluster ${CLUSTER_NAME} \\ --services ${SERVICE_NAME} \\ --query \"services[].deployments[].networkConfiguration[].awsvpcConfiguration[].subnets[]\") SGS_CONFIG=$(aws ecs describe-services \\ --cluster ${CLUSTER_NAME} \\ --services ${SERVICE_NAME} \\ --query \"services[].deployments[].networkConfiguration[].awsvpcConfiguration[].securityGroups[]\") # 実行したいコマンドをoverridesに設定する． echo \"Run Task\" TASK_ARN=$(aws ecs run-task \\ --launch-type FARGATE \\ --cluster ${CLUSTER_NAME} \\ --platform-version \"1.4.0\" \\ --network-configuration \"awsvpcConfiguration={subnets=${SUBNETS_CONFIG},securityGroups=${SGS_CONFIG}}\" \\ --task-definition ${TASK_NAME} \\ --overrides '{\\\"containerOverrides\\\": [{\\\"name\\\": \\\"laravel-container\\\",\\\"command\\\": [\\\"php\\\", \\\"artisan\\\", \\\"db:seed\\\", \\\"--class=DummySeeder\\\", \\\"--force\\\"]}]}' \\ --query \"tasks[0].taskArn\" | tr -d \"\"\") echo \"Wait until task stopped\" aws ecs wait tasks-stopped \\ --cluster ${CLUSTER_NAME} \\ --tasks ${TASK_ARN} echo \"Get task result\" RESULT=$(aws ecs describe-tasks \\ --cluster ${CLUSTER_NAME} \\ --tasks ${TASK_ARN}) echo ${RESULT} EXIT_CODE=$(echo ${RESULT} | jq .tasks[0].containers[0].exitCode) echo exitCode ${EXIT_CODE} exit ${EXIT_CODE} なお，実行IAMユーザを作成し，ECSタスクを起動できる最低限の権限をアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"iam:PassRole\", \"ecs:RunTask\", \"ecs:DescribeServices\", \"ecs:DescribeTasks\" ], \"Resource\": [ \"arn:aws:ecs:*::service/*\", \"arn:aws:ecs:*::task/*\", \"arn:aws:ecs:*::task-definition/*\", \"arn:aws:iam:::role/*\" ] } ] } ・ECS Exec ECSタスクのコンテナに対して，シェルログインを実行する．ECSサービスにおけるECS-Execオプションの有効化，ssmmessagesエンドポイントの作成，System ManagerにアクセスするためのIAMポリシーの作成，ECSタスク実行ロールへのIAMポリシーの付与，IAMユーザへのポリシーの付与，が必要になる． 参考： https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/ecs-exec.html https://docs.aws.amazon.com/ja_jp/systems-manager/latest/userguide/systems-manager-setting-up-messageAPIs.html { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ # ssmmesages APIへのアクセス権限 \"ssmmessages:CreateControlChannel\", \"ssmmessages:CreateDataChannel\", \"ssmmessages:OpenControlChannel\", \"ssmmessages:OpenDataChannel\" ], \"Resource\": \"*\" } ] } なお，事前の設定がなされているかどうかをecs-exec-checkerスクリプトを実行して確認できる． 参考：https://github.com/aws-containers/amazon-ecs-exec-checker #!/bin/bash ECS_CLUSTER_NAME=prd-foo-ecs-cluster ECS_TASK_ID=bar bash ECS Execを実行するユーザに，実行権限のポリシーを付与する必要がある． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ecs:ExecuteCommand\", ], \"Resource\": [ \"arn:aws:ecs:*::cluster/*\", \"arn:aws:ecs:*::task/*\", ] } ] } laravelコンテナに対して，シェルログインを実行する．bashを実行する時に，『/bin/bash』や『/bin/sh』で指定すると，binより上のパスもECSに送信されてしまう．例えば，Windowsなら『C:/Program Files/Git/usr/bin/bash』が送信される．これはCloudTrailでExecuteCommandイベントとして確認できる．ECSコンテナ内ではbashへのパスが異なるため，接続に失敗する．そのため，bashを直接指定するようにする． #!/bin/bash set -xe ECS_CLUSTER_NAME=prd-foo-ecs-cluster ECS_TASK_ID=bar ECS_CONTAINER_NAME=laravel aws ecs execute-command \\ --cluster $ECS_CLUSTER_NAME \\ --task $ECS_TASK_ID \\ --container $ECS_CONTAINER_NAME \\ --interactive \\ --debug \\ --command \"bash\" Fargate ・Fargateとは コンテナの実行環境のこと．『ECS on Fargate』という呼び方は，Fargateが環境の意味合いを持つからである．Fargate環境ではホストが隠蔽されており，実体としてEC2インスタンスをホストとしてコンテナが稼働している（ドキュメントに記載がないが，AWSサポートに確認済み）． 参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-fargate-data-plane/ ・コンテナエージェント コンテナ内で稼働し，コンテナの操作を行うプログラムのこと． ・コンテナ定義 タスク内のコンテナ一つに対して，環境を設定する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/task_definition_parameters.html 設定項目 対応するdockerコマンドオプション 説明 補足 cpu --cpus タスク全体に割り当てられたCPUのうち，該当のコンテナに割り当てるCPU分を設定する． dnsServers --dns コンテナが名前解決に使用するDNSサーバの\u0010IPアドレスを設定する． essential コンテナが必須か否かを設定する． ・trueの場合，コンテナが停止すると，タスクに含まれる全コンテナが停止する．falseの場合，コンテナが停止しても，その他のコンテナは停止しない． healthCheck(command) --health-cmd ホストマシンからFargateに対して，curlコマンドによるリクエストを送信し，レスポンス内容を確認． healthCheck(interval) --health-interval ヘルスチェックの間隔を設定する． healthCheck(retries) --health-retries ヘルスチェックを成功と見なす回数を設定する． hostName --hostname コンテナにホスト名を設定する． image ECRのURLを設定する． logConfiguration(logDriver) --log-driver ログドライバーを指定することにより，ログの出力先を設定する． Dockerのログドライバーにおおよそ対応しており，Fargateであれば『awslogs，awsfirelens，splunk』に設定できる．EC2であれば『awslogs，json-file，syslog，journald，fluentd，gelf，logentries』を設定できる． logConfiguration(options) --log-opt ログドライバーに応じて，詳細な設定を行う． portMapping --publish--expose ホストマシンとFargateのアプリケーションのポート番号をマッピングし，ポートフォワーディングを行う． containerPortのみを設定し，hostPortは設定しなければ，EXPOSEとして定義できる．参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/APIReference/API_PortMapping.html secrets(volumesFrom) SSMパラメータストアから出力する変数を設定する． memory --memory--memory-reservation タスク全体に割り当てられたメモリのうち，該当のコンテナに割り当てるメモリ分を設定する． mountPoints ulimit Linuxコマンドの--ulimitに相当 ・awslogsドライバー 標準出力／標準エラー出力に出力されたログをCloudWatch-APIに送信する． 参考： https://docs.docker.com/config/containers/logging/awslogs/ https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/using_awslogs.html#create_awslogs_logdriver_options 設定項目 説明 補足 awslogs-group ログ送信先のCloudWatchログのロググループを設定する． awslogs-datetime-format 日時フォーマットを定義し，またこれをログの区切り単位としてログストリームに出力する． 正規表現で設定する必要があり，さらにJSONでは『\\』を『\\\\』にエスケープしなければならない．例えば『\\\\[%Y-%m-%d %H:%M:%S\\\\]』となる．参考：https://docs.docker.com/config/containers/logging/awslogs/#awslogs-datetime-format awslogs-region ログ送信先のCloudWatchログのリージョンを設定する． awslogs-stream-prefix ログ送信先のCloudWatchログのログストリームのプレフィックス名を設定する． ログストリームには，『//』の形式で送信される． ・割り当てられるプライベートIPアドレス タスクごとに異なるプライベートIPが割り当てられる．このIPアドレスに対して，ALBはルーティングを行う． ロール ・サービスロール サービス機能がタスクを操作するために必要なロールのこと．サービスリンクロールに含まれ，ECSの構築時に自動的にアタッチされる． ・タスクロール タスク内のコンテナのアプリケーションが，他のリソースにアクセスするために必要なロールのこと．アプリケーションにS3やSSMへのアクセス権限を与えたい場合は，タスク実行ロールではなくタスクロールに権限をアタッチする． ＊実装例＊ アプリケーションからCloudWatchログにログを送信するために，ECSタスクロールにカスタマー管理ポリシーをアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"logs:CreateLogStream\", \"logs:PutLogEvents\" ], \"Resource\": [ \"arn:aws:logs:*:*:*\" ] } ] } ＊実装例＊ SSMパラメータストアから変数を取得するために，ECSタスクロールにインラインポリシーをアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ssm:GetParameters\" ], \"Resource\": \"*\" } ] } ・タスク実行ロール タスク上に存在するコンテナエージェントが，他のリソースにアクセスするために必要なロールのこと．AWS管理ポリシーである『AmazonECSTaskExecutionRolePolicy』がアタッチされたロールを，タスクにアタッチする必要がある．このポリシーには，ECRへのアクセス権限の他，CloudWatchログにログを生成するための権限が設定されている．タスク内のコンテナがリソースにアクセスするために必要なタスクロールとは区別すること． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ecr:GetAuthorizationToken\", \"ecr:BatchCheckLayerAvailability\", \"ecr:GetDownloadUrlForLayer\", \"ecr:BatchGetImage\", \"logs:CreateLogStream\", \"logs:PutLogEvents\" ], \"Resource\": \"*\" } ] } ＊実装例＊ Datadogエージェントがクラスターやコンテナにアクセスできるように，ECSタスク実行ロールにカスタマー管理ポリシーをアタッチする． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"ecs:ListClusters\", \"ecs:ListContainerInstances\", \"ecs:DescribeContainerInstances\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" } ] } ネットワークモードとコンテナ間通信 ・noneモード 外部ネットワークが無く，タスクと外と通信できない． ・hostモード Dockerのhostネットワークに相当する． ・bridgeモード Dockerのbridgeネットワークに相当する． ・awsvpcモード awsの独自ネットワークモード．タスクはElastic Networkインターフェースと紐付けられ，Primary プライベートIPアドレスを割り当てられる．同じタスクに属するコンテナ間は，localhostインターフェイスというENI経由で通信できるようになる（推測ではあるが，Fargate環境でコンテナのホストとなるEC2インスタンスにlocalhostインターフェースが紐付けられる）．これにより，コンテナからコンテナにリクエストを転送するとき（例：NginxコンテナからPHP-FPMコンテナへの転送）は，転送元コンテナにて，転送先のアドレスを『localhost（127.0.0.1）』で指定すれば良い．また，awsvpcモードの独自の仕組みとして，同じタスク内であれば，互いにコンテナポートを開放せずとも，プロセスのリッスンするポートを指定するだけでコンテナ間通信が可能である．例えば，NginxコンテナからPHP-FPMコンテナにリクエストを転送するためには，PHP-FPMプロセスが9000番ポートをリッスンし，さらにコンテナが9000番ポートを開放する必要がある．しかし，awsvpcモードではコンテナポートを開放する必要はない． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/fargate-task-networking.html タスクのデプロイ方法の種類 ・ローリングアップデート 参考：https://toris.io/2021/04/speeding-up-amazon-ecs-container-deployments/ 最小ヘルス率の設定値に基づいて，ローリングアップデート時の稼働中タスクの最低合計数が決定される． 最大率の設定値に基づいて，ローリングアップデート時の稼働中／停止中タスクの最高合計数が決まる ECSは，既存タスクを稼働中のまま，新タスクを最高合計数いっぱいまで構築する． ECSは，猶予期間後にALB／NLBによる新タスクに対するヘルスチェックの結果を確認する．ヘルスチェックが成功していれば，既存タスクを停止する．ただし，最小ヘルス率によるタスクの最低合計数が保たれる． 『新タスクの起動』と『ヘルスチェック確認後の既存タスクの停止』のプロセスが繰り返し実行され，徐々に既存タスクが新タスクに置き換わる． 全ての既存タスクが新タスクに置き換わる． ・Blue/Greenデプロイメント CodeDeployを使用してデプロイを行う．本ノート内を検索せよ． プライベートなECSタスクのアウトバウンド通信 ・プライベートサブネットからの通信 プライベートサブネットにECSタスクを配置した場合，アウトバウンドな通信を実行するためには，NAT GatewayまたはVPCエンドポイントを配置する必要がある．パブリックサブネットに配置すればこれらは不要となるが，パブリックサブネットよりもプライベートサブネットにECSタスクを配置する方が望ましい． ・NAT Gatewayを経由 FargateからECRに対するDockerイメージのプルは，VPCの外側に対するアウトバウンド通信（グローバルネットワーク向き通信）である．以下の通り，NAT Gatewayを設置したとする．この場合，ECSやECRとのアウトバウンド通信がNAT Gatewayを通過するため，高額料金を請求されてしまう． ・VPCエンドポイントを経由 VPCエンドポイントを設け，これに対してアウトバウンド通信を行うようにするとよい．なお，NAT GatewayとVPCエンドポイントの両方を構築している場合，ルートテーブルでは，VPCエンドポイントへのアウトバウンド通信の方が優先される．料金的な観点から，NAT GatewayよりもVPCエンドポイントを経由した方がよい． VPCエンドポイントの接続先 プライベートDNS名 説明 CloudWatchログ logs.ap-northeast-1.amazonaws.com ECSコンテナのログをPOSTリクエストを送信するため． ECR api.ecr.ap-northeast-1.amazonaws.com*.dkr.ecr.ap-northeast-1.amazonaws.com イメージのGETリクエストを送信するため． S3 なし イメージのレイヤーをPOSTリクエストを送信するため SSMパラメータストア ssm.ap-northeast-1.amazonaws.com SSMパラメータストアにGETリクエストを送信するため． SSMシークレットマネージャ ssmmessage.ap-northeast-1.amazonaws.com シークレットマネージャの機能を使用するため． FireLensコンテナ ・FireLensコンテナとは 以下のノートを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/summary.html?q=firelens Tips ・割り当てられるパブリックIPアドレス，FargateのIPアドレス問題 FargateにパブリックIPアドレスを持たせたい場合，Elastic IPアドレスの設定項目がなく，動的パブリックIPアドレスしか設定できない（Fargateの再構築後に変化する）．アウトバウンド通信の先にある外部サービスが，セキュリティ上で静的なIPアドレスを要求する場合，アウトバウンド通信（グローバルネットワーク向き通信）時に送信元パケットに付加されるIPアドレスが動的になり，リクエストができなくなってしまう． そこで，Fargateのアウトバウンド通信が，Elastic IPアドレスを持つNAT Gatewayを経由するようにする（Fargateは，パブリックサブネットとプライベートサブネットのどちらに置いても良い）．これによって，Nat GatewayのElastic IPアドレスが送信元パケットに付加されるため，Fargateの送信元IPアドレスを見かけ上静的に扱うことができるようになる． 参考：https://aws.amazon.com/jp/premiumsupport/knowledge-center/ecs-fargate-static-elastic-ip-address/ 15. EFS：Elastic File System EFSとは マウントターゲットと接続された片方のEC2インスタンスから，ファイルを読み込み，これをもう一方に出力する．ファイルの実体はいずれかのEC2に存在しているため，接続を切断している間，片方のEC2インスタンス内のファイルは無くなる．再接続すると，切断直前のファイルが再び表示されようになる． 設定項目 ・概要 設定項目 説明 補足 パフォーマンスモード スループットモード EFSのスループット性能を設定する． ライフサイクルポリシー しばらくリクエストされていないファイルが低頻度アクセス（IA：Infrequent Access）ストレージクラスに移動保存するまでの期限を設定する． ・ライフサイクルポリシーを有効にしない場合，スタンダードストレージクラスのみが使用される．・画面から両ストレージの使用量を確認できる．参考：https://ap-northeast-1.console.aws.amazon.com/efs/home?region=ap-northeast-1#/file-systems/fs-f77d60d6 ファイルシステムポリシー 他のAWSリソースがEFSを利用する時のポリシーを設定する． 自動バックアップ AWS Backupに定期的に保存するかどうかを設定する． ネットワーク マウントターゲットを設置するサブネット，セキュリティグループを設定する． ・サブネットは，ファイル供給の速度の観点から，マウントターゲットにアクセスするAWSリソースと同じにする．・セキュリティグループは，EC2からのNFSプロトコルアクセスを許可したものを設定する．EC2のセキュリティグループを通過したアクセスだけを許可するために，IPアドレスでは，EC2のセキュリティグループを設定する． スペック ・バーストモードの仕組み スループット性能の自動スケーリングに残高があり，ベースラインを超過した分だけ自動スケーリング残高が減っていく．また，ベースライン未満の分は残高として蓄積されていく． 元々の残高は，ファイルシステムのスタンダードストレージクラスの容量に応じて大きくなる． 参考：https://docs.aws.amazon.com/ja_jp/efs/latest/ug/performance.html#efs-burst-credits 残高は，BurstCreditBalanceメトリクスから確認できる．このメトリクスが常に減少し続けている場合はプロビジョニングモードの方がより適切である． 参考：https://docs.aws.amazon.com/ja_jp/efs/latest/ug/performance.html#using-throughputmode ・プロビジョニングモードの仕組み スループット性能の自動スケーリング機能は無いが，一定の性能は保証されている． 参考：https://docs.aws.amazon.com/ja_jp/efs/latest/ug/performance.html#provisioned-throughput コマンド ・マウント DNS経由で，EFSマウントヘルパーを使用した場合を示す． $ mount -t -o tls :/ # EFSで，マウントポイントを登録 $ mount -t efs -o tls fs-xxxxx:/ /var/www/app # マウントポイントを解除 $ umount /var/www/app # dfコマンドでマウントしているディレクトリを確認できる $ df Filesystem 1K-blocks Used Available Use% Mounted on fs-xxx.efs.ap-northeast-1.amazonaws.com:/ xxx xxx xxx 1% /var/www/cerenavi 16. ElastiCache ElasticCacheとは アプリケーションの代わりに，セッション，クエリCache，を管理する．RedisとMemcachedがある． Redisの設定項目 設定項目 説明 補足 クラスターエンジン キャッシュエンジンを設定する．Redis通常モード，Redisクラスターモードから選択する． Redisクラスターモードと同様に，Redis通常モードもクラスター構成になる．ただ，クラスターモードとはクラスターの構成方法が異なる． ロケーション エンジンバージョンの互換性 選んだキャッシュエンジンのバージョンを設定する． マイナーバージョンが自動的に更新されないように，例えば『6.x』は設定しない方がよい． パラメータグループ グローバルパラメータを設定する． デフォルトを使用せずに独自定義する場合，事前に構築しておく必要がある． ノードのタイプ レプリケーション数 プライマリノードとは別に，リードレプリカノードをいくつ構築するかを設定する． マルチAZにプライマリノードとリードレプリカノードを一つずつ配置させる場合，ここでは『１個』を設定する． マルチAZ プライマリノードとリードレプリカを異なるAZに配置するかどうかを設定する．合わせて，自動フェールオーバーを実行できるようになる． サブネットグループ Redisにアクセスできるサブネットを設定する． セキュリティ セキュリティグループを設定する． クラスターへのデータのインポート あらかじめ作成しておいたバックアップをインポートし，これを元にRedisを構築する． キャッシュデータを引き継ぐことができる．そのため，新しいRedisへのセッションファイルの移行に役立つ．新しいRedisを構築する例としては，Redisのアップグレード時に，セッションIDを引き継いだアップグレード後のRedisを別途構築し，アプリケーションの向き先を古いRedisから新しいRedisに変える，といった状況がある． バックアップ バックアップの有効化，保持期間，時間を設定する． バックアップを取るほどでもないため，無効化しておいて問題ない． メンテナンス メンテナンスの時間を設定する． セッション管理機能 ・仕組み サーバ内のセッションファイルの代わりにセッションIDを管理し，冗長化されたアプリケーション間で共通のセッションIDを使用できるようにする．セッションIDについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_collaboration_api_restful.html クエリCache管理機能 ・仕組み RDSに対するSQLと読み出されたデータを，キャッシュとして管理する． （１）アプリケーションは，RDSの前に，Redisに対してSQLを実行する． SELECT * FROM users; （２）始めて実行されたSQLの場合，RedisはSQLをキーとして保存し，Cacheが無いことがアプリケーションに返却する． （３）アプリケーションはRDSに対してSQLを実行する． （４）データが読み出される． （５）アプリケーションはRedisにデータを登録する． # ElastiCacheには，SQLの実行結果がまだ保存されていない *** no cache *** {\"id\"=>\"1\", \"name\"=>\"alice\"} {\"id\"=>\"2\", \"name\"=>\"bob\"} {\"id\"=>\"3\", \"name\"=>\"charles\"} {\"id\"=>\"4\", \"name\"=>\"donny\"} {\"id\"=>\"5\", \"name\"=>\"elie\"} {\"id\"=>\"6\", \"name\"=>\"fabian\"} {\"id\"=>\"7\", \"name\"=>\"gabriel\"} {\"id\"=>\"8\", \"name\"=>\"harold\"} {\"id\"=>\"9\", \"name\"=>\"Ignatius\"} {\"id\"=>\"10\", \"name\"=>\"jonny\"} （６）次回，アプリケーションは，RDSの前に，Redisに対してSQLを実行する． SELECT * FROM users; （７）Redisは，SQLをキーにしてデータを特定し，アプリケーションに返却する． # ElastiCacheには，SQLの実行結果が既に保存されている *** cache hit *** {\"id\"=>\"1\", \"name\"=>\"alice\"} {\"id\"=>\"2\", \"name\"=>\"bob\"} {\"id\"=>\"3\", \"name\"=>\"charles\"} {\"id\"=>\"4\", \"name\"=>\"donny\"} {\"id\"=>\"5\", \"name\"=>\"elie\"} {\"id\"=>\"6\", \"name\"=>\"fabian\"} {\"id\"=>\"7\", \"name\"=>\"gabriel\"} {\"id\"=>\"8\", \"name\"=>\"harold\"} {\"id\"=>\"9\", \"name\"=>\"Ignatius\"} {\"id\"=>\"10\", \"name\"=>\"jonny\"} ・クエリCacheの操作 # Redis接続コマンド $ /usr/local/sbin/redis-stable/src/redis-cli \\ -c -h -p 6379 # Redis接続中の状態 # 全てのキーを表示 redis xxxxx:6379> keys * # Redis接続中の状態 # キーを指定して，対応する値を表示 redis xxxxx:6379> type # Redis接続中の状態 # Redisが受け取ったコマンドをフォアグラウンドで表示 redis xxxxx:6379> monitor Redisの障害対策 ・フェイルオーバー ノードの障害を検知し，障害が発生したノードを新しいものに置き換えることができる． 障害の発生したノード 挙動 プライマリノード リードレプリカの一つがプライマリノードに昇格し，障害が起きたプライマリノードと置き換えられる． リードレプリカノード 障害が起きたリードレプリカノードが，別の新しいものに置き換えられる． ノードのダウンタイム バックアップとインポート機能を使用して，セッションIDを引き継いだアップグレード後のRedisを別途構築する．その後，アプリケーションの向き先を古いRedisから新しいRedisに変えるようにすると，ダウンタイムを最小限にしてアップグレードできる． 状況 ダウンタイム サービスのアップグレード 1分30秒ほどのダウンタイムが発生する． 17. EventBridge（CloudWatchイベント） EventBridge（CloudWatchイベント）とは AWSリソースで起こったイベントを，他のAWSリソースに転送する．サポート対象のAWSリソースは以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/eventbridge/latest/userguide/what-is-amazon-eventbridge.html パターン ・イベントパターン 指定したAWSリソースでイベントが起こると，以下のようなJSONが送信される．イベントパターンを定義し，JSON構造が一致するイベントのみをターゲットに転送する．イベントパターンに定義しないキーは任意のデータと見なされる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/events/CloudWatchEventsandEventPatterns.html { \"version\": \"0\", \"id\": \"*****\", \"detail-type\": \"\", \"source\": \"aws.\", \"account\": \"*****\", \"time\": \"2021-01-01T00:00:00Z\", \"region\": \"us-west-1\", \"resources\": [ \"\" ], \"detail\": { // その時々のイベントごとに異なるデータ } } ＊実装例＊ Amplifyの指定したIDのアプリケーションが，Amplify Deployment Status Changeのイベントを送信し，これのjobStatusがSUCCEED／FAILEDだった場合に，これを転送する． { \"detail\": { \"appId\": [ \"foo\", \"bar\" ], \"jobStatus\": [ \"SUCCEED\", \"FAILED\" ] }, \"detail-type\": [ \"Amplify Deployment Status Change\" ], \"source\": \"aws.amplify\" } ・スケジュール cron式またはrate式を使用し，定期ジョブを定義づける．これとLambdaを組み合わせることにより，バッチ処理を構築できる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/events/ScheduledEvents.html ターゲット ・ターゲットの一覧 参考：https://docs.aws.amazon.com/ja_jp/eventbridge/latest/userguide/eb-targets.html ・デバッグ EventBridgeでは，どのようなJSONのイベントをターゲットに転送したかを確認できない．そこで，デバッグ時はEventBridgeのターゲットにLambdaを設定し，イベント構造をログから確認する． ＊実装例＊ あらかじめ，イベントの内容を出力する関数をLambdaに作成しておく． // Lambdaにデバッグ用の関数を用意する exports.handler = async (event) => { console.log(JSON.stringify({event}, null, 2)); }; 対象のAWSリソースで任意のイベントが起こった時に，EventBridgeからLambdaに転送するように設定する． { \"source\": \"aws.amplify\" } AWSリソースで意図的にイベントを起こし，Lambdaのロググループから内容を確認する．detailキーにイベントが割り当てられている． { \"event\": { \"version\": \"0\", \"id\": \"b4a07570-eda1-9fe1-da5e-b672a1705c39\", \"detail-type\": \"Amplify Deployment Status Change\", \"source\": \"aws.amplify\", \"account\": \"\", \"time\": \"\", \"region\": \"\", \"resources\": [ \"\" ], \"detail\": { \"appId\": \"\", \"branchName\": \"\", \"jobId\": \"\", \"jobStatus\": \"\" } } } 入力 ・入力トランスフォーマー 入力パスで使用する値を抽出し，入力テンプレートで転送するJSONを定義できる．イベントのJSONの値を変数として出力できる．eventキーをドルマークとして，ドットで繋いでアクセスする． ＊実装例＊ 入力パスにて，使用する値を抽出する．Amplifyで起こったイベントのJSONを変数として取り出す．JSONのキー名が変数名として機能する． { \"appId\": \"$.detail.appId\", \"branchName\": \"$.detail.branchName\", \"jobId\": \"$.detail.jobId\", \"jobStatus\": \"$.detail.jobStatus\", \"region\": \"$.region\" } 入力テンプレートにて，転送するJSONを定義する．例えばここでは，Slackに送信するJSONに出力する．出力するときは，入力パスの変数名を『<>』で囲う．Slackに送信するメッセージの作成ツールは，以下のリンクを参考にせよ． 参考：https://app.slack.com/block-kit-builder { \"channel\": \"XXXXXX\", \"text\": \"Amplifyデプロイ完了通知\", \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \":github: プルリク検証用環境\" } }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \"*結果*: \" } ] }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \"*ブランチ名*: \" } ] }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \"*検証URL*: https://..amplifyapp.com\" } ] }, { \"type\": \"context\", \"elements\": [ { \"type\": \"mrkdwn\", \"text\": \":amplify: .console.aws.amazon.com/amplify/home?region=#///|*Amplifyコンソール画面はこちら*>\" } ] }, { \"type\": \"divider\" } ] } 18. Global Accelerator 設定項目 ・基本的設定 設定項目 説明 補足 Accelerator タイプ エンドポイントグループへのルーティング時のアルゴリズムを設定する． Standard：ユーザに最も近いリージョンにあるエンドポイントグループに，リクエストがルーティングされる． IPアドレスプール Global Acceleratorに割り当てる静的IPアドレスを設定する． ・リスナー 設定項目 説明 補足 ポート ルーティング先のポート番号を設定する． プロトコル ルーティング先のプロトコルを設定する． Client affinity ユーザごとにルーティング先を固定するかを設定する． ・None：複数のルーティング先があった場合，各ユーザの毎リクエスト時のルーティング先は固定されなくなる．・Source IP：複数のルーティング先があったとしても，各ユーザの毎リクエスト時のルーティング先を固定できるようになる． ・エンドポイントグループ 設定項目 説明 補足 エンドポイントグループ 特定のリージョンに紐付くエンドポイントのグループを設定する． トラフィックダイヤルにて，各エンドポイントグループの重みを設定できる． トラフィックダイヤル 複数のエンドポイントグループがある場合，それぞれの重み（%）を設定する． ・例えば，カナリアリリースのために，新アプリと旧アプリへのルーティングに重みを付ける場合に役立つ． ヘルスチェック ルーティング先に対するヘルスチェックを設定する． ・エンドポイント 設定項目 説明 補足 エンドポイントタイプ ルーティング先のAWSリソースを設定する． ALB，NLB，EC2，Elastic IPを選択できる． 重み 複数のエンドポイントがある場合，それぞれの重みを設定する． 各エンドポイントの重みの合計値を256とし，1～255で相対値を設定する． クライアントIPアドレスの保持 X-Forwarded-ForヘッダーにクライアントIPアドレスを含めて転送するかどうかを設定する． 素早いレスポンスの理由 最初，クライアントPCからのリクエストはエッジロケーションで受信される．プライベートネットワーク内のエッジロケーションを経由して，ルーティング先のリージョンまで届く．パブリックネットワークを使用しないため，小さなレイテシーでトラフィックをルーティングできる． Global Acceleratorを使用しない場合，クライアントPCのリージョンから指定したリージョンに至るまで，いくつもパブリックネットワークを経由する必要があり，時間がかかってしまう． 以下のサイトで，Global Acceleratorを使用した場合としなかった場合のレスポンス速度を比較できる． 参考：https://speedtest.globalaccelerator.aws/#/ 19. IAM：Identify and Access Management IAM ・IAMとは AWSリソースへのアクセスに関する認証と認可を制御する．認証はアクセスキーとシークレットアクセスキーによって，また認可はIAMロール／IAMポリシー／IAMステートメントによって制御される． ・IAMロールとは IAMポリシーのセットを定義する． ・IAMポリシーとは IAMステートメントのセットを定義する． IAMポリシーの種類 説明 アイデンティティベースのポリシー IAMユーザ，IAMグループ，IAMロール，にアタッチするためのポリシーのこと． リソースベースのインラインポリシー 単一のAWSリソースにインポリシーのこと． アクセスコントロールポリシー json形式で定義する必要が無いポリシーのこと． ＊例＊ 以下に，EC2の読み出しのみ権限（AmazonEC2ReadOnlyAccess）をアタッチできるポリシーを示す．このIAMポリシーには，他のAWSリソースに対する権限も含まれている． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"ec2:Describe*\", \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": \"elasticloadbalancing:Describe*\", \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"cloudwatch:ListMetrics\", \"cloudwatch:GetMetricStatistics\", \"cloudwatch:Describe*\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": \"autoscaling:Describe*\", \"Resource\": \"*\" } ] } ・IAMステートメントとは AWSリソースに関する認可のスコープを定義する．各アクションについては以下のリンクを参考にせよ． AWSリソースの種類 リンク CloudWatchログ https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/logs/permissions-reference-cwl.html ＊例＊ 以下のインラインポリシーがアタッチされたロールを持つAWSリソースは，任意のSSMパラメータを取得できるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ssm:GetParameters\" ], \"Resource\": \"*\" } ] } Statementの項目 説明 Sid 任意の一意な文字列を設定する．空文字でもよい． Effect 許可／拒否を設定する． Action リソースに対して実行できるアクションを設定する． Resource アクションの実行対象に選べるリソースを設定する． 以下に主要なアクションを示す． アクション名 説明 Create リソースを構築する． Describe リソースを表示する． Delete リソースを削除する． Get リソースを取得する． Put リソースを上書きする． ・ARNとは：Amazon Resource Namespace AWSリソースの識別子のこと． 参考：https://docs.aws.amazon.com/ja_jp/general/latest/gr/aws-arns-and-namespaces.html { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Resource\": \"arn:::::\" } ] } IAMロール ・サービスリンクロール AWSリソースを構築した時に自動的に作成されるロール．他にはアタッチできない専用のポリシーがアタッチされている．『AWSServiceRoleFor*****』という名前で自動的に構築される．特に設定せずとも，自動的にリソースにアタッチされる．関連するリソースを削除するまで，ロール自体できない．サービスリンクロールの一覧については，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_aws-services-that-work-with-iam.html ・クロスアカウントのアクセスロール ・プロバイダのアクセスロール アイデンティティベースのポリシー ・アイデンティティベースのポリシーとは IAMユーザ，IAMグループ，IAMロール，にアタッチするためのポリシーのこと． ・AWS管理ポリシー AWSが提供しているポリシーのこと．アタッチ式のポリシーのため，すでにアタッチされていても，他のものにもアタッチできる． ・カスタマー管理ポリシー ユーザが独自に構築したポリシーのこと．すでにアタッチされていても，他のものにもアタッチできる． ・インラインポリシー 単一のアイデンティティにアタッチするためのポリシーのこと．組み込み式のポリシーのため，アイデンティティ間で共有してアタッチすることはできない． ＊実装例＊ IAMロールにインラインポリシーをアタッチする．このロールを持つユーザは，ユーザーアカウントのすべての ACM 証明書を一覧表示できるようになる． { \"Version\":\"2012-10-17\", \"Statement\":[ { \"Effect\":\"Allow\", \"Action\":\"acm:ListCertificates\", \"Resource\":\"*\" } ] } ＊実装例＊ IAMロールにインラインポリシーをアタッチする．このロールを持つユーザは，全てのAWSリソースに，任意のアクションを実行できる． { \"Version\":\"2012-10-17\", \"Statement\":[ { \"Effect\":\"Allow\", \"Action\":\"*\", \"Resource\":\"*\" } ] } リソースベースのインラインポリシー ・リソースベースのインラインポリシーとは 単一のAWSリソースにインポリシーのこと．すでにアタッチされていると，他のものにはアタッチできない． ・バケットポリシー S3にアタッチされる，自身へのアクセスを制御するためのインラインポリシーのこと． ・ライフサイクルポリシー ECRにアタッチされる，イメージの有効期間を定義するポリシー．コンソール画面から入力できるため，基本的にポリシーの実装は不要であるが，TerraformなどのIaCツールでは必要になる． ＊実装例＊ { \"rules\": [ { \"rulePriority\": 1, \"description\": \"Keep last 10 images untagged\", \"selection\": { \"tagStatus\": \"untagged\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } }, { \"rulePriority\": 2, \"description\": \"Keep last 10 images any\", \"selection\": { \"tagStatus\": \"any\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } } ] } ・信頼ポリシー ロールにアタッチされる，Assume Roleを行うためのインラインポリシーのこと． ＊実装例＊ 例えば，以下の信頼ポリシーを任意のロールにアタッチしたとする．その場合，Principalのecs-tasksが信頼されたエンティティと見なされ，ロールをアタッチできるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ecs-tasks.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] } 信頼ポリシーでは，IAMユーザを信頼されたエンティティとして設定することもできる． ＊実装例＊ 例えば，以下の信頼ポリシーを任意のロールにアタッチしたとする．その場合，PrincipalのIAMユーザが信頼されたエンティティと見なされ，ロールをアタッチできるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam:::user/\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"StringEquals\": { \"sts:ExternalId\": \"\" } } } ] } IAMポリシーをアタッチできる対象 ・IAMユーザに対するアタッチ ・IAMグループに対するアタッチ ・IAMロールに対するアタッチ ルートユーザ，IAMユーザ ・ルートユーザとは 全ての権限をもったアカウントのこと． ・IAMユーザとは 特定の権限をもったアカウントのこと． ・credentialsファイルを使用したCLI AWS CLIでクラウドインフラを操作するためには，credentialsファイルに定義されたクレデンシャル情報が必要である．『aws_region』ではなく『aws_default_region』であることに注意する． $ aws configure set aws_access_key_id \"\" $ aws configure set aws_secret_access_key \"\" $ aws configure set aws_default_region \"リージョン>\" # Linux，Unixの場合：$HOME/.aws/ # Windowsの場合：%USERPROFILE%\\.aws\\ [default] aws_access_key_id= aws_secret_access_key= [user1] aws_access_key_id= aws_secret_access_key= ・環境変数を使用したCLI AWS CLIでクラウドインフラを操作するためには，環境変数で定義されたクレデンシャル情報が必要である．『AWS_REGION』ではなく『AWS_DEFAULT_REGION』であることに注意する． $ export AWS_ACCESS_KEY_ID= $ export AWS_SECRET_ACCESS_KEY= $ export AWS_DEFAULT_REGION= IAMグループ ・IAMグループとは IAMユーザをグループ化したもの．IAMグループごとにIAMロールをアタッチすれば，IAMユーザのIAMロールを管理しやすくなる． ・IAMグループへのIAMロールの紐付け IAMグループに対して，IAMロールを紐付ける．そのIAMグループに対して，IAMロールをアタッチしたいIAMユーザを追加していく． ・グループ一覧 種類 説明 補足 Administrator 全ての操作に権限がある． PowerUserAccess IAM以外の操作権限がある． ViewOnlyAccess 閲覧のみの操作権限がある． CLI ・CLIの社内アクセス制限 特定の送信元IPアドレスを制限するポリシーをIAMユーザにアタッチすることで，そのIAMユーザがAWS CLIの実行する時に，社外から実行できないように制限をかけられる． ＊実装例＊ { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Deny\", \"Action\": \"*\", \"Resource\": \"*\", \"Condition\": { \"NotIpAddress\": { \"aws:SourceIp\": [ \"nn.nnn.nnn.nnn/32\" ] } } } } ポリシーのDenyステートメントによってアクセスが拒否された場合，エラーメッセージの最後に『with an explicit deny』という文言がつく． ＊例＊ Error: An error occurred (AccessDeniedException) when calling the operation: is not authorized to perform: on resource: with an explicit deny ・ユーザ名を変更 ユーザ名は，コンソール画面から変更できず，コマンドで変更する必要がある． $ aws iam update-user \\ --user-name \\ --new-user-name 20. Kinesis Data Streams Kinesis Data Streamsとは リアルタイムなストリーミングデータ（動画データ，音声データ，など）を継続的に収集し，保管する． 参考：https://docs.aws.amazon.com/ja_jp/streams/latest/dev/amazon-kinesis-streams.html 20-02. Kinesis Data Firehose（Kinesis Delivery Stream） Kinesis Data Firehoseとは リアルタイムなストリーミングデータ（動画データ，音声データ，など）を継続的に収集し，保管／可視化／分析／レポート作成／アラートが可能な外部サービスやAWSリソースに転送する．転送時にLambda関数を使用することで，収集したデータを加工できる． 参考：https://docs.aws.amazon.com/ja_jp/firehose/latest/dev/what-is-this-service.html 設定項目 項目 説明 レコードの変換 転送先 転送先とするS3バケットを設定する． バックアップ 収集したデータを加工する場合に，加工前データを保管しておく． 暗号化 エラーログの収集 データの転送時にエラーが発生した場合，エラーログをCloudWatchログに送信する． IAMロール Kinesis Data FirehoseがAWSリソースにデータを転送できるように，権限を設定する． 20-03. Kinesis Data Analytics Kinesis Data Analyticsとは リアルタイムなストリーミングデータ（動画データ，音声データ，など）を継続的に収集し，分析する． 参考：https://docs.aws.amazon.com/kinesisanalytics/latest/dev/what-is.html 21. Lambda Lambdaとは 他のAWSリソースのイベントによって駆動する関数を管理できる．ユースケースについては，以下のリンクを参考にせよ． 参考：参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/applications-usecases.html 設定項目 ・概要 設定項目 説明 補足 ランタイム 関数の実装に使用する言語を設定する． コンテナイメージの関数では使用できない． ハンドラ 関数の実行時にコールしたい具体的メソッド名を設定する． ・コンテナイメージの関数では使用できない．・Node.js：index.js というファイル名で exports.handler メソッドを呼び出したい場合，ハンドラ名をindex.handlerとする レイヤー 異なる関数の間で，特定の処理を共通化できる． コンテナイメージの関数では使用できない． メモリ Lambdaに割り当てるメモリ量を設定する． 最大10240MBまで増設でき，増設するほどパフォーマンスが上がる．参考：https://www.business-on-it.com/2003-aws-lambda-performance-check/ タイムアウト 実行ロール Lambda内のメソッドが実行される時に必要なポリシーを持つロールを設定する． 既存ロール Lambdaにロールを設定する． トリガー LambdaにアクセスできるようにするAWSリソースを設定する． 設定されたAWSリソースに応じて，Lambdaのポリシーが自動的に修正される． アクセス権限 Lambdaのポリシーを設定する． トリガーの設定に応じて，Lambdaのポリシーが自動的に修正される． 送信先 LambdaからアクセスできるようにするAWSリソースを設定する． 送信先のAWSリソースのポリシーは自動的に修正されないため，別途，手動で修正する必要がある． 環境変数 Lambdaの関数内に出力する環境変数を設定する． 標準では，環境変数はAWSマネージド型KMSキーによって暗号化される． 同時実行数 同時実行の予約を設定する． プロビジョニングされた同時実行設定 モニタリング LambdaをCloudWatchまたはX-Rayを用いて，メトリクスを収集する． 次の方法がある・CloudWatchによって，メトリクスを収集する．・CloudWatchのLambda Insightsによって，パフォーマンスに関するメトリクスを収集する．・X-Rayによって，APIへのリクエスト，Lambdaコール，Lambdaの下流とのデータ通信をトレースし，これらをスタックトレース化する． ・設定のベストプラクティス 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/best-practices.html#function-configuration Lambdaと関数の関係性 ・Lambdaサービス コンソール画面のLamdaに相当する． ・関数の実行環境 Lambdaの実行環境は，API（ランタイムAPI，ログAPI，拡張API）と実行環境から構成されている．関数は実行環境に存在し，ランタイムAPIを介して，Lambdaによって実行される． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-extensions-api.html#runtimes-extensions-api-lifecycle 実行環境には，３つのフェーズがある． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-context.html#runtimes-lifecycle ・Initフェーズ Lambdaが発火する．実行環境が構築され，関数を実行するための準備が行われる． ・Invokeフェーズ Lambdaは関数を実行する．実行環境側のランタイムは，APIを介してLambdaから関数に引数を渡す．また関数の実行後に，APIを介して返却値をLambdaに渡す． ・Shutdownフェーズ 一定期間，Invokeフェーズにおける関数実行が行われなかった場合，Lambdaはランタイムを終了し，実行環境を削除する． Lambda関数 on Docker ・ベースイメージの準備 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-images.html#runtimes-images-lp ・RIC：Runtime Interface Clients 通常のランタイムはコンテナ内関数と通信できないため，ランタイムの代わりにRICを使用してコンテナ内関数と通信を行う．言語別にRICパッケージが用意されている． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-images.html#runtimes-api-client ・RIE：Runtime Interface Emulator 開発環境のコンテナで，擬似的にLambda関数を再現する．全ての言語で共通のRIEライブラリが用意されている． 参考：https://github.com/aws/aws-lambda-runtime-interface-emulator RIEであっても，稼働させるためにAWSのクレデンシャル情報（アクセスキー，シークレットアクセスキー，リージョン）が必要なため，環境変数やcredentialsファイルを使用して，Lambdaにこれらの値を出力する． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/images-test.html#images-test-env ＊参考＊ $ docker run --rm \\ # エミュレーターをエントリポイントをバインドする． -v ~/.aws-lambda-rie:/aws-lambda \\ -p 9000:8080 \\ # エミュレーターをエントリポイントとして指定する． --entrypoint /aws-lambda/aws-lambda-rie \\ : /go/bin/cmd # ハンドラー関数の引数に合ったJSONデータを送信する． $ curl \\ -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" \\ -d '{}' ＊参考＊ version: \"3.7\" services: lambda: build: context: . dockerfile: ./build/Dockerfile container_name: lambda # エミュレーターをエントリポイントとして指定する． entrypoint: /aws-lambda/aws-lambda-rie env_file: - .docker.env image: : ports: - 9000:8080 # エミュレーターをエントリポイントをバインドする． volumes: - ~/.aws-lambda-rie:/aws-lambda $ docker-compose up lambda $ curl \\ -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" \\ -d '{}' Lambda関数 ・Goの使用例 以下のリンクを参考にせよ． 参考： https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-golang.html https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws_lambda_function.html ・Node.jsの使用例 以下のリンクを参考にせよ． 参考： https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-nodejs.html https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws_lambda_function.html 同時実行 ・同時実行の予約 Lambdaは，関数の実行中に再びリクエストが送信されると，関数のインスタンスを新しく作成する．そして，各関数インスタンスを用いて，同時並行的にリクエストに応じる．標準では，関数の種類がいくつあっても，AWSアカウント当たり，合計で1000個までしかスケーリングして同時実行できない．関数ごとに同時実行数の使用枠を割り当てるためには，同時実行の予約を設定する必要がある．同時実行の予約数を0個とした場合，Lambdがスケーリングしなくなる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/configuration-concurrency.html#configuration-concurrency-reserved VPC外／VPC内 ・VPC外への配置 Lambdaは標準ではVPC外に配置される．この場合，LambdaにENIがアタッチされ，ENIに割り当てられたIPアドレスがLambdaに適用される．Lambdaの実行時にENIは再作成されるため，実行ごとにIPアドレスは変化するが，一定時間内の再実行であればENIは再利用されるため，前回の実行時と同じIPアドレスになることもある． ・VPC内への配置 LambdaをVPC内に配置するように設定する．VPC内に配置したLambdaにはパブリックIPアドレスが割り当てられないため，アウトバウンドな通信を行うためには，NAT Gatewayを設置する必要がある． ポリシー ・実行のための最低限のポリシー Lambdaを実行するためには，デプロイされた関数を使用する権限が必要である．そのため，関数を取得するためのステートメントを設定する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"lambda:InvokeFunction\", \"Resource\": \"arn:aws:lambda:::function:*\" } ] } デプロイ ・直接修正 デプロイを行わずに，関数のソースコードを直接修正し，『Deploy』ボタンでデプロイする． ・S3におけるzipファイル ビルド後のソースコードをzipファイルにしてアップロードする．ローカルPCまたはS3からアップロードできる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/gettingstarted-package.html#gettingstarted-package-zip ・ECRにおけるイメージ コンテナイメージの関数でのみ有効である．ビルド後のソースコードをDockerイメージしてアップロードする．ECRからアップロードできる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/gettingstarted-package.html#gettingstarted-package-images 21-02. Lambda@Edge Lambda@Edgeとは CloudFrontに統合されたLambdaを，特別にLambda@Edgeという． 設定項目 ・トリガーの種類 CloudFrontのビューワーリクエスト，オリジンリクエスト，オリジンレスポンス，ビューワーレスポンス，をトリガーとする．エッジロケーションのCloudFrontに，Lambdaのレプリカが構築される． トリガーの種類 発火のタイミング ビューワーリクエスト CloudFrontが，ビューワーからリクエストを受信した後（キャッシュを確認する前）． オリジンリクエスト CloudFrontが，リクエストをオリジンサーバーに転送する前（キャッシュを確認した後）． オリジンレスポンス CloudFrontが，オリジンからレスポンスを受信した後（キャッシュを確認する前）． ビューワーレスポンス CloudFrontが，ビューワーにレスポンスを転送する前（キャッシュを確認した後）． ・各トリガーのeventオブジェクトへのマッピング 各トリガーのeventオブジェクトへのマッピングは，リンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudFront/latest/DeveloperGuide/lambda-event-structure.html ポリシー ・実行のための最低限のポリシー Lambda@Edgeを実行するためには，最低限，以下の権限が必要である． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"iam:CreateServiceLinkedRole\" ], \"Resource\": \"*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"lambda:GetFunction\", \"lambda:EnableReplication*\" ], \"Resource\": \"arn:aws:lambda:::function::\" }, { \"Effect\": \"Allow\", \"Action\": [ \"cloudfront:UpdateDistribution\" ], \"Resource\": \"arn:aws:cloudfront:::distribution/\" } ] } Node.jsを用いた関数例 ・オリジンの動的な切り替え ＊実装例＊ eventオブジェクトのdomainNameとhost.valueに代入されたバケットのドメイン名によって，ルーティング先のバケットが決まる．そのため，この値を切り替えれば，動的オリジンを実現できる．なお，各バケットには同じOAIを設定する必要がある． \"use strict\"; exports.handler = (event, context, callback) => { const request = event.Records[0].cf.request; // ログストリームに変数を出力する． console.log(JSON.stringify({request}, null, 2)); const headers = request.headers; const s3Backet = getBacketBasedOnDeviceType(headers); request.origin.s3.domainName = s3Backet request.headers.host[0].value = s3Backet // ログストリームに変数を出力する． console.log(JSON.stringify({request}, null, 2)); return callback(null, request); }; /** * デバイスタイプに基づいて，オリジンを切り替える． * * @param {Object} headers * @param {string} env * @returns {string} pcBucket|spBucket */ const getBacketBasedOnDeviceType = (headers) => { const pcBucket = env + \"-bucket.s3.amazonaws.com\"; const spBucket = env + \"-bucket.s3.amazonaws.com\"; if (headers[\"cloudfront-is-desktop-viewer\"] && headers[\"cloudfront-is-desktop-viewer\"][0].value === \"true\") { return pcBucket; } if (headers[\"cloudfront-is-tablet-viewer\"] && headers[\"cloudfront-is-tablet-viewer\"][0].value === \"true\") { return pcBucket; } if (headers[\"cloudfront-is-mobile-viewer\"] && headers[\"cloudfront-is-mobile-viewer\"][0].value === \"true\") { return spBucket; } return spBucket; }; オリジンリクエストは，以下のeventオブジェクトのJSONデータにマッピングされている．なお，一部のキーは省略している． { \"Records\": [ { \"cf\": { \"request\": { \"body\": { \"action\": \"read-only\", \"data\": \"\", \"encoding\": \"base64\", \"inputTruncated\": false }, \"clientIp\": \"nnn.n.nnn.nnn\", \"headers\": { \"host\": [ { \"key\": \"Host\", \"value\": \"prd-sp-bucket.s3.ap-northeast-1.amazonaws.com\" } ], \"cloudfront-is-mobile-viewer\": [ { \"key\": \"CloudFront-Is-Mobile-Viewer\", \"value\": true } ], \"cloudfront-is-tablet-viewer\": [ { \"key\": \"loudFront-Is-Tablet-Viewer\", \"value\": false } ], \"cloudfront-is-smarttv-viewer\": [ { \"key\": \"CloudFront-Is-SmartTV-Viewer\", \"value\": false } ], \"cloudfront-is-desktop-viewer\": [ { \"key\": \"CloudFront-Is-Desktop-Viewer\", \"value\": false } ], \"user-agent\": [ { \"key\": \"User-Agent\", \"value\": \"Amazon CloudFront\" } ] }, \"method\": \"GET\", \"origin\": { \"s3\": { \"authMethod\": \"origin-access-identity\", \"customHeaders\": { \"env\": [ { \"key\": \"env\", \"value\": \"prd\" } ] }, \"domainName\": \"prd-sp-bucket.s3.amazonaws.com\", \"path\": \"\", \"port\": 443, \"protocol\": \"https\", \"region\": \"ap-northeast-1\" } }, \"querystring\": \"\", \"uri\": \"/images/12345\" } } } ] } 22. RDS：Relational Database Service 設定項目 設定項目 説明 補足 エンジンのオプション データベースエンジンの種類を設定 エディション Amazon Auroraを選んだ場合の互換性を設定する． キャパシティタイプ エンジンバージョン データベースエンジンのバージョンを指定する． ・SELECT AURORA_VERSION()を使用して，エンジンバージョンを確認できる． レプリケーション機能 DBクラスター識別子 クラスター名を設定する． インスタンス名は，最初に設定できず，RDSの構築後に設定できる． マスタユーザ名 データベースのrootユーザを設定 マスターパスワード データベースのrootユーザのパスワードを設定 DBインスタンスサイズ データベースのインスタンスのスペックを設定する． バースト可能クラスを選ぶこと．ちなみに，Amazon Auroraのデータベース容量は自動でスケーリングするため，設定する必要がない． マルチAZ配置 プライマリインスタンスとは別に，リーダーレプリカをマルチAZ配置で追加するかどうかを設定する． 最初のデータベース名 データベースに自動的に構築されるデータベース名を設定 サブネットグループ データベースにアクセスできるサブネットを設定する． パラメータグループ グローバルパラメータを設定する． デフォルトを使用せずに独自定義する場合，事前に構築しておく必要がある．クラスターパラメータグループとインスタンスパラメータグループがあるが，クラスターパラメータを設定すればよい．各パラメータに適用タイプ（dynamic/static）があり，dynamicタイプは設定の適用に再起動が必要である．新しく作成したクラスタパラメータグループにて以下の値を設定するとよい．・time_zone=Asia/Tokyo・character_set_client=utf8mb4・character_set_connection=utf8mb4・character_set_database=utf8mb4・character_set_results=utf8mb4・character_set_server=utf8mb4・server_audit_logging=1（監査ログをCloudWatchに送信するかどうか）・server_audit_logs_upload=1・general_log=1（通常クエリログをCloudWatchに送信するかどうか）・slow_query_log=1（スロークエリログをCloudWatchに送信するかどうか）・long_query_time=3（スロークエリと見なす最短秒数） ログのエクスポート 必ず，全てのログを選択すること． バックアップ保持期間 RDSがバックアップを保持する期間を設定する． 7日間にしておく． マイナーバージョンの自動アップグレード データベースエンジンのバージョンを自動的に更新するかを設定する． 開発環境では有効化，本番環境とステージング環境では無効化しておく．開発環境で新しいバージョンに問題がなければ，ステージング環境と本番環境にも適用する． データベースインスタンス ・データベースエンジン，RDB，DBMSの対応関係 RDSでは，DBMS，RDBを選べる． DBMSの種類 RDBの種類 MySQL／PostgreSQL Amazon Aurora MariaDB MariaDBデータベース MySQL MySQLデータベース PostgreSQL PostgreSQLデータベース ・データベースインスタンスの種類 読み出し／書き込みインスタンス 読み出しオンリーインスタンス 別名 プライマリインスタンス リードレプリカインスタンス CRUD制限 制限なし．ユーザ権限に依存する． ユーザ権限の権限に関係なく，READしか実行できない． エンドポイント 各インスタンスに，リージョンのイニシャルに合わせたエンヂポイントが割り振られる． 各インスタンスに，リージョンのイニシャルに合わせたエンヂポイントが割り振られる． データ同期 RDSクラスターに対するデータ変更を受けつける． 読み出し／書き込みインスタンスのデータの変更が同期される． インスタンスのダウンタイム ・ダウンタイムの発生条件 その他の全ての項目は，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html#USER_ModifyInstance.Settings 変更する項目 ダウンタイムの有無 補足 インスタンスクラス あり サブネットグループ あり エンジンバージョン あり 20～30秒のダウンタイムが発生する．参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.html メンテナンスウィンドウ 条件付きでなし ダウンタイムが発生する操作が保留中になっている状態で，メンテナンス時間を現在が含まれるように変更すると，保留中の操作がすぐに適用される．そのため，ダウンタイムが発生する． バックアップウインドウ 条件付きでなし 0から0以外の値，0以外の値から0に変更した場合，ダウンタイムが発生する． パラメータグループ なし パラメータグループの変更ではダウンタイムは発生しない．ただし，パラメータグループの変更をインスタンスに反映させる上で再起動が必要なため，ここでダウンタイムが発生する． セキュリティグループ なし マイナーバージョン自動アップグレード なし エンジンバージョンの変更にはダウンタイムが発生するが，自動アップグレードの設定にはダウンタイムが発生しない． パフォーマンスインサイト 条件付きでなし パフォーマンスインサイトの有効化ではダウンタイムが発生しない．ただし，有効化のためにパラメータグループのperformance_schemaを有効化する必要がある．パラメータグループの変更をインスタンスに反映させる上で再起動が必要なため，ここでダウンタイムが発生する． ・再起動ダウンタイムの短縮 非マルチAZ構成の場合，アプリケーションの向き先をプライマリーインスタンスにしたまま，変更対象のデータベースからリードレプリカを新しく作成し，これを更新した後に，リードレプリカを手動フェイルオーバーさせる．フェイルオーバー時に約1～2分のダウンタイムが発生するが，インスタンスの再起動よりも時間が短いため，相対的にダウンタイムを短縮できる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.MySQL.html#USER_UpgradeDBInstance.MySQL.ReducedDowntime マルチAZ構成の場合，アプリケーションの向き先をプライマリーインスタンスにしたまま，既存のリードレプリカを更新し，リードレプリカを自動フェイルオーバーさせる．フェイルオーバー時に約1～2分のダウンタイムが発生するが，インスタンスの再起動よりも時間が短いため，相対的にダウンタイムを短縮できる． ・メンテナンスウインドウ メンテナスウインドウには，以下の状態がある． 状態 説明 利用可能 アクションは実行可能である．また，以降のメンテナンスウィンドウの間に自動的に実行することはない． 次のウィンドウ アクションは実行可能である．また，次回のメンテナンスウィンドウの間に，アクションを自動的に実行する．後でアップグレードを選択することで，『利用可能』の状態に戻すことも可能． 必須 アクションは実行可能である．また，指定されたメンテナンスウィンドウの間に必ず実行され，これは延期できない． 進行中 現在時刻がメンテナンスウィンドウに含まれており，アクションを実行中である． ・ダウンタイムの計測 アプリケーションの目視ではなく，RDSに直接クエリを送信し，レスポンスとRDSイベントログから，ダウンタイムを計測する． ＊実装例＊ 踏み台サーバを経由してRDSに接続し，現在時刻を取得するSQLを送信する．平常アクセス時の再現テストも同時に実行することで，より正確なダウンタイムを取得するようにする．また，ヘルスチェックの時刻を正しくロギングできるように，ローカルPCから時刻を取得する． #!/bin/bash set -x BASTION_HOST=\"\" BASTION_USER=\"\" DB_HOST=\"\" DB_PASSWORD=\"\" DB_USER=\"\" SECRET_KEY=\"~/.ssh/xxx.pem\" SQL=\"SELECT NOW();\" ssh -o serveraliveinterval=60 -f -N -L 3306:${DB_HOST}:3306 -i ${SECRET_KEY} ${BASTION_USER}@${BASTION_HOST} -p 22 for i in {1..900}; do LOCAL_DATETIME=$(date +\"%Y-%m-%d %H:%M:%S\") echo \"---------- No. ${i} Local PC: ${LOCAL_DATETIME} ------------\" >> health_check.txt echo ${SQL} | mysql -u ${DB_USER} -P 3306 -p${DB_PASSWORD} >> health_check.txt 2>&1 & sleep 1 done 上記のシェルスクリプトにより，例えば次のようなログを取得できる．このログからは，15:23:09 ~ 15:23:14の間で，接続に失敗していることを確認できる． ---------- No. 242 Local PC: 2021-04-21 15:23:06 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:06 ---------- No. 243 Local PC: 2021-04-21 15:23:07 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:08 ---------- No. 244 Local PC: 2021-04-21 15:23:08 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2026 (HY000): SSL connection error: error:00000000:lib(0):func(0):reason(0) ---------- No. 245 Local PC: 2021-04-21 15:23:09 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 246 Local PC: 2021-04-21 15:23:10 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 247 Local PC: 2021-04-21 15:23:11 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 248 Local PC: 2021-04-21 15:23:13 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 249 Local PC: 2021-04-21 15:23:14 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0 ---------- No. 250 Local PC: 2021-04-21 15:23:15 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:16 ---------- No. 251 Local PC: 2021-04-21 15:23:16 ------------ mysql: [Warning] Using a password on the command line interface can be insecure. NOW() 2021-04-21 06:23:17 アップグレード時のプライマリインスタンスのRDSイベントログは以下の通りで，ログによるダウンタイムは，再起動からシャットダウンまでの期間と一致することを確認する． ちなみに，リードレプリカは再起動のみを実行していることがわかる． 負荷対策 ・エンドポイントの使い分け インスタンスに応じたエンドポイントが用意されている．アプリケーションからのCRUDの種類に応じて，アクセス先を振り分けることにより，負荷を分散させられる．読み出しオンリーエンドポイントに対して，READ以外の処理を行うと，以下の通り，エラーとなる． /* SQL Error (1290): The MySQL server is running with the --read-only option so it cannot execute this statement */ 種類 エンドポイント クエリの種類 説明 クラスターエンドポイント .cluster-.ap-northeast-1.rds.amazonaws.com 書き込み／読み出し プライマリインスタンスに接続できる． 読み出しエンドポイント .cluster-ro-.ap-northeast-1.rds.amazonaws.com 読み出し リードレプリカインスタンスに接続できる．インスタンスが複数ある場合，クエリが自動的に割り振られる． インスタンスエンドポイント .cwgrq25vlygf.ap-northeast-1.rds.amazonaws.com 選択したインスタンスに接続できる．フェイルオーバーによって読み書きインスタンスと読み出しインスタンスが入れ替わってしまうため，インスタンスエンドポイントを指定しない方が良い．これは，Redisも同じである． ・クエリキャッシュの利用 MySQLやRedisのクエリキャッシュ機能を利用する．ただし，MySQLのクエリキャッシュ機能は，バージョン8で廃止されることになっている． ・ユニークキーまたはインデックスの利用 スロークエリを検出し，そのSQLで対象としているカラムにユニークキーやインデックスを設定する．スロークエリを検出する方法として，RDSのlong_query_timeパラメータに基づいた検出や，EXPLAIN句による予想実行時間の比較などがある．ユニークキー，インデックス，EXPLAIN句，については以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/backend_database_mysql.html ・テーブルを正規化し過ぎない テーブルを正規化すると保守性が高まるが，アプリケーションのSQLでJOIN句が必要になる．しかし，JOIN句を含むSQLは，含まないSQLと比較して，実行速度が遅くなる．そこで，戦略的に正規化し過ぎないようにする． ・インスタンスタイプのスケールアップ インスタンスタイプをスケールアップさせることで，接続過多のエラー（ERROR 1040 (HY000): Too many connections）に対処する．ちなみに現在の最大接続数はパラメータグループの値から確認できる．コンソール画面からはおおよその値しかわからないため，SQLで確認した方が良い． MySQL > SHOW GLOBAL VARIABLES LIKE 'max_connections'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 640 | +-----------------+-------+ 1 row in set (0.00 sec) 障害対策 ・フェイルオーバー RDSのフェイルオーバーには，データベースの種類に応じて，以下の種類のものがある．フェイルオーバー時に約1～2分のダウンタイムが発生する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover データベース フェイルオーバーの仕組み 補足 Aurora リードレプリカがプライマリインスタンスに昇格する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/Concepts.AuroraHighAvailability.html Aurora以外 スタンバイレプリカがプライマリインスタンスに昇格する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html Auroraの場合，フェイルオーバーによって昇格するインスタンスは次の順番で決定される．基本的には，優先度の数値の小さいインスタンスが昇格対象になる．優先度が同じだと，インスタンスクラスが大きいインスタンスが昇格対象になる．インスタンスクラスが同じだと，同じサブネットにあるインスタンスが昇格対象になる． 優先度の順番 インスタンスクラスの大きさ 同じサブネット ・エンジンバージョンアップグレード時の事前調査 エンジンバージョンのアップグレード時，ダウンタイムが発生する．そのため，以下のような報告書のもと，調査と対応を行う． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.html またマージされる内容の調査のため，リリースノートの確認が必要になる． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Updates.11Updates.html # 調査 ## バージョンの違い 『SELECT AURORA_VERSION()』を使用して，正確なバージョンを取得する． ## マージされる内容 ベンダーのリリースノートを確認し，どのような『機能追加』『バグ修正』『機能廃止』『非推奨機能』がマージされるかを調査する． 機能廃止や非推奨機能がある場合，アプリケーション内のSQL文に影響が出る可能性がある． ## 想定されるダウンタイム テスト環境でダウンタイムを計測し，ダウンタイムを想定する． # 本番環境対応 ## 日時と周知 対応日時と周知内容を決定する． ## 想定外の結果 本番環境での対応で起こった想定外の結果を記載する． セキュリティ ・配置されるサブネット データベースが配置されるサブネットはプライベートサブネットにする，これには，data storeサブネットと名付ける．アプリケーション以外は，踏み台サーバ経由でしかデータベースにアクセスできないようにする． ・セキュリティグループ コンピューティングからのインバウンド通信のみを許可するように，これらのプライベートIPアドレス（n.n.n.n/32）を設定する． 23. RegionとZone Region ・Regionとは 物理サーバのあるデータセンターの地域名のこと． ・Globalとエッジロケーションとは Regionとは別に，物理サーバが世界中にあり，これらの間ではグローバルネットワークが構築されている．そのため，Globalなサービスは，特定のRegionに依存せずに，全てのRegionと連携できる． 24. Route53 Route53とは クラウドDNSサーバーとして働く．リクエストされた完全修飾ドメイン名とEC2のグローバルIPアドレスをマッピングしている． 設定項目 ・概要 設定項目 説明 ホストゾーン ドメイン名を設定する． レコードセット 名前解決時のルーティング方法を設定する．サブドメイン名を扱うことも可能． ホストゾーン ・レコードタイプの設定値の違い レコードタイプ 補足 NS IPアドレスの問い合わせに応えられる権威DNSサーバの名前が定義されている． A リクエストを転送したいAWSリソースの，IPv4アドレスまたはDNS名を設定する． AAAA リクエストを転送したいAWSリソースの，IPv6アドレスまたはDNS名を設定する． CNAME リクエストを転送したい任意のサーバのドメイン名を設定する． 転送先はAWSリソースでなくともよい． MX リクエストを転送したいメールサーバのドメイン名を設定する． TXT リクエストを転送したいサーバのドメイン名に紐付けられた文字列を設定する． ・リソースのDNS名，ドメイン名，エンドポイント名 リソースのDNS名は，以下の様に決定される． 種別 リソース 例 DNS名 ALB -..elb.amazonaws.com EC2 ec2-..compute.amazonaws.com ドメイン名 CloudFront .cloudfront.net エンドポイント名 S3 ..amazonaws.com ・レコードタイプの名前解決方法の違い レコードタイプ 名前解決方法（1） （2） （3） A 完全修飾ドメイン名 → パブリックIPv4 → - AAAA 完全修飾ドメイン名 → パブリックIPv6 → - CNAME 完全修飾ドメイン名 → （リダイレクト） → パブリックIPv4 ・CloudFrontへのルーティング CloudFrontにルーティングする場合，CloudFrontのCNAMEをレコード名とすると，CloudFrontのデフォルトドメイン名（xxxxx.cloudfront.net.）が，入力フォームに表示されるようになる． ・Route53を含む多数のDNSサーバによって名前解決される仕組み === （1）完全修飾ドメイン名に対応するIPアドレスのレスポンス === クライアントPCは，自身に保存されるwww.example.jp（完全修飾ドメイン名）のキャッシュを検索する． キャッシュが無ければ，クライアントPCはwww.example.jpを，フォワードプロキシサーバ（キャッシュDNSサーバ）にリクエスト． フォワードプロキシサーバは，DNSキャッシュを検索する． フォワードプロキシサーバは，ルートDNSサーバにwww.example.jpのIPアドレスを問い合わせる． ルートDNSサーバは，NSレコードとして定義された権威DNSサーバ名をレスポンス． フォワードプロキシサーバは，www.example.jpを，リバースプロキシサーバに代理リクエスト．次いで，リバースプロキシサーバは，DNSサーバ（ネームサーバ）にwww.example.jpのIPアドレスを問い合わせる． DNSサーバは，NSレコードとして定義された権威DNSサーバ名をレスポンス． フォワードプロキシサーバは，www.example.jpを，リバースプロキシサーバに代理リクエスト．次いで，リバースプロキシサーバは，グローバルリージョンRoute53にwww.example.jpのIPアドレスを問い合わせる． グローバルリージョンRoute53はDNSサーバとして機能し，リバースプロキシサーバに東京リージョンALBのIPアドレスをレスポンス．次いで，リバースプロキシサーバは，東京リージョンALBのIPアドレスを，フォワードプロキシサーバに代理レスポンス．（※ NATによるIPアドレスのネットワーク間変換が起こる） 完全修飾ドメイン名 Route53 IPv4アドレス http://www.example.com ⇄ 203.142.205.139 フォワードプロキシサーバは，東京リージョンALBのIPアドレスを，クライアントPCに代理レスポンス． クライアントPCは東京リージョンALBのIPアドレスにリクエストを送信する． === （2）東京リージョンALBのIPアドレスに対応するWebページのレスポンス === クライアントPCは，レスポンスされた東京リージョンALBのIPアドレスを基に，Webページを，リバースプロキシサーバにリクエスト． リバースプロキシサーバは，Webページを，東京リージョンALBに代理リクエスト． 東京リージョンALBは，EC2やFargateにリクエストを転送する． EC2やFargateは，Webページをリバースプロキシサーバにレスポンス． リバースプロキシサーバは，WebページをクライアントPCに代理レスポンス． ・AWS以外でドメインを購入した場合 DNSサーバによる名前解決は，ドメインを購入したドメインレジストラで行われる．そのため，AWS以外でドメインを購入した場合，Route53のNSレコード値を，ドメインレジストラに登録する必要がある．これにより，ドメインレジストラに対してIPアドレスの問い合わせがあった場合は，Route53のNSレコード値がレスポンスされるようになる．NSレコード値を元に，クライアントはRoute53にアクセスする． ・Route53におけるDNSキャッシュ ルートサーバは世界に13機しか存在しておらず，世界中の名前解決のリクエストを全て処理することは現実的に不可能である．そこで，IPアドレスとドメイン名の関係をキャッシュするプロキシサーバ（キャッシュDNSサーバ）が使用されている．基本的には，プロキシサーバとDNSサーバは区別されるが，Route53はプロキシサーバとDNSサーバの機能を両立している． リゾルバー ・リゾルバーとは 要勉強． 25. S3：Simple Storage Service S3とは クラウド外付けストレージとして働く．S3に保存するCSSファイルや画像ファイルを管理できる． 設定項目 ・概要 設定項目 説明 バケット バケットに関して設定する． バッチオペレーション アクセスアナライザー ・プロパティ 設定項目 説明 補足 バージョニング サーバアクセスのログ記録 静的サイトホスティング オブジェクトレベルのログ記録 デフォルト暗号化 オブジェクトのロック Transfer acceleration イベント リクエスタ支払い ・外部／内部ネットワークからのアクセス制限 設定項目 説明 補足 ブロックパブリックアクセス パブリックネットワークがS3にアクセスする時の許否を設定する． ・パブリックアクセスを有効にすると，パブリックネットワークから『https://.s3.amazonaws.com』というようにURLを指定して，S3にアクセスできるようになる．ただし非推奨．・パブリックアクセスを全て無効にすると，パブリックネットワークからの全アクセスを遮断できる．・特定のオブジェクトで，アクセスコントロールリストを制限した場合，そのオブジェクトだけはパブリックアクセスにならない． バケットポリシー IAMユーザ（クロスアカウントも可）またはAWSリソースがS3へにアクセスするためのポリシーで管理する． ・IAMユーザ（クロスアカウントも可）やAWSリソースがS3にアクセスするために必要である．ただし代わりに，IAMポリシーをAWSリソースにアタッチすることでも，アクセスを許可できる．・ポリシーをアタッチできないCloudFrontやALBなどでは，自身へのアクセスログを生成するために必須である． アクセスコントロールリスト IAMユーザ（クロスアカウントも可）がS3にアクセスする時の許否を設定する． ・バケットポリシーと機能が重複する．・仮にバケット自体のブロックパブリックアクセスを無効化したとしても，特定のオブジェクトでアクセスコントロールリストを制限した場合，そのオブジェクトだけはパブリックアクセスにならない． CORSの設定 レスポンスヘッダー ・レスポンスヘッダーの設定 レスポンスヘッダーに埋め込むHTTPヘッダーを，メタデータとして設定する． 設定可能なヘッダー 説明 補足 ETag コンテンツの一意な識別子．ブラウザキャッシュの検証に使用される． 全てのコンテンツにデフォルトで設定されている． Cache-Control Expiresと同様に，ブラウザにおけるキャッシュの有効期限を設定する． 全てのコンテンツにデフォルトで設定されている． Content-Type コンテンツのMIMEタイプを設定する． 全てのコンテンツにデフォルトで設定されている． Expires Cache-Controlと同様に，ブラウザにおけるキャッシュの有効期限を設定する．ただし，Cache-Controlの方が優先度が高い． Content-Disposition Content-Encoding x-amz-website-redirect-location コンテンツのリダイレクト先を設定する． バケットポリシーの例 ・S3のARNについて ポリシーにおいて，S3のARでは，『arn:aws:s3:::/*』のように，最後にバックスラッシュアスタリスクが必要． ・ALBのアクセスログの保存を許可 パブリックアクセスが無効化されたS3に対して，ALBへのアクセスログを保存したい場合，バケットポリシーを設定する必要がある．バケットポリシーには，ALBからS3へのログ書き込み権限を実装する．『\"AWS\": \"arn:aws:iam::582318560864:root\"』において，582318560864は，ALBアカウントIDと呼ばれ，リージョンごとに値が決まっている．これは，東京リージョンのアカウントIDである．その他のリージョンのアカウントIDについては，以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-access-logs.html#access-logging-bucket-permissions ＊実装例＊ { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::582318560864:root\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::/*\" } ] } ・CloudFrontのファイル読み出しを許可 パブリックアクセスが無効化されたS3に対して，CloudFrontからのルーティングで静的ファイルを読み出したい場合，バケットポリシーを設定する必要がある． ＊実装例＊ { \"Version\": \"2008-10-17\", \"Id\": \"PolicyForCloudFrontPrivateContent\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity \" }, \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\" } ] } ・CloudFrontのアクセスログの保存を許可 2020-10-08時点の仕様では，パブリックアクセスが無効化されたS3に対して，CloudFrontへのアクセスログを保存することはできない．よって，危険ではあるが，パブリックアクセスを有効化する必要がある． // ポリシーは不要 ・Lambdaからのアクセスを許可 バケットポリシーは不要である．代わりに，AWS管理ポリシーの『AWSLambdaExecute』がアタッチされたロールをLambdaにアタッチする必要がある．このポリシーには，S3へのアクセス権限の他，CloudWatchログにログを生成するための権限が設定されている． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"logs:*\" ], \"Resource\": \"arn:aws:logs:*:*:*\" }, { \"Effect\": \"Allow\", \"Action\": [ \"s3:GetObject\", \"s3:PutObject\" ], \"Resource\": \"arn:aws:s3:::*\" } ] } ・特定のIPアドレスからのアクセスを許可 パブリックネットワーク上の特定のIPアドレスからのアクセスを許可したい場合，そのIPアドレスをポリシーに設定する必要がある． { \"Version\": \"2012-10-17\", \"Id\": \"S3PolicyId1\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": \"*\", \"Action\": \"s3:GetObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"IpAddress\": { \"aws:SourceIp\": \"/32\" } } } ] } CORS設定 ・指定したドメインからのGET送信を許可 [ { \"AllowedHeaders\": [ \"Content-*\" ], \"AllowedMethods\": [ \"GET\" ], \"AllowedOrigins\": [ \"https://example.jp\" ], \"ExposeHeaders\": [], \"MaxAgeSeconds\": 3600 } ] CLI ・バケット内ファイルを表示 ＊コマンド例＊ 指定したバケット内のファイル名を表示する． $ aws s3 ls s3:// ・バケット内容量を合計 ＊コマンド例＊ 指定したバケット内のファイル容量を合計する． $ aws s3 ls s3:// --summarize --recursive --human-readable 26. Security Group Security Groupとは アプリケーションのクラウドパケットフィルタリング型ファイアウォールとして働く．インバウンド通信（プライベートネットワーク向き通信）では，プロトコルや受信元IPアドレスを設定でき，アウトバウンド通信（グローバルネットワーク向き通信）では，プロトコルや送信先プロトコルを設定できる． 設定項目 ・概要 インバウンドルールとアウトバウンドルールを設定できる． インバウンドルール ・パケットフィルタリング型ファイアウォール パケットのヘッダ情報に記載された送信元IPアドレスやポート番号などによって，パケットを許可するべきかどうかを決定する．速度を重視する場合はこちら．ファイアウォールとWebサーバの間には，NATルータやNAPTルータが設置されている．これらによる送信元プライベートIPアドレスから送信元グローバルIPアドレスへの変換についても参考にせよ． ・セキュリティグループIDの紐付け ソースに対して，セキュリティグループIDを設定した場合，そのセキュリティグループがアタッチされているENIと，このENIに紐付けられたリソースからのトラフィックを許可できる．リソースのIPアドレスが動的に変化する場合，有効な方法である． 参考：https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/VPC_SecurityGroups.html#DefaultSecurityGroup ・アプリケーションEC2の例 ALBに割り振られる可能性のあるIPアドレスを許可するために，ALBのSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 HTTP TCP 80 ALBのSecurity Group ID HTTP access from ALB HTTPS TCP 443 踏み台EC2のSecurity Group ID SSH access from bastion EC2 ・踏み台EC2の例 タイプ プロトコル ポート ソース 説明 SSH TCP 22 社内のグローバルIPアドレス SSH access from global ip addess ・EFSの例 EC2に割り振られる可能性のあるIPアドレスを許可するために，EC2のSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 NFS TCP 2049 アプリケーションEC2のSecurity Group ID NFS access from app EC2 ・RDSの例 EC2に割り振られる可能性のあるIPアドレスを許可するために，EC2のSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 MYSQL/Aurora TCP 3306 アプリケーションEC2のSecurity Group ID MYSQL access from app EC2 ・Redisの例 EC2に割り振られる可能性のあるIPアドレスを許可するために，EC2のSecurity GroupのID，またはサブネットのIPアドレス範囲を設定する． タイプ プロトコル ポート ソース 説明 カスタムTCP TCP 6379 アプリケーションEC2のSecurity Group ID TCP access from app EC2 ・ALBの例 CloudFrontと連携する場合，CloudFrontに割り振られる可能性のあるIPアドレスを許可するために，全てのIPアドレスを許可する．その代わりに，CloudFrontにWAFを紐付け，ALBの前でIPアドレスを制限するようにする．CloudFrontとは連携しない場合，ALBのSecurity GroupでIPアドレスを制限するようにする． タイプ プロトコル ポート ソース 説明 HTTP TCP 80 0.0.0.0/0 HTTP access from CloudFront HTTPS TCP 443 0.0.0.0/0 HTTPS access from CloudFront アウトバウンドルール ・任意AWSリソースの例 タイプ プロトコル ポート 送信先 説明 すべてのトラフィック すべて すべて 0.0.0.0/0 Full access Zone ・Availability Zoneとは Regionは，さらに，各データセンターは物理的に独立したAvailability Zoneというロケーションから構成されている．例えば，東京Regionには，3つのAvailability Zoneがある．AZの中に，VPCサブネットを作ることができ，そこにEC2を構築できる． 27. SES：Simple Email Service SESとは クラウドメールサーバとして働く．メール受信をトリガーとして，アクションを実行する． 設定項目 ・概要 設定項目 説明 補足 Domain SESのドメイン名を設定する． 設定したドメイン名には，『10 inbound-smtp.us-east-1.amazonaws.com』というMXレコードタイプの値が紐付く． Email Addresses 送信先として認証するメールアドレスを設定する．設定するとAWSからメールが届くので，指定されたリンクをクリックする． Sandboxモードの時だけ機能する． Sending Statistics SESで収集されたデータをメトリクスで確認できる． Request Increased Sending Limitsのリンクにて，Sandboxモードの解除を申請できる． SMTP Settings SMTP-AUTHの接続情報を確認できる． アプリケーションの25番ポートは送信制限があるため，465番を使用する．これに合わせて，SESも受信で465番ポートを使用するようにする． Rule Sets メールの受信したトリガーとして実行するアクションを設定できる． IP Address Filters ・Rule Sets 設定項目 説明 Recipiet 受信したメールアドレスで，何の宛先の時にこれを許可するかを設定する． Actions 受信を許可した後に，これをトリガーとして実行するアクションを設定する． 仕様上の制約 ・構築リージョンの制約 SESは連携するAWSリソースと同じリージョンに構築しなければならない． ・Sandboxモードの解除 SESはデフォルトではSandboxモードになっている．Sandboxモードでは以下の制限がかかっており．サポートセンターに解除申請が必要である． 制限 説明 送信制限 SESで認証したメールアドレスのみに送信できる． 受信制限 1日に200メールのみ受信できる． SMTP-AUTH ・AWSにおけるSMTP-AUTHの仕組み 一般的なSMTP-AUTHでは，クライアントユーザの認証が必要である．同様にして，AWSにおいてもこれが必要であり，IAMユーザを用いてこれを実現する．送信元となるアプリケーションにIAMユーザを紐付け，このIAMユーザにはユーザ名とパスワードを設定する．アプリケーションがSESを介してメールを送信する時，アプリケーションに対して，SESがユーザ名とパスワードを用いた認証を実行する．ユーザ名とパスワードは後から確認できないため，メモしておくこと．SMTP-AUTHの仕組みについては，以下のリンクを参考にせよ． 参考：hhttps://hiroki-it.github.io/tech-notebook-gitbook/public/network/network_osi_tcp_model.html?h=smtp 28. SNS：Simple Notification Service SNSとは パブリッシャーから発信されたメッセージをエンドポイントで受信し，サブスクライバーに転送するAWSリソース． 設定項目 ・概要 設定項目 説明 トピック 複数のサブスクリプションをグループ化したもの． サブスクリプション エンドポイントで受信するメッセージの種類を設定する． ・トピック 設定項目 説明 サブスクリプション サブスクリプションを登録する． アクセスポリシー トピックへのアクセス権限を設定する． 配信再試行ポリシー サブスクリプションのHTTP/Sエンドポイントが失敗した時のリトライ方法を設定する．参考：https://docs.aws.amazon.com/ja_jp/sns/latest/dg/sns-message-delivery-retries.html 配信ステータスのログ記録 サブスクリプションへの発信のログをCloudWatchLogsに転送するように設定する． 暗号化 ・サブスクリプション メッセージの種類 転送先 補足 Kinesis Data Firehose Kinesis Data Firehose SQS SQS Lambda Lambda Eメール 任意のメールアドレス HTTP/S 任意のドメイン名 Chatbotのドメイン名は『https://global.sns-api.chatbot.amazonaws.com』 JSON形式のメール 任意のメールアドレス SMS SMS 受信者の電話番号を設定する． 29. SQS：Simple Queue Service SQSとは クラウドメッセージキューとして働く．パブリッシャーが送信したメッセージは，一旦SQSに追加される．その後，サブスクライバーは，SQSに対してリクエストを送信し，メッセージを取り出す．異なるVPC間でも，メッセージキューを同期できる． 設定項目 ・SQSの種類 設定項目 説明 スタンダード方式 サブスクライバーの取得レスポンスを待たずに，次のキューを非同期的に転送する． FIFO方式 サブスクライバーの取得レスポンスを待ち，キューを同期的に転送する． CLI ・キューURLを取得 キューのURLを取得する． $ aws sqs get-queue-url --queue-name ・キューに受信リクエストを送信 キューに受信リクエストを送信し，メッセージを受信する． $ SQS_QUEUE_URL=$(aws sqs get-queue-url --queue-name ) $ aws sqs receive-message --queue-url ${SQS_QUEUE_URL} キューに受信リクエストを送信し，メッセージを受信する．また，メッセージの内容をファイルに書き出す． $ SQS_QUEUE_URL=$(aws sqs get-queue-url --queue-name ) $ aws sqs receive-message --queue-url ${SQS_QUEUE_URL} > receiveOutput.json { \"Messages\": [ { \"Body\": \"\", \"ReceiptHandle\": \"AQEBUo4y+XVuRSe4jMv0QM6Ob1viUnPbZ64WI01+Kmj6erhv192m80m+wgyob+zBgL4OMT+bps4KR/q5WK+W3tnno6cCFuwKGRM4OQGM9omMkK1F+ZwBC49hbl7UlzqAqcSrHfxyDo5x+xEyrEyL+sFK2MxNV6d0mF+7WxXTboyAu7JxIiKLG6cUlkhWfk3W4/Kghagy5erwRhwTaKtmF+7hw3Y99b55JLFTrZjW+/Jrq9awLCedce0kBQ3d2+7pnlpEcoY42+7T1dRI2s7um+nj5TIUpx2oSd9BWBHCjd8UQjmyye645asrWMAl1VCvHZrHRIG/v3vgq776e1mmi9pGxN96IW1aDZCQ1CSeqTFASe4=\", \"MD5OfBody\": \"6699d5711c044a109a6aff9fc193aada\", \"MessageId\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\" } ] } 30. STS：Security Token Service STSとは AWSリソースに一時的にアクセスできる認証情報（アクセスキー，シークレットアクセスキー，セッショントークン）を発行する．この認証情報は，一時的なアカウント情報として使用できる． STSの設定手順 1. IAMロールに信頼ポリシーをアタッチ 必要なポリシーが設定されたIAMロールを構築する．その時，信頼ポリシーにおいて，ユーザのARNを信頼されたエンティティとして設定しておく．これにより，そのユーザに対して，ロールをアタッチできるようになる． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam:::user/\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"StringEquals\": { \"sts:ExternalId\": \"\" } } } ] } 2. ロールを引き受けたアカウント情報をリクエスト 信頼されたエンティティ（ユーザ）から，STS（https://sts.amazonaws.com）に対して，ロールのアタッチをリクエストする． #!/bin/bash set -xeuo pipefail set -u # 事前に環境変数にインフラ環境名を代入する． case $ENV in \"test\") aws_account_id=\"\" aws_access_key_id=\"\" aws_secret_access_key=\"\" aws_iam_role_external_id=\"\" ;; \"stg\") aws_account_id=\"\" aws_access_key_id=\"\" aws_secret_access_key=\"\" aws_iam_role_external_id=\"\" ;; \"prd\") aws_account_id=\"\" aws_access_key_id=\"\" aws_secret_access_key=\"\" aws_iam_role_external_id=\"\" ;; *) echo \"The parameter ${ENV} is invalid.\" exit 1 ;; esac # 信頼されたエンティティのアカウント情報を設定する． aws configure set aws_access_key_id \"$aws_account_id\" aws configure set aws_secret_access_key \"$aws_secret_access_key\" aws configure set aws_default_region \"ap-northeast-1\" # https://sts.amazonaws.com に，ロールのアタッチをリクエストする． aws_sts_credentials=\"$(aws sts assume-role \\ --role-arn \"arn:aws:iam::${aws_access_key_id}:role/${ENV}-\" \\ --role-session-name \"\" \\ --external-id \"$aws_iam_role_external_id\" \\ --duration-seconds \"\" \\ --query \"Credentials\" \\ --output \"json\")\" STSへのリクエストの結果，ロールがアタッチされた新しいIAMユーザ情報を取得できる．この情報には有効秒数が存在し，期限が過ぎると新しいIAMユーザになる．秒数の最大値は，該当するIAMロールの概要の最大セッション時間から変更できる． レスポンスされるデータは以下の通り． { \"AssumeRoleUser\": { \"AssumedRoleId\": \":\", \"Arn\": \"arn:aws:sts::assumed-role//\" }, \"Credentials\": { \"SecretAccessKey\": \"\", \"SessionToken\": \"\", \"Expiration\": \"\", \"AccessKeyId\": \"\" } } 3-1. アカウント情報を取得（１） jqを使用して，レスポンスされたJSONデータからアカウント情報を抽出する．環境変数として出力し，使用できるようにする．あるいは，AWSのcredentialsファイルを作成してもよい． 参考：https://stedolan.github.io/jq/ #!/bin/bash cat assumed_user.sh export AWS_ACCESS_KEY_ID=\"$(echo \"$aws_sts_credentials\" | jq -r \".AccessKeyId\")\" export AWS_SECRET_ACCESS_KEY=\"$(echo \"$aws_sts_credentials\" | jq -r \".SecretAccessKey\")\" export AWS_SESSION_TOKEN=\"$(echo \"$aws_sts_credentials\" | jq -r \".SessionToken\")\" export AWS_ACCOUNT_ID=\"$aws_account_id\" export AWS_DEFAULT_REGION=\"ap-northeast-1\" EOF 3-2. アカウント情報を取得（２） jqを使用して，レスポンスされたJSONデータからアカウント情報を抽出する．ロールを引き受けた新しいアカウントの情報を，credentialsファイルに書き込む． #!/bin/bash aws configure --profile ${ENV}-repository > ~/.aws/credentials 4. 接続確認 ロールを引き受けた新しいアカウントを使用して，AWSリソースに接続できるかを確認する．アカウント情報の取得方法としてcredentialsファイルの作成を選んだ場合，profileオプションが必要である． #!/bin/bash # 3-2を選んだ場合，credentialsファイルを参照するオプションが必要がある． aws s3 ls --profile 2020-xx-xx xx:xx:xx 31. Step Functions Step Functionsとは AWSサービスを組み合わせて，イベント駆動型アプリケーションを構築できる． AWSリソースのAPIコール ・APIコールできるリソース 参考：https://docs.aws.amazon.com/step-functions/latest/dg/connect-supported-services.html ・Lambda ＊実装例＊ { \"StartAt\": \"Call Lambda\", \"States\": { \"Call Lambda\": { \"Type\": \"Task\", \"Resource\": \"arn:aws:states:::lambda:invoke.waitForTaskToken\", \"Parameters\": { \"FunctionName\": \"arn:aws:lambda:ap-northeast-1:xxxxx:foo-function:1\" }, \"Retry\": [ { \"ErrorEquals\": [ \"\" ], \"MaxAttempts\": 0 } ], \"End\": true, \"Comment\": \"The state that call Lambda\" } } } 32. VPC：Virtual Private Cloud VPCとは クラウドプライベートネットワークとして働く．プライベートIPアドレスが割り当てられた，VPCと呼ばれるプライベートネットワークを仮想的に構築できる．異なるAvailability Zoneに渡ってEC2を立ち上げることによって，クラウドサーバをデュアル化することできる．VPCのパケット通信の仕組みについては，以下のリンクを参考にせよ． 参考：https://pages.awscloud.com/rs/112-TZM-766/images/AWS-08_AWS_Summit_Online_2020_NET01.pdf Internet Gateway，NAT Gateway ・Internet Gatewayとは VPCの出入り口に設置され，グローバルネットワークとプライベートネットワーク間（ここではVPC）におけるNAT（静的NAT）の機能を持つ．一つのパブリックIPに対して，一つのEC2のプライベートIPを紐付けられる．NAT（静的NAT）については，以下のリンクを参考にせよ． 参考：hhttps://hiroki-it.github.io/tech-notebook-gitbook/public/network/network_osi_tcp_model.html ・NAT Gatewayとは NAPT（動的NAT）の機能を持つ．一つのパブリックIPに対して，複数のEC2のプライベートIPを紐付けられる．パブリックサブネットに置き，プライベートサブネットのEC2からのレスポンスを受け付ける．NAPT（動的NAT）については，以下のリンクを参考にせよ． 参考：hhttps://hiroki-it.github.io/tech-notebook-gitbook/public/network/network_osi_tcp_model.html ・比較表 Internet Gateway NAT Gateway 機能 グローバルネットワークとプライベートネットワーク間（ここではVPC）におけるNAT（静的NAT） NAPT（動的NAT） 設置場所 VPC上 パブリックサブネット内 Route Table（= マッピングテーブル） ・ルートテーブルとは クラウドルータのマッピングテーブルとして働く．ルータについては，別ノートのNATとNAPTを参考にせよ． Destination（プライベートIPの範囲） Target xx.x.x.x/xx Destinationの範囲内だった場合の送信先 ・ルートテーブルの種類 種類 説明 メインルートテーブル VPCの構築時に自動で構築される．どのルートテーブルにも紐付けられていないサブネットのルーティングを設定する． カスタムルートテーブル 特定のサブネットのルーティングを設定する． ・例1 上の図中で，サブネット2にはルートテーブル1が紐付けられている．サブネット2内のEC2の送信先のプライベートIPアドレスが，10.0.0.0/16の範囲内にあれば，インバウンド通信と見なし，local（VPC内の他サブネット）を送信先に選び，範囲外にあれば通信を破棄する． Destination（プライベートIPアドレス範囲） Target 10.0.0.0/16 local 指定範囲以外の場合 通信破棄 ・例2 上の図中で，サブネット3にはルートテーブル2が紐付けられている．サブネット3内のEC2の送信先のプライベートIPアドレスが，10.0.0.0/16の範囲内にあれば，インバウンド通信と見なし，local（VPC内の他サブネット）を送信先に選び，0.0.0.0/0（local以外の全IPアドレス）の範囲内にあれば，アウトバウンド通信と見なし，インターネットゲートウェイを送信先に選ぶ． Destination（プライベートIPアドレス範囲） Target 10.0.0.0/16 local 0.0.0.0/0 Internet Gateway Network ACL：Network Access Control List ・Network ACLとは サブネットのクラウドパケットフィルタリング型ファイアウォールとして働く．ルートテーブルとサブネットの間に設置され，双方向のインバウンドルールとアウトバウンドルールを決定する． ・ACLルール ルールは上から順に適用される．例えば，インバウンドルールが以下だった場合，ルール100が最初に適用され，サブネットに対する，全IPアドレス（0.0.0.0/0）からのインバウンド通信を許可していることになる． ルール # タイプ プロトコル ポート範囲 / ICMP タイプ ソース 許可 / 拒否 100 すべての トラフィック すべて すべて 0.0.0.0/0 ALLOW * すべての トラフィック すべて すべて 0.0.0.0/0 DENY VPCサブネット クラウドプライベートネットワークにおけるセグメントとして働く． ・パブリックサブネットとは 非武装地帯に相当する．攻撃の影響が内部ネットワークに広がる可能性を防ぐために，外部から直接リクエストを受ける， ・プライベートサブネットとは 内部ネットワークに相当する．外部から直接リクエストを受けずにレスポンスを返せるように，内のNATを経由させる必要がある． ・サブネットの種類 サブネットには，役割ごとにいくつか種類がある． 名前 役割 Public subnet (Frontend Subnet) NATGatewayを配置する． Private app subnet アプリケーション，Nginxなどを配置する． Private datastore subnet RDS，Redisなどを配置する VPCエンドポイント ・概要 VPCのプライベートサブネット内のリソースが，VPC外のリソースに対して，アウトバウンド通信を実行できるようにする．Gateway型とInterface型がある．VPCエンドポイントを使用しない場合，プライベートサブネット内からのアウトバウンド通信には，インターネットゲートウェイとNAT Gatewayを使用する必要がある． ＊（例）＊ ECS Fargateをプライベートサブネットに置いた場合に，ECS FargateからVPC外にあるAWSリソースに対するアウトバウンドな通信のために必要．（例：CloudWatchログ，ECR，S3，SSM） ・メリット インターネットゲートウェイとNAT Gatewayの代わりに，VPCエンドポイントを使用すると，料金が少しだけ安くなり，また，VPC外のリソースとの通信がより安全になる． ・タイプ タイプ 説明 リソース例 Interface型 プライベートリンクともいう．プライベートIPアドレスを持つENIとして機能し，AWSリソースからアウトバウンドな通信を受信する． S3，DynamoDB以外の全てのリソース Gateway型 ルートテーブルにおける定義に従う．VPCエンドポイントとして機能し，AWSリソースからアウトバウンドな通信を受信する． S3，DynamoDBのみ ENI：Elastic Network Interface ・ENIとは クラウドネットワークインターフェースとして働く．物理ネットワークにおけるNICについては以下を参考にせよ． 参考：hhttps://hiroki-it.github.io/tech-notebook-gitbook/public/network/network_osi_tcp_model.html ・紐付けられるリソース リソースの種類 役割 補足 ALB ENIに紐付けられたパブリックIPアドレスをALBに割り当てられる． EC2 ENIに紐付けられたパブリックIPアドレスがEC2に割り当てられる． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/using-eni.html#eni-basics Fargate環境のEC2 明言されていないため推測ではあるが，ENIに紐付けられたlocalインターフェースがFargate環境でコンテナのホストとなるEC2インスタンスに割り当てられる． Fargate環境のホストがEC2とは明言されていない．参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-fargate-data-plane/ Elastic IP ENIにElastic IPアドレスが紐付けられる．このENIを他のAWSリソースに紐付けることにより，ENIを介して，Elastic IPを紐付けられる． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/using-eni.html#managing-network-interface-ip-addresses GlobalAccelerator NAT Gateway ENIに紐付けられたパブリックIPアドレスがNAT Gatewayに割り当てられる． RDS Security Group ENIにセキュリティグループが紐付けれる．このENIを他のAWSリソースに紐付けることにより，ENIを介して，セキュリティグループを紐付けられる． VPCエンドポイント Interface型のVPCエンドポイントとして機能する． IPアドレス ・種類 IPアドレスの種類 説明 自動割り当てパブリックIPアドレス（動的IPアドレス） 動的なIPアドレスで，EC2の再構築後に変化する． Elastic IP（静的IPアドレス） 静的なIPアドレスで，再構築後も保持される． ・紐付け 種類 補足 インスタンスとの紐付け 非推奨の方法である．参考：https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/vpc-eips.html#vpc-eip-overview ENIとの紐付け 推奨される方法である．参考：https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/vpc-eips.html#vpc-eip-overview VPCのCIDR設計の手順 一つのVPC内には複数のサブネットが入る．そのため，サブネットのIPアドレス範囲は，サブネットの個数だけ含めなければならない．また，VPCがもつIPアドレス範囲から，VPC内の各AWSリソースにIPアドレスを割り当てていかなければならない．VPC内でIPアドレスが枯渇しないように，以下の手順で，割り当てを考える． 参考：https://note.com/takashi_sakurada/n/n502fb0299938 （１）RFC1918の推奨する10.0.0.0/8，172.16.0.0/12，192.168.0.0/16を使用する．VPCのCIDR設計では，これらの範囲に含まれるIPアドレスを使用するようにする． RFC1918推奨のIPアドレス範囲 IPアドレス 個数 10.0.0.0/8 10.0.0.0 ~ 10.255.255.255 16777216 172.16.0.0/12 172.16.0.0 ~ 172.31.255.255 1048576 192.168.0.0/16 192.168.0.0 ~ 192.168.255.255 65536 （２）あらかじめ，会社内の全てのアプリケーションのCIDRをスプレッドシートなどで一括で管理しておく． （３）各アプリケーション間でTransit Gatewayやピアリング接続を実行する可能性がある場合は．拡張性を考慮して，アプリケーション間のCIDRは重ならないようにしておく必要がある．例えば，以前に開発したアプリケーションが10.200.47.0までを使用していた場合，10.200.48.0から使用を始める．また，VPCで許可されるIPアドレスの個数は最多65536個（/16）で最少16個（/28）であり，実際は512個（/23）ほどあれば問題ないため，10.200.48.0/23を設定する． 参考：https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/VPC_Subnets.html#SubnetRouting （４）VPCのIPアドレスをパブリックサブネットとプライベートサブネットを割り当てる．パブリックサブネットとプライベートサブネットを冗長化する場合は，VPCのIPアドレス数をサブネット数で割って各サブネットのIPアドレス数を算出し，CIDRブロックを設定する．例えば，VPCのサブネットマスクを/16 としている場合は，各サブネットのサブネットマスクは/24とする．一方で，VPCを/23としている場合は，各サブネットは/27とする．また，各サブネットのCIDRブロックを同じにする必要はなく，アプリケーションが稼働するサブネットにIPアドレス数がやや多くなるようにし，その分DBの稼働するサブネットのIPアドレスを少なくするような設計でもよい． 参考：https://d0.awsstatic.com/events/jp/2017/summit/slide/D2T3-5.pdf （５）VPC内の各AWSリソースの特徴に合わせて，IPアドレス範囲を割り当てる． 参考：https://dev.classmethod.jp/articles/amazon-vpc-5-tips/ AWSサービスの種類 最低限のIPアドレス数 ALB ALB1つ当たり，8個 オートスケーリング 水平スケーリング時のEC2最大数と同じ個数 VPCエンドポイント VPCエンドポイント1つ当たり，1個 ECS，EKS Elastic Network Interface 数と同じ個数 Lambda Elastic Network Interface 数と同じ個数 32-02. VPC間，VPC-オンプレ間の通信 VPCピアリング接続 ・VPCピアリング接続とは 『一対一』の関係で，『異なるVPC間』の双方向通信を可能にする． ・VPCピアリング接続の可否 アカウント VPCのあるリージョン VPC内のCIDRブロック 接続の可否 同じ／異なる 同じ／異なる 全て異なる 〇 同じものが一つでもある ✕ VPC に複数の IPv4 CIDR ブロックがあり，一つでも 同じCIDR ブロックがある場合は，VPC ピアリング接続はできない． たとえ，IPv6が異なっていても，同様である． VPCエンドポイントサービス ・VPCエンドポイントサービスとは VPCエンドポイントとは異なる機能なので注意．Interface型のVPCエンドポイント（プライベートリンク）をNLBに紐付けることにより，『一対多』の関係で，『異なるVPC間』の双方向通信を可能にする．エンドポイントのサービス名は，『com.amazonaws.vpce.ap-northeast-1.vpce-svc-xxxxx』になる．API GatewayのVPCリンクは，VPCエンドポイントサービスに相当する． Transit Gateway ・Transit Gatewayとは 『多対多』の関係で，『異なるVPC間』や『オンプレ-VPC間』の双方向通信を可能にする．クラウドルーターとして働く． 各サービスとの比較 機能 VPCピアリング接続 VPCエンドポイントサービス Transit gateway 通信可能なVPC数 一対一 一対一，一対多 一対一，一対多，多対多 通信可能なIPアドレスの種類 IPv4，IPv6 IPv4 IPv4，IPv6 接続可能なリソース 制限なし NLBでルーティングできるリソースのみ 制限なし CIDRブロックがVPC間で被ることによる通信の可否 × ◯ × クロスアカウント ◯ ◯ ◯ クロスリージョン ◯ × ◯ VPC間 ◯ ◯ ◯ VPC-オンプレ間 × × ◯ 33. WAF：Web Applicarion Firewall 設定項目 定義できるルール数や文字数に制限がある．以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/limits.html 設定項目 説明 補足 Web ACLs：Web Access Control List 各トリガーと許可／拒否アクションの紐付けを『ルール』とし，これをセットで設定する． アタッチするAWSリソースに合わせて，リージョンが異なる． IP sets アクション実行のトリガーとなるIPアドレス ・許可するIPアドレスは，意味合いに沿って異なるセットとして構築するべき．例えば，社内IPアドレスセット，協力会社IPアドレスセット，など・拒否するIPアドレスはひとまとめにしてもよい． Regex pattern sets アクション実行のトリガーとなるURLパスの文字列 ・許可／拒否する文字列は，意味合いに沿って異なる文字列セットとして構築するべき．例えば，ユーザエージェントセット，リクエストパスセット，など Rule groups AWS Markets AWSリソース vs. サイバー攻撃 サイバー攻撃の種類 対抗するAWSリソースの種類 マルウェア なし 傍受，盗聴 VPC内の特にプライベートサブネット間のピアリング接続．VPC外を介さずにデータを送受信できる． ポートスキャン セキュリティグループ DDoS Shield ゼロディ WAF インジェクション WAF XSS WAF データ漏洩 KMS，CloudHSM 組織内部での裏切り IAM 設定項目 ・概要 設定項目 説明 補足 Web ACLs アクセス許可と拒否のルールを定義する． Bot Control Botに関するアクセス許可と拒否のルールを定義する． IP Sets IPアドレスの共通部品を管理する． アクセスを許可したいIPアドレスセットを作成する時，全てのIPアドレスを一つのセットで管理してしまうと，何のIPアドレスかわらなあくなってしまう．そこで，許可するIPアドレスのセットを種類（自社，外部のA社／B社，など）で分割するとよい． Regex pattern sets 正規表現パターンの共通部品を管理する． Rule groups ルールの共通部品を管理する． 各WAFに同じルールを設定する場合，ルールグループを使用するべきである．ただ，ルールグループを使用すると，これらのルールを共通のメトリクスで監視しなければならなくなる．そのため，もしメトリクスを分けるのであれば，ルールグループを使用しないようにする． ・Web ACLs 設定項目 説明 補足 Overview WAFによって許可／拒否されたリクエストのアクセスログを確認できる． Rules 順番にルールを判定し，一致するルールがあればアクションを実行する．この時，一致するルールの後にあるルールは．判定されない． AWSマネージドルールについては，以下のリンクを参考にせよ．参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/aws-managed-rule-groups-list.html Associated AWS resources WAFをアタッチするAWSリソースを設定する． CloudFront，ALBなどにアタッチできる． Logging and metrics アクセスログをKinesis Data Firehoseに出力するように設定する． ・OverviewにおけるSampled requestsの見方 『全てのルール』または『個別のルール』におけるアクセス許可／拒否の履歴を確認できる．ALBやCloudFrontのアクセスログよりも解りやすく，様々なデバッグに役立つ．ただし，３時間分しか残らない．一例として，CloudFrontにアタッチしたWAFで取得できるログを以下に示す． GET /foo/ # ホスト Host: example.jp Upgrade-Insecure-Requests: 1 # ユーザエージェント User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Sec-Fetch-Mode: navigate Sec-Fetch-User: ?1 Sec-Fetch-Dest: document # CORSであるか否か Sec-Fetch-Site: same-origin Accept-Encoding: gzip, deflate, br Accept-Language: ja,en;q=0.9 # Cookieヘッダー Cookie: sessionid=; _gid=; __ulfpc=; _ga= ルール ・ルールの種類 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/classic-web-acl-rules-creating.html 種類 説明 レートベース 同じ送信元IPアドレスからの５分間当たりのリクエスト数制限をルールに付与する． レギュラー リクエスト数は制限しない． ・ルールの粒度のコツ わかりやすさの観点から，可能な限り設定するステートメントを少なくし，一つのルールに一つの意味合いだけを持たせるように命名する． ・Count（検知）モード ルールに該当するリクエスト数を数え，許可／拒否せずに次のルールを検証する．計測結果に応じて，Countモードを無効化し，拒否できるようにする． 参考：https://oji-cloud.net/2020/09/18/post-5501/ ・ルールグループアクションの上書き ルールのCountモードが有効になっている場合に，Countアクションに続けて，そのルールの元々のアクションを実行する．そのため，Countアクションしつつ，Blockアクションを実行できる（仕様がややこしすぎるので，なんとかしてほしい）． 参考：https://docs.aws.amazon.com/ja_jp/waf/latest/developerguide/web-acl-rule-group-override-options.html マネージドルールの元々のアクション Countモード 上書きオプション 結果 Block ON ON Countし，その後Blockが実行する．そのため，その後のルールは検証せずに終了する． Block ON OFF Countのみが実行される．そのため，その後のルールも検証する． Block OFF ON そもそもCountモードが無効なため，上書きオプションは機能せずに，Blockが実行される． Block OFF OFF そもそもCountモードが無効なため，マネージドルールのBlockが実行される．（と思っていたが，結果としてCountとして機能する模様...） マネージドルールを使用するかどうかの判断基準 ・マネージドルールの動作確認の必要性 マネージドルールを導入する時は，事前にルールのカウント機能を使用することが推奨されている．カウントで検知されたリクエストのほとんどが悪意のないものであれば，設定したマネージドルールの使用をやめる必要がある． ・ブラウザを送信元とした場合 ブラウザを送信元とした場合，リクエストのヘッダーやボディはブラウザによって生成されるため，これに基づいた判断が必要である． ブラウザからのリクエスト自体が悪意判定されているかどうか サイトのURLの記法によって，悪意判定されているかどうか 送信元の国名が『日本』であるのにもかかわらず，悪意判定されているかどうか サイトに送信された全リクエストのうち，カウントで検知されたリクエストの数が多すぎないかどうか ・連携するアプリケーションを送信元とした場合 アプリケーションを送信元とした場合，リクエストのヘッダーやボディは連携するアプリケーションによって生成されるため，これに基づいた判断が必要である． ルールの例 ・ユーザエージェント拒否 ＊例＊ 悪意のあるユーザエージェントを拒否する． ルール：block-user-agents Statementの順番 If a request Inspect Match type Regex pattern set Then 挙動 0 matches URI path Matches pattern from regex pattern set 文字列セット Block 指定した文字列を含むユーザエージェントの場合，アクセスすることを拒否する． Default Action 説明 Allow 指定したユーザエージェントでない場合，全てのファイルパスにアクセスすることを許可する． ・CI/CDツールのアクセスを許可 ＊例＊ 社内の送信元IPアドレスのみ許可した状態で，CircleCIなどのサービスが社内サービスにアクセスできるようにする． ルール：allow-request-including-access-token Statementの順番 If a request Inspect Header field name Match type String to match Then 挙動 0 matches Header authorization Exactly matched string 『Bearer 』で文字列を設定する Allow authorizationヘッダーに指定した文字列を含むリクエストの場合，アクセスすることを拒否する． Default Action 説明 Block 正しいトークンを持たないアクセスの場合，全てのファイルパスにアクセスすることを拒否する． ・特定のパスを社内アクセスに限定 ＊例＊ アプリケーションにおいて，特定のURLパスにアクセスできる送信元IPアドレスを，社内だけに制限する．二つのルールを構築する必要がある． ルール：allow-access--to-url-path Statementの順番 If a request Inspect IP set Match type Regex pattern set Then 挙動 0 matches (AND) Originates from an IP address in 社内IPセット - - - 社内の送信元IPアドレスの場合，指定したファイルパスにアクセスすることを許可する． 1 matches URI path - Matches pattern from regex pattern set 文字列セット Allow 0番目かつ，指定した文字列を含むURLパスアクセスの場合，アクセスすることを許可する． ルール：block-access-to-url-path Statementの順番 If a request Inspect Match type Regex pattern set Then 挙動 0 matches URI path Matches pattern from regex pattern set 文字列セット Block 指定した文字列を含むURLパスアクセスの場合，アクセスすることを拒否する． Default Action 説明 Allow 指定したURLパス以外のアクセスの場合，そのパスにアクセスすることを許可する． ・社内アクセスに限定 ＊例＊ アプリケーション全体にアクセスできる送信元IPアドレスを，特定のIPアドレスだけに制限する． ルール：allow-global-ip-addresses Statementの順番 If a request Inspect IP set Originating address Then 挙動 0 matches (OR) Originates from an IP address in 社内IPセット Source IP address - 社内の送信元IPアドレスの場合，全てのファイルパスにアクセスすることを許可する． 1 matches Originates from an IP address in 協力会社IPセット Source IP address Allow 0番目あるいは，協力会社の送信元IPアドレスの場合，全てのファイルパスにアクセスすることを許可する． Default Action 説明 Block 指定した送信元IPアドレス以外の場合，全てのファイルパスにアクセスすることを拒否する． 34. WorkMail WorkMailとは Gmail，サンダーバード，Yahooメールなどと同類のメール管理アプリケーション． 設定項目 設定項目 説明 補足 Users WorkMailで管理するユーザを設定する． Domains ユーザに割り当てるメールアドレスのドメイン名を設定する． @{組織名}.awsapps.comをドメイン名としてもらえる．ドメイン名の検証が完了した独自ドメイン名を設定することもできる． Access Controle rules 受信するメール，受信を遮断するメール，の条件を設定する． 35. 負荷テスト Distributed Load Testing（分散負荷テスト） ・分散負荷テストとは AWSから提供されている負荷を発生させるインフラ環境のこと．CloudFormationで構築でき，Fargateを使用して，ユーザからのリクエストを擬似的に再現できる． 参考：https://d1.awsstatic.com/Solutions/ja_JP/distributed-load-testing-on-aws.pdf ・インフラ構成 36. タグ タグ付け戦略 ・よくあるタグ タグ名 用途 Name リソース自体に名前を付けられない場合，代わりにタグで名付けるため． Environment 同一のAWS環境内に異なる実行環境が存在している場合，それらを区別するため． User 同一のAWS環境内にリソース別に所有者が存在している場合，それらを区別するため． ・タグ付けによるフィルタリング AWSの各リソースには，タグをつけることができる．例えば，AWSコストエクスプローラーにて，このタグでフィルタリングすることにより，任意のタグが付いたリソースの請求合計額を確認できる． "},"public/cloud_computing/cloud_computing_aws_api_gateway_import.html":{"url":"public/cloud_computing/cloud_computing_aws_api_gateway_import.html","title":"📖 ︎API Gatewayへのymlインポート","keywords":"","body":"API Gatewayへのymlインポート はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. APIGateway拡張機能 ・必要なキー APIGatewayのインポートに当たり，OpenAPIのYAMLファイルにキーを新たに実装する必要がある． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions.html x-amazon-apigateway-integrationキー ・x-amazon-apigateway-integrationキーとは 該当するHTTPメソッドで統合リクエストや統合レスポンスを定義するために x-amazon-apigateway-integrationキー が必要である．各項目の説明は以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions-integration.html 各種パラメータのマッピングも可能である．メソッドリクエストから統合リクエストへのマッピングについては，以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions-integration-requestParameters.html 統合レスポンスからメソッドレスポンスへのマッピングについては，以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-swagger-extensions-integration-responseParameters.html ・設定項目（VPCリンク&プロキシ統合） paths: /users: get: # ～ 中略 ～ #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: \"GET\" # 転送するHTTPメソッド uri: \"http:///api/v1/users/\" # 転送先のバックエンドURL requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" # 転送するカスタムヘッダーとAPIキー integration.request.querystring.userId: method.request.querystring.userId # マッピングするクエリパラメータ # パスパラメータ間のマッピングであれば，integration.request.path.userId: method.request.path.userId # 他パラメータからボディへのマッピングであれば，integration.request.header.userId: method.request.body.userId connectionType: VPC_LINK # VPCリンクを使用 connectionId: # VPCリンクのID passthroughBehavior: when_no_match # プロキシ統合の場合は設定の変更不可で固定 type: http_proxy # プロキシ統合を使用 responses: # プロキシ統合の場合は設定の変更不可で固定 default: statusCode: 200 ・設定項目（VPCリンク&非プロキシ統合の場合） パススルー条件やresponseキー以下の統合レスポンスを設定できる． paths: /users: post: x-amazon-apigateway-integration: httpMethod: POST uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" requestTemplates: application/json: '{\"body\" : $input.json(\"$\")}' passthroughBehavior: when_no_templates # 統合リクエストのマッピングテンプレートのパススルー条件を選択 connectionType: VPC_LINK connectionId: type: http # 非プロキシ統合 responses: # 統合レスポンスを設定 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' # レスポンス統合のマッピングテンプレート 400: statusCode: 400 401: statusCode: 401 ・設定項目（モック統合） パススルー条件を設定できる．モックに処理を定義する必要がある paths: /users: post: x-amazon-apigateway-integration: type: mock # モック統合を使用 requestTemplates: application/json: '{\"statusCode\": 200}' # リクエストの処理 passthroughBehavior: when_no_templates # 統合リクエストのマッピングテンプレートのパススルー条件を選択 responses: 200: statusCode: 200 responseTemplates: application/json: '{\"id\": 1}' # レスポンスの処理 400: statusCode: 400 401: statusCode: 401 x-amazon-apigateway-request-validatorsキー ・x-amazon-apigateway-request-validatorsキーとは メソッドリクエストで各種パラメータのバリデーションを定義するために，x-amazon-apigateway-request-validatorsキーが必要である．実際に定義したものを使用する時は，後述のx-amazon-apigateway-request-validatorキーが必要である． ・設定項目 各種パラメータのいずれをバリデーションの対象とするかを指定したうえで，エイリアス名を定義する．ルートで定義する． paths: /users: # ～ 中略 ～ #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false x-amazon-apigateway-request-validatorキー ・x-amazon-apigateway-request-validatorキーとは メソッドリクエストで各種パラメータのバリデーションを実行するために，x-amazon-apigateway-request-validatorキーが必要である． ・設定項目 事前に定義したx-amazon-apigateway-request-validatorsキーの中から，使用するバリデーションのエイリアス名を宣言する． paths: /users: post: # ～ 中略 ～ #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 # エイリアス名を宣言 # ～ 中略 ～ #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false 02. サンプルYAML サンプルについて ・注意点 インポートにあたり，以下に注意する．Swagger EditorでAPIの仕様書のHTMLファイルを確認できる． 参考：https://editor.swagger.io/ OpenAPI仕様のバージョン2.0と3.0に対応している． x-amazon-apigateway-integrationキーを各HTTPメソッドに定義する． API Gatewayがsecurityキーのルート定義に非対応のため，冗長ではあるが，各HTTPメソッドに個別に定義する． リクエストメソッドで受信するAPIキーのヘッダー名は，小文字で「x-api-key」以外は設定できない．ただし，統合リクエストで転送する時に付与するヘッダー名は「X-API-Key」と設定できる． 統合リクエストでバックエンドに転送するAPIキーは，シングルクオートで囲う必要がある． APIキーの作成は手動で行う必要がある． ステージの作成は手動で行う必要がある． serversキーの実装はインポートしても反映できない． マッピングテンプレートはVTLによる定義が可能である． ・その他非対応な記法 その他の非対応の記述については，以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-known-issues.html#api-gateway-known-issues-rest-apis VPCリンク＆プロキシ統合 実装例 openapi: 3.0.0 info: title: example-api-with-proxy-integration # API名 description: The API for example with proxy integration # APIの説明 termsOfService: https://www.example.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.example.com/support # 連絡先に関するURL email: support@example.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン servers: - url: https://{env}.example.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: query # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.querystring.userId: method.request.querystring.userId # マッピングするクエリパラメータ connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # path itemオブジェクト #=========================== post: tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: [ ] requestBody: # リクエストボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type example: # リクエストボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # 正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: POST uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: PUT uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId connectionType: VPC_LINK connectionId: type: http_proxy passthroughBehavior: when_no_match responses: default: statusCode: 200 #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type example: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"認証に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # カスタムヘッダー名 in: header VPCリンク＆非プロキシ統合 実装例 openapi: 3.0.0 info: title: example-api-with-non-proxy-integration # API名 description: The API for example with non-proxy integration. # APIの説明 termsOfService: https://www.example.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.example.com/support # 連絡先に関するURL email: support@example.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン servers: - url: https://{env}.example.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: query # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.querystring.userId: method.request.querystring.userId # マッピングするクエリパラメータ passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 #=========================== # path itemオブジェクト #=========================== post: tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: [ ] requestBody: # リクエストボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type example: # リクエストボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # 正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: POST uri: \"http:///api/v1/users/\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" requestTemplates: application/json: '{\"body\" : $input.json(\"$\")}' passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 # type: http #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: GET uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 404: statusCode: 404 #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: httpMethod: PUT uri: \"http:///api/v1/users/{userId}\" requestParameters: integration.request.header.X-API-Key: \"'XXXXX'\" integration.request.path.userId: method.request.path.userId passthroughBehavior: when_no_templates connectionType: VPC_LINK connectionId: type: http responses: 200: statusCode: 200 responseTemplates: application/json: '{\"body\" : $input.json(\"$\")}' 400: statusCode: 400 401: statusCode: 401 #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type example: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"認証に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # カスタムヘッダー名 in: header モック統合 API Gatewayのエンドポイントに対して，以下のパラメータでリクエストを送信すると，レスポンスを確認できる． GET https://xxxxx.execute-api.ap-northeast-1.amazonaws.com/dev/users/?userId=1 X-API-Key：XXXXX 実装例 openapi: 3.0.0 info: title: example-api-with-mock-integration # API名 description: The API for example with mock integration # APIの説明 termsOfService: https://www.example.com/terms/ # 利用規約 contact: name: API support # 連絡先名 url: https://www.example.com/support # 連絡先に関するURL email: support@example.com # メールアドレス license: name: Apache 2.0 # ライセンス url: https://www.apache.org/licenses/LICENSE-2.0.html # URL version: 1.0.0 # APIドキュメントのバージョン servers: - url: https://{env}.example.com/api/v1 description: | variables: env: default: stg description: API environment enum: - stg - www paths: #=========================== # pathsオブジェクト #=========================== /users: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: ユーザ情報取得 description: 全ユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: query # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 Users: User: userId: 1 name: Hiroki schema: $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"不正なリクエストです．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{[{\"id\": 1,\"name\": test}]}' 400: statusCode: 400 401: statusCode: 401 #=========================== # path itemオブジェクト #=========================== post: tags: - ユーザ情報作成エンドポイント summary: ユーザ情報作成 description: ユーザ情報を作成する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: [ ] requestBody: # リクエストボディにパラメータを割り当てる． description: ユーザID content: application/json: # MIME type example: # リクエストボディ例 userId: 1 schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # レスポンスボディ例 userId: 1 schema: $ref: \"#/components/schemas/normal\" # 正常系モデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # レスポンスボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{\"id\": 1}' 400: statusCode: 400 401: statusCode: 401 # type: mock #=========================== # pathsオブジェクト #=========================== /users/{userId}: #=========================== # path itemオブジェクト #=========================== get: tags: - ユーザ情報取得エンドポイント summary: 指定ユーザ情報取得 description: 指定したユーザ情報を取得する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: クエリ文字列パラメータおよびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{[{\"id\": 1,\"name\": test}]}' 400: statusCode: 400 401: statusCode: 401 404: statusCode: 404 #=========================== # path itemオブジェクト #=========================== put: tags: - ユーザ情報更新エンドポイント summary: 指定ユーザ更新 description: 指定したユーザ情報を更新する． #=========================== # メソッドリクエスト #=========================== x-amazon-apigateway-request-validator: 本文、クエリ文字列パラメータ、およびヘッダーの検証 security: - apiKeyAuth: [ ] # APIキーの必須化 parameters: - in: path # パスにパラメータを割り当てる． name: userId required: true description: ユーザID schema: type: string example: # パスパラメータ例 userId=1 #=========================== # メソッドレスポンス #=========================== responses: '200': description: OK レスポンス content: application/json: # MIME type example: # ボディ例 userId: 1 name: Hiroki schema: # スキーマ $ref: \"#/components/schemas/user\" # Userモデルを参照する． '400': description: Bad Request レスポンス content: application/json: # MIME type example: # ボディ例 status: 400 title: Bad Request errors: messages: [ \"ユーザIDは必ず指定してください．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． '401': $ref: \"#/components/responses/unauthorized\" # 認証エラーを参照する． '404': description: Not Found レスポンス content: application/json: # MIME type example: # ボディ例 status: 404 title: Not Found errors: messages: [ \"対象のユーザが見つかりませんでした．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # 統合 #=========================== x-amazon-apigateway-integration: requestTemplates: application/json: '{\"statusCode\": 200}' passthroughBehavior: when_no_templates type: mock responses: 200: statusCode: 200 responseTemplates: application/json: '{\"id\": 1}' 400: statusCode: 400 401: statusCode: 401 #=========================== # バリデーションセットの定義 #=========================== x-amazon-apigateway-request-validators: 本文、クエリ文字列パラメータ、およびヘッダーの検証: validateRequestParameters: true # クエリパラメータとヘッダー validateRequestBody: true # ボディ クエリ文字列パラメータおよびヘッダーの検証: validateRequestParameters: true validateRequestBody: false components: #=========================== # callbackキーの共通化 #=========================== callbacks: { } #=========================== # linkキーの共通化 #=========================== links: { } #=========================== # responseキーの共通化 #=========================== responses: unauthorized: description: Unauthorized レスポンス content: application/json: # MIME type example: # ボディ例 status: 401 title: Unauthorized errors: messages: [ \"認証に失敗しました．\" ] schema: $ref: \"#/components/schemas/error\" # 異常系モデルを参照する． #=========================== # schemaキーの共通化 #=========================== schemas: # ユーザ user: type: object properties: userId: type: string name: type: string # 正常系 normal: type: object properties: userId: type: string # 異常系 error: type: object properties: messages: type: array items: type: string #=========================== # securityフィールドの共通化 #=========================== securitySchemes: # APIキー認証 apiKeyAuth: description: APIキー認証 type: apiKey name: x-api-key # カスタムヘッダー名 in: header "},"public/cloud_computing/cloud_computing_aws_lambda_function.html":{"url":"public/cloud_computing/cloud_computing_aws_lambda_function.html","title":"📖 ︎Lambda関数の実装","keywords":"","body":"Lambda関数の実装 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ハンドラ関数 ハンドラ関数とは 自身から起動することはなく，外部から要求されて実行される関数のこと． 参考：https://garop.com/36/ Lambdaハンドラ関数 ・非同期ハンドラ関数（Async handlers） Lambdaはハンドラ関数を非同期関数としてコールし，引数のオブジェクト（event）に値をわたす．ハンドラ関数の初期名はhandlerメソッドであるが別名でもよい．returnまたはthrowを使用して，Lambdaのコール元にレスポンスを送信する．レスポンスとして，Promiseオブジェクトを送信することもできる． 参考：https://docs.aws.amazon.com/lambda/latest/dg/nodejs-handler.html#nodejs-handler-async ＊実装例＊ Node.jsの場合を示す． exports.handler = async (event) => { const response = { \"statusCode\": null, \"body\" : null }; response.statusCode = 200; response.body = \"Hello World!\" // もしくはthrowを使用して，レスポンスを送信する． return response; } const aws = require(\"aws-sdk\"); const s3 = new aws.S3(); exports.handler = async function(event) { // Promiseオブジェクトをレスポンスとして送信する． return s3.listBuckets().promise(); } exports.handler = async (event) => { // Promiseオブジェクトをレスポンスとして送信する． return new Promise((resolve, reject) => { // 何らかの処理 } } ・同期ハンドラ関数（Non-async handlers） Lambdaはハンドラ関数を同期関数としてコールし，引数（eventオブジェクト，contextオブジェクト，callback関数）に値をわたす．このオブジェクトにはメソッドとプロパティを持つ．ハンドラ関数の初期名はhandlerであるが別名でもよい．callbackメソッドを使用して，Lambdaのコール元にPromiseオブジェクトのレスポンスを送信する． 参考：https://docs.aws.amazon.com/lambda/latest/dg/nodejs-handler.html#nodejs-handler-sync （※『Non』が翻訳をおかしくしているため，英語版を推奨） ＊実装例＊ Node.jsの場合を示す．レスポンスを返信するには，doneメソッド，succeedメソッド，callbackメソッドが必要である．また，処理を終える場合はreturnで返却する必要がある． exports.handler = (event, context, callback) => { // なんらかの処理 // context以前の処理を待機はしない context.done(null, /*レスポンス*/); // 処理を終える場合 // return context.done(null, /*レスポンス*/) } exports.handler = (event, context, callback) => { // なんらかの処理 // context以前の処理を待機はしない context.succeed( /*レスポンス*/ ); // 処理を終える場合 // return context.succeed( /*レスポンス*/ ) } exports.handler = (event, context, callback) => { // なんらかの処理 // callback以前の処理を待機する． callback(null, /*レスポンス*/); // 処理を終える場合 // return callback(null, /*レスポンス*/) } ・予約された引数の説明 引数 説明 補足 eventオブジェクト HTTPリクエストに関するデータが代入されている． Lambdaにリクエストを送信するAWSリソースごとに，オブジェクトの構造が異なる．構造は以下の通り．参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/lambda-services.html contextオブジェクト Lambdaに関するデータ（名前，バージョンなど）を取得できるメソッドとプロパティが代入されている． オブジェクトの構造は以下の通り参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/nodejs-context.html callback関数 代入されている関数の実体は不明である．全ての処理が終わるまで実行が待機され，Lambdaのコール元にレスポンスを送信する． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/nodejs-handler.html ・テストとデバッグ Lambdaで関数を作成すると，CloudWatchログのロググループに，『/aws/lambda/』というグループが自動的に作成される．Lambdaの関数内で発生したエラーやconsole.logメソッドのログはここに出力されるため，都度確認すること． ・ベストプラクティス 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/best-practices.html#function-code 02. Goによる実装 発表スライド aws-lambda-go ・aws-lambda-goとは Goを使用して，Lambda-APIに対してリクエストを送信し，AWSリソースを操作できる． ・Start関数 Lamda関数を実行するための関数．Start関数に渡すパラメータには，必ず一つでもerrorインターフェースの実装が含まれている必要がある．もし含まれていない場合は，Lambdaで内部エラーが起こる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-handler.html package main import ( \"context\" \"fmt\" \"github.com/aws/aws-lambda-go/lambda\" ) type MyEvent struct { Name string `json:\"name\"` } // HandleRequest リクエストをハンドリングします． func HandleRequest(ctx context.Context, name MyEvent) (string, error) { return fmt.Sprintf(\"Hello %s!\", name.Name), nil } func main() { // Lambda関数を実行します． lambda.Start(HandleRequest) } ・パラメータ contextオブジェクトとeventオブジェクトをパラメータとして使用できる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-context.html eventオブジェクトの種類 ・全種類 参考：https://github.com/aws/aws-lambda-go/tree/master/events#overview ・SNSイベントの場合 package main import ( \"context\" \"github.com/aws/aws-lambda-go/events\" \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-lambda-go/lambdacontext\" ) /** * Lambdaハンドラー関数 */ func HandleRequest(context context.Context, event events.SNSEvent) (string, error) { } func main() { lambda.Start(HandleRequest) } ・CloudWatchイベントの場合 package main import ( \"context\" \"github.com/aws/aws-lambda-go/events\" \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-lambda-go/lambdacontext\" ) /** * Lambdaハンドラー関数 */ func HandleRequest(context context.Context, event events.CloudWatchEvent) (string, error) { } func main() { lambda.Start(HandleRequest) } ・APIGatewayイベントの場合 package main import ( \"context\" \"github.com/aws/aws-lambda-go/events\" \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-lambda-go/lambdacontext\" ) /** * Lambdaハンドラー関数 */ func HandleRequest(context context.Context, event events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) { } func main() { lambda.Start(HandleRequest) } レスポンス ・正常系 正常系レスポンスの構成要素については以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/API_Invoke.html#API_Invoke_ResponseElements 文字列を返却すると，Lambdaはその文字列をそのまま返信する．また，JSONをレスポンスすることもできる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-handler.html#golang-handler-structs ・異常系 Lambdaのエラーレスポンスのステータスコードについては以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/API_Invoke.html#API_Invoke_Errors エラーレスポンスのメッセージボディには以下のJSONが割り当てられる． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-exceptions.html#go-exceptions-createfunction { \"errorMessage\": \"\", \"errorType\": \"\" } errorsパッケージのNew関数を使用すると，内部で発生したエラーメッセージをオーバーライドできる． package main import ( \"errors\" \"github.com/aws/aws-lambda-go/lambda\" ) func HandleRequest() (string, error) { return \"\", errors.New(\"something went wrong!\") } func main() { lambda.Start(OnlyErrors) } /* 結果 { \"errorMessage\": \"something went wrong!\", \"errorType\": \"errorString\" } */ ログ ・レポートログ 種類 RequestId リクエストID Duration イベントの処理時間 Billed Duration Lambdaの課金対象の時間 Memory Size Lambdaのメモリサイズ Max Memory Used Lambdaが実際に使用するメモリの最大量 ・ログの出力方法 標準パッケージのfmt，または任意のロギングパッケージを使用し，標準出力／標準エラー出力に出力する．CloudWatchログにてこれを確認する． 参考：https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-logging.html 02-02. 関数例 Amplify -> EventBridge -> Lambda ->Slack-API 参考：https://github.com/hiroki-it/notify-slack-of-amplify-events 03. Node.jsによる実装 標準で使用可能なパッケージ 以下のパッケージでは，npmを使用する必要はない．パッケージから提供されるパッケージの関数のほとんどが非同期処理として実装されている．もし後続の処理で非同期処理の結果を使用したい場合，非同期処理の状態をPromiseオブジェクトで管理する必要がある． パッケージ名 説明 補足 Node.jsの標準パッケージ Node.jsに標準で組み込まれている関数を使用できる 参考：https://nodejs.org/api/index.html aws-sdk.js JavaScriptを使用して，AWS-APIに対してリクエストを送信し，AWSリソースを操作できる． 参考：https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/index.html 非同期処理の状態管理 ・Node.jsの標準パッケージの場合 ・aws-sdk.jsの場合 各AWSオブジェクトのメソッドの後に，promiseメソッドをチェーンできる．これにより，各メソッドの非同期処理の状態をPromiseオブジェクトで管理できるようになる． 参考：https://docs.aws.amazon.com/ja_jp/sdk-for-javascript/v2/developer-guide/using-promises.html \"use strict\"; const aws = require(\"aws-sdk\"); /** * @param event * @returns Promise */ exports.handler = async (event) => { const ec2 = new aws.EC2({apiVersion: '2014-10-01'}); // Promiseオブジェクトを返却する const ec2Instances = ec2.describeInstances().promise(); ec2Instances.then( (data) => { // 非同期処理が成功した時の後続処理 }, (error) => { // 非同期処理が失敗した時の後続処理 } ) }; 03-02. 関数例 Amplify -> EventBridge -> Lambda -> Slack-API ＊実装例＊ AmplifyのイベントをEventBridgeでキャッチし，これをLambdaに転送する．Lambdaでは，メッセージを構成し，Slack-APIに送信する． 参考： https://stackoverflow.com/questions/38533580/nodejs-how-to-promisify-http-request-reject-got-called-two-times https://gist.github.com/ktheory/df3440b01d4b9d3197180d5254d7fb65#file-httppromise-js \"use strict\"; const aws = require(\"aws-sdk\"); const https = require(\"https\"); const {format} = require(\"util\"); /** * @param event * @returns Promise */ exports.handler = async (event) => { console.log(JSON.stringify({event}, null, 2)); const amplify = new aws.Amplify({apiVersion: \"2017-07-25\"}); const option = { appId: event.detail.appId, branchName: event.detail.branchName }; let result; try { // Amplifyのブランチ情報を取得します． const app = await amplify.getBranch(option).promise(); console.log(JSON.stringify({app}, null, 2)); const message = buildMessage(event, app); console.log(message); result = await postMessageToSlack(message); } catch (error) { console.error(error); } console.log(JSON.stringify({result}, null, 2)); return result; }; /** * メッセージを作成します． * * @param event * @param app * @returns string */ const buildMessage = (event, app) => { return JSON.stringify({ channel: process.env.SLACK_CHANNEL_ID, text: \"develop環境 通知\", attachments: [{ color: event.detail.jobStatus === \"SUCCEED\" ? \"#00FF00\" : \"#ff0000\", blocks: [ { type: \"section\", text: { type: \"mrkdwn\", text: format( \"%s環境\", event.detail.appId === process.env.AMPLIFY_APP_ID_PC ? \":computer: PC\" : \":iphone: SP\" ) } }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*結果*: %s\", event.detail.jobStatus === \"SUCCEED\" ? \"成功\" : \"失敗\", ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*ブランチ名*: %s\", event.detail.branchName ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*プルリクURL*: https://github.com/foo-repository/compare/%s\", event.detail.branchName ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \"*検証URL*: https://%s.%s.amplifyapp.com\", app.branch.displayName, event.detail.appId ) }] }, { type: \"context\", elements: [{ type: \"mrkdwn\", text: format( \":amplify: \", event.region, event.region, event.detail.appId, app.branch.displayName, event.detail.jobId ) }] }, { type: \"divider\" } ] }] }); }; /** * メッセージを送信します． * * @param message * @returns Promise */ const postMessageToSlack = (message) => { // 非同期処理を持つ関数をコンストラクタに渡し，非同期処理を管理します． return new Promise((resolve, reject) => { const options = { host: \"slack.com\", path: \"/api/chat.postMessage\", method: \"POST\", headers: { \"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + process.env.SLACK_API_TOKEN, \"Content-Length\": Buffer.byteLength(message) } }; // 非同期処理 const request = https.request(options, (response) => { console.info({response}, null, 2); let tmp; // 正常なレスポンスからデータを取り出します． response.on(\"data\", (data) => { tmp = data; }); // 異常なレスポンスからエラーを取り出します． response.on(\"error\", (error) => { tmp = error; }); // data，error，end，の間でawaitの効力は横断できない． // そのため，できるだけendで事後処理を実装し，awaitを使用するようにする． response.on(\"end\", async () => { tmp = param.toString(tmp); const body = JSON.parse(tmp); const result = { statusCode: response.statusCode, body: body }; if (!response.statusCode === 200 || !body.ok) { return reject(result); } return resolve(result); }); }); request.on(\"error\", (error) => { console.error(JSON.stringify({error}, null, 2)); }); // メッセージボディを設定して，リクエストを送信します． request.write(message); request.end(); console.log(JSON.stringify({request}, null, 2)); }); }; API Gateway -> Lambda -> S3 ＊実装例＊ API Gatewayでリクエストを受信し，それに応じて特定のデータをS3に保存する．LambdaがS3に対してアクションを実行できるように，事前に，AWS管理ポリシーの『AWSLambdaExecute』がアタッチされたロールをLambdaにアタッチしておく必要がある． \"use strict\"; const aws = require(\"aws-sdk\"); const s3 = new aws.S3(); exports.handler = (event, context, callback) => { // API Gatewayとのプロキシ統合を意識したJSON構造にする // レスポンスメッセージの初期値 const response = { \"statusCode\": null, \"body\": null }; // 認証バリデーション if (event.headers[\"X-API-Key\"] !== process.env.X_API_KEY) { response.statusCode = 401; response.body = \"An API key is invalid.\"; return callback(null, response); } // リクエストメッセージバリデーション if (!event.headers || !event.body) { response.statusCode = 400; response.body = \"Parameters are not found.\"; return callback(null, response); } s3.putObject({ Bucket: \"\", Key: \"\", Body: \"\", }, (err, data) => { if (err) { response.statusCode = 500; response.body = \"[ERROR] \" + err; return callback(null, response); } response.statusCode = 200; response.body = \"OK\"; return callback(null, response); }); }; "},"public/cloud_computing/cloud_computing_aws_cost_management.html":{"url":"public/cloud_computing/cloud_computing_aws_cost_management.html","title":"📖 ︎コスト管理","keywords":"","body":"コスト管理 01. コスト管理の観点 スペック，時間単価，数量，月額料金 02. Service Quotas Service Quotastとは 各種AWSリソースの設定の上限値を上げられる． 参考：https://docs.aws.amazon.com/ja_jp/servicequotas/latest/userguide/intro.html 各種AWSリソースの上限値 参考：https://docs.aws.amazon.com/ja_jp/general/latest/gr/aws-service-information.html 方法 参考：https://docs.aws.amazon.com/ja_jp/servicequotas/latest/userguide/request-quota-increase.html 03. リソース別コスト CloudFront ・転送 オリジンに転送する前にキャッシュを用いてレスポンスを返信できるため，オリジンでかかる料金を抑えられる． EBS ・ボリュームサイズ ボリュームの使用率にかかわらず，構築されたボリュームの合計サイズに基づいて，料金が発生する．そのため，安易に500GiBを選んではいけない． EC2 ・料金体系の選択 使い方に応じた料金体系を選べる．レスポンスの返信時に料金が発生する． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/concepts.html#ec2-pricing 種類 説明 補足 オンデマンドインスタンス 参考：https://aws.amazon.com/jp/ec2/pricing/on-demand/ Savings Plans リザーブドインスタンス EC2インスタンスの一定期間分の使用料金を前払いし，その代わりに安く利用できるようになる． スポットインスタンス ・料金発生の条件 インスタンスのライフサイクルの状態に応じて，料金が発生する． 参考：https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html インスタンスの状態 料金発生の有無 補足 pending なし running あり stopping 条件付きでなし 停止準備中の間は料金が発生し，休止準備中の間は発生しない． stopped なし shutting-down なし terminated なし ECS ・ECRの容量 500MBを超えると，請求が発生するため，古いイメージを定期的に削除する必要がある． Lambda ・実行時間の従量課金制 関数を実行している時間分だけ料金がかかる．関数を使用せずに設置しているだけであれば，料金はかからない． RDS ・料金体系 以下のリンクを参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/User_DBInstanceBilling.html 種類 説明 オンデマンドインスタンス 参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_OnDemandDBInstances.html リザーブドインスタンス RDSインスタンスの一定期間分の使用料金を前払いし，その代わりに安く利用できるようになる．参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_WorkingWithReservedDBInstances.html SES ・送受信数 受信は1000件/月まで，送信は62000/月まで無料である． "},"public/cloud_computing/cloud_computing_gcp.html":{"url":"public/cloud_computing/cloud_computing_gcp.html","title":"📖 ︎GCP","keywords":"","body":"GCP：Google Cloud Platform はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. GCPによるWebサービスのリリース GCPから，グローバルIPアドレスと完全修飾ドメイン名が提供され，Webサービスがリリースされる． クラウドデザイン例 以下のデザイン例では，Dualシステムが採用されている． GAE：Google App Engine：GAE クラウドデプロイサーバとして働く．AWSにおけるElastic Beanstalkに相当する． GCE：Google Compute Engine クラウドWebサーバとして働く．AWSにおけるEC2に相当する． SSLサーバ証明書の設置場所 ・認証局 サーバ提供者 自社の中間認証局名 ルート認証局名 GCP Google Trust Services "},"public/infrastructure_as_code/infrastructure_as_code.html":{"url":"public/infrastructure_as_code/infrastructure_as_code.html","title":"📖 ︎Infrastructure as Code","keywords":"","body":"Infrastructure as Code はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 仮想サーバ(仮想マシン)のコード化 仮想サーバの構成管理 ・コード化ツールの種類 ツール名 対象のProvider Ansible 要勉強 Puppet 要勉強 Chef 要勉強 ・Ansible Ansibleでは，ymlの文法を用いて関数処理を実行できる． ファイル名 役割 playbook.yml ソフトウェアのインストールタスクの手順 inventory/* 反映先のサーバの情報 group_vars/* 複数のサーバへの設定 host_vars/* 単一のサーバへの設定 02. コンテナのコード化 コンテナの構成管理 ・コード化ツールの種類 名前 対象のProvider Dockerfile Docker Ansible Container 要勉強 03. クラウドインフラストラクチャのコード化 クラウドインフラストラクチャオーケストレーション ・コード化ツールの種類 名前 対象のプロバイダー Terraform いろいろ AWS CloudFormation AWS Azure Resource Manager Azure メリット ・変更をコードレビュー可能 画面上からインフラを変更する場合，画面共有しながら操作し，レビューと変更を同時に行うことになる．コード化により，レビューを事前に行ったうえで変更する，という手順を踏める． ・ヒューマンエラーが減る 画面上からの変更であると，ヒューマンエラーが起こってしまう．コード化すれば，これが減る． ・再利用や冗長化が簡単 複数のアプリケーションのために，同様の設定で同様のインフラを構築する場合や，一つのアプリケーションのために，インフラを冗長化する場合，いくつも手動で構築する必要があり，労力がかかる．コード化すれば，これが楽になる． ・過去の変更が記録に残る 画面上からの変更であると，過去の変更履歴が残らない．ソースコードをバージョン管理すれば，Issueと紐付けて，履歴を残せる． デメリット ・運用のスピードが落ちる 運用時に，画面上からの操作であればすぐに終わる変更であるのにもかかわらず，コード化により，変更までに時間がかかる．そのため例えばAWSとすると，運用時に変更する頻度が多いインフラ（例：API Gateway（VPCリンクを含む），IAMユーザ（紐付けるロールやポリシーを含む））はコード化せず，あえて画面上から構築する． ・プロバイダーの機能追加に追従しにくい プロバイダーは日々機能を追加している．画面上からの操作であればすぐにこの機能を支えるが，コード化により，ツールのバージョンをアップグレードしなければ，この機能を使えない．運用時に便利な機能をすぐに使えないため，インフラを改善できないことに繋がる．また，エンジニアの『新機能を使ってみたい欲』が行き場を失う． ・リリースの心理的ハードルが高い 画面上から変更すれば，インフラ変更のリリース中に予期せぬエラーが起こることはまずない．しかし，コード化ツールでは，変更のリリース中に予期せぬエラーが起こる可能性は決して低くないため，リリースの心理的ハードルが高くなる． "},"public/infrastructure_as_code/infrastructure_as_code_terraform.html":{"url":"public/infrastructure_as_code/infrastructure_as_code_terraform.html","title":"📖 ︎Terraform","keywords":"","body":"Terraform はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コマンド global option 参考：https://www.terraform.io/docs/cli/commands/index.html#switching-working-directory-with-chdir init ・-backend=false ローカルにstateファイルを作成する． 参考：https://www.terraform.io/docs/language/settings/backends/index.html $ terraform init -backend=false # ディレクトリを指定することも可能 $ terraform -chdir= init -backend=false ・-backend=true, -backend-config 実インフラにstateファイルを作成する．代わりに，terraform settingsブロック内のbackendで指定しても良い．ただし，terraform settingブロック内では変数を使用できないため，こちらのオプションが推奨である． $ terraform init \\ -backend=true \\ -reconfigure \\ # バケット名 -backend-config=\"bucket=foo-tfstate-bucket\" \\ # tfstateファイル名 -backend-config=\"key=terraform.tfstate\" \\ # credentialsファイルのプロファイル名 -backend-config=\"profile=bar\" \\ -backend-config=\"encrypt=true\" ・-reconfigure Terraformを初期化する． 参考：https://www.terraform.io/docs/cli/commands/init.html#backend-initialization $ terraform init -reconfigure ・-upgrade 現在のバージョンに基づいて，lockファイル，モジュール，プラグインのアップグレード／ダウングレードを行う． 参考：https://www.terraform.io/docs/cli/commands/init.html#upgrade $ terraform init -upgrade validate ・オプション無し 設定ファイルの検証を行う． $ terraform validate Success! The configuration is valid. # ディレクトリを指定することも可能 $ terraform -chdir= validate fmt ・-check インデントを揃えるべき箇所が存在するかどうかを判定する．もし存在する場合「1」，存在しない場合は「0」を返却する． $ terraform fmt -check ・-recursive 設定ファイルのインデントを揃える．処理を行ったファイルが表示される． # -recursive: サブディレクトリを含む全ファイルをフォーマット $ terraform fmt -recursive main.tf graph rosource間の依存関係をグラフ化する．これにより，どのresourceが他のどのresourceを使用しているかがわかる．Graphvizのダウンロードが必要である． 参考：https://graphviz.org/download/ $ terraform graph | dot -Tsvg > graph.svg import ・-var-file terraformによる構築ではない方法で，すでにクラウド上にリソースが構築されている場合，これをterraformの管理下におく必要がある．リソースタイプとリソース名を指定し，stateファイルに実インフラの状態を書き込む．現状，全てのリソースを一括してimportする方法は無い．リソースIDは，リソースによって異なるため，リファレンスの「Import」または「Attributes Referenceのid」を確認すること（例えば，ACMにとってのIDはARNだが，S3バケットにとってのIDはバケット名である）． $ terraform import \\ -var-file=foo.tfvars \\ . モジュールを使用している場合，指定の方法が異なる． $ terraform import \\ -var-file=foo.tfvars \\ module... 例えば，AWS上にすでにECRが存在しているとして，これをterraformの管理下におく． $ terraform import \\ -var-file=foo.tfvars \\ module.ecr.aws_ecr_repository.www xxxxxxxxx そして，ローカルのstateファイルと実インフラの差分が無くなるまで，importを繰り返す． $ terraform plan -var-file=foo.tfvars No changes. Infrastructure is up-to-date. ・importを行わなかった場合のエラー もしimportを行わないと，すでにクラウド上にリソースが存在しているためにリソースを構築できない，というエラーになる． （エラー例1） Error: InvalidParameterException: Creation of service was not idempotent. （エラー例2） Error: error creating ECR repository: RepositoryAlreadyExistsException: The repository with name 'tech-notebook_www' already exists in the registry with id 'XXXXXXXXXXXX' refresh ・-var-file クラウドに対してリクエストを行い，現在のリソースの状態をtfstateファイルに反映する． $ terraform refresh -var-file=foo.tfvars plan ・シンボルの見方 構築（+），更新（~），削除（-），再構築（-/+）で表現される． + create ~ update in-place - destroy -/+ destroy and then create replacement ・出力内容の読み方 前半部分と後半部分に区別されている．前半部分は，Terraform管理外の方法（画面上，他ツール）による実インフラの変更について，その変更前後を検出する．ただの検出のため，applyによって変更される実インフラを表しているわけではない．そして後半部分は，Terraformのソースコードの変更によって，実インフラがどのように変更されるか，を表している．結果の最後に表示される対象リソースの数を確認しても，前半部分のリソースは含まれていないことがわかる． Note: Objects have changed outside of Terraform Terraform detected the following changes made outside of Terraform since the last \"terraform apply\": # Terraform管理外の方法（画面上，他ツール）による実インフラの変更について，その変更前後を検出． Unless you have made equivalent changes to your configuration, or ignored the relevant attributes using ignore_changes, the following plan may include actions to undo or respond to these changes. ───────────────────────────────────────────────────────────────────────────── Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: ~ update in-place Terraform will perform the following actions: # Terraformのソースコードの変更によって，実インフラがどのように変更されるか． Plan: 0 to add, 1 to change, 0 to destroy. ・差分認識される／されない変更 変更内容 される／されない リソース名の変更 される モジュール名の変更 される ファイルやディレクトリを指定するパスの変更 されない リソースにハードコーディングされた値を環境変数に変更（tfvarsファイルに移行） されない ・-var-file クラウドに対してリクエストを行い，現在のリソースの状態をtfstateファイルには反映せずに，設定ファイルの記述との差分を検証する．スクリプト実行時に，変数が定義されたファイルを実行すると，variableで宣言した変数に，値が格納される． $ terraform plan -var-file=foo.tfvars # ディレクトリを指定することも可能 # 第一引数で変数ファイルの相対パス，第二引数でをルートモジュールの相対パス $ terraform plan -chdir= \\ -var-file=/foo.tfvars 差分がなければ，以下の通りになる． No changes. Infrastructure is up-to-date. This means that Terraform did not detect any differences between your configuration and real physical resources that exist. As a result, no actions need to be performed. ・-target 特定のリソースに対して，planコマンドを実行する． $ terraform plan \\ -var-file=foo.tfvars \\ -target=. モジュールを使用している場合，指定の方法が異なる． $ terraform plan \\ -var-file=foo.tfvars \\ -target=module... ・-refresh このオプションをつければ，refreshコマンドを同時に実行してくれる．ただ，標準でtrueなので，不要である． $ terraform plan \\ -var-file=foo.tfvars \\ -refresh=true https://github.com/hashicorp/terraform/issues/17311 ・-parallelism 並列処理数を設定できる．標準値は10である． $ terraform plan \\ -var-file=foo.tfvars \\ -parallelism=30 ・-out 実行プランファイルを生成する．applyコマンドのために使用できる． $ terraform plan \\ -var-file=foo.tfvars \\ # 実行プランファイル名 -out=foo.tfplan apply ・-var-file AWS上にクラウドインフラストラクチャを構築する． $ terraform apply -var-file foo.tfvars # ディレクトリを指定することも可能 $ terraform -chdir= apply \\ -var-file=/foo.tfvars 成功すると，以下のメッセージが表示される． Apply complete! Resources: 1 added, 0 changed, 0 destroyed. ・-target 特定のリソースに対して，applyコマンドを実行する． $ terraform apply \\ -var-file=foo.tfvars \\ -target=. モジュールを使用している場合，指定の方法が異なる． $ terraform apply \\ -var-file=foo.tfvars \\ -target=module... ・-parallelism 並列処理数を設定できる．標準値は10である． $ terraform apply \\ -var-file=foo.tfvars \\ -parallelism=30 ・実行プランファイル 事前に，planコマンドによって生成された実行プランファイルを元に，applyコマンドを実行する．実行プランを渡す場合は，変数をオプションに設定する必要はない． $ terraform apply foo.tfplan taint ・-var-file stateファイルにおける指定されたリソースのtaintedフラグを立てる．例えば，applyしたが，途中でエラーが発生してしまい，実インフラに中途半端はリソースが構築されてしまうことがある．ここで，taintedを立てておくと，実インフラのリソースを削除したと想定したplanを実行できる． $ terraform taint \\ -var-file=foo.tfvars \\ module... この後のplanコマンドのログからも，-/+で削除が行われる想定で，差分を比較していることがわかる． $ terraform plan -var-file=foo.tfvars An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: -/+ destroy and then create replacement Terraform will perform the following actions: -/+ . (tainted) (new resource required) id: '1492336661259070634' => (forces new resource) Plan: 1 to add, 0 to change, 1 to destroy. state list ・オプション無し ファイル内で定義しているリソースの一覧を表示する． $ terraform state list 以下の通り，モジュールも含めて，リソースが表示される． aws_instance.www-1a aws_instance.www-1c aws_key_pair.key_pair module.alb_module.aws_alb.alb module.ami_module.data.aws_ami.amazon_linux_2 module.route53_module.aws_route53_record.r53_record module.route53_module.aws_route53_zone.r53_zone module.security_group_module.aws_security_group.security_group_alb module.security_group_module.aws_security_group.security_group_ecs module.security_group_module.aws_security_group.security_group_instance module.vpc_module.aws_internet_gateway.internet_gateway module.vpc_module.aws_route_table.route_table_public module.vpc_module.aws_route_table_association.route_table_association_public_1a module.vpc_module.aws_route_table_association.route_table_association_public_1c module.vpc_module.aws_subnet.subnet_public_1a module.vpc_module.aws_subnet.subnet_public_1c module.vpc_module.aws_vpc.vpc 01-02. バージョン バージョン管理 ・lockファイル 現在使用中のプロバイダーのバージョンが定義される．これにより，他の人がリポジトリを使用する時に，異なるバージョンのプロバイダーを宣言できないようにする．もし，異なるバージョンを使用したい場合は，以下のコマンドを実行する．これにより，lockファイルのアップグレード／ダウングレードが実行される． $ terraform init -upgrade Terraform／プロバイダーのアップグレード 1. 現在のTerraformのバージョンでapplyコマンドを実行 アップグレードと同時に新しいAWSリソースをデプロイせずに，アップグレードのみに専念する．そのために，現在のTerraformのバージョンでapplyコマンドを実行し，差分が無いようにしておく． 2. アップグレード以外の作業を済ませておく 低いバージョンのTerraformに対して，より高いバージョンをデプロイすることは可能である．反対に，高いバージョンのTerraoformに対して，より低いバージョンをデプロイできない．そのため，アップグレードしてしまうと，それ以外のTeraformバージョンの異なる作業に影響が出る． 3. メジャーバージョン単位でアップグレード Terraformでは，メジャーバージョン単位でアップグレードを行うことが推奨されている．そのため，現在のバージョンと最新バージョンがどんなに離れていても，必ず一つずつメジャーバージョンをアップグレードするように気をつける． 参考：https://www.terraform.io/upgrade-guides/1-0.html 4. planコマンドの警告／エラーを解消 アップグレードに伴って，非推奨／廃止の機能がリリースされ，警告／エラーが出力される場合がある．警告／エラーを解消できるように，記法やオプション値を修正する．場合によってはtfstateファイルの差分として表示されているだけで，実インフラとの差分ではない場合もあるため，planで差分があったとしても，実インフラに影響がなければ問題ない． 5. Terraformの後にプロバイダーをアップグレード Terraformとプロバイダーのバージョンは独立して管理されている．プロバイダーはTerraformが土台になって稼働するため，一旦，Terraformのアップグレードを済ませてから，プロバイダーをアップグレードする． 01-03. ディレクトリ構成 ルートモジュールの構成 ・稼働環境別 稼働環境別に，foo.tfvarsファイルで値を定義する． terraform_project/ ├── modules │ ├── route53 # Route53 │ │ ├── dev # 開発 │ | ├── prd # 本番 │ | └── stg # ステージング │ | │ ├── ssm # SSM | | ├── dev │ | ├── prd │ | └── stg │ | │ └── waf # WAF | ├── dev │ ├── prd │ └── stg | ├── dev # 開発環境ルートモジュール │ ├── dev.tfvars │ ├── main.tf │ ├── providers.tf │ ├── tfnotify.yml │ └── variables.tf │ ├── prd # 本番環境ルートモジュール │ ├── prd.tfvars │ ├── main.tf │ ├── providers.tf │ ├── tfnotify.yml │ └── variables.tf │ └── stg # ステージング環境ルートモジュール ├── stg.tfvars ├── main.tf ├── providers.tf ├── tfnotify.yml └── variables.tf リソースのモジュールの構成 　・対象リソース別 一つのリソースの設定が対象のリソースごとに異なる場合，冗長性よりも保守性を重視して，リソースに応じたディレクトリに分割する． terraform_project/ └── modules ├── cloudwatch # CloudWatch │ ├── alb # ALB | ├── cloudfront # CloudFront | ├── ecs # ECS | ├── lambda # Lambda | └── rds # RDS | └── waf # WAF ├── alb # ALB ├── api_gateway # API Gateway └── cloudfront # CloudFront ・稼働環境別 一つのリソースの設定が稼働環境ごとに異なる場合，冗長性よりも保守性を重視して，稼働環境に応じたディレクトリに分割する． terraform_project/ └── modules ├── route53 # Route53 │ ├── dev # 開発 | ├── prd # 本番 | └── stg # ステージング | ├── ssm # SSM | ├── dev | ├── prd | └── stg | └── waf # WAF └── alb ├── dev ├── prd └── stg ・リージョン別 一つのリソースの設定がリージョンごとに異なる場合，冗長性よりも保守性を重視して，リージョンに応じたディレクトリに分割する． terraform_project/ └── modules └── acm # ACM ├── ap-northeast-1 # 東京リージョン └── us-east-1 # バージニアリージョン ・共通セット別 WAFで使用するIPパターンセットと正規表現パターンセットには，CloudFrontタイプとRegionalタイプがある．Regionalタイプは，同じリージョンの異なるAWSリソース間で共通して使用できるため，共通セットとしてディレクトリ分割を行う． terraform_project/ └── modules └── waf # WAF ├── alb ├── api_gateway ├── cloudfront └── regional_sets # Regionalタイプのセット ├── ip_sets # IPセット | ├── prd | └── stg | └── regex_pattern_sets # 正規表現パターンセット ├── prd └── stg ・ファイルの切り分け ポリシーのためにJSONを定義する場合，Terraformのソースコードにハードコーディングせずに，切り分けるようにする．また，「カスタマー管理ポリシー」「インラインポリシー」「信頼ポリシー」も区別し，ディレクトリを分割している．なお，templatefileメソッドでこれを読みこむ時，bashファイルではなく，tplファイルとして定義しておく必要あるため，注意する． terraform_project/ └── modules ├── ecr #ECR │ └── ecr_lifecycle_policy.tpl # ECRライフサイクル │ ├── ecs # ECS │ └── container_definitions.tpl # コンテナ定義 │ ├── iam # IAM │ └── policies | ├── customer_managed_policies # カスタム管理ポリシー | | ├── aws_cli_executor_access_policy.tpl | | ├── aws_cli_executor_access_address_restriction_policy.tpl | | ├── cloudwatch_logs_access_policy.tpl | | └── lambda_edge_execution_policy.tpl | | | ├── inline_policies # インラインポリシー | | └── ecs_task_policy.tpl | | | └── trust_policies # 信頼ポリシー | ├── cloudwatch_events_policy.tpl | ├── ecs_task_policy.tpl | ├── lambda_policy.tpl | └── rds_policy.tpl | └── s3 # S3 └── policies # バケットポリシー └── alb_bucket_policy.tpl CI/CDディレクトリ ・opsディレクトリ TerraformのCI/CDで必要なシェルスクリプトは，opsディレクトリで管理する． terraform_project/ ├── .circleci # CI/CDツールの設定ファイル └── ops # TerraformのCI/CDの自動化シェルスクリプト 02. ルートモジュールにおける実装 tfstateファイル ・tfstateファイルとは 実インフラのインフラの状態が定義されたjsonファイルのこと．初回時，applyコマンドを実行し，成功もしくは失敗したタイミングで生成される． terraform settings ・terraform settingsとは terraformの実行時に，エントリポイントとして機能するファイル． ・required_providers AWSやGCPなど，使用するプロバイダを定義する．プロバイダによって，異なるリソースタイプが提供される．一番最初に読みこまれるファイルのため，変数やモジュール化などが行えない． ＊実装例＊ terraform { required_providers { # awsプロバイダを定義 aws = { # グローバルソースアドレスを指定 source = \"hashicorp/aws\" # プロバイダーのバージョン変更時は initを実行 version = \"3.0\" } } } ・backend stateファイルを管理する場所を設定する．S3などの実インフラで管理する場合，アカウント情報を設定する必要がある．代わりに，initコマンド実行時に指定しても良い．標準値はlocalである．変数を使用できず，ハードコーディングする必要があるため，もし値を動的に変更したい場合は，initコマンドのオプションを使用して値を渡すようにする． 参考：https://www.terraform.io/docs/language/settings/backends/s3.html#credentials-and-shared-configuration ＊実装例＊ terraform { # ローカルPCで管理するように設定 backend \"local\" { path = \"${path.module}/terraform.tfstate\" } } terraform { # S3で管理するように設定 backend \"s3\" { # バケット名 bucket = \"foo-tfstate-bucket\" # stateファイル名 key = \"terraform.tfstate\" region = \"ap-northeast-1\" # credentialsファイルの場所 shared_credentials_file = \"$HOME/.aws/credentials\" # credentialsファイルのプロファイル名 profile = \"bar-profile\" } } どのユーザもバケット内のオブジェクトを削除できないように，ポリシーを設定しておくとよい． ＊実装例＊ { \"Version\": \"2008-10-17\", \"Statement\": [ { \"Effect\": \"Deny\", \"Principal\": \"*\", \"Action\": \"s3:DeleteObject\", \"Resource\": \"arn:aws:s3:::foo-tfstate-bucket/*\" } ] } provider ・providerとは Terraformがリクエストを送信するプロバイダ（AWS，GCP，Azure，など）を選択し，そのプロバイダにおけるアカウント認証を行う．terraform settingsで定義したプロバイダ名を指定する必要がある． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { # awsプロバイダを定義 aws = { # 何らかの設定 } } backend \"s3\" { # 何らかの設定 } } # awsプロバイダを指定 provider \"aws\" { # アカウント認証の設定 } multiple providers ・multiple providersとは 複数のproviderを実装し，エイリアスを使用して，これらを動的に切り替える方法． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } } provider \"aws\" { # 標準値とするリージョン region = \"ap-northeast-1\" } provider \"aws\" { # 別リージョン alias = \"ue1\" region = \"us-east-1\" } ・子モジュールでproviderを切り替える 子モジュールでproviderを切り替えるには，ルートモジュールでproviderの値を明示的に渡す必要がある． ＊実装例＊ module \"route53\" { source = \"../modules/route53\" providers = { aws = aws.ue1 } # その他の設定値 } さらに子モジュールで，providerの値を設定する必要がある． ＊実装例＊ ############################################### # Route53 ############################################### resource \"aws_acm_certificate\" \"example\" { # CloudFrontの仕様のため，us-east-1リージョンでSSL証明書を作成します． provider = aws domain_name = \"example.co.jp\" subject_alternative_names = [\"*.example.co.jp\"] validation_method = \"DNS\" tags = { Name = \"prd-foo-example-cert\" } lifecycle { create_before_destroy = true } } アカウント情報の設定方法 ・ハードコーディングによる設定 リージョンの他，アクセスキーとシークレットキーをハードコーディングで設定する．誤ってコミットしてしまう可能性があるため，ハードコーディングしないようにする． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } backend \"s3\" { bucket = \"foo-tfstate-bucket\" key = \"terraform.tfstate\" region = \"ap-northeast-1\" # アクセスキー access_key = \"*****\" # シークレットアクセスキー secret_key = \"*****\" } } provider \"aws\" { region = \"ap-northeast-1\" # アクセスキー access_key = \"*****\" # シークレットアクセスキー secret_key = \"*****\" } ・credentialsファイルによる設定 　AWSアカウント情報は，~/.aws/credentialsファイルに記載されている． # 標準プロファイル [default] aws_access_key_id=***** aws_secret_access_key=***** # 独自プロファイル [bar-profile] aws_access_key_id=***** aws_secret_access_key=***** credentialsファイルを読み出し，プロファイル名を設定することにより，アカウント情報を参照できる． ＊実装例＊ terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } # credentialsファイルから，アクセスキー，シークレットアクセスキーを読み込む backend \"s3\" { # バケット名 bucket = \"foo-tfstate-bucket\" # stateファイル名 key = \"terraform.tfstate\" region = \"ap-northeast-1\" # credentialsファイルの場所 shared_credentials_file = \"$HOME/.aws/credentials\" # credentialsファイルのプロファイル名 profile = \"bar-profile\" } } # credentialsファイルから，アクセスキー，シークレットアクセスキーを読み込む provider \"aws\" { region = \"ap-northeast-1\" profile = \"foo\" shared_credentials_file = \"$HOME/.aws/\" } ・環境変数による設定 Credentialsファイルではなく，exportを使用して，必要な情報を設定しておくことも可能である．参照できる環境変数名は決まっている． # regionの代わり $ export AWS_DEFAULT_REGION=\"ap-northeast-1\" # access_keyの代わり $ export AWS_ACCESS_KEY_ID=\"*****\" # secret_keyの代わり $ export AWS_SECRET_ACCESS_KEY=\"*****\" # profileの代わり $ export AWS_PROFILE=\"bar-profile\" #tokenの代わり（AmazonSTSを使用する場合） $ export AWS_SESSION_TOKEN=\"*****\" 環境変数を設定した上でteraformを実行すると，値がproviderに自動的に出力される．CircleCIのような，一時的に環境変数が必要になるような状況では有効な方法である． terraform { required_version = \"0.13.5\" required_providers { aws = { source = \"hashicorp/aws\" version = \"3.0\" } } # リージョン，アクセスキー，シークレットアクセスキーは不要 backend \"s3\" { bucket = \"\" key = \"\" } } # リージョン，アクセスキー，シークレットアクセスキーは不要 provider \"aws\" {} module ・moduleとは ルートモジュールで子モジュール読み込み，子モジュールに対して変数を渡す． ・実装方法 ＊実装例＊ ############################### # ALB ############################### module \"alb\" { # モジュールのResourceを参照 source = \"../modules/alb\" # モジュールに他のモジュールのアウトプット値を渡す． acm_certificate_api_arn = module.acm.acm_certificate_api_arn } 03. 変数 環境変数 ・優先順位 上の項目ほど優先される． 参考：https://www.terraform.io/docs/language/values/variables.html#variable-definition-precedence ・-var，-var-file $ terraform plan -var=\"foo=foo\" $ terraform plan -var=\"foo=foo\" -var=\"bar=bar\" $ terraform plan -var-file=xxxxx.tfvars ・*.auto.tfvarsファイル，*.auto.tfvars.jsonファイル ・terraform.tfvars.jsonファイル ・terraform.tfvarsファイル #　ファイルを指定しなくとも読み込まれる $ terraform plan ・TF_VAR_XXXXX 環境変数としてエクスポートしておくと自動的に読み込まれる．XXXXXの部分が変数名としてTerraformに渡される． $ printenv TF_VAR_ecr_image_tag=foo tfvarsファイル ・tfvarsファイルの用途 実行ファイルに入力したい環境変数を定義する．『terraform.tfvars』という名前にすると，terraformコマンドの実行時に自動的に読み込まれる．各サービスの間で実装方法が同じため，VPCのみ例を示す． ＊実装例＊ ############################### # VPC ############################### vpc_cidr_block = \"n.n.n.n/n\" # IPv4アドレス範囲 ・値のデータ型 単一値，list型，map型で定義できる．AZ，サブネットのCIDR，RDSのパラメータグループ値，などはmap型として保持しておくとよい．また，IPアドレスのセット，ユーザエージェント，などはlist型として保持しておくとよい．なお，RDSのパラメータグループの適正値については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws.html ＊実装例＊ ############################################### # RDS ############################################### variable \"rds_parameter_group_values\" { type = map(string) } ############################################### # VPC ############################################### variable \"vpc_availability_zones\" { type = map(string) } variable \"vpc_cidr\" { type = string } variable \"vpc_endpoint_port_https\" { type = number } variable \"vpc_subnet_private_datastore_cidrs\" { type = map(string) } variable \"vpc_subnet_private_app_cidrs\" { type = map(string) } variable \"vpc_subnet_public_cidrs\" { type = map(string) } ############################################### # WAF ############################################### variable \"waf_allowed_global_ip_addresses\" { type = list(string) } variable \"waf_blocked_user_agents\" { type = list(string) } ############################################### # RDS ############################################### rds_parameter_group_values = { time_zone = \"asia/tokyo\" character_set_client = \"utf8mb4\" character_set_connection = \"utf8mb4\" character_set_database = \"utf8mb4\" character_set_results = \"utf8mb4\" character_set_server = \"utf8mb4\" server_audit_events = \"connect,query,query_dcl,query_ddl,query_dml,table\" server_audit_logging = 1 server_audit_logs_upload = 1 general_log = 1 slow_query_log = 1 long_query_time = 3 } ############################################### # VPC ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } vpc_cidr = \"n.n.n.n/23\" vpc_subnet_private_datastore_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } vpc_subnet_private_app_cidrs = { a = \"n.n.n.n/25\", c = \"n.n.n.n/25\" } vpc_subnet_public_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } ############################################### # WAF ############################################### waf_allowed_global_ip_addresses = [ \"n.n.n.n/32\", \"n.n.n.n/32\", ] waf_blocked_user_agents = [ \"XXXXX\", \"YYYYY\" ] variable ・variableとは リソースで使用する変数のデータ型を定義する． ＊実装例＊ ############################################### # ECS ############################################### variable \"ecs_container_laravel_port_http\" { type = number } variable \"ecs_container_nginx_port_http\" { type = number } ############################################### # RDS ############################################### variable \"rds_auto_minor_version_upgrade\" { type = bool } variable \"rds_instance_class\" { type = string } variable \"rds_parameter_group_values\" { type = map(string) } 04. リソースの実装 resource ・resourceとは AWSのAPIに対してリクエストを送信し，クラウドインフラの構築を行う． ・実装方法 ＊実装例＊ ############################################### # ALB ############################################### resource \"aws_lb\" \"this\" { name = \"prd-foo-alb\" load_balancer_type = \"application\" security_groups = [\"*****\"] subnets = [\"*****\",\"*****\"] } data ・dataとは AWSのAPIに対してリクエストを送信し，クラウドインフラに関するデータを取得する．ルートモジュールに実装することも可能であるが，各モジュールに実装した方が分かりやすい． ・実装方法 ＊実装例＊ 例として，タスク定義名を指定して，AWSから ############################################### # ECS task definition ############################################### data \"aws_ecs_task_definition\" \"this\" { task_definition = \"prd-foo-ecs-task-definition\" } ＊実装例＊ 例として，AMIをフィルタリングした上で，AWSから特定のAMIの値を取得する． ############################################### # AMI ############################################### data \"aws_ami\" \"bastion\" { most_recent = true owners = [\"amazon\"] filter { name = \"architecture\" values = [\"x86_64\"] } filter { name = \"root-device-type\" values = [\"ebs\"] } filter { name = \"name\" values = [\"amzn-ami-hvm-*\"] } filter { name = \"virtualization-type\" values = [\"hvm\"] } filter { name = \"block-device-mapping.volume-type\" values = [\"gp2\"] } } output ・outputとは モジュールで構築されたリソースがもつ特定の値を出力する．可読性の観点から，リソース一括ではなく，具体的なattributeをアウトプットする． ・実装方法 ＊実装例＊ 例として，ALBを示す．resourceブロックとdataブロックでアウトプットの方法が異なる． ############################################### # ALB ############################################### output \"alb_zone_id\" { value = aws_lb.this.zone_id } output \"elb_service_account_arn\" { value = data.aws_elb_service_account.this.arn } ・count関数のアウトプット 後述の説明を参考にせよ． ・for_each関数のアウトプット 後述の説明を参考にせよ． 05. メタ引数 メタ引数とは 全てのリソースで使用できるオプションのこと． depends_on ・depends_onとは リソース間の依存関係を明示的に定義する．Terraformでは，基本的にリソース間の依存関係が暗黙的に定義されている．しかし，複数のリソースが関わると，リソースを適切な順番で構築できない場合があるため，そういったときに使用する． ・ALB target group vs. ALB，ECS 例として，ALB target groupを示す．ALB Target groupとALBのリソースを適切な順番で構築できないため，ECSの構築時にエラーが起こる．ALBの後にALB target groupを構築する必要がある． ＊実装例＊ ############################################### # ALB target group ############################################### resource \"aws_lb_target_group\" \"this\" { name = \"prd-foo-alb-tg\" port = 80 protocol = \"HTTP\" vpc_id = \"*****\" deregistration_delay = \"60\" target_type = \"ip\" slow_start = \"60\" health_check { interval = 30 path = \"/healthcheck\" protocol = \"HTTP\" timeout = 5 unhealthy_threshold = 2 matcher = 200 } depends_on = [aws_lb.this] } ・Internet Gateway vs. EC2，Elastic IP，NAT Gateway 例として，NAT Gatewayを示す．NAT Gateway，Internet Gateway，のリソースを適切な順番で構築できないため，Internet Gatewayの構築後に，NAT Gatewayを構築するように定義する必要がある． ############################################### # EC2 ############################################### resource \"aws_instance\" \"bastion\" { ami = \"*****\" instance_type = \"t2.micro\" vpc_security_group_ids = [\"*****\"] subnet_id = \"*****\" key_name = \"prd-foo-bastion\" associate_public_ip_address = true disable_api_termination = true tags = { Name = \"prd-foo-bastion\" } depends_on = [var.internet_gateway] } ############################################### # Elastic IP ############################################### resource \"aws_eip\" \"nat_gateway\" { for_each = var.vpc_availability_zones vpc = true tags = { Name = format( \"prd-foo-ngw-%s-eip\", each.value ) } depends_on = [aws_internet_gateway.this] } ############################################### # NAT Gateway ############################################### resource \"aws_nat_gateway\" \"this\" { for_each = var.vpc_availability_zones subnet_id = aws_subnet.public[each.key].id allocation_id = aws_eip.nat_gateway[each.key].id tags = { Name = format( \"prd-foo-%s-ngw\", each.value ) } depends_on = [aws_internet_gateway.this] } ・S3バケットポリシー vs. パブリックアクセスブロックポリシー 例として，S3を示す．バケットポリシーとパブリックアクセスブロックポリシーを同時に構築できないため，構築のタイミングが重ならないようにする必要がある． ############################################### # S3 ############################################### # foo bucket resource \"aws_s3_bucket\" \"foo\" { bucket = \"prd-foo-foo-bucket\" acl = \"private\" } # Public access block resource \"aws_s3_bucket_public_access_block\" \"foo\" { bucket = aws_s3_bucket.foo.id block_public_acls = true block_public_policy = true ignore_public_acls = true restrict_public_buckets = true } # Bucket policy attachment resource \"aws_s3_bucket_policy\" \"foo\" { bucket = aws_s3_bucket.foo.id policy = templatefile( \"${path.module}/policies/foo_bucket_policy.tpl\", { foo_s3_bucket_arn = aws_s3_bucket.foo.arn s3_cloudfront_origin_access_identity_iam_arn = var.s3_cloudfront_origin_access_identity_iam_arn } ) depends_on = [aws_s3_bucket_public_access_block.foo] } count ・countとは 指定した数だけ，リソースの構築を繰り返す．count.indexでインデックス数を出力する． ＊実装例＊ ############################################### # EC2 ############################################### resource \"aws_instance\" \"server\" { count = 4 ami = \"ami-a1b2c3d4\" instance_type = \"t2.micro\" tags = { Name = \"ec2-${count.index}\" } } ・list型でアウトプット リソースの構築にcount関数を使用した場合，そのリソースはlist型として扱われる．そのため，キー名を指定してアウトプットできる．この時，アウトプットはlist型になる．ちなみに，for_each関数で構築したリソースはアスタリスクでインデックス名を指定できないので，注意． ＊実装例＊ 例として，VPCのサブネットを示す．ここでは，パブリックサブネット，applicationサブネット，datastoreサブネット，をcount関数で構築したとする． ############################################### # Public subnet ############################################### resource \"aws_subnet\" \"public\" { count = 2 # ～ 中略 ～ } ############################################### # Private subnet ############################################### resource \"aws_subnet\" \"private_app\" { count = 2 # ～ 中略 ～ } resource \"aws_subnet\" \"private_datastore\" { count = 2 # ～ 中略 ～ } ############################################### # Output VPC ############################################### output \"public_subnet_ids\" { value = aws_subnet.public[*].id } output \"private_app_subnet_ids\" { value = aws_subnet.private_app[*].id } output \"private_datastore_subnet_ids\" { value = aws_subnet.private_datastore[*].id } for_each ・for_eachとは 事前にfor_eachに格納したmap型のkeyの数だけ，リソースを繰り返し実行する．繰り返し処理を行う時に，countとは違い，要素名を指定して出力できる． ＊実装例＊ 例として，subnetを繰り返し構築する． ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } vpc_cidr = \"n.n.n.n/23\" vpc_subnet_private_datastore_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } vpc_subnet_private_app_cidrs = { a = \"n.n.n.n/25\", c = \"n.n.n.n/25\" } vpc_subnet_public_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } ############################################### # Public subnet ############################################### resource \"aws_subnet\" \"public\" { for_each = var.vpc_availability_zones vpc_id = aws_vpc.this.id cidr_block = var.vpc_subnet_public_cidrs[each.key] availability_zone = \"${var.region}${each.value}\" map_public_ip_on_launch = true tags = { Name = format( \"prd-foo-pub-%s-subnet\", each.value ) } } ・冗長化されたAZにおける設定 冗長化されたAZで共通のルートテーブルを構築する場合，そこで，for_each関数を使用すると，少ない実装で構築できる．for_each関数で構築されたリソースはapply中にmap構造として扱われ，リソース名の下層にキー名でリソースが並ぶ構造になっている．これを参照するために，『.[each.key].』とする ＊実装例＊ パブリックサブネット，プライベートサブネット，プライベートサブネットに紐付くNAT Gatewayの設定が冗長化されたAZで共通の場合，for_each関数で構築する． ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } ############################################### # Internet Gateway ############################################### resource \"aws_internet_gateway\" \"this\" { vpc_id = aws_vpc.this.id tags = { Name = \"prd-foo-igw\" } } ############################################### # Route table (public) ############################################### resource \"aws_route_table\" \"public\" { vpc_id = aws_vpc.this.id route { cidr_block = \"0.0.0.0/0\" gateway_id = aws_internet_gateway.this.id } tags = { Name = \"prd-foo-pub-rtb\" } } ############################################### # Route table (private) ############################################### resource \"aws_route_table\" \"private_app\" { for_each = var.vpc_availability_zones vpc_id = aws_vpc.this.id route { cidr_block = \"0.0.0.0/0\" nat_gateway_id = aws_nat_gateway.this[each.key].id } tags = { Name = format( \"prd-foo-pvt-%s-app-rtb\", each.value ) } } ############################################### # NAT Gateway ############################################### resource \"aws_nat_gateway\" \"this\" { for_each = var.vpc_availability_zones subnet_id = aws_subnet.public[each.key].id allocation_id = aws_eip.nat_gateway[each.key].id tags = { Name = format( \"prd-foo-%s-ngw\", each.value ) } depends_on = [aws_internet_gateway.this] } ・単一値でアウトプット リソースの構築にfor_each関数を使用した場合，そのリソースはmap型として扱われる．そのため，キー名を指定してアウトプットできる． ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } ############################################### # Output VPC ############################################### output \"public_a_subnet_id\" { value = aws_subnet.public[var.vpc_availability_zones.a].id } output \"public_c_subnet_id\" { value = aws_subnet.public[var.vpc_availability_zones.c].id } ・map型でアウトプット ＊実装例＊ ############################################### # Variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } ############################################### # Output VPC ############################################### output \"public_subnet_ids\" { value = { a = aws_subnet.public[var.vpc_availability_zones.a].id, c = aws_subnet.public[var.vpc_availability_zones.c].id } } output \"private_app_subnet_ids\" { value = { a = aws_subnet.private_app[var.vpc_availability_zones.a].id, c = aws_subnet.private_app[var.vpc_availability_zones.c].id } } output \"private_datastore_subnet_ids\" { value = { a = aws_subnet.private_datastore[var.vpc_availability_zones.a].id, c = aws_subnet.private_datastore[var.vpc_availability_zones.c].id } } ############################################### # ALB ############################################### resource \"aws_lb\" \"this\" { name = \"prd-foo-alb\" subnets = values(private_app_subnet_ids) security_groups = [var.alb_security_group_id] internal = false idle_timeout = 120 enable_deletion_protection = true access_logs { enabled = true bucket = var.alb_s3_bucket_id } } dynamic ・dynamicとは 指定したブロックを繰り返し構築する． ＊実装例＊ 例として，RDSパラメータグループのparameterブロックを，map型変数を使用して繰り返し構築する． ############################################### # Variables ############################################### rds_parameter_group_values = { time_zone = \"asia/tokyo\" character_set_client = \"utf8mb4\" character_set_connection = \"utf8mb4\" character_set_database = \"utf8mb4\" character_set_results = \"utf8mb4\" character_set_server = \"utf8mb4\" server_audit_events = \"connect,query,query_dcl,query_ddl,query_dml,table\" server_audit_logging = 1 server_audit_logs_upload = 1 general_log = 1 slow_query_log = 1 long_query_time = 3 } ############################################### # RDS Cluster Parameter Group ############################################### resource \"aws_rds_cluster_parameter_group\" \"this\" { name = \"prd-foo-cluster-pg\" description = \"The cluster parameter group for prd-foo-rds\" family = \"aurora-mysql5.7\" dynamic \"parameter\" { for_each = var.rds_parameter_group_values content { name = parameter.key value = parameter.value } } } ＊実装例＊ 例として，WAFの正規表現パターンセットのregular_expressionブロックを，list型変数を使用して繰り返し構築する． ############################################### # Variables ############################################### waf_blocked_user_agents = [ \"FooCrawler\", \"BarSpider\", \"BazBot\", ] ############################################### # WAF Regex Pattern Sets ############################################### resource \"aws_wafv2_regex_pattern_set\" \"cloudfront\" { name = \"blocked-user-agents\" description = \"Blocked user agents\" scope = \"CLOUDFRONT\" dynamic \"regular_expression\" { for_each = var.waf_blocked_user_agents content { regex_string = regular_expression.value } } } lifecycle ・lifecycleとは リソースの構築，更新，そして削除のプロセスをカスタマイズする． ・create_before_destroy リソースを新しく構築した後に削除するように，変更できる．通常時，Terraformの処理順序として，リソースの削除後に構築が行われる．しかし，他のリソースと依存関係が存在する場合，先に削除が行われることによって，他のリソースに影響が出てしまう．これに対処するために，先に新しいリソースを構築し，紐付けし直してから，削除する必要がある． ＊実装例＊ 例として，ACM証明書を示す．ACM証明書は，ALBやCloudFrontに紐付いており，新しい証明書に紐付け直した後に，既存のものを削除する必要がある． ############################################### # For foo domain ############################################### resource \"aws_acm_certificate\" \"foo\" { # ～ 中略 ～ # 新しい証明書を構築した後に削除する． lifecycle { create_before_destroy = true } } ＊実装例＊ 例として，RDSのクラスターパラメータグループとサブネットグループを示す．クラスターパラメータグループとサブネットグループは，RDSに紐付いており，新しいクラスターパラメータグループに紐付け直した後に，既存のものを削除する必要がある． ############################################### # RDS Cluster Parameter Group ############################################### resource \"aws_rds_cluster_parameter_group\" \"this\" { # ～ 中略 ～ lifecycle { create_before_destroy = true } } ############################################### # RDS Subnet Group ############################################### resource \"aws_db_subnet_group\" \"this\" { # ～ 中略 ～ lifecycle { create_before_destroy = true } ＊実装例＊ 例として，Redisのパラメータグループとサブネットグループを示す．ラメータグループとサブネットグループは，RDSに紐付いており，新しいパラメータグループとサブネットグループに紐付け直した後に，既存のものを削除する必要がある． ############################################### # Redis Parameter Group ############################################### resource \"aws_elasticache_parameter_group\" \"redis\" { # ～ 中略 ～ lifecycle { create_before_destroy = true } } ############################################### # Redis Subnet Group ############################################### resource \"aws_elasticache_subnet_group\" \"redis\" { # ～ 中略 ～ lifecycle { create_before_destroy = true } } ・ignore_changes 実インフラのみで起こったリソースの構築・更新・削除を無視し，tfstateファイルに反映しないようにする．これにより，オプションをignore_changesしたタイミング以降，実インフラとtfstateファイルに差分があっても，tfstateファイルの値が更新されなくなる．一つのテクニックとして，機密情報をignore_changesに指定し，tfstateファイルへの書き込みを防ぐ方法がある． ＊実装例＊ 例として，ECSを示す．ECSでは，AutoScalingによってタスク数が増加する．そのため，これらを無視する必要がある． ############################################### # ECS Service ############################################### resource \"aws_ecs_service\" \"this\" { # ～ 中略 ～ lifecycle { ignore_changes = [ # AutoScalingによるタスク数の増減を無視． desired_count, ] } } ＊実装例＊ 例として，Redisを示す．Redisでは，AutoScalingによってプライマリ数とレプリカ数が増減する．そのため，これらを無視する必要がある． ############################################### # Redis Cluster ############################################### resource \"aws_elasticache_replication_group\" \"redis\" { # ～ 中略 ～ lifecycle { ignore_changes = [ # プライマリ数とレプリカ数の増減を無視します． number_cache_clusters ] } } } ＊実装例＊ 使用例はすくないが，ちなみにリソース全体を無視する場合はallを設定する． resource \"aws_foo\" \"foo\" { # ～ 中略 ～ lifecycle { ignore_changes = all } } 06. tpl形式の切り出しと読み出し templatefile関数 ・templatefile関数とは 第一引数でポリシーが定義されたファイルを読み出し，第二引数でファイルに変数を渡す．ファイルの拡張子はtplとするのがよい． ＊実装例＊ 例として，S3を示す． ############################################### # S3 bucket policy ############################################### resource \"aws_s3_bucket_policy\" \"alb\" { bucket = aws_s3_bucket.alb_logs.id policy = templatefile( \"${path.module}/policies/alb_bucket_policy.tpl\", { aws_elb_service_account_arn = var.aws_elb_service_account_arn aws_s3_bucket_alb_logs_arn = aws_s3_bucket.alb_logs.arn } ) } バケットポリシーを定義するtpl形式ファイルでは，string型で出力する場合は\"${}\"で，int型で出力する場合は${}で出力する．ここで拡張子をjsonにしてしまうと，int型の出力をjsonの構文エラーとして扱われてしまう． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"${aws_elb_service_account_arn}/*\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"${aws_s3_bucket_alb_logs_arn}/*\" } ] } ポリシーのアタッチ containerDefinitionsの設定 ・containerDefinitionsとは タスク定義のうち，コンテナを定義する部分のこと． ＊実装例＊ { \"ipcMode\": null, \"executionRoleArn\": \"\", \"containerDefinitions\": [ ], ~ ~ ~ その他の設定 ~ ~ ~ } ・設定方法 int型を変数として渡せるように，拡張子をjsonではなくtplとするのが良い．imageキーでは，ECRイメージのURLを指定する．イメージタグは任意で指定でき，もし指定しない場合は，『latest』という名前のタグが自動的に割り当てられる．イメージタグにハッシュ値が割り当てられている場合，Terraformでは時系列で最新のタグ名を取得する方法がないため，，secretsキーでは，SSMのパラメータストアの値を参照できる．ログ分割の目印を設定するawslogs-datetime-formatキーでは，タイムスタンプを表す\\\\[%Y-%m-%d %H:%M:%S\\\\]を設定すると良い．これにより，同じ時間に発生したログを一つのログとしてまとめることができるため，スタックトレースが見やすくなる． ＊実装例＊ [ { # コンテナ名 \"name\": \"laravel\", # ECRのURL．タグを指定しない場合はlatestが割り当てられる． \"image\": \"*****.dkr.ecr.ap-northeast-1.amazonaws.com/prd-foo-laravel-repository\", \"essential\": true, \"portMappings\": [ { \"containerPort\": 80, \"hostPort\": 80, \"protocol\": \"tcp\" } ], \"secrets\": [ { # アプリケーションの環境変数名 \"name\": \"DB_HOST\", # SSMのパラメータ名 \"valueFrom\": \"/prd-foo/DB_HOST\" }, { \"name\": \"DB_DATABASE\", \"valueFrom\": \"/prd-foo/DB_DATABASE\" }, { \"name\": \"DB_PASSWORD\", \"valueFrom\": \"/prd-foo/DB_PASSWORD\" }, { \"name\": \"DB_USERNAME\", \"valueFrom\": \"/prd-foo/DB_USERNAME\" }, { \"name\": \"REDIS_HOST\", \"valueFrom\": \"/prd-foo/REDIS_HOST\" }, { \"name\": \"REDIS_PASSWORD\", \"valueFrom\": \"/prd-foo/REDIS_PASSWORD\" }, { \"name\": \"REDIS_PORT\", \"valueFrom\": \"/prd-foo/REDIS_PORT\" } ], \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { # ロググループ名 \"awslogs-group\": \"/prd-foo/laravel/log\", # スタックトレースのグループ化（同時刻ログのグループ化） \"awslogs-datetime-format\": \"\\\\[%Y-%m-%d %H:%M:%S\\\\]\", # リージョン \"awslogs-region\": \"ap-northeast-1\", # ログストリーム名のプレフィクス \"awslogs-stream-prefix\": \"/container\" } } } ] 07. 命名規則 module AWSリソースのアルファベット順にmoduleを並べる．また，変数やアウトプット値をモジュールに渡す時もAWSリソースのアルファベット順とする． 変数の命名 ・単数形と複数形の命名分け 複数の値を持つlist型の変数であれば複数形で命名する．一方で，string型など値が一つしかなければ単数形とする． ＊実装例＊ 例として，VPCを示す． ############################################### # VPC variables ############################################### vpc_availability_zones = { a = \"a\", c = \"c\" } vpc_cidr = \"n.n.n.n/23\" vpc_subnet_private_datastore_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } vpc_subnet_private_app_cidrs = { a = \"n.n.n.n/25\", c = \"n.n.n.n/25\" } vpc_subnet_public_cidrs = { a = \"n.n.n.n/27\", c = \"n.n.n.n/27\" } 環境変数の命名 AWSリソースのアルファベット順に環境変数を並べる，環境変数の名前は，使用するAWSリソースの名前を最初につけるようにする．list型またはmap型であれば複数形，それ以外であれば単数形とする． ############################################### # Route53 ############################################### # ～ 中略 ～ ############################################### # VPC ############################################### # ～ 中略 ～ ############################################### # WAF ############################################### waf_blocked_user_agents = [ \"AdCrawler\", ] 複数のAWSリソースで使用する場合は，『General』とし，グローバルな名前にする． ############################################### # General ############################################### camel_case_prefix = \"Bar\" region = \"ap-northeast-1\" environment = \"stg\" service = \"bar\" リソースとデータリソースの命名 ・リソース名で種類を表現 リソース名において，リソースタイプを繰り返さないようにする．もし種類がある場合，リソース名でその種類を表現する． ＊実装例＊ 例として，VPCを示す． ############################################### # VPC route table ############################################### # 良い例 resource \"aws_route_table\" \"public\" { } resource \"aws_route_table\" \"private\" { } ############################################### # VPC route table ############################################### # 悪い例 resource \"aws_route_table\" \"route_table_public\" { } resource \"aws_route_table\" \"route_table_private\" { } ・this 一つのリソースタイプに，一つのリソースしか種類が存在しない場合，thisで命名する．ただし，後から種類が増えることがよくあるため，非推奨である． ＊実装例＊ resource \"aws_internet_gateway\" \"this\" { } ・AWSリソース名 --とする． 接頭辞は， -とする． 接尾辞は，AWSリソース名とする． ＊実装例＊ 例として，CloudWatchを示す．この時，他のresourceと比較して，種類はALBのHTTPCode_TARGET_4XX_Countメトリクスに関するアラームと見なせる．そのため，alb_httpcode_4xx_countと名付けている． resource \"aws_cloudwatch_metric_alarm\" \"alb_httpcode_target_4xx_count\" { alarm_name = \"prd-foo-alb-httpcode-target-4xx-count-alarm\" } ・設定の順序，行間 最初にcountやfor_eachを設定し改行する．その後，各リソース別の設定を行間を空けずに記述する（この順番にルールはなし）．最後に共通の設定として，tags，depends_on，lifecycle，の順で配置する．ただし実際，これらの全ての設定が必要なリソースはない． ＊実装例＊ ############################################### # EXAMPLE ############################################### resource \"aws_baz\" \"this\" { for_each = var.vpc_availability_zones # 最初にfor_each # スペース subnet_id = aws_subnet.public[*].id # 各設定（順番にルールなし） # スペース tags = { Name = format( \"prd-foo-%d-baz\", each.value ) } # スペース depends_on = [] # スペース lifecycle { create_before_destroy = true } } アウトプット値の命名 ・基本ルール アウトプット値の名前は，『__』で命名する． ＊実装例＊ 例として，CloudWatchを示す．リソース名はecs_container_nginx，リソースタイプはaws_cloudwatch_log_group，attributeはnameオプションである． output \"ecs_container_nginx_cloudwatch_log_group_name\" { value = aws_cloudwatch_log_group.ecs_container_nginx.name } ＊実装例＊ 例として，IAM Roleを示す． ############################################### # Output IAM Role ############################################### output \"ecs_task_execution_iam_role_arn\" { value = aws_iam_role.ecs_task_execution.arn } output \"lambda_execute_iam_role_arn\" { value = aws_iam_role.lambda_execute.arn } output \"rds_enhanced_monitoring_iam_role_arn\" { value = aws_iam_role.rds_enhanced_monitoring.arn } ・thisは省略 リソース名がthisである場合，アウトプット値名ではこれを省略してもよい． ＊実装例＊ 例として，ALBを示す． ############################################### # Output ALB ############################################### output \"alb_zone_id\" { value = aws_lb.this.zone_id } output \"alb_dns_name\" { value = aws_lb.this.dns_name } ・冗長なattribute名は省略 ＊実装例＊ 例として，ECRを示す． ############################################### # Output ECR ############################################### output \"laravel_ecr_repository_url\" { value = aws_ecr_repository.laravel.repository_url } output \"nginx_ecr_repository_url\" { value = aws_ecr_repository.nginx.repository_url } "},"public/infrastructure_as_code/infrastructure_as_code_terraform_aws_tips.html":{"url":"public/infrastructure_as_code/infrastructure_as_code_terraform_aws_tips.html","title":"📖 ︎Terraformを用いたAWS構築Tips","keywords":"","body":"Terraformを用いたAWS構築Tips はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. AMI まとめ ＊実装例＊ ############################################### # For bastion ############################################### data \"aws_ami\" \"bastion\" { # 後述の説明を参考にせよ．（１） most_recent = false # 後述の説明を参考にせよ．（１） owners = [\"amazon\"] filter { name = \"name\" values = [\"amzn-ami-hvm-2018.03.0.20201028.0-x86_64-gp2\"] } filter { name = \"image-id\" values = [\"ami-040c9333a9c90b2b6\"] } } （１）取得するAMIのバージョンを固定 取得するAMIが常に最新になっていると，EC2が再構築されなねない．そこで，特定のAMIを取得できるようにしておく．most_recentは無効化しておき，特定のAMをフィルタリングする． 02. API Gateway まとめ ＊実装例＊ ############################################### # REST API ############################################### resource \"aws_api_gateway_rest_api\" \"foo\" { name = \"prd-foo-api-for-foo\" description = \"The API that enables two-way communication with prd-foo\" # VPCリンクのプロキシ統合のAPIを定義したOpenAPI仕様 # 後述の説明を参考にせよ．（１） body = templatefile( \"${path.module}/open_api.yaml\", { api_gateway_vpc_link_foo_id = aws_api_gateway_vpc_link.foo.id nlb_dns_name = var.nlb_dns_name } ) endpoint_configuration { types = [\"REGIONAL\"] } lifecycle { ignore_changes = [ policy ] } } ############################################### # Deployment ############################################### resource \"aws_api_gateway_deployment\" \"foo\" { rest_api_id = aws_api_gateway_rest_api.foo.id # 後述の説明を参考にせよ．（１） triggers = { redeployment = sha1(aws_api_gateway_rest_api.foo.body) } lifecycle { create_before_destroy = true } } ############################################### # Stage ############################################### resource \"aws_api_gateway_stage\" \"foo\" { deployment_id = aws_api_gateway_deployment.foo.id rest_api_id = aws_api_gateway_rest_api.foo.id stage_name = var.environment } （１）OpenAPI仕様のインポートと差分認識 あらかじめ用意したOpenAPI仕様のYAMLファイルをbodyオプションのパラメータとし，これをインポートすることにより，APIを定義できる．YAMLファイルに変数を渡すこともできる．APIの再デプロイのトリガーとして，redeploymentパラメータにbodyパラメータのハッシュ値を渡すようにする．これにより，インポート元のYAMLファイルに差分があった場合に，Terraformがredeploymentパラメータの値の変化を認識できるようになり，再デプロイを実行できる． （※）ステージ名を取得する方法はない API Gatewayのステージ名を参照するためには，resourceを使用する必要があり，dataではこれを取得することができない．もしステージをコンソール画面上から構築している場合，ステージのARNを参照することができないため，ARNを自力で作る必要がある．API Gatewayの各ARNについては，以下を参考にせよ． 参考：https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/arn-format-reference.html ＊実装例＊ WAFにAPI Gatewayを紐付けるために，ステージのARNが必要である．これは自力で作る． ############################################### # Web ACL Association ############################################### resource \"aws_wafv2_web_acl_association\" \"api_gateway\" { resource_arn = \"${var.api_gateway_rest_arn}/stages/prd\" web_acl_arn = aws_wafv2_web_acl.api_gateway.arn } 03. CloudFront まとめ ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { price_class = \"PriceClass_200\" web_acl_id = var.cloudfront_wafv2_web_acl_arn aliases = [var.route53_domain_foo] comment = \"prd-foo-cf-distribution\" enabled = true # 後述の説明を参考にせよ．（１） retain_on_delete = true viewer_certificate { acm_certificate_arn = var.foo_acm_certificate_arn ssl_support_method = \"sni-only\" minimum_protocol_version = \"TLSv1.2_2019\" } logging_config { bucket = var.cloudfront_s3_bucket_regional_domain_name include_cookies = true } restrictions { geo_restriction { restriction_type = \"none\" } } # ～ 中略 ～ } （１）削除保持機能 Terraformでは，retain_on_deleteで設定できる．固有の設定で，AWSに対応するものは無い． originブロック Origins画面に設定するオリジンを定義する． ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { # ～ 中略 ～ # オリジン（ここではS3としている） origin { domain_name = var.s3_bucket_regional_domain_name origin_id = \"S3-${var.s3_bucket_id}\" s3_origin_config { origin_access_identity = aws_cloudfront_origin_access_identity.s3_foo.cloudfront_access_identity_path } } # ～ 中略 ～ } resource \"aws_cloudfront_distribution\" \"this\" { # ～ 中略 ～ # オリジン（ここではALBとしている） origin { domain_name = var.alb_dns_name origin_id = \"ELB-${var.alb_name}\" custom_origin_config { origin_ssl_protocols = [\"TLSv1.2\"] origin_protocol_policy = \"match-viewer\" origin_read_timeout = 30 origin_keepalive_timeout = 5 http_port = var.alb_listener_port_http https_port = var.alb_listener_port_https } } # ～ 中略 ～ } ordered_cache_behaviorブロック Behavior画面に設定するオリジンにルーティングするパスを定義する． ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { # ～ 中略 ～ ordered_cache_behavior { path_pattern = \"/images/*\" target_origin_id = \"S3-${var.s3_bucket_id}\" viewer_protocol_policy = \"redirect-to-https\" allowed_methods = [\"GET\", \"HEAD\", \"OPTIONS\", \"PUT\", \"POST\", \"PATCH\", \"DELETE\"] cached_methods = [\"GET\", \"HEAD\"] min_ttl = 0 max_ttl = 31536000 default_ttl = 86400 compress = true forwarded_values { query_string = true cookies { forward = \"none\" } } } # ～ 中略 ～ } default_cache_behavior Behavior画面に設定するオリジンにルーティングする標準パスを定義する． ＊実装例＊ resource \"aws_cloudfront_distribution\" \"this\" { default_cache_behavior { target_origin_id = \"ELB-${var.alb_name}\" viewer_protocol_policy = \"redirect-to-https\" allowed_methods = [\"GET\", \"HEAD\", \"OPTIONS\", \"PUT\", \"POST\", \"PATCH\", \"DELETE\"] cached_methods = [\"GET\", \"HEAD\"] min_ttl = 0 max_ttl = 31536000 default_ttl = 86400 compress = true forwarded_values { query_string = true headers = [\"*\"] cookies { forward = \"all\" } } } # ～ 中略 ～ } 04. ECR ライフサイクルポリシー ECRにアタッチされる，イメージの有効期間を定義するポリシー．コンソール画面から入力できるため，基本的にポリシーの実装は不要であるが，TerraformなどのIaCツールでは必要になる． { \"rules\": [ { \"rulePriority\": 1, \"description\": \"Keep last 10 images untagged\", \"selection\": { \"tagStatus\": \"untagged\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } }, { \"rulePriority\": 2, \"description\": \"Keep last 10 images any\", \"selection\": { \"tagStatus\": \"any\", \"countType\": \"imageCountMoreThan\", \"countNumber\": 10 }, \"action\": { \"type\": \"expire\" } } ] } 05. ECS まとめ ＊実装例＊ ############################################### # ECS Service ############################################### resource \"aws_ecs_service\" \"this\" { name = \"prd-foo-ecs-service\" cluster = aws_ecs_cluster.this.id launch_type = \"FARGATE\" platform_version = \"1.4.0\" desired_count = var.ecs_service_desired_count deployment_maximum_percent = 200 deployment_minimum_healthy_percent = 100 # 後述の説明を参考にせよ．（１） health_check_grace_period_seconds = 330 # 後述の説明を参考にせよ．（２） task_definition = \"${aws_ecs_task_definition.this.family}:${max(aws_ecs_task_definition.this.revision, data.aws_ecs_task_definition.this.revision)}\" network_configuration { security_groups = [var.ecs_security_group_id] subnets = [var.private_a_app_subnet_id, var.private_c_app_subnet_id] assign_public_ip = false } load_balancer { target_group_arn = var.alb_target_group_arn container_name = \"nginx\" container_port = 80 } load_balancer { target_group_arn = var.nlb_target_group_arn container_name = \"nginx\" container_port = 80 } depends_on = [ # 後述の説明を参考にせよ．（３） var.alb_listener_https, var.nlb_listener ] lifecycle { ignore_changes = [ # ※後述の説明を参考にせよ（４） desired_count, ] } } （１）ヘルスチェック猶予期間 タスクの起動が完了する前にサービスがロードバランサ－のヘルスチェックを検証し，Unhealthyと誤認してしまうため，タスクの起動完了を待機する．例えば，ロードバランサ－が30秒間隔でヘルスチェックを実行する場合は，30秒単位で待機時間を増やし，適切な待機時間を見つけるようにする． （２）実インフラのリビジョン番号の追跡 アプリケーションのデプロイによって，実インフラのタスク定義のリビジョン番号が増加するため，これを追跡できるようにする． 参考：https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/ecs_task_definition （３）ALB/NLBリスナーの構築を待機 Teraformは，特に依存関係を実装しない場合に，『ターゲットグループ → ALB/NLB → リスナー』の順でリソースを構築する．問題として，ALB/NLBやリスナーの構築が終わる前に，ECSサービスの構築が始まってしまう．ALB/NLBの構築（※リスナーも含む可能性）が完全に完了しない状態では，ターゲットグループはECSサービスに紐付けらず，これが完了する前にECSサービスがターゲットグループを参照しようとするため，エラーになる．リスナーの後にECSサービスを構築するようにし，『ターゲットグループ → ALB/NLB → リスナー → ECSサービス』の順でリソースを構築できるようにする． 参考：https://github.com/hashicorp/terraform/issues/12634#issuecomment-313215022 （４）AutoScalingによるタスク数の増減を無視 AutoScalingによって，タスク数が増減するため，これを無視する． （※）タスク定義の更新 Terraformでタスク定義を更新すると，現在動いているECSで稼働しているタスクはそのままに，新しいリビジョン番号のタスク定義が作成される．コンソール画面の「新しいリビジョンの作成」と同じ挙動である．実際にタスクが増えていることは，サービスに紐付くタスク定義一覧から確認できる．次のデプロイ時に，このタスクが用いられる． （※）サービスのデプロイの削除時間 ECSサービスの削除には『ドレイニング』の時間が発生する．約2分30秒かかるため，気長に待つこと． （※）ローリングアップデート applyで，新しいリビジョン番号のタスク定義を作成すると，これを用いてローリングアップデートが自動で実行されることに注意する．ただ，ローリングアップデートの仕組み上，新しいタスクのヘルスチェックが失敗すれば，既存のタスクは停止せずにそのまま稼働するため，安心ではあるが． 06. EC2 まとめ ＊実装例＊ ############################################### # For bastion ############################################### resource \"aws_instance\" \"bastion\" { ami = \"*****\" instance_type = \"t2.micro\" vpc_security_group_ids = [\"*****\"] subnet_id = \"*****\" associate_public_ip_address = true # ※後述の説明を参考にせよ（１） key_name = \"prd-foo-bastion\" disable_api_termination = true tags = { Name = \"prd-foo-bastion\" } # ※後述の説明を参考にせよ（２） depends_on = [var.internet_gateway] } （１）キーペアはコンソール上で設定 誤って削除しないように，またソースコードに機密情報をハードコーディングしないように，キーペアはコンソール画面で作成した後，key_nameでキー名を指定するようにする． （２）インターネットゲートウェイの後に構築 インターネットゲートウェイの後にEC2を構築できるようにする． 参考：https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/internet_gateway#argument-reference 07. IAMユーザ カスタマー管理ポリシーを持つロール 事前に，tpl形式のカスタマー管理ポリシーを定義しておく．構築済みのIAMロールに，aws_iam_policyリソースを使用して，AWS管理ポリシーをIAMユーザにアタッチする． ＊実装例＊ ローカルからAWS CLIコマンドを実行する必要がある場合に，コマンドを特定の送信元IPアドレスを特定のものに限定する．事前に，list型でIPアドレスを定義する． ############################################### # IP addresses ############################################### global_ip_addresses = [ \"nn.nnn.nnn.nnn/32\", \"nn.nnn.nnn.nnn/32\" ] また事前に，指定した送信元IPアドレス以外を拒否するカスタマー管理ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Deny\", \"Action\": \"*\", \"Resource\": \"*\", \"Condition\": { \"NotIpAddress\": { \"aws:SourceIp\": ${global_ip_addresses} } } } } コンソール画面で作成済みのIAMユーザの名前を取得する．tpl形式のポリシーにlist型の値を渡す時，jsonencode関数を使用する必要がある． ############################################### # For IAM User ############################################### data \"aws_iam_user\" \"aws_cli_command_executor\" { user_name = \"aws_cli_command_executor\" } resource \"aws_iam_policy\" \"aws_cli_command_executor_ip_address_restriction\" { name = \"prd-aws-cli-command-executor-ip-address-restriction-policy\" description = \"Allow global IP addresses\" policy = templatefile( \"${path.module}/policies/customer_managed_policies/aws_cli_command_executor_ip_address_restriction_policy.tpl\", { global_ip_addresses = jsonencode(var.global_ip_addresses) } ) } AWS管理ポリシー IAMユーザにAWS管理ポリシーをアタッチする． ＊実装例＊ ############################################### # For IAM User ############################################### resource \"aws_iam_user_policy_attachment\" \"aws_cli_command_executor_s3_read_only_access\" { user = data.aws_iam_user.aws_cli_command_executor.user_name policy_arn = \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\" } 08. IAMロール 信頼ポリシーを持つロール コンソール画面でロールを作成する場合は意識することはないが，特定のリソースにロールをアタッチするためには，ロールに信頼ポリシーを組み込む必要がある．事前に，tpl形式の信頼ポリシーを定義しておく．aws_iam_roleリソースを使用して，IAMロールを構築すると同時に，これに信頼ポリシーをアタッチする． ＊実装例＊ 事前に，ECSタスクのための信頼ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ecs-tasks.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] } ECSタスクロールとECSタスク実行ロールに信頼ポリシーアタッチする． ############################################### # IAM Role For ECS Task Execution ############################################### resource \"aws_iam_role\" \"ecs_task_execution\" { name = \"prd-foo-ecs-task-execution-role\" description = \"The role for prd-foo-ecs-task\" assume_role_policy = templatefile( \"${path.module}/policies/trust_policies/ecs_task_policy.tpl\", {} ) } ############################################### # IAM Role For ECS Task ############################################### resource \"aws_iam_role\" \"ecs_task\" { name = \"prd-foo-ecs-task-role\" description = \"The role for prd-foo-ecs-task\" assume_role_policy = templatefile( \"${path.module}/policies/trust_policies/ecs_task_policy.tpl\", {} ) } ＊実装例＊ 事前に，Lambda@Edgeのための信頼ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": [ \"lambda.amazonaws.com\", \"edgelambda.amazonaws.com\" ] }, \"Action\": \"sts:AssumeRole\" } ] } Lambda実行ロールに信頼ポリシーアタッチする． ############################################### # IAM Role For Lambda@Edge ############################################### # ロールに信頼ポリシーをアタッチします． resource \"aws_iam_role\" \"lambda_execute\" { name = \"prd-foo-lambda-execute-role\" assume_role_policy = templatefile( \"${path.module}/policies/lambda_execute_role_trust_policy.tpl\", {} ) } インラインポリシーを持つロール 事前に，tpl形式のインラインポリシーを定義しておく．aws_iam_role_policyリソースを使用して，インラインポリシーを構築すると同時に，これにインラインポリシーをアタッチする． ＊実装例＊ 事前に，ECSタスクに必要最低限の権限を与えるインラインポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"ssm:GetParameters\" ], \"Resource\": \"*\" } ] } ECSタスクロールとECSタスク実行ロールにインラインポリシーアタッチする． ############################################### # IAM Role For ECS Task ############################################### resource \"aws_iam_role_policy\" \"ecs_task\" { name = \"prd-foo-ssm-read-only-access-policy\" role = aws_iam_role.ecs_task_execution.id policy = templatefile( \"${path.module}/policies/inline_policies/ecs_task_policy.tpl\", {} ) } AWS管理ポリシーを持つロール 事前に，tpl形式のAWS管理ポリシーを定義しておく．aws_iam_role_policy_attachmentリソースを使用して，実インフラにあるAWS管理ポリシーを構築済みのIAMロールにアタッチする．ポリシーのARNは，AWSのコンソール画面を確認する． ＊実装例＊ ############################################### # IAM Role For ECS Task Execution ############################################### resource \"aws_iam_role_policy_attachment\" \"ecs_task_execution\" { role = aws_iam_role.ecs_task_execution.name policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\" } カスタマー管理ポリシーを持つロール 事前に，tpl形式のインラインポリシーを定義しておく．aws_iam_role_policyリソースを使用して，カスタマー管理ポリシーを構築する．aws_iam_role_policy_attachmentリソースを使用して，カスタマー管理ポリシーを構築済みのIAMロールにアタッチする． ＊実装例＊ 事前に，ECSタスクに必要最低限の権限を与えるカスタマー管理ポリシーを定義する． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"logs:CreateLogStream\", \"logs:PutLogEvents\" ], \"Resource\": [ \"arn:aws:logs:*:*:*\" ] } ] } ECSタスクロールにカスタマー管理ポリシーアタッチする． ############################################### # IAM Role For ECS Task ############################################### resource \"aws_iam_policy\" \"ecs_task\" { name = \"prd-foo-cloudwatch-logs-access-policy\" description = \"Provides access to CloudWatch Logs\" policy = templatefile( \"${path.module}/policies/customer_managed_policies/cloudwatch_logs_access_policy.tpl\", {} ) } resource \"aws_iam_role_policy_attachment\" \"ecs_task\" { role = aws_iam_role.ecs_task.name policy_arn = aws_iam_policy.ecs_task.arn } サービスリンクロール サービスリンクロールは，AWSリソースの構築時に自動的に作成され，アタッチされる．そのため，Terraformの管理外である．aws_iam_service_linked_roleリソースを使用して，手動で構築することが可能であるが，数が多く実装の負担にもなるため，あえて管理外としても問題ない． ＊実装例＊ サービス名を指定して，Application Auto Scalingのサービスリンクロールを構築する． ############################################### # IAM Role For ECS Service ############################################### # Service Linked Role resource \"aws_iam_service_linked_role\" \"ecs_service_auto_scaling\" { aws_service_name = \"ecs.application-autoscaling.amazonaws.com\" } ############################################### # Output IAM Role ############################################### output \"ecs_service_auto_scaling_iam_service_linked_role_arn\" { value = aws_iam_service_linked_role.ecs_service_auto_scaling.arn } Application Auto Scalingにサービスリンクロールをアタッチする．手動で設定することも可能であるが，Terraformの管理外で自動的にアタッチされるため，あえて妥協しても良い． ######################################### # Application Auto Scaling For ECS ######################################### resource \"aws_appautoscaling_target\" \"ecs\" { service_namespace = \"ecs\" resource_id = \"service/prd-foo-ecs-cluster/prd-foo-ecs-service\" scalable_dimension = \"ecs:service:DesiredCount\" max_capacity = 4 min_capacity = 2 # この設定がなくとも，サービスリンクロールが自動的に構築され，AutoScalingにアタッチされる． role_arn = var.ecs_service_auto_scaling_iam_service_linked_role_arn } 10. LBリスナーとターゲットグループ まとめ ＊実装例＊ ############################################### # NLB target group ############################################### resource \"aws_lb_target_group\" \"this\" { name = \"prd-foo-nlb-tg\" port = 80 protocol = \"TCP\" vpc_id = \"*****\" deregistration_delay = \"60\" target_type = \"ip\" # ※後述の説明を参考にせよ（１） slow_start = \"0\" # ※後述の説明を参考にせよ（２） health_check { protocol = \"HTTP\" healthy_threshold = 3 path = \"/healthcheck\" } # stickiness ※後述の説明を参考にせよ（３） # https://registry.terraform.io/providers/hashicorp/aws/3.16.0/docs/resources/lb_target_group#stickiness lifecycle { create_before_destroy = false } } （１）NLBはスロースタートに非対応 NLBに紐付くターゲットグループはスロースタートに非対応のため，これを明示的に無効化する必要がある． （２）NLBヘルスチェックには設定可能な項目が少ない ターゲットグループの転送プロトコルがTCPの場合は，設定できないヘルスチェックオプションがいくつかある．ヘルスチェックプロトコルがHTTPまたはHTTPSの時のみ，パスを設定できる． 参考：https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lb_target_group#health_check （３）NLBスティッキーネスは明示的に無効化 スティッキネス機能を無効化する場合，AWSプロバイダーのアップグレード時に問題が起こらないように，このブロックを実装しないようにする．リンク先のNOTE文を参考にせよ． 参考：https://registry.terraform.io/providers/hashicorp/aws/3.16.0/docs/resources/lb_target_group#stickiness （※）ターゲットグループの削除時にリスナーを先に削除できない． LBリスナーがターゲットグループに依存しているが，Terraformがターゲットグループの削除時にリスナーを先に削除しようとしないため，以下のようなエラーが発生する． Error deleting Target Group: ResourceInUse: Target group 'arn:aws:elasticloadbalancing:ap-northeast-1:123456789:targetgroup/xxxxx-tg/xxxxx' is currently in use by a listener or a rule status code: 400, request id: xxxxx このエラーが発生した場合，コンソール画面上でLBリスナーを削除したうえで，もう一度applyする． 参考：https://github.com/hashicorp/terraform-provider-aws/issues/1315#issuecomment-415423529 11. RDS まとめ ＊実装例＊ ######################################### # RDS Cluster ######################################### resource \"aws_rds_cluster\" \"this\" { engine = \"aurora-mysql\" engine_version = \"5.7.mysql_aurora.2.08.3\" cluster_identifier = \"prd-foo-rds-cluster\" # 後述の説明を参考にせよ．（１） master_username = var.rds_db_master_username_ssm_parameter_value master_password = var.rds_db_master_password_ssm_parameter_value port = var.rds_db_port_ssm_parameter_value database_name = var.rds_db_name_ssm_parameter_value vpc_security_group_ids = [var.rds_security_group_id] db_subnet_group_name = aws_db_subnet_group.this.name db_cluster_parameter_group_name = aws_rds_cluster_parameter_group.this.id storage_encrypted = true backup_retention_period = 7 preferred_backup_window = \"00:00-00:30\" copy_tags_to_snapshot = true final_snapshot_identifier = \"final-db-snapshot\" skip_final_snapshot = false enabled_cloudwatch_logs_exports = [\"audit\", \"error\", \"general\", \"slowquery\"] preferred_maintenance_window = \"sun:01:00-sun:01:30\" # 後述の説明を参考にせよ．（２） apply_immediately = true # 後述の説明を参考にせよ．（３） availability_zones = [\"${var.region}${var.vpc_availability_zones.a}\", \"${var.region}${var.vpc_availability_zones.c}\"] deletion_protection = true lifecycle { ignore_changes = [ # 後述の説明を参考にせよ．（４） availability_zones ] } } ############################################### # RDS Cluster Instance ############################################### resource \"aws_rds_cluster_instance\" \"this\" { for_each = var.vpc_availability_zones engine = \"aurora-mysql\" engine_version = \"5.7.mysql_aurora.2.08.3\" identifier = \"prd-foo-rds-instance-${each.key}\" cluster_identifier = aws_rds_cluster.this.id instance_class = var.rds_instance_class db_subnet_group_name = aws_db_subnet_group.this.id db_parameter_group_name = aws_db_parameter_group.this.id monitoring_interval = 60 monitoring_role_arn = var.rds_iam_role_arn auto_minor_version_upgrade = var.rds_auto_minor_version_upgrade preferred_maintenance_window = \"sun:01:00-sun:01:30\" apply_immediately = true # 後述の説明を参考にせよ．（５） # preferred_backup_window } （１）SSMパラメータストア Terraformに値をハードコーディングしたくない場合は，SSMパラメータストアで値を管理し，これをデータリソースで取得するようにする． （２）メンテナンスウインドウ時に変更適用 メンテナンスウインドウ時の変更適用をTerraformで行う場合，一段階目にapply_immediatelyオプションをfalseに変更してapplyし，二段階目に修正をapplyする． （３）クラスターにはAZが３つ必要 クラスターでは，レプリケーションのために，３つのAZが必要である．そのため，指定したAZが２つであっても，コンソール画面上で３つのAZが自動的に設定される．Terraformがこれを認識しないように，ignore_changesでAZを指定しておく必要がある． 参考： https://github.com/hashicorp/terraform-provider-aws/issues/7307#issuecomment-457441633 https://github.com/hashicorp/terraform-provider-aws/issues/1111 （４）インスタンスを配置するAZは選べない 事前にインスタンスにAZを表す識別子を入れたとしても，Terraformはインスタンスを配置するAZを選べない．そのため，AZと識別子の関係が逆になってしまうことがある．多くの場合， Cゾーンのインスタンスが最初に構築されるため，インスタンスのゾーン名と配置されるA/Cゾーンが逆になる．その場合は，デプロイ後に手動で名前を変更すればよい．この変更は，Terraformが差分として認識しないので問題ない． （５）インスタンスにバックアップウインドウは設定しない クラスターとインスタンスの両方に，preferred_backup_windowを設定できるが，RDSインスタンスに設定してはいけない． 12. Route53 まとめ ＊実装例＊ ############################################### # For foo domain ############################################### resource \"aws_route53_zone\" \"foo\" { name = var.route53_domain_foo } resource \"aws_route53_record\" \"foo\" { zone_id = aws_route53_zone.foo.id name = var.route53_domain_foo type = \"A\" alias { name = var.alb_dns_name zone_id = var.alb_zone_id evaluate_target_health = false } } 13. Route Table メインルートテーブルは自動構築 Terraformを用いてVPCを構築した時，メインルートテーブルが自動的に構築される．そのため，これはTerraformの管理外である． 14. S3 バケットポリシー S3アタッチされる，自身へのアクセスを制御するためにインラインポリシーのこと．定義したバケットポリシーは，aws_s3_bucket_policyでロールにアタッチできる． ALBアクセスログ ALBがバケットにログを書き込めるように，『ELBのサービスアカウントID』を許可する必要がある． ＊実装例＊ ############################################### # S3 bucket policy ############################################### # S3にバケットポリシーをアタッチします． resource \"aws_s3_bucket_policy\" \"alb\" { bucket = aws_s3_bucket.alb_logs.id policy = templatefile( \"${path.module}/policies/alb_bucket_policy.tpl\", {} ) } ALBのアクセスログを送信するバケット内には，自動的に『/AWSLogs/』の名前でディレクトリが生成される．そのため，『arn:aws:s3:::/*』の部分を最小権限として，『arn:aws:s3:::/AWSLogs//;*』にしてもよい．東京リージョンのELBサービスアカウントIDは，『582318560864』である． 参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-access-logs.html#access-logging-bucket-permissions { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::582318560864:root\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::/*\" } ] } NLBアクセスログ ALBがバケットにログを書き込めるように，『delivery.logs.amazonaws.com』からのアクセスを許可する必要がある． ＊実装例＊ ############################################### # S3 bucket policy ############################################### # S3にバケットポリシーをアタッチします． resource \"aws_s3_bucket_policy\" \"nlb\" { bucket = aws_s3_bucket.nlb_logs.id policy = templatefile( \"${path.module}/policies/nlb_bucket_policy.tpl\", {} ) } NLBのアクセスログを送信するバケット内には，自動的に『/AWSLogs/』の名前でディレクトリが生成される．そのため，『arn:aws:s3:::/*』の部分を最小権限として，『arn:aws:s3:::/AWSLogs//;*』にしてもよい． { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"AWSLogDeliveryWrite\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"delivery.logs.amazonaws.com\" }, \"Action\": \"s3:PutObject\", \"Resource\": \"arn:aws:s3:::/*\", \"Condition\": { \"StringEquals\": { \"s3:x-amz-acl\": \"bucket-owner-full-control\" } } }, { \"Sid\": \"AWSLogDeliveryAclCheck\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"delivery.logs.amazonaws.com\" }, \"Action\": \"s3:GetBucketAcl\", \"Resource\": \"arn:aws:s3:::\" } ] } 15. WAF ruleブロック ＊実装例＊ API Gateway用のWAFに，特定のユーザエージェントを拒否するルールを設定する． resource \"aws_wafv2_web_acl\" \"api_gateway\" { rule { name = \"block-user-agents\" priority = 0 statement { regex_pattern_set_reference_statement { # 別ディレクトリのmain.tfファイルに分割した正規表現パターンセットを参照する． arn = var.wafv2_regex_pattern_set_regional_block_user_agents_arn field_to_match { # ヘッダーを検証する． single_header { name = \"user-agent\" } } text_transformation { priority = 0 type = \"NONE\" } } } action { block {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFBlockUserAgentsRule\" sampled_requests_enabled = true } } default_action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayALBWAFRules\" sampled_requests_enabled = true } # ～ 中略 ～ } ＊実装例＊ API Gateway用のWAFに，特定のグローバルIPアドレスを拒否するルールを設定する． resource \"aws_wafv2_web_acl\" \"api_gateway\" { rule { name = \"block-global-ip-addresses\" priority = 0 statement { ip_set_reference_statement { # 別ディレクトリのmain.tfファイルに分割したIPアドレスセットを参照する． arn = var.waf_blocked_global_ip_addresses } } action { block {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFBlockGlobalIPAddressesRule\" sampled_requests_enabled = true } } default_action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFRules\" sampled_requests_enabled = true } # ～ 中略 ～ } ＊実装例＊ API Gateway用のWAFに，SQLインジェクションを拒否するマネージドルールを設定する． resource \"aws_wafv2_web_acl\" \"api_gateway\" { rule { name = \"block-sql-injection\" priority = 0 statement { # マネージドルールを使用する． managed_rule_group_statement { vendor_name = \"AWS\" name = \"AWSManagedRulesSQLiRuleSet\" } } override_action { count {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFBlockSQLInjectionRule\" sampled_requests_enabled = true } } default_action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFRules\" sampled_requests_enabled = true } # ～ 中略 ～ } ＊実装例＊ ALB用のWAFに，APIキーまたはBearerトークンをOR条件ルールを設定する．あくまで例としてで，本来であれば，別々のルールとした方が良い． resource \"aws_wafv2_web_acl\" \"api_gateway\" { # x-api-keyヘッダーにAPIキーを含むリクエストを許可します． rule { name = \"allow-request-including-api-key\" priority = 3 statement { or_statement { # APIキーを持つのリクエストを許可します． statement { byte_match_statement { positional_constraint = \"EXACTLY\" search_string = var.waf_api_key_ssm_parameter_value field_to_match { single_header { name = \"x-api-key\" } } text_transformation { priority = 0 type = \"NONE\" } } } # Bearerトークンを持つリクエストを許可します． statement { byte_match_statement { positional_constraint = \"EXACTLY\" search_string = var.waf_bearer_token_ssm_parameter_value field_to_match { single_header { name = \"authorization\" } } text_transformation { priority = 0 type = \"NONE\" } } } } } action { allow {} } visibility_config { cloudwatch_metrics_enabled = true metric_name = \"APIGatewayWAFAllowRequestIncludingAPIKeyRule\" sampled_requests_enabled = true } } # ～ 中略 ～ } IPセットの依存関係 WAFのIPセットと他設定の依存関係に癖がある．新しいIPセットへの付け換えと古いIPセットの削除を同時にデプロイしないようにする．もし同時に行った場合，Terraformは古いIPセットの削除処理を先に実行するが，これはWAFに紐付いているため，ここでエラーが起こってしまう．そのため，IPセットを新しく設定し直す場合は，以下の通り二つの段階に分けてデプロイするようにする．ちなみに，IPセットの名前を変更する場合は，更新処理ではなく削除を伴う再構築処理が実行されるため注意する． 新しいIPセットのresourceを実装し，ACLに紐付け，デプロイする． 古いIPセットのresourceを削除し，デプロイする． もし，これを忘れてしまった場合は，画面上で適当なIPセットに付け換えて，削除処理を実行できるようにする． 16. 共通の設定 Terraform管理外のAWSリソース 以下のAWSリソースはTerraformで管理しない方が便利である．また，AWSの仕様上の理由で，管理外になってしまうものもある．Terraformの管理外のリソースには，コンソール画面上から，「Not managed by = Terraform」というタグをつけた方が良い． AWSリソース 管理外の部分 管理外の理由 API Gateway，紐付くVPCリンク 全て バックエンドチームがスムーズにAPIを構築できるようにするため． Chatbot 全て AWSがAPIを公開していないため，Terraformで構築できない． EC2 秘密鍵 Terraformで構築する時にGitHubで秘密鍵を管理する必要があるため，セキュリティ上の理由で却下する． Global Accelerator セキュリティグループ リソースを構築するとセキュリティグループが自動生成されるため，セキュリティグループのみTerraformで管理できない． IAMユーザ 全て IAMユーザグループ 全て IAMロール ・ユーザに紐付くロール・サービスリンクロール サービスリンクロールは，AWSリソースの構築に伴って，自動的に作られるため，Terraformで管理できない．ただし，数が多いためあえて行わないが，Terraformで構築してAWSリソースに紐付けることもことも可能である． Network Interface 全て 他のAWSリソースの構築に伴って，自動的に構築されるため，Terraformで管理できない． RDS admin以外のユーザ 個別のユーザ作成のために，mysql providerという機能を使用する必要がある．しかし，使用する上でディレクトリ構成戦略と相性が悪い． Route53 ネームサーバーレコード ホストゾーンを作成すると，レコードとして，ネームサーバレコードの情報が自動的に設定される．これは，Terraformの管理外である． S3 tfstateの管理バケット tfstateファイルを格納するため，Terraformのデプロイより先に存在している必要がある． SSMパラメータストア 全て ECSに機密な環境変数を出力するため． 削除保護機能のあるAWSリソース 削除保護設定のあるAWSリソースに癖がある．削除保護の無効化とリソースを削除を同時にデプロイしないようにする．もし同時に行った場合，削除処理を先に実行するが，削除は保護されたままなので，エラーになる．エラーになる．そのため，このAWSリソースを削除する時は，以下の通り二つの段階に分けてデプロイするようにする． 削除保護を無効化（false）に変更し，デプロイする． ソースコードを削除し，デプロイする． もし，これを忘れてしまった場合は，画面上で削除処理を無効化し，削除処理を実行できるようにする． AWSリソース名 Terraform上での設定名 ALB enable_deletion_protection EC2 disable_api_termination RDS deletion_protection "},"public/infrastructure_as_code/infrastructure_as_code_terraform_ci_cd.html":{"url":"public/infrastructure_as_code/infrastructure_as_code_terraform_ci_cd.html","title":"📖 ︎TerraformのCICDフロー","keywords":"","body":"TerraformのCICDフロー はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. シェルスクリプト assume_role.sh 参考： terraform_apply.sh #!/bin/bash set -xeuo pipefail # credentialsの情報を出力します． source ./aws_envs.sh terraform -chdir=./${ENV} apply \\ -parallelism=30 \\ ${ENV}.tfplan | ./ops/tfnotify --config ./${ENV}/tfnotify.yml apply terraform_fmt.sh #!/bin/bash set -xeuo pipefail terraform fmt \\ -recursive \\ -check terraform_init.sh #!/bin/bash set -xeuo pipefail # credentialsの情報を出力します． source ./aws_envs.sh terraform -chdir=./${ENV} init \\ -upgrade \\ -reconfigure \\ -backend=true \\ -backend-config=\"bucket=${ENV}-tfstate-bucket\" \\ -backend-config=\"key=terraform.tfstate\" \\ -backend-config=\"encrypt=true\" terraform_plan.sh #!/bin/bash set -xeuo pipefail # credentialsの情報を出力します． source ./aws_envs.sh terraform -chdir=./${ENV} plan \\ -var-file=./${ENV}/foo.tfvars \\ -out=${ENV}.tfplan \\ -parallelism=30 | ./ops/tfnotify --config ./${ENV}/tfnotify.yml plan terraform_validate.sh #!/bin/bash set -xeuo pipefail terraform -chdir=./${ENV} validate 02. CircleCIを用いたCICD 要素 ・環境 env 説明 dev プルリクのレビュー時に，コードの変更を検証するためのインフラ環境 stg ステージング環境 prd 本番環境 ・ジョブ jobs 説明 plan aws-cliのインストールからterraform plan -outコマンドまでの一連の処理を実行する． 承認ジョブ apply stg環境またはprd環境にデプロイ ・ワークフロー workflows 説明 feature featureブランチからdev環境にデプロイ develop developブランチからstg環境にデプロイ main mainブランチからprd環境にデプロイ config.ymlファイル version: 2.1 executors: primary_container: parameters: env: type: enum enum: [ \"dev\", \"stg\", \"prd\" ] docker: - image: hashicorp/terraform:x.xx.x working_directory: ~/foo_infrastructure environment: ENV: > commands: # AWSにデプロイするための環境を構築します． aws_setup: steps: - run: name: Install jq command: | apk add curl curl -o /usr/bin/jq -L https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 chmod +x /usr/bin/jq - run: name: Install aws-cli command: | apk add python3 apk add py-pip pip3 install awscli aws --version - run: name: Assume role command: | set -x source ./ops/assume.sh # terraform initを行います． terraform_init: steps: - run: name: Terraform init command: | set -x source ./ops/terraform_init.sh # terraform fmtを行います． terraform_fmt: steps: - run: name: Terraform fmt command: | set -x source ./ops/terraform_fmt.sh # terraform validateを行います． terraform_validate: steps: - run: name: Terraform validate command: | set -x source ./ops/terraform_validate.sh # terraform planを行います． terraform_plan: steps: - run: name: Terraform plan command: | set -x source ./ops/terraform_plan.sh ls -la # terraform applyを行います． terraform_apply: steps: - run: name: Terraform apply command: | set -x ls -la source ./ops/terraform_apply.sh jobs: plan: parameters: exr: type: executor executor: > steps: - checkout - aws_setup - terraform_init - terraform_fmt - terraform_validate - terraform_plan - persist_to_workspace: root: . paths: - . apply: parameters: exr: type: executor executor: > steps: - attach_workspace: at: . - terraform_apply workflows: # Dev env feature: jobs: - plan: name: plan_dev exr: name: primary_container env: dev filters: branches: only: - /feature.*/ - apply: name: apply_dev exr: name: primary_container env: dev requires: - plan_dev # Staging env develop: jobs: - plan: name: plan_stg exr: name: primary_container env: stg filters: branches: only: - develop - hold_apply: name: hold_apply_stg type: approval requires: - plan_stg - apply: name: apply_stg exr: name: primary_container env: stg requires: - hold_apply_stg # Production env main: jobs: - plan: name: plan_prd exr: name: primary_container env: prd filters: branches: ignore: /.*/ tags: only: /release\\/.*/ - hold_apply: name: hold_apply_prd type: approval requires: - plan_prd filters: branches: ignore: /.*/ tags: only: /release\\/.*/ - apply: name: apply_prd exr: name: primary_container env: prd requires: - hold_apply_prd filters: branches: ignore: /.*/ tags: only: /release\\/.*/ 03. tfnotify tfnotifyとは terraformのplanまたはapplyの処理結果を，POSTで送信するバイナリファイルのこと．URLや送信内容を設定ファイルで定義する． コマンド CircleCIで利用する場合は，commandの中で，以下からダウンロードしたtfnotifyのバイナリファイルを実行する．環境別にtfnotifyを配置しておくとよい． https://github.com/mercari/tfnotify/releases/tag/v0.7.0 #!/bin/bash set -xeuo pipefail terraform -chdir=./${ENV} plan | ./ops/tfnotify --config ./${ENV}/tfnotify.yml plan 設定ファイル あらかじめ，GitHubのアクセストークンを発行し，CIツールの環境変数に登録しておく． ＊実装例＊ 例として，GitHubの特定のリポジトリのプルリクエストにPOSTで送信する． # https://github.com/mercari/tfnotify --- ci: circleci notifier: github: # 環境変数に登録したパーソナルアクセストークン token: $GITHUB_TOKEN repository: # 送信先のユーザ名もしくは組織名 owner: \"foo-company\" name: \"foo-repository\" terraform: plan: template: | {{ .Title }} for staging [CI link]( {{ .Link }} ) {{ .Message }} {{if .Result}} {{ .Result }} {{end}} Details (Click me) {{ .Body }} apply: template: | {{ .Title }} {{ .Message }} {{if .Result}} {{ .Result }} {{end}} Details (Click me) {{ .Body }} "},"public/virtualization/virtualization.html":{"url":"public/virtualization/virtualization.html","title":"📖 ︎仮想化","keywords":"","body":"仮想化 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 仮想化 仮想化とは 自身の開発環境でWebサイトを動かしたい場合，まず，パソコン内にLinux環境のWebサーバ，Appサーバ，DBサーバなどの物理サーバを仮想的に構築する．そして，自身のパソコンをクライアント，各仮想サーバをリクエスト先に見立てて，SSHプロトコルを用いてこれらのサーバにリモートログインする．仮想環境の構築方法にはいくつか種類がある． ホスト型仮想化 ・ホスト型仮想化とは ホストOS上で，各サーバを仮想的に構築する． ・Provider例 VMware Workstation，Oracle VM VirtualBox，など ハイパーバイザー型仮想化 ・ハイパーバイザー型仮想化とは BIOSから起動したハイパーバイザー上で，各サーバを仮想的に構築する（※ホストOSは用いない）． ・Provider例 VMware vSphere Hypervisor，Xen，KVM，など コンテナ型仮想化 ・コンテナ型仮想化とは ホストOS上で，サーバではなく，サーバとしての機能を持つコンテナを仮想的に構築する．カーネルのリソースを分割できるNamespace（PID namespace，Network namespace，UID namespace）とControl Groupsを用いて，単一のOS上に独立したコンテナを構築する． → DockerToolboxがちょい違う ・Provider例 Docker，LXC，OpenVZ，など 01-02. 各仮想化のパフォーマンスの比較 起動速度の違い ホスト型とハイパーバイザ型では，ハードウェア（CPU，メモリ，ハードディスク）とゲストOSを仮想化することが必要である．一方で，コンテナ型では，ハードウェアとゲストOSの仮想化は行わず，namespaceを用いてコンテナを構成するため，その分起動が速い． 処理速度の違い ・Overheadの小ささ ゲストOS上のアプリを操作する場合，ホスト型とハイパーバイザ型では，ハードウェアやハイパーバイザーを経由する必要がある．この分だけ，時間（Overhead）を要する．一方で，コンテナ型では，各コンテナがホストOSとカーネルを共有するため，Overheadが小さい． ・Overheadの比較 sysbenchというベンチマークツールを用いて，CPU・メモリ・ファイルI/Oに着目し，物理マシン・コンテナ型仮想化（Docker）・ホスト型仮想化（VirtualBox）のパフォーマンスを比較すると，コンテナ型であるDockerは最もOverheadが小さい． "},"public/virtualization/virtualization_container_docker_command.html":{"url":"public/virtualization/virtualization_container_docker_command.html","title":"📖 ︎dockerコマンド","keywords":"","body":"dockerコマンド はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Dockerコマンドの仕組み Dockerクライアント ・Dockerクライアントとは Dockerクライアントは，接続によって，Dockerデーモンを操作できる． Dockerデーモン ・Dockerデーモンとは ホストOS上で稼働し，Dockerの操作を担う．Dockerクライアントは，Dockerデーモンを通して，Docker全体を操作できる． 参考：https://www.slideshare.net/zembutsu/docker-underlying-and-containers-lifecycle 02. コマンド attach ・オプションなし ＊コマンド例＊ デタッチドモードによって，起動中のコンテナに接続する． $ docker attach build ・-force-rm，--no-cache ＊コマンド例＊ キャッシュ無しで，指定のDockerfileを基に，イメージをビルドする．失敗した時は削除するように，--force-rmオプションを有効化する． $ docker build --file Dockerfile --tag : --force-rm=true --no-cache . commit ・オプションなし 停止中のコンテナからイメージを作成する． ＊コマンド例＊ $ docker commit $ docker commit /: container ・prune 停止中のコンテナのみを全て削除する． ＊コマンド例＊ $ docker container prune cp ・オプションなし DockerfileのCOPYコマンドを使用してコンテナ内に配置しているファイルに関して，変更のたびにイメージをビルドを行うことは面倒のため，ホストOSからコンテナにコピーし，再読み込みを行う．ただし，コンテナを再構築すると元に戻ってしまうことに注意． ＊コマンド例＊ # ホストのファイルをコンテナにコピー $ docker cp ./docker/www/nginx.conf :/etc/nginx/nginx.conf # コンテナに接続後に，nginxの設定ファイルを再読み込み． $ docker exec -it bin/bash # もしくはbin/sh [root@:~] $ nginx -s reload [root@:~] $ exit # アクセスログを確認 $ docker logs create ・オプションなし ＊コマンド例＊ コンテナレイヤーを生成し，コンテナを構築．起動はしない． $ docker create : exec ・-it ＊コマンド例＊ デタッチドモードによって，起動中のコンテナ内でコマンドを実行する．実行するコマンドがbashやbashの場合，コンテナに接続できる． # i：interactive，t：tty（対話モード） $ docker exec -it /bin/bash # イメージ内に/bin/bash がない場合 $ docker exec -it /bin/sh ・attach，execの違い まずattachコマンドでは，起動中のコンテナに接続する．exitコマンドを使用して，コンテナとの接続を切断した後，コンテナが停止してしまう． # デタッチドモードによる起動 $ docker run -d -it --name : /bin/bash # デタッチドモードによって起動中のコンテナに接続 $ docker attach # PID=1で，1つの/bin/bashプロセスが稼働していることが確認できる [root@:~] ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 16152 3872 pts/0 Ss+ 18:06 0:00 /bin/bash root 33 0.0 0.1 45696 3732 pts/1 R+ 18:22 0:00 ps aux # コンテナとの接続を切断 [root@:~] exit # コンテナの状態を確認 $ docker container ps -a --no-trunc # ==> コンテナのSTATUSがEXITedになっている 一方でexecコマンドでは，起動中のコンテナでコマンドを実行する．実行するコマンドがbashやbashの場合，コンテナに接続できる．exitコマンドを使用して，コンテナとの接続を切断した後でも，コンテナが起動し続ける． # デタッチドモードによる起動 $ docker run -d -it --name : /bin/bash # 対話モードを使用して，デタッチドモードによって起動中のコンテナに接続 $ docker exec -it /bin/bash # もしくはbin/sh # PID=1,17で，2つの/bin/bashプロセスが稼働していることが確認できる [root@:~] ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 16152 3872 pts/0 Ss+ 18:06 0:00 /bin/bash root 17 0.0 0.1 16152 4032 pts/1 Ss 18:21 0:00 /bin/bash root 34 0.0 0.1 45696 3732 pts/1 R+ 18:22 0:00 ps aux # コンテナとの接続を切断 [root@:~] exit # コンテナの状態を確認 $ docker container ps -a --no-trunc # ==> コンテナのSTATUSがUPになっている search ・オプションなし ＊コマンド例＊ レジストリ側に保管されているイメージを検索する． $ docker search images ・オプションなし ＊コマンド例＊ ホストOSにインストールされたイメージを確認する． $ docker images ・prune ＊コマンド例＊ コンテナに使用されていないイメージを一括で削除 $ docker image prune ・rmi ＊コマンド例＊ タグ名のないイメージのみを全て削除する． $ docker rmi --force $(sudo docker images --filter \"dangling=true\" --all --quiet) inspect ・オプションなし ＊コマンド例＊ 起動中コンテナの全ての設定内容を表示する．grepとも組み合わせられる． $ docker inspect $ docker inspect | grep IPAddress ＊コマンド例＊ json-fileドライバーを使用している時に，ログファイルの出力先を確認する． $ docker inspect | grep 'LogPath' \"LogPath\": \"/var/lib/docker/containers/*****-json.log\", network ・ls ＊コマンド例＊ $ docker network ls NETWORK ID NAME DRIVER SCOPE ae25b9b7740b bridge bridge local aeef782b227d tech-notebook_default bridge local ・prune $ docker network prune ・inspect 複数のコンテナが起動している時に，コンテナがいずれのネットワークを使用しているかを確認する． $ docker network inspect ps ・-a ＊コマンド例＊ コンテナの起動と停止にかかわらず，IDなどを一覧で表示． $ docker ps -a pull ＊コマンド例＊ レジストリ側のイメージをクライアント側にインストールする． $ docker pull : push ・オプションなし ＊コマンド例＊ ホストOSで作成したイメージを，指定したDockerHubのユーザにアップロードする． $ docker push /: ＊コマンド例＊ ホストOSで作成したイメージを，指定したECRにアップロードする．ECRはタグ名がやや特殊のため，事前にタグを付け替える必要がある． $ docker tag : /: $ docker push /: rm ・--force ＊コマンド例＊ 起動中／停止中の全てコンテナを強制的に削除する． $ docker rm --force $(docker ps --all --quiet) run ・--hostname コンテナ内のetc/hostsファイルで，コンテナのプライベートIPアドレスを確認できる．hostnameオプションで命名していればその名前，指定していなければランダムな文字列が割り当てられる． ＊コマンド例＊ $ docker run -d -it --hostname --name --publish=8080:80 : /bin/bash $ docker exec -it /bin/bash [root@:/] cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 172.18.0.2 ・--publish 指定したホストポートとコンテナポートのマッピングを実行する．--publish-allオプションではホストポートをランダムに選んでポートマッピングを実行する． 参考：https://www.whitesourcesoftware.com/free-developer-tools/blog/docker-expose-port/ $ docker run -d -it --name --publish=8080:80 : /bin/bash ・--expose コンテナポート公開をexposeオプションで設定できる．これはDockerfileでEXPOSE命令として設定してもよい．なお，プロセスのリッスンするポートと合わせる必要がある． 参考：https://www.whitesourcesoftware.com/free-developer-tools/blog/docker-expose-port/ $ docker run -d -it --name --expose=80 : /bin/bash ・-a，-d すでに停止中または起動中のコンテナが存在していても，これとは別にコンテナを新しく構築し，起動する．さらにそのコンテナ内でコマンドを実行する．起動時にbashプロセスやbashプロセスを実行すると，コンテナに接続できる．何も渡さない場合は，デフォルトのプロセスとしてbashプロセスが実行される．runコマンドでは，アタッチモードとデタッチモードを選ぶことができる．新しく起動したコンテナを停止後に自動削除する場合は，rmオプションを付けるようにする． ＊コマンド例＊ # アタッチモードによる起動．フォアグラウンドで起動する． $ docker run -a -it --rm --name : /bin/bash # デタッチドモードによる起動．バックグラウンドで起動する． $ docker run -d -it --rm --name : /bin/bash コンテナを起動する時に，bashプロセスを実行すると以下のようなエラーが出ることがある．その場合は，bashプロセスを実行するようにする． docker: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: exec: \"/bin/bash\": stat /bin/bash: no such file or directory: unknown. アタッチモードは，フォアグラウンド起動である．ターミナルにプロセスのログが表示されないため，同一ターミナルで他のコマンドを入力できる． ＊コマンド例＊ # -a：atattch mode $ docker run -a -it --name : /bin/bash デタッチドモードは，バックグラウンド起動である．ターミナルにプロセスのログが表示され続けるため，同一ターミナルで他のコマンドを入力できない．プロセスのログを監視できるが，他のプロセスを入力するためには，そのターミナル上でコンテナを停止させる必要がある． ＊コマンド例＊ # -d；detached mode $ docker run -d -it --name : /bin/bash start コンテナを起動する．startコマンドでは，アタッチモードによる起動しかできない． ＊コマンド例＊ 停止中コンテナをアタッチモードによって起動する． $ docker start -i stop ・オプションなし ＊コマンド例＊ 起動中コンテナを停止する． $ docker stop ＊コマンド例＊ 全てのコンテナを停止する． $ docker stop $(docker ps --all --quiet) volume ・create Volumeマウントを作成する．dockerコマンドではなく，docker-composeコマンドで作成することが推奨されている． ＊コマンド例＊ ホストOSのDockerエリアにVolumeを作成 $ docker volume create ・ls ＊コマンド例＊ DockerエリアのVolumeの一覧を表示 $ docker volume ls ・rm ＊コマンド例＊ DockerエリアのVolumeを削除 $ docker volume rm ・inspect ＊コマンド例＊ DockerエリアのVolumeの詳細を表示 $ docker volume inspect [ { \"CreatedAt\": \"2020-09-06T15:04:02Z\", \"Driver\": \"local\", \"Labels\": { \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.26.2\", \"com.docker.compose.volume\": \"foo\" }, \"Mountpoint\": \"/var/lib/docker/volumes/_foo/_data\", \"Name\": \"_foo\", \"Options\": null, \"Scope\": \"local\" } ] # DockerエリアをVolumeマウントして起動 # マウントポイントのVolume名を使用 $ docker run -d -it --name /bin/bash \\ --mount type=volume, src= volume-driver=local, dst= ＊実装例＊ DockerfileでVolumeマウントを行う場合，マウント先のコンテナ側ディレクトリ名を指定する．Dockerエリアのマウントポイントは，自動的に作成される．Docker Composeで行うことが推奨されている． FROM ubuntu RUN mkdir /myvol RUN echo \"hello world\" > /myvol/greeting # マウント先のコンテナ側ディレクトリ名 VOLUME /myvol 03. ロギング log ・--follow ログを表示し続ける．ロギングドライバーがjson-fileの場合のみ有効． $ docker logs -f ・--tail ＊コマンド例＊ 指定した行数だけ，ログを表示する．ロギングドライバーがjson-fileの場合のみ有効． $ docker logs --follow=true --tail=500 --log-driver ・ロギングドライバーとは コンテナ内の標準出力（/dev/stdout）と標準エラー出力（/dev/stderr）に出力されたログを，ファイルやAPIに対して転送する． $ docker run -d -it --log-driver --name : /bin/bash ・json-file 標準出力／標準エラー出力に出力されたログを，/var/lib/docker/containers/＜コンテナID＞/＜コンテナID＞-json.logファイルに転送する．標準の設定値である． { \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"10m\", \"max-file\": \"3\" } } ・fluentd 構造化ログに変換し，サイドカーとして稼働するFluentdコンテナに送信する．ECSコンテナのawsfirelensドライバーは，fluentdドライバーをラッピングしたものである． 参考： https://docs.docker.com/config/containers/logging/fluentd/ https://aws.amazon.com/jp/blogs/news/under-the-hood-firelens-for-amazon-ecs-tasks/ { \"log-driver\": \"fluentd\", \"log-opts\": { \"fluentd-address\": \":24224\" } } ・none 標準出力／標準エラー出力に出力されたログを，ファイルやAPIに転送しない． ファイルに出力しないことで，開発環境のアプリケーションサイズの肥大化を防ぐ． ・awslogs 標準出力／標準エラー出力に出力されたログをCloudWatch-APIに送信する． 参考：https://docs.docker.com/config/containers/logging/awslogs/ { \"log-driver\": \"awslogs\", \"log-opts\": { \"awslogs-region\": \"us-east-1\" } } ・gcplogs 標準出力／標準エラー出力に出力されたログを，Google Cloud LoggingのAPIに転送する． 参考：https://docs.docker.com/config/containers/logging/gcplogs/ { \"log-driver\": \"gcplogs\", \"log-opts\": { \"gcp-meta-name\": \"example-instance-12345\" } } 各ベンダーのイメージのログ出力先 ・Dockerコンテナの標準出力／標準エラー出力 Linuxでは，標準出力は『/proc//fd/1』，標準エラー出力は『/proc//fd/2』である．Dockerコンテナでは，『/dev/stdout』が『/proc/self/fd/1』のシンボリックリンク，また『/dev/stderr』が『/proc//fd/2』のシンボリックリンクとして設定されている． [root@*****:/dev] ls -la total 4 drwxr-xr-x 5 root root 340 Oct 14 11:36 . drwxr-xr-x 1 root root 4096 Oct 14 11:28 .. lrwxrwxrwx 1 root root 11 Oct 14 11:36 core -> /proc/kcore lrwxrwxrwx 1 root root 13 Oct 14 11:36 fd -> /proc/self/fd crw-rw-rw- 1 root root 1, 7 Oct 14 11:36 full drwxrwxrwt 2 root root 40 Oct 14 11:36 mqueue crw-rw-rw- 1 root root 1, 3 Oct 14 11:36 null lrwxrwxrwx 1 root root 8 Oct 14 11:36 ptmx -> pts/ptmx drwxr-xr-x 2 root root 0 Oct 14 11:36 pts crw-rw-rw- 1 root root 1, 8 Oct 14 11:36 random drwxrwxrwt 2 root root 40 Oct 14 11:36 shm lrwxrwxrwx 1 root root 15 Oct 14 11:36 stderr -> /proc/self/fd/2 # 標準エラー出力 lrwxrwxrwx 1 root root 15 Oct 14 11:36 stdin -> /proc/self/fd/0 lrwxrwxrwx 1 root root 15 Oct 14 11:36 stdout -> /proc/self/fd/1 # 標準出力 crw-rw-rw- 1 root root 5, 0 Oct 14 11:36 tty crw-rw-rw- 1 root root 1, 9 Oct 14 11:36 urandom crw-rw-rw- 1 root root 1, 5 Oct 14 11:36 zero ・nginxイメージ 公式のnginxイメージは，/dev/stdoutというシンボリックリンクを，/var/log/nginx/access.logファイルに作成している．また，/dev/stderrというシンボリックリンクを，/var/log/nginx/error.logファイルに作成している．これにより，これらのファイルに対するログの出力は，/dev/stdoutと/dev/stderrに転送される． 参考：https://docs.docker.com/config/containers/logging/ ・php-fpmイメージ 要勉強． "},"public/virtualization/virtualization_container_docker_dockerfile.html":{"url":"public/virtualization/virtualization_container_docker_dockerfile.html","title":"📖 ︎Dockerfile","keywords":"","body":"Dockerfile はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コンテナに接続するまでの手順 手順の流れ Docker Hubから，ベースとなるイメージをインストールする． Dockerfileがイメージレイヤーからなるイメージをビルド． コマンドによって，イメージ上にコンテナレイヤーを生成し，コンテナを構築． コマンドによって，停止中のコンテナを起動． コマンドによって，起動中のコンテナに接続． 02. Dockerfileの実装 イメージレイヤーの積み重ね ・Dockerfileの仕組み 任意のイメージをベースとして，新しいイメージをビルドするためには，ベースのイメージの上に，他のイメージレイヤーを積み重ねる必要がある．この時，Dockerfileを用いて，各命令によってイメージレイヤーを積み重ねていく． ・Dockerfileの記述方法 任意のイメージをベースとして，新しいイメージをビルドするためには，以下の5つ順番で命令を用いて，イメージレイヤーを積み重ねていく．命令は，慣例的に大文字で記述する． ＊実装例＊ NginxのイメージをビルドするためのDockerfileを示す．命令のパラメータの記述形式には，文字列形式，JSON形式がある．ここでは，JSON形式で記述する． # ベースのイメージ（CentOS）を，コンテナにインストール FROM centos:8 # ubuntu上に，nginxをインストール RUN yum update -y \\ && yum install -y \\ nginx # ホストOSの設定ファイルを，コンテナ側の指定ディレクトリにコピー COPY infra/docker/web/nginx.conf /etc/nginx/nginx.conf # nginxをデーモン起動 CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] # コンテナのポートを開放を明示する．これはドキュメンテーションとしての機能しかない． EXPOSE 80 命令 処理 FROM ベースのイメージを，コンテナにインストール. RUN ベースイメージ上に，ソフトウェアをインストール. COPY ・ホストOSのファイルをイメージレイヤー化し，コンテナの指定ディレクトリにコピー.・イメージのビルド時にコピーされるだけで，ビルド後のコードの変更は反映されない．・nginx.confファイル，php.iniファイル，などの設定ファイルをホストOSからコンテナにコピーしたい時によく使う． CMD イメージのプロセスの起動コマンドを実行．runコマンドの引数として，上書きできる． VOLUME Volumeマウントを行う．COPYとは異なり，ビルド後のコードの変更が反映される．Docker Composeで記述した方が良い． EXPOSE コンテナのポートを開放する．また，イメージの利用者にとってのドキュメンテーション機能もあり，ポートマッピングを実行する時に使用可能なコンテナポートとして保証する機能もある．参考：・https://docs.docker.com/engine/reference/builder/#expose・https://www.whitesourcesoftware.com/free-developer-tools/blog/docker-expose-port/また加えて，プロセス自体が命令をリッスンできるようにポートを設定する必要がある．ただし，多くの場合標準でこれが設定されている．（例：PHP-FPMでは，/usr/local/etc/www.conf.defaultファイルと/usr/local/etc/php-fpm.d/www.confファイルには，listen = 127.0.0.1:9000の設定がある） ENTRYPOINT イメージのプロセスの起動コマンドを実行．CMDとは異なり，後から上書き実行できない．使用者に，コンテナの起動方法を強制させたい場合に適する． ENV OS上のコマンド処理で扱える変数を定義する．Dockerfileの命令では扱えない．ARGとの違いの例については下記． ARG Dockerfikeの命令で扱える変数を定義する．OS上のコマンド処理では扱えない．ENVとの違いの例については下記． ADD ・ホストOSのファイルを，コンテナの指定ディレクトリにコピー（COPYと同じ）・インターネットからファイルをダウンロードし，解凍も行う．・イメージのビルド時にコピーされるだけで，ビルド後のコードの変更は反映されない． WORKDIR 絶対パスによる指定で，現在のディレクトリを変更. ・CMDの決め方 DockerfileでCMDを指定しない場合，イメージのデフォルトのバイナリファイルが割り当てられる．一旦，デフォルトのバイナリファイルを確認した後に，これをDockerfileに明示的に実装するようにする． CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2b2d3dfafee8 xxxxx \"/bin/sh\" 11 seconds ago Up 8 seconds 0.0.0.0:8000->8000/tcp xxxxx 静的型付け言語ではプロセスの起動時に，代わりにアーティファクトのバイナリファイルを実行しても良い．その場合，binディレクトリにバイナリファイルとしてのアーティファクトを配置することになる．しかし，binディレクトリへのアクセス権限がないことがあるため，その場合は，一つ下にディレクトリを作成し，そこにバイナリファイルを置くようにする． # /go/bin にアクセスできない時は，/go/bin/cmdにアーティファクトを置く． ERROR: for xxx-container Cannot start service go: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: \"/go/bin\": permission denied: unknown ・ENTRYPOINTの注意点 イメージのプロセスの起動コマンドを後から上書きできなくなるため，runコマンドの引数として新しいコマンドを渡せずに，デバッグができないことがある． # 上書きできず，失敗してしまう． $ docker run --rm -it /bin/bash ・ENVとARGの違い 一つ目に，ENVが使えて，ARGが使えない例． # ENVは，OS上のコマンド処理で扱える変数を定義 ARG PYTHON_VERSION=\"3.8.0\" RUN pyenv install ${PYTHON_VERSION} # ARGは，OS上のコマンド処理では扱えない ARG PYTHON_VERSION=\"3.8.0\" RUN pyenv install ${PYTHON_VERSION} # ===> 変数を展開できない 二つ目に，ARGが使えて，ENVが使えない例． # ARGは,Dockerfikeの命令で扱える変数を定義 ARG OS_VERSION=\"8\" FROM centos:${OS_VERSION} # ENVは，OS上のコマンド処理では扱えない ENV OS_VERSION \"8\" FROM centos:${OS_VERSION} # ===> 変数を展開できない 三つ目に，これらの違いによる可読性の悪さの対策として，ENVとARGを組み合わせた例． # 最初に全て，ARGで定義 ARG CENTOS_VERSION=\"8\" ARG PYTHON_VERSION=\"3.8.0\" # 変数展開できる FROM centos:${OS_VERSION} # ARGを事前に宣言 ARG PYTHON_VERSION # 必要に応じて，事前にENVに詰め替える． ENV PYTHON_VERSION ${PYTHON_VERSION} # 変数展開できる RUN pyenv install ${PYTHON_VERSION} ・Docker Hubに対する継続的インテグレーション 方法 仕組み GitHub Actions GitHubが，Docker Hubに対して，pushを行う． Circle CI GitHubが，Circle CIに対して，送信WebHookを行う． Docker Hub Auto Build GitHubが，Docker Hubに対して，送信WebHookを行う． ・Dockerfileを使用するメリット Dockerfileを用いない場合，各イメージレイヤーのインストールを手動で行わなければならない．しかし，Dockerfileを用いることで，これを自動化できる． イメージのデバッグ ＊コマンド例＊ ビルドに失敗したイメージからコンテナを構築し，接続する．rmオプションを設定し，接続の切断後にコンテナを削除する．Dockerfileにおいて，イメージのプロセスの起動コマンドをENTRYPOINTで設定している場合は，後から上書きできなくなるため，runコマンドの引数として新しいコマンドを渡せずに，デバッグができないことがある． $ docker run --rm -it /bin/bash # コンテナの中 root@xxxxxxxxxx: コンテナレイヤー ・コンテナレイヤーとは イメージレイヤーの上に積み重ねられる 02-02. ベースイメージ イメージリポジトリ ・イメージリポジトリとは イメージは，実行OSによらずに一貫してビルドできるため，配布できる．各イメージリポジトリ（DockerHub，ECR，など）には，カスタマイズする上でのベースとなるイメージが提供されている． ベースイメージ ・ベースイメージの種類 イメージ 特徴 相性の良いシステム例 scratch 以下の通り，何も持っていない・OS：無・パッケージ：無・パッケージマネージャ：無 ？ BusyBox ・OS：Linux（※ディストリビューションではない）・パッケージ：基本ユーティリティツール・パッケージマネージャ：無 組み込みシステム Alpine Linux ・OS：Linux（※ディストリビューションではない）・パッケージ：基本ユーティリティツール・パッケージマネージャ：Apk ？ ・対応可能なCPUアーキテクチャの種類 Dockerは全てのPCで稼働できるわけではなく，イメージごとに対応可能なCPUアーキテクチャ（AMD系，ARM系，など）がある．同じOSでも，機種ごとに搭載されるCPUアーキテクチャは異なる．例えば，MacBook 2020 にはIntel，またMacBook 2021（M1 Mac）にはARMベースの独自CPUが搭載されているため，ARMに対応したイメージを選ぶ必要がある．ただし，イメージがOSのCPUアーキテクチャに対応しているかどうかを開発者が気にする必要はなく，docker pull時に，OSのCPUアーキテクチャに対応したイメージが自動的に選択されるようになっている． 参考：https://github.com/docker-library/official-images#architectures-other-than-amd64 ・バージョン イメージのバージョンには種類があり，追跡できるバージョンアップが異なる．ここでは，composerのイメージを例に挙げる． 参考：https://hub.docker.com/_/composer/?tab=description&page=1&ordering=last_updated composerバージョン 追跡できるバージョンアップ 2.0.9 バージョンを直指定し，追跡しない． 2.0 「2.0.X」のマイナーアップデートのみを追跡する． 2 「2.X」と「2.0.X」のマイナーアップデートのみを追跡する． latest メジャーアップデートとマイナーアップデートを追跡する． 03-02 イメージの軽量化 プロセス単位によるDockerfileの分割 これは，Dockerの原則である．アプリケーションを稼働させるには，最低限，Webサーバミドルウェア，アプリケーション，DBMSが必要である．これらを，個別のコンテナで稼働させ，ネットワークで接続するようにする． キャッシュを削除 Unixユーティリティをインストールすると，キャッシュが残る． ＊実装例＊ FROM centos:8 RUN dnf upgrade -y \\ && dnf install -y \\ curl \\ # メタデータ削除 && dnf clean all \\ # キャッシュ削除 && rm -rf /var/cache/dnf RUNコマンドをまとめる Dockerfileの各命令によって，イメージ レイヤーが一つ増えてしまうため，同じ命令に異なるパラメータを与える時は，これを一つにまとめてしまう方が良い．例えば，以下のような時， # ベースイメージ上に，複数のソフトウェアをインストール RUN yum -y isntall httpd RUN yum -y install php RUN yum -y install php-mbstring RUN yum -y install php-pear これは，以下のように一行でまとめられる．イメージレイヤーが少なくなり，イメージを軽量化できる． # ベースイメージ上に，複数のソフトウェアをインストール RUN yum -y install httpd php php-mbstring php-pear さらに，これは以下のようにも書くことができる． # ベースイメージ上に，複数のソフトウェアをインストール RUN yum -y install \\ httpd \\ php \\ php-mbstring \\ php-pear マルチステージビルド ・マルチステージビルドとは 一つのDockerfile内に複数の独立したステージを定義する方法．以下の手順で作成する． シングルステージビルドに成功するDockerfileを作成する． ビルドによって生成されたバイナリファイルがどこに配置されるかを場所を調べる． Dockerfileで，二つ目のFROMを宣言する． 一つ目のステージで，バイナリファイルをコンパイルするだけで終わらせる． 二つ目のステージで，Unixユーティリティをインストールする．また，バイナリファイルを一つ目のステージからコピーする． ・コンパイルされたバイナリファイルを再利用 ＊実装例＊ # 中間イメージ FROM golang:1.7.3 AS builder WORKDIR /go/src/github.com/alexellis/href-counter/ RUN go get -d -v golang.org/x/net/html COPY app.go . RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . # 最終イメージ FROM alpine:latest RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=builder /go/src/github.com/alexellis/href-counter/app . CMD [\"./app\"] ・実行環境別にステージを分ける ＊実装例＊ #=================== # Global ARG #=================== ARG NGINX_VERSION=\"1.19\" ARG LABEL=\"Hiroki \" #=================== # Build Stage #=================== FROM nginx:${NGINX_VERSION} as build RUN apt-get update -y \\ && apt-get install -y \\ curl \\ vim \\ # キャッシュ削除 && apt-get clean #=================== # Develop Stage #=================== FROM build as develop LABEL mantainer=${LABEL} COPY ./infra/docker/www/develop.nginx.conf /etc/nginx/nginx.conf CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] #=================== # Production Stage #=================== FROM build as production LABEL mantainer=${LABEL} COPY ./infra/docker/www/production.nginx.conf /etc/nginx/nginx.conf CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] 可能な限りOSイメージをベースとしない ・OSイメージをベースとした場合（悪い例） OSベンダーが提供するベースイメージを使用すると，不要なバイナリファイルが含まれてしまう．原則として，一つのコンテナで一つのプロセスしか実行せず，OS全体のシステムは不要なため，OSイメージをベースとしないようにする． ＊実装例＊ # CentOSイメージを，コンテナにインストール FROM centos:8 # PHPをインストールするために，EPELとRemiリポジトリをインストールして有効化． RUN dnf upgrade -y \\ && dnf install -y \\ https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm \\ https://rpms.remirepo.net/enterprise/remi-release-8.rpm \\ && dnf module enable php:remi-${PHP_VERSION} \\ # フレームワークの要件のPHP拡張機能をインストール && dnf install -y \\ php \\ php-bcmath \\ php-ctype \\ php-fileinfo \\ php-json \\ php-mbstring \\ php-openssl \\ php-pdo \\ php-tokenizer \\ php-xml \\ && dnf clean all \\ && rm -Rf /var/cache/dnf # DockerHubのComposerイメージからバイナリファイルを取得 COPY --from=composer /usr/bin/composer /usr/bin/composer ＊実装例＊ # CentOSイメージを，コンテナにインストール FROM centos:8 # nginxをインストール RUN dnf upgrade -y \\ 　　&& dnf install -y \\ 　　 nginx \\ 　　 curl \\ 　　&& dnf clean all \\ 　　&& rm -Rf /var/cache/dnf COPY infra/docker/web/nginx.conf /etc/nginx/nginx.conf CMD [\"/usr/sbin/nginx\", \"-g\", \"daemon off;\"] EXPOSE 80 ・ミドルウェアイメージをベースとした場合（良い例） 代わりに，ミドルウェアベンダーが提供するベースイメージを使用するようにする． ＊実装例＊ # Nginxイメージを，コンテナにインストール FROM nginx:1.19 # NginxイメージがUbuntuベースなためにapt-getコマンド RUN apt-get updatedocke -y \\ && apt-get install -y \\ curl \\ && apt-get clean COPY ./infra/docker/www/production.nginx.conf /etc/nginx/nginx.conf ・言語イメージをベースとした場合 代わりに，言語ベンダーが提供するベースイメージを使用するようにする． # ここに実装例 ・alpineイメージをベースとした場合 # ここに実装例 04. ホストとコンテナ間のマウント Bindマウント ・Bindマウントとは ホストOSの/Usersディレクトリをコンテナ側にマウントする方法．ホストOSで作成されるデータが継続的に変化する場合に適しており，例えばアプリケーションをホストコンテナ間と共有する方法として推奨である．しかし，ホストOSのデータを永続化する方法としては不適である．また，Dockerfileまたはdocker-composeファイルに記述する方法があるが，後者が推奨である． ＊コマンド例＊ # ホストOSをコンテナ側にbindマウント $ docker run -d -it --name /bin/bash \\ --mount type=bind, src=home/projects/, dst=/var/www/ ・マウント元として指定できるディレクトリ 以下の通り，ホストOSのマウント元のディレクトリにはいくつか選択肢がある． Volumeマウント ・Volume（Data Volume），Dockerエリアとは ホストOSのDockerエリア（/var/lib/docker/volumesディレクトリ）に保存される永続データのこと．Data Volumeともいう．Volumeへのパス（/var/lib/docker/volumes//_data）は，マウントポイントという． ・Volumeマウントとは ホストOSにあるDockerエリアのマウントポイントをコンテナ側にマウントする方法．ホストOSで作成されるデータがめったに変化しない場合に適しており，例えばDBのデータをホストコンテナ間と共有する方法として推奨である． ・Data Volumeコンテナによる永続化データの提供 Volumeを使用する場合のコンテナ配置手法の一つ．DockerエリアのVolumeをData Volumeをコンテナ （Data Volumeコンテナ）のディレクトリにマウントしておく．Volumeを使用する時は，Dockerエリアを参照するのではなく，Data Volumeコンテナを参照するようにする． 05. ホストとコンテナ間のネットワーク接続 bridgeネットワーク ・bridgeネットワークとは 複数のコンテナ間に対して，仮想ネットワークで接続させる．また，仮想ネットワークを物理ネットワークの間を，仮想ブリッジを用いてbridge接続する．ほとんどの場合，この方法を用いる． 参考：https://www.itmedia.co.jp/enterprise/articles/1609/21/news001.html 物理サーバへのリクエストメッセージがコンテナに届くまでを以下に示す．物理サーバの8080番ポートと，WWWコンテナの80番ポートのアプリケーションの間で，ポートフォワーディングを行う．これにより，『http://:8080』にリクエストを送信すると，WWWコンテナのポート番号に転送されるようになる． 処理場所 リクエストメッセージの流れ プライベートIPアドレス例 ポート番号例 コンテナ内プロセス プロセスのリッスンするポート :80 ↑ コンテナ コンテナポート ・http://127.0.0.1・http:// :80 ↑ ホストOS 仮想ネットワーク http://172.XX.XX.XX ↑ ホストOS 仮想ブリッジ ↑ ホストハードウェア 物理サーバのNIC（ Ethernetカード） http://127.0.0.1 :8080 noneネットワーク ・noneネットワークとは 特定のコンテナを，ホストOSや他のコンテナとは，ネットワーク接続させない． $ docker network list NETWORK ID NAME DRIVER SCOPE 7edf2be856d7 none null local hostネットワーク ・hostネットワークとは 特定のコンテナに対して，ホストOSと同じネットワーク情報をもたせる． $ docker network list NETWORK ID NAME DRIVER SCOPE ac017dda93d6 host host local コンテナ間の接続方法 ・『ホストOS』から『ホストOS（localhost）』にリクエスト 『ホストOS』から『ホストOS』に対して，アウトバウンドなリクエストを送信する．ここでのホストOSのホスト名は，『localhost』となる．リクエストは，ポートフォワーディングされたコンテナに転送される．ホストOSとコンテナの間のネットワーク接続の成否を確認できる． ＊コマンド例＊ 『ホストOS』から『ホストOS』に対してアウトバウンドなリクエストを送信し，ホストOSとappコンテナの間の成否を確認する． # ホストOSで実行 $ curl --fail http://localhost:8080/ ・『コンテナ』から『コンテナ』にリクエスト 『コンテナ』から『コンテナ』に対して，アウトバウンドなリクエストを送信する．ここでのコンテナのホスト名は，コンテナ内の『/etc/hosts』に定義されたものとなる．リクエストはホストOSを経由せず，そのままコンテナに送信される．コンテナ間のネットワーク接続の成否を確認できる．コンテナのホスト名の定義方法については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/virtualization/virtualization_container_orchestration.html ＊コマンド例＊ 『appコンテナ』から『nginxコンテナ』に対して，アウトバウンドなリクエストを送信し，appコンテナとnginxコンテナの間の成否を確認する． # コンテナ内で実行 $ curl --fail http://:80/ ・『コンテナ』から『ホストOS（host.docker.internal）』にリクエスト 『コンテナ』から『ホストOS』に対して，アウトバウンドなリクエストを送信する．ここでのホストOSのホスト名は，『host.docker.internal』になる．リクエストは，ホストOSを経由して，ポートフォワーディングされたコンテナに転送される．ホストOSとコンテナの間のネットワーク接続の成否を確認できる． # コンテナ内で実行 $ curl --fail http://host.docker.internal:8080/ "},"public/virtualization/virtualization_container_orchestration.html":{"url":"public/virtualization/virtualization_container_orchestration.html","title":"📖 ︎コンテナオーケストレーション","keywords":"","body":"コンテナオーケストレーション はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コンテナオーケストレーションの種類 単一ホストOS上のコンテナオーケストレーション 単一ホストOS上のコンテナが対象である．異なるDockerfileに基づいて，Dockerイメージのビルド，コンテナレイヤーの生成，コンテナの構築，コンテナの起動，を実行できる． ツール名 ベンダー Docker Compose Docker ECS：Elastic Container Service Amazon 複数ホストOSに渡るコンテナオーケストレーション 複数ホストOS上のコンテナが対象である．どのホストOSのDockerデーモンに対して，どのコンテナに関する操作を行うのかを選択的に命令できる． 参考：https://www.techrepublic.com/article/simplifying-the-mystery-when-to-use-docker-docker-compose-and-kubernetes/ ツール名 ベンダー Docker Swarm Docker Kubernetes Google EKS：Elastic Kubernetes Service Amazon 02. コンテナデザインパターン サイドカー・パターン ・サイドカー・パターンとは アプリケーションコンテナを補助するコンテナとして，同じECSタスクやPod内に配置する． ・ロギングコンテナの配置 FluentBitコンテナをサイドカーコンテナとして稼働させ，アプリケーションコンテナから送信されたログを他にルーティングする． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability_fluentbit.html ・メトリクス収集コンテナの配置 Datadogコンテナをサイドカーコンテナとして稼働させ，アプリケーションコンテナからメトリクスを収集する． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability_datadog_metrics.html アンバサダー・パターン アダプター・パターン "},"public/virtualization/virtualization_container_orchestration_docker_compose_command.html":{"url":"public/virtualization/virtualization_container_orchestration_docker_compose_command.html","title":"📖 ︎docker-composeコマンド","keywords":"","body":"docker-composeコマンド はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コマンド config ・configとは バリデーションとして，docker-compose.ymlファイルを展開する．ファイル内で，相対パスや変数を使用している場合，これらが正しく設定されているかを確認できる． ・オプションなし $ docker-compose config build ・buildとは イメージをビルドする． ・--no-cache キャッシュを使用せずにイメージをビルドする． $ docker-compose build --no-cache up ・upとは 指定したサービスのイメージのビルド，コンテナレイヤー生成，コンテナ構築，コンテナ起動を行う．コンテナ構築までが完了していて停止中が存在する場合，これをコンテナを起動する．また起動中のコンテナがあれば，これを再起動する．オプションにより起動モードが異なる． ・オプションなし 指定したサービスのイメージのビルド，コンテナレイヤー生成，コンテナ構築，コンテナ起動を行う．アタッチモードでコンテナを起動する． # アタッチモード $ docker-compose up ・-d 指定したサービスのイメージのビルド，コンテナレイヤー生成，コンテナ構築，コンテナ起動を行う．デタッチドモードでコンテナを起動する． # デタッチモード $ docker-compose up -d ・--build イメージをビルドし，コンテナを構築する． $ docker-compose up --build -d run ・runとは すでに停止中または起動中のコンテナが存在していても，これとは別にコンテナを新しく構築し，起動する．さらにそのコンテナ内でコマンドを実行する．起動時にbashプロセスやbashプロセスを実行すると，コンテナに接続できる．何も渡さない場合は，デフォルトのプロセスとしてbashプロセスが実行される．runコマンドでは，アタッチモードとデタッチモードを選ぶことができる．新しく起動したコンテナを停止後に自動削除する場合は，rmオプションを付けるようにする．service-portsオプションを使用しないと，ホストOSとコンテナ間のポートフォワーディングを有効化できないため注意する． ・--service-ports 既存コンテナを残して，指定したサービスの新しいコンテナをアタッチモードで起動する．また，ホストOSとコンテナ間のポートフォワーディングを有効化する． # アタッチモード $ docker-compose run --rm --service-ports ・-d --service-ports 既存コンテナを残して，指定したサービスの新しいコンテナをデタッチドモードで起動する．また，ホストOSとコンテナ間のポートフォワーディングを有効化する． # デタッチモード $ docker-compose run --rm -d --service-ports stop ・stopとは 指定したサービスの起動中コンテナを全て停止する． ・オプションなし $ docker-compose stop down ・downとは 指定したリソースを削除する． ・--rmi --volumes --remove-orphans 全てのリソース（イメージ，コンテナ，ボリューム，ネットワーク）を削除する． $ docker-compose down --rmi all --volumes --remove-orphans logs ・logsとは コンテナ内に入ることなく，起動プロセスから出力されるログを確認することできる． ・オプションなし バックグラウンドでログを表示する． $ docker-compose logs ・-f フォアグラウンドでログを表示する． $ docker-compose logs -f "},"public/virtualization/virtualization_container_orchestration_docker_compose_yml.html":{"url":"public/virtualization/virtualization_container_orchestration_docker_compose_yml.html","title":"📖 ︎docker-compose.yml","keywords":"","body":"docker-compose.yml 01. services servicesとは コンテナオーケストレーションにおける一つのコンテナを定義する．コンテナ名と異なり，サービス名は他のプロジェクトと重複してもよい．docker-composeコマンドの引数として指定するため，できるだけ簡潔にする．オプション一覧は以下を参考にせよ． 参考：https://docs.docker.jp/compose/compose-file.html args DockerfileのARGSに展開する変数を定義する．Dockerfileに直接実装することとの使い分けとして，Dockerfileの実装は簡単に変更できないが，docker-compose.ymlファイルにおける定義は変更しやすい．そのため，使用者に変更して欲しくない変数はDockerfileに実装し，変更しても問題ない変数はこのオプションを使用する．他に，マルチステージビルドを使用しており，全てのステージで共通した変数を展開したい場合，このオプションを使用すると展開する変数を共通化できる． ＊実装例＊ services: app: build: - PARAM=$PARAM ARG PARAM ENV PARAM=${PARAM} ＊実装例＊ # ここに実装例 build ・dockerfile Dockerfileの名前．パスごと指定する． ＊実装例＊ services: app: build: dockerfile: ./docker/app/Dockerfile ・context 指定したDockerfileのあるディレクトリをカレントディレクトリとして，Dockerデーモン（Dockerエンジン）に送信するディレクトリを指定する． ＊実装例＊ services: app: build: context: . ・target ビルドするステージ名．主に，マルチステージビルドの時に使用する． ＊実装例＊ services: app: build: target: develop command コンテナの起動時に最初に実行するコマンドを設定する．Dockerfileを必要とせず，ベンダーが提供するイメージをそのまま使用するような場合に役立つ． ＊実装例＊ mysqlイメージを使用してコンテナを構築するときに，最初に文字コードを設定するコマンドを実行する． services: db: command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci container_name コンテナ名を命名する．サービス名とは異なり，コンテナ名は他のプロジェクトと重複しないようにする． ＊実装例＊ services: web: container_name: nginx depends_on コンテナが起動する順番を設定する． ＊実装例＊ DBコンテナの起動後に，該当するコンテナを起動するようにする． services: app: depends_on: - db env_file，environment コンテナで展開する環境変数を定義する．Dockerfile内での環境変数とは異なり，マルチステージビルドの全ステージで使用できる．dotenv系ライブラリを使用しなくてもよくなる． ＊実装例＊ mysqlイメージを使用した場合，データベースの環境変数の設定が必要である．データベースの環境変数は，バックエンドコンテナでも必要なため，environmentキーに直接環境変数を設定せずに，envファイルに定義した環境変数をenvironmentキーで参照するとよい． services: db: env_file: - .env environment: MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD} # rootユーザのパス MYSQL_DATABASE: ${DB_DATABASE} # データベース名 MYSQL_USER: ${DB_USER} # 一般ユーザ名 MYSQL_PASSWORD: ${DB_PASSWORD} # 一般ユーザのパス # .envファイル MYSQL_ROOT_PASSWORD=foo # rootユーザのパス MYSQL_DATABASE=bar # データベース名 MYSQL_USER=baz # 一般ユーザ名 MYSQL_PASSWORD=qux # 一般ユーザのパス mysqlイメージでは，環境変数の設定に応じて，コンテナ起動時にSQLが実行されるようになっている．データベース名の環境変数が設定されている場合は『CREATE DATABASE』，またユーザ名とパスワードが設定されている場合は『CREATE USER』と『GRANT ALL』のSQLが実行される． 参考：https://github.com/docker-library/mysql/blob/master/5.7/docker-entrypoint.sh#L308-L322 ルートユーザ名は定義できず，『root』となる． 参考：https://github.com/docker-library/mysql/blob/master/5.7/docker-entrypoint.sh#L156 extra_host コンテナに，ユーザ定義のプライベートIPアドレスと，これにマッピングされたホスト名を設定する．マッピングは，/etc/hostsファイルに書き込まれる．もし設定しなかった場合，サービス名またはコンテナ名がホスト名として扱われる． services: web: extra_hosts: - web:162.242.195.82 $ cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters # ユーザ定義のプライベートIPアドレスと，これにマッピングされたホスト名 162.242.195.82 web 172.23.0.3 c9bd8ace335d hostname ＊実装例＊ コンテナに割り当てられるプライベートIPアドレスに，指定したホスト名をマッピングする．マッピングは，/etc/hostsファイルに書き込まれる．もし設定しなかった場合，サービス名またはコンテナ名がホスト名として扱われる． ＊実装例＊ services: web: hostname: web $ cat /etc/hosts 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters # プライベートIPアドレスにマッピングされたホスト名 172.18.0.3 web image イメージに名前をつける．標準では，『プロジェクト名_サービス名』となる． ＊実装例＊ services: app: image: foo-app: logging ・fluentd コンテナで生成されたログをFluentdコンテナに転送する． 参考：https://docs.fluentd.org/container-deployment/docker-compose#step-0-create-docker-compose.yml ＊実装例＊ services: app: logging: driver: fluentbit options: fluentd-address: localhost:24224 tag: app log_router: build: ./docker/fluentd/Dockerfile ports: - \"24224:24224\" networks コンテナを接続する内部／外部ネットワークのエイリアス名を設定する．ネットワーク名ではなく，エイリアス名を指定することに注意する． ＊実装例＊ networks: # 内部／外部ネットワークのエイリアス名を指定する． - foo-network ネットワークに接続されているコンテナはコマンドで確認できる． # 指定したネットワークに接続するコンテナを確認する． $ docker network inspect foo-network [ { \"Name\": \"foo-network\", # ～ 中略 ～ \"Containers\": { \"e681fb35e6aa5c94c85acf3522a324d7d75aad8eada13ed1779a4f8417c3fb44\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" \"33632947e4210126874a7c26dce281642a6040e1acbebbdbbe8ba333c281dff8\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" } }, # ～ 中略 ～ \"Labels\": { \"com.docker.compose.network\": \"foo-network\", \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.29.0\" } } ] なお，接続するネットワークは明示的に指定しなくてもよい．その場合，『_default』というネットワークが，『default』というエイリアス名で作成される． services: web: networks: # defaultは，明示的に指定してもしなくてもどちらでもよい． - default $ docker network inspect _default [ { \"Name\": \"_default\", # ～ 中略 ～ \"Containers\": { \"e681fb35e6aa5c94c85acf3522a324d7d75aad8eada13ed1779a4f8417c3fb44\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" \"33632947e4210126874a7c26dce281642a6040e1acbebbdbbe8ba333c281dff8\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" } }, # ～ 中略 ～ \"Labels\": { \"com.docker.compose.network\": \"default\", \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.29.0\" } } ] platform コンテナのCPUアーキテクチャを設定する． ＊実装例＊ services: app: platform: linux/amd64 ports ホストOSとコンテナの間のポートフォワーディングを設定する．コンテナのみポート番号を指定した場合，ホストOS側のポート番号はランダムになる． ＊実装例＊ services: web: ports: - \"8080:80\" # : stdin_open docker-composeコマンドの裏側で実行されるrunコマンドにおいて，iオプションを有効化する． ＊実装例＊ services: app: stdin_open: true tty docker-composeコマンドの裏側で実行されるrunコマンドにおいて，tオプションを有効化する．疑似ターミナルを割り当てるによって，exitの後もバックグラウンドでコンテナを起動させ続けられる． ＊実装例＊ services: app: tty: true volumes（Bindマウント） 最上層とservice内で，異なるVolume名を記述した場合，Bindマウントを定義する．ホストOSにある/Usersディレクトリをコンテナ側にマウントする． ＊実装例＊ services: app: volumes: - ./web:/var/www/foo # : volumes（Volumeマウント） 最上層とservice内の両方に，同じVolume名を記述した場合，Volumeマウントを定義する．DockerエリアにVolumeが作成され，serviceオプション内に設定したvolumesオプションでVolumeマウントを行う． ＊実装例＊ service: db: volumes: # volumeマウント - mysql_volume:/var/www/lib/mysql volumes: # volume名 mysql_volume: # localで，ホストOSのDockerエリアを指定 driver: local 変数展開 環境変数をdocker-compose.ymlファイルに展開する．変数の展開にあたり，docker-compose.ymlファイルと同じ階層にある.envファイルが自動的に読み込まれる．この展開にenv_fileオプションを使用することはできない．そのため，例えば.envファイル以外の名前の環境変数ファイルを変数展開のために使用することはできない． ＊実装例＊ services: app: build: # 出力元の値は，.envファイルに定義しなければならない． target: ${APP_ENV} image: ${APP_ENV}-foo-app 02. networks networksとは 標準のネットワークを作成する．ただし定義しなくとも自動的に構築される．ネットワーク名は，指定しない場合に『_default』になる． ・name ネットワーク名をユーザ定義名にする． networks: default: # ユーザ定義のネットワーク名とエイリアス名 name: foo-network なお，このネットワークを明示的に設定する場合は，エイリアス名（default）で指定する． services: web: networks: # defaultは，明示的に指定してもしなくてもどちらでもよい． - default $ docker network ls NETWORK ID NAME DRIVER SCOPE ************ foo-network bridge local $ docker network inspect foo-network [ { \"Name\": \"foo-network\", # ～ 中略 ～ \"Containers\": { \"e681fb35e6aa5c94c85acf3522a324d7d75aad8eada13ed1779a4f8417c3fb44\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" \"33632947e4210126874a7c26dce281642a6040e1acbebbdbbe8ba333c281dff8\": { \"Name\": \"\", \"EndpointID\": \"ef04da88901646359086eeb45aab81d2393c2f71b4266ccadc042ae49d684409\", \"MacAddress\": \"**:**:**:**:**:**\", \"IPv4Address\": \"nnn.nn.n.n/nn\", \"IPv6Address\": \"\" } }, # ～ 中略 ～ \"Labels\": { \"com.docker.compose.network\": \"foo-network\", \"com.docker.compose.project\": \"\", \"com.docker.compose.version\": \"1.29.0\" } } ] ・external 異なるdocker-compose.ymlファイルから接続できるネットワークを作成する．作成されるネットワーク名とエイリアス名は，externalキーの上部で設定したものになる． ＊実装例＊ バックエンドとフロントエンドが異なるdocker-compose.ymlファイルで管理されている．フロントエンドコンテナからバックエンドコンテナに接続できるように，ネットワークを作成する． # バックエンドのDocker-compose services: app: container_name: backend-container # ～ 中略 ～ networks: # 作成したい外部ネットワーク名とエイリアス名 backend: external: true フロントエンドコンテナにて，エイリアス名にネットワーク名を指定して， # フロントエンドのDocker-compose services: app: container_name: frontend-container # 内部／外部ネットワークのいずれかのエイリアス名を指定する． networks: - backend # ～ 中略 ～ networks: default: external: # 接続したい外部ネットワーク名とエイリアス名 name: backend 作成した内部／外部ネットワークは，コマンドで確認できる．『_default』というネットワーク名になる． ＊コマンド例＊ $ docker network ls NETWORK ID NAME DRIVER SCOPE ************ backend bridge local 04. プラグイン Volumeプラグイン ・NFSストレージ NFSプラグインを使用することで，永続化データを/var/lib/docker/volumesではなく，NFSストレージに保存する． ＊実装例＊ 以下にdocker-composeを使用した場合を示す． version: \"3.7\" services: app: build: # ～ 中略 ～ ports: # ～ 中略 ～ depends_on: # ～ 中略 ～ volumes: - example:/data # 下方のオプションが適用される． volumes: example: driver_opts: # NFSプラグインを使用し，NFSストレージに保存． type: \"nfs\" o: \"addr=10.40.0.199,nolock,soft,rw\" device: \":/nfs/example\" 05. イメージ別Tips mysqlイメージ ・ビルド時にSQL実行 mysqlコンテナにはdocker-entrypoint-initdb.dディレクトリがある．このディレクトリに配置されたsqlファイルやbashプロセスは，mysqlコンテナのビルド時にdocker-entrypoint.shファイルによって実行される．そのため，Bindマウントを用いてこのディレクトリにファイルを置くことで，初期データの投入や複数データベースの作成を実現できる．具体的な実行タイミングについては，以下を参考にせよ． 参考：https://github.com/docker-library/mysql/blob/master/8.0/Dockerfile.debian#L92-L93 ＊実装例＊ mysqlコンテナに，PHPUnitの実行時のみ使用するデータベースを追加する．以下のような，docker-compose.ymlファイルを作成する． version: \"3.7\" services: db: container_name: foo-mysql hostname: foo-mysql image: mysql:5.7 ports: - \"3307:3306\" volumes: - mysql_volume:/var/www/lib/mysql # docker-entrypoint-initdb.dディレクトリにBindマウントを行う． - ./infra/docker/mysql/init:/docker-entrypoint-initdb.d environment: MYSQL_ROOT_PASSWORD: foo MYSQL_DATABASE: foo MYSQL_USER: foo MYSQL_PASSWORD: foo TZ: \"Asia/Tokyo\" command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci networks: - default volumes: mysql_volume: また，docker-entrypoint-initdb.dディレクトリに配置するファイルとして，以下のsqlファイルを作成する．このファイルでは，testというデータベースを作成するためのSQLを実装する． -- /infra/docker/mysql/initにSQLファイルを置く． CREATE DATABASE IF NOT EXISTS `test` COLLATE 'utf8mb4_general_ci' CHARACTER SET 'utf8mb4'; GRANT ALL ON *.* TO 'foo'@'%' ; PHPUnitで接続するデータベースを指定する方法については，以下を参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_php_testing_based_on_code.html "},"public/virtualization/virtualization_container_orchestration_kubernetes.html":{"url":"public/virtualization/virtualization_container_orchestration_kubernetes.html","title":"📖 ︎Kubernetes","keywords":"","body":"Kubernetes はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. コマンド Kubectl ・Kubectlとは 02. .yml spec／statu 参考：https://kubernetes.io/ja/docs/concepts/overview/working-with-objects/kubernetes-objects/ Node ・Master Node Kubernetesが実行されるホスト物理サーバを指す． ・Worker Node Dockerが実行されるホスト仮想サーバを指す． Service ・Serviceとは Podにリクエストを転送するロードバランサーとして機能する． 参考：https://kubernetes.io/ja/docs/concepts/services-networking/service/ ・定義 apiVersion: v1 kind: Service metadata: name: my-service # Service名 spec: selector: app: MyApp ports: - protocol: TCP port: 80 # Service受信ポート targetPort: 9376 # 転送先のPod受信ポート Pod ・Podとは ホスト仮想サーバ上のコンテナを最小グループ単位のこと．Podを単位として，コンテナ起動／停止や水平スケールイン／スケールアウトを実行する． 参考：https://kubernetes.io/ja/docs/concepts/workloads/pods/ AWS ECSタスクにおける類似するessential機能やオートスケーリングについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/cloud_computing/cloud_computing_aws.html ＊例＊ PHP-FPMコンテナとNginxコンテナを稼働させる場合，これら同じPodに配置する． ・定義 apiVersion: batch/v1 kind: Job metadata: name: hello spec: template: # Pod spec: containers: - name: hello # Pod内コンテナ名 image: busybox # イメージ command: ['sh', '-c', 'echo \"Hello, Kubernetes!\" && sleep 3600'] # コンテナ起動時コマンド restartPolicy: OnFailure Secret ・Secretとは セキュリティに関するデータを管理し，コンテナに選択的に提供するもの． Replica Set ・Replica Set（Replication Controller）とは 02. Istio Istioとは ただし，Istioを必ずしも使用する必要はなく，Kubernetesの標準の機能でこれを実現してもよい． 参考：https://qiita.com/Ladicle/items/4ba57078128d6affadd5 システムのコンポーネント間通信を制御しきれない． 障害時に何が起こるか分からない． 鍵と証明書を管理しきれない． システムの全体像が把握できない ・依存関係の解決 マイクロサービスアーキテクチャの各アプリケーションを管理するソフトウェアのこと．機能『A ---> B ---> C ---> D』を持つモノリシックアプリケーションがあるとする．これをマイクロサービス化して，ABCDを別々のアプリケーションに分割する．それぞれのアプリケーションがPod上で稼働することになる．しかし，これだけではABCDが独立しておらず，各機能は一つ前の機能に依存している．この依存関係を解決する． Istiod ・Istiodとは Envoyを管理する機能のこと．Envoyは，各アプリケーションから通信を委譲され，アプリケーション間の通信を代理で行う． "},"public/virtualization/virtualization_container_orchestration_docker_swarm.html":{"url":"public/virtualization/virtualization_container_orchestration_docker_swarm.html","title":"📖 ︎Docker Swarm","keywords":"","body":"Docker Swarm はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 概念 "},"public/virtualization/virtualization_server.html":{"url":"public/virtualization/virtualization_server.html","title":"📖 ︎仮想サーバ（仮想マシン）","keywords":"","body":"仮想サーバ（仮想マシン） はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Providerによる仮想サーバ（仮想マシン）の構築 Providerの操作 ・Providerとは 基本ソフトウェアにおける制御プログラムや一連のハードウェアを仮想的に構築できる．これを，仮想サーバ（仮想マシンとも）という．構築方法の違いによって，『ホスト型』，『ハイパーバイザ型』に分類できる． Provisionerの操作 ・Provisionerとは Providerによって構築された仮想サーバに，Web開発のためのソフトウェアをインストールできる（構成管理できる）．具体的には，プログラミング言語やファイアウォールをインストールする． VagrantによるProviderとProvisionerの操作 ・Vagrantとは ProviderとProvisionerの操作を自動化できる．チームメンバーが別々に仮想サーバを構築する場合，ProviderとProvisionerの処理によって作られる仮想サーバの環境に，違いが生じてしまう．Vagrantを使う場合，ProviderとProvisionerによる処理方法は，Vagrantfileに記述されている．このために，Vagrantを用いれば，チームメンバーが同じソフトウェアの下で，仮想サーバを構築し，ソフトウェアをインストールできる． ・サーバの情報の管理方法 サーバの情報は，.envファイルで以下の様に管理する．全ての値が文字列として認識されるため，数値や真偽値は使用できない． #======================================= # Webサーバ情報 #======================================= WEB_HOST= #======================================= # データベースサーバ情報 #======================================= DB_HOST=foo-db DB_NAME=foo DB_USER=foo DB_PASSWORD=***** ・主なvagrantコマンド コマンド 処理 vagrant up 仮想サーバ起動 vagrant halt 仮想サーバ停止 vagrant ssh 仮想サーバへのリモート接続 vagrant global-status 起動中仮想サーバの一覧 02. フレームワークのビルトインサーバの構築 "},"public/ci_cd/ci_cd.html":{"url":"public/ci_cd/ci_cd.html","title":"📖 ︎CICD","keywords":"","body":"CI／CD はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. CICDパイプライン ・CICDパイプラインとは Commitから本番環境へのDeployまでのプロセスを『継続的に』行うことを，CI：Continuous Integration』という．また，変更内容をステージング環境などに自動的に反映し，『継続的に』リリースすることを，CD：Continuous Deliveryという． ・自動化できるプロセスとできないプロセス プロセス 自動化の可否 説明 Build 〇 CI/CDツールとIaCツールで自動化可能 Unitテスト，Functionalテスト 〇 CI/CDツールとテストフレームワークで自動化可能． Integrationテスト ✕ テスト仕様書を作成し，動作を確認する必要がある． コーディング規約に関するReview 〇 CI/Cdツールと静的解析ツール 仕様に関するReview ✕ GitHub上でレビューする必要がある． ステージング環境へのデプロイ 〇 CI/CDツールで自動化可能． 本番環境へのデプロイ 〇 CI/CDツールで自動化可能． "},"public/ci_cd/ci_cd_circleci.html":{"url":"public/ci_cd/ci_cd_circleci.html","title":"📖 ︎CircleCI","keywords":"","body":"CircleCI はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. CircleCIとは 設定ファイルの参考ドキュメント https://circleci.com/docs/reference-2-1/#circleci-2-1-reference 設定ファイルのデバッグ ・デバッグの事前準備 デバッグでは行数がわからない仕様になっている．そこで，Workflowのjobのどこで失敗しているのかを特定するために，検証しないjobをコメントアウトしておく． workflows: # build以外を実行しないようにすることで，buildのみを検証できる． build-test-and-deploy: jobs: - build # - test1: # requires: # - build # - test2: # requires: # - test1 # - deploy: # requires: # - test2 ・バリデーション ホストOS側で，以下のコマンドを実行する． $ circleci config validate # 以下の文章が表示されれば問題ない． # Config file at .circleci/config.yml is valid. ・処理の展開 設定ファイルを実行した時の処理を展開し，ファイルに出力できる $ circleci config process .circleci/config.yml > .circleci/process.yml ・ローカルテスト コマンドにより，テストに必要なDockerイメージをpullし，コンテナを構築する．続いて，コンテナ内でCircleCIを実行する．バージョン2.1以降では，事前に，設定ファイルの処理を展開しておく必要がある． # バージョン2.1の設定ファイルの処理を展開 $ circleci config process .circleci/config.yml > .circleci/process.yml # 専用のDockerコンテナを構築し，展開ファイルを元にテストを実行 $ circleci local execute -c .circleci/process.yml --job ・CircleCIコンテナにssh接続 CircleCIコンテナにssh接続し，コンテナ内で生成されたファイルを確認できる． $ -i ~/.ssh/ ・Test Insights 各テストのパフォーマンスや成功失敗率を確認できる． https://circleci.com/docs/2.0/insights-tests/ PHPUnitの自動実行 ・仕組み テストクラスを実装したうえで，新機能を設計実装する． リポジトリへPushすると，CIツールがGituHubからブランチの状態を取得する． CIツールによって，DockerHubから取得したDockerfileのビルド，PHPUnitなどが自動実行される． 結果を通知することも可能． PHPStanの自動実行 ・仕組み 02-02. version versionとは CircleCIのバージョンを宣言． ＊実装例＊ version: 2.1 02-03. parameters parameters ・parametersとは 種類 参照範囲 値を設定する場所 command parameters command内で定義する．定義されたcommand内のみで定義できる． workflows job parameters job内で定義する．定義されたjob内のみで参照できる． workflows executors parameter executors内で定義する．定義されたexecutos内のみで参照できる． job pipeline parameters トップレベルで定義する．リポジトリ内でのみ参照できる． workflows command parameters ・値の出力方法 引数名を使用して，parametersから値を出力する． > ・job parameterを参照 定義できるデータ型は，job parameterと同じ．定義されたcommand内のみで定義できる． version: 2.1 commands: sayhello: description: \"Echo hello world\" # 引数の定義 parameters: to: type: string # デフォルト値 default: \"Hello World\" steps: - run: echo > job parameters ・値の出力方法 引数名を使用して，parametersから値を出力する． > ・デフォルト値について 引数が与えられなかった場合に適用されるdefaultを設定できる．defaultを設定しない場合，引数が必須と見なされる． version: 2.1 commands: sayhello: description: \"Echo hello world\" parameters: to: type: string default: \"Hello World\" steps: - run: echo > ・string型 引数として，任意の文字列を渡したいときに使用する．workflowsにて，値を設定する． ＊実装例＊ version: 2.1 commands: print: # 引数を定義 parameters: message: # デフォルト値が無い場合は必須 type: string steps: - run: echo > jobs: cat-file: parameters: file: type: string steps: - print: # parametersの値を渡す message: Printing > - run: cat > workflows: my-workflow: jobs: - cat-file: # workflowにて文字列型の値を設定 file: test.txt ・boolean型 多くの場合，引数がTrueの場合のみ，特定のstepを実行したい時に用いる．jobで定義した後，workflowsにて値を設定する．workflowsにて，値を設定する． ＊実装例＊ version: 2.1 jobs: job_with_optional_custom_checkout: # 引数の定義 parameters: custom_checkout: type: boolean # デフォルト値 default: false machine: true steps: - when: # 引数がtrueの場合 condition: > steps: - run: echo \"my custom checkout\" - unless: # 引数のfalseの場合 condition: > steps: - checkout workflows: build-test-deploy: jobs: - job_with_optional_custom_checkout: # workflowにてbool型の値を設定 custom_checkout: true ・enum型 引数として，特定の文字列や整数のみを渡したいときに用いる．workflowsにて，値を設定する． ＊実装例＊ version: 2.1 jobs: deploy: parameters: # 引数を定義 environment: # デフォルト値 default: \"test\" type: enum enum: [\"test\", \"stg\", \"prd\"] steps: - run: # デフォルト値testを与えるときは何も設定しない name: Deploy to > command: # 何らかの処理 workflows: deploy: jobs: - deploy: # workflowにてenum型の値を設定 environment: stg executors parameter ・値の出力方法 引数名を使用して，parametersから値を出力する． > ・job parametersを参照 引数として，任意の文字列をexecutorsに渡したいときに使用する．他のparametersとは異なり，jobにて，値を設定する． version: 2.1 executors: python: # 引数の定義 parameters: tag: type: string # デフォルト値 default: latest myspecialvar: type: string docker: - image: circleci/python:> environment: MYPRECIOUS: > jobs: build: executor: name: python tag: \"2.7\" # jobにて文字列型の値を設定 myspecialvar: \"myspecialvalue\" ・workflowで値を設定する 公式リファレンスには載っていないため，方法としては非推奨．parameterを渡したいexecutorを使いまわしたい時に使用する． version: 2.1 executors: python: # 引数の定義 parameters: env: type: enum enum: [ \"2.7\", \"3.5\" ] myspecialvar: type: string docker: - image: circleci/python:> environment: MYPRECIOUS: > jobs: build: # 引数の定義 parameters: # executorをデータ型として選択 executor_param: type: executor executor: > workflows: version: 2.1 build-push: jobs: - build: # jobにてexecutor名を設定し，さらにexecutorに値を渡す executor_param: name: python # バージョン3.5を設定 tag: \"2.7\" myspecialvar: \"myspecialvalue\" - build: executor_param: name: python # バージョン3.5を設定 tag: \"3.5\" myspecialvar: \"myspecialvalue\" pipeline parameters ・値の出力方法 引数名を使用して，pipeline.parametersから値を出力する． > ・job parametersを参照 定義できるデータ型は，job parameterと同じ．リポジトリ内でのみ参照できる． version: 2.1 parameters: # 引数を定義 image-tag: type: string # デフォルト値 default: \"latest\" workingdir: type: string default: \"~/main\" jobs: build: docker: - image: circleci/node:> auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD environment: IMAGETAG: > working_directory: > steps: - run: echo \"Image tag used was ${IMAGETAG}\" - run: echo \"$(pwd) == >\" workflows: my-workflow: jobs: - build: # 引数名: 渡す値 image-tag: \"1.0\" workdir: \"/tmp\" 02-04. jobs jobs ・jobsとは 複数のjobを定義する．Workflowsを使わない場合は，少なくとも一つのjobにはbuildという名前を使用しなければならない． ・jobの粒度 粒度 説明 備考 build プログラムの実行環境を構築する． buildとtestを分割しにくい場合は，同じjobで定義してもよい． test 種々のテスト（Unitテスト，Functionalテスト，など）を実行する． deploy ステージング環境または本番環境へのデプロイを実行する． docker，machine ・仮想環境の選択 jobを実行する仮想環境を選択できる． ・dockerタイプとは Dockerコンテナを実行環境として設定する．これを選択したうえで，Dockerイメージのビルド（Docker composeを含む）を実行する場合，実行環境Dockerコンテナの中でDockerコンテナを構築するという入れ子構造になる．これは非推奨のため，setup_remote_dockerを使用して，実行環境Dockerコンテナとは別の環境でjobを行う必要がある．また，dockerコマンドがインストールされていないイメージで合った場合に，setup_remote_dockerを有効化すると，これを使用できるようになる．machineタイプを選んだ場合，setup_remote_dockerは不要である．ただし，ボリュームマウントを使用できなくなるので注意する．また，DockerfileのCOPYコマンドが機能しなくなる． 参考：https://circleci.com/docs/ja/2.0/building-docker-images/ ＊実装例＊ version: 2.1 jobs: build: docker: - image: circleci/foo steps: - checkout # コンテナが入れ子にならないようにする． - setup_remote_docker - run: | # DockerHubへのログイン echo \"$DOCKER_PASS\" | docker login --username $DOCKER_USER --password-stdin docker run -d --name db company/proprietary-db:1.2.3 # Dockerイメージのビルド - run: docker build -t company/app:$CIRCLE_BRANCH . # DockerイメージのDockerHubへのデプロイ - run: docker push company/app:$CIRCLE_BRANCH ・machineタイプとは Linuxサーバを実行環境として設定する． ＊実装例＊ version: 2.1 jobs: build: machine: true steps: - checkout - run: | # DockerHubへのログイン echo \"$DOCKER_PASS\" | docker login --username $DOCKER_USER --password-stdin docker run -d --name db company/proprietary-db:1.2.3 # Dockerイメージのビルド - run: docker build -t company/app:$CIRCLE_BRANCH . # DockerイメージのDockerHubへのデプロイ - run: docker push company/app:$CIRCLE_BRANCH steps ・stepsとは 処理をMap型で定義する． ・when，unless if文を定義する．whenでは条件がtrueの場合，またunlessではfalseの場合に実行するstepを定義する． ＊実装例＊ version: 2.1 jobs: custom_checkout: parameters: custom_checkout_parameters: type: bool # デフォルト値はfalse default: false machine: true steps: # 引数がtrueの場合 - when: condition: > steps: - run: echo \"独自のチェックアウト処理\" # 引数がfalseの場合 - unless: condition: > steps: - checkout workflows: version: 2.1 build-test-deploy: jobs: - custom_checkout: # 引数名: 渡す値 custom_checkout_parameters: true ・restore_cache，save_cache ビルドのアーティファクトをキャッシュとして保存する．この機能を使用しない場合，例えば，CircleCIコンテナでcomposer installを実行すると，毎回のWorkflowで同じライブラリがインストールされる．しかし，Workflowのたびに，ライブラリをインストールするのは非効率である．そこで，composer.jsonファイルの実装が変更されない限り，前回のWorkflowのビルド時に，vendorディレクトリに配置されたアーティファクトを再利用するようにする．この機能は，複数のWorkflowの間だけでなく，一つのWorkflowの中でも利用できる． 参考：https://circleci.com/docs/ja/2.0/caching/#%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%AE%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5 ＊実装例＊ composerを使用してライブラリをインストールする時に，前回の結果を再利用する． version: 2.1 jobs: build: steps: # composer.jsonが変更されている場合は処理をスキップ． - restore_cache: key: - v1-dependecies-{{ checksum \"composer.json\" }} - v1-dependencies- # 取得したcomposer.jsonを元に，差分のvendorをインストール - run: name: Run composer install commands: | composer install -n --prefer-dist # 最新のvendorディレクトリをキャッシュとして保存 - save_cache: key: v1-dependecies-{{ checksum \"composer.json\" }} paths: - ./vendor ＊実装例＊ yarnを使用してライブラリをインストールする時に，前回の結果を再利用する． version: 2.1 jobs: build_and_test: docker: - image: circleci/python:3.8-node steps: - checkout - restore_cache: keys: - v1-dependencies-{{ checksum \"package.json\" }} - v1-dependencies- - run: name: Run yarn install commands: | yarn install - save_cache: paths: - node_modules key: v1-dependencies-{{ checksum \"yarn.lock\" }} - run: name: Run yarn build commands : | yarn build - run: name: Run yarn test commands : | yarn test ただ，この機能はcommandsで共通化した方が可読性が良い． ＊実装例＊ version: 2.1 commands: restore_vendor: steps: # composer.jsonの実装が変更されていない場合は処理をスキップ． - restore_cache: key: - v1-dependencies-{{ checksum \"composer.json\" }} - v1-dependencies- save_vendor: steps: # 最新のvendorを保存． - save_cache: key: v1-dependencies-{{ checksum \"composer.json\" }} paths: - ./vendor jobs: build: steps: - restore_vendor # 取得したcomposer.jsonを元に，差分のvendorをインストール - run: name: Run composer install commands: | composer install -n --prefer-dist - save_vendor ・persist_to_workspace，attach_workspace CircleCIでは，jobごとに異なる仮想環境が構築されるため，他のjobで使用された一時ファイルを再利用したい場合に，これを使う． ＊実装例＊ version: 2.1 jobs: jobA: steps: # Workspaceにファイルをアップロード - persist_to_workspace: # jobAにて，Workspaceとするディレクトリのroot root: /tmp/workspace # Rootディレクトリを基準とした相対パス（\"./\"以外の場合は，ディレクトリの作成が必要） # パラメータは環境変数として出力できないので注意 paths: - target/application.jar - build/* jobB: steps: # persist_to_workspaceで作成されたWorkspaceからファイルをダウンロード - attach_workspace: # jobAとは異なるディレクトリに，ファイルをダウンロードしてもよい at: /tmp/workspace 全てのディレクトリを保持するような場合がほとんどと思われるため，カレントディレクトリ以下（.）を指定するのがよい． ＊実装例＊ version: 2.1 jobs: jobA: steps: - persist_to_workspace: root: . paths: - . jobB: steps: - attach_workspace: at: . 02-04. commands commandsとは 設定を部品化し，異なるjobでstepとして繰り返し利用できる． 部品化と再利用 ＊実装例＊ version: 2.1 commands: sayhello: description: \"Echo hello world\" parameters: text: type: string default: \"Hello World\" steps: # parametersの値を渡す - run: echo > jobs: myjob: docker: - image: \"circleci/node:9.6.1\" steps: # command名 - sayhello: # 引数名: 渡す値 text: \"Lev\" 02-05. executors executors ・executorsとは 実行環境に関する設定を部品化し，異なるjobで繰り返し利用できる． 部品化と再利用 ＊実装例＊ version: 2.1 executors: # ホストOS環境名 my-executor: # ホストOS環境 docker: - image: circleci/ruby:2.5.1-node-browsers working_directory: ~/foo_project environment: XX: xx YY: yy jobs: my-job: executor: my-executor steps: - run: echo \"${XX}と${YY}です\" 02-06. Workflow Workflowの粒度 ・ブランチ別 ＊実装例＊ workflows: # Featureブランチをレビュー feature: jobs: - build: name: build_feat filters: branches: only: - /feature.*/ - test: name: test_feat requires: - build_feat # ステージング環境にデプロイ develop: jobs: - build: name: build_stg filters: branches: only: - develop - test: name: test_stg requires: - build_stg - deploy: name: deploy_stg requires: - test_stg # 本番環境にデプロイ main: jobs: - build: name: build_prd filters: branches: only: - main - test: name: test_prd requires: - build_prd - deploy: name: deploy_prd requires: - test_prd 特殊なsteps ・pre-steps，post-steps 事前にjobに定義する必要はない．workspaceで，コールされるjobの引数として設定することで，そのjob内の最初と最後に，stepsを追加できる． ＊実装例＊ version: 2.1 jobs: bar: machine: true steps: - checkout - run: command: echo \"building\" - run: command: echo \"testing\" workflows: build: jobs: - bar: # Workspace前に行う処理 pre-steps: - run: command: echo \"install custom dependency\" # Workspace後に行う処理 post-steps: - run: command: echo \"upload artifact to s3\" Orbsを使う場合は，オプションに引数を渡す前に定義する． ＊実装例＊ workflows: build: jobs: - aws-foo/build-push-yyy: # Workspace前に行う処理 pre-steps: - run: command: echo \"FOO\" # Workspace後に行う処理 post-steps: - run: command: echo \"FOO\" # Orbsのオプション name: foo dockerfile: foo tag: foo filters ・filtersとは コミットされた時にjobが発火するブランチ名，あるいは発火しないブランチ名，を設定する．正規表現で実装する必要がある． ・only，ignore よくあるパターン 説明 /.*/ 全てのブランチを明示的に指定 /feature\\/.*/ 「feature/」と名前のついたブランチを指定 ＊実装例＊ workflows: version: 2.1 build: jobs: - foo: filters: branches: only: - /.*/ workflows: version: 2.1 build: jobs: - foo: filters: branches: ignore: - /feature\\/.*/ ・tags タグをつけたコミットに対して発火する．ignoreキーで全てのブランチを指定することにより，マージによる発火を防げる． workflows: version: 2.1 build: jobs: - foo: filters: branches: ignore: /.*/ tags: only: /release\\/.*/ 02-07. 環境変数 CircleCIにおける環境変数とは ・環境変数の種類と参照範囲 参照レベル 方法 説明 Bash export，source，$BASH_ENV runにおけるcommand内のみで参照できる．ただし，$BASH_ENVを使用すれば，異なるcommands間で値を共有可能． Container environment job内の特定のコンテナのみで参照できる． Job environment job内のみで参照できる． Project Environment Variables機能 リポジトリ内のみ参照できる． Global Contexts機能 異なるリポジトリ間で参照できる． ・環境変数の出力方法 環境変数をechoの引数に指定する．あらかじめエンコードされた環境変数を管理しておき，base64 --decodeを実行して出力すると，安全に環境変数を管理できる．ここで出力している環境変数は，以下のノートを参考にせよ 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/software/software_application_object_oriented_language_js_framework_nuxtjs.html jobs: build_and_ docker: - image: circleci/python:3.8-node steps: - checkout - run: name: Make env file command: | echo $API_URL_BROWSER | base64 --decode > .env echo $API_URL | base64 --decode >> .env echo $OAUTH_CLIENT_ID | base64 --decode >> .env echo $OAUTH_CLIENT_SECRET | base64 --decode >> .env echo $GOOGLE_MAP_QUERY_URL | base64 --decode >> .env - run: name: Install node module commands: | yarn install - run: name: Generate nuxt-ts commands: | yarn nuxt-ts generate なお，文字列の中に値を出力する変数展開の場合，${}を使用する． # 変数展開の場合 steps: - checkout - run: name: FOO commands: | echo \"This is ${FOO}\" Bashレベル ・commandキーによる設定 一番参照範囲が小さく，runにおける同じcommand内のみで参照できる．command内で使用する環境変数を定義するためには，『$BASH_ENV』にexport処理を格納する必要がある．定義したものを使用するためには，『$BASH_ENV』をsourceで読み込む必要があるために注意する． 参考：https://circleci.com/docs/ja/2.0/env-vars/#%E3%82%B7%E3%82%A7%E3%83%AB-%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E3%81%AE%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%81%AE%E8%A8%AD%E5%AE%9A ＊実装例＊ version: 2.1 jobs: build: docker: - image: smaant/lein-flyway:2.7.1-4.0.3 auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD steps: - run: name: Update PATH and Define Environment Variable at Runtime command: | echo \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV echo \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV source $BASH_ENV echo \"$PATH\" echo \"$VERY_IMPORTANT\" CircleCIではrunを実行する時に『$BASH_ENV』がsourceで自動的に読み込まれるようになっている．そのため，『$BASH_ENV』は複数のrun間」で共有できる．ただし，Alpineベースのイメージでは，この共有機能を使えないため注意する（かなりたくさんある）． 参考：https://github.com/circleci/circleci-docs/issues/1650 version: 2.1 jobs: build: docker: - image: smaant/lein-flyway:2.7.1-4.0.3 auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD steps: - run: name: Update PATH and Define Environment Variable at Runtime command: | echo \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV echo \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV - run: name: Echo # BASH_ENVが自動的に読み込まれる． command: | echo \"$PATH\" echo \"$VERY_IMPORTANT\" ・シェルスクリプトによる設定 環境変数に値を設定する処理をシェルスクリプトに切り分け，環境変数を使用する前にこれを読み込む． ＊実装例＊ version: 2.1 jobs: build: docker: - image: smaant/lein-flyway:2.7.1-4.0.3 auth: username: mydockerhub-user password: $DOCKERHUB_PASSWORD steps: - run: name: Update PATH and Define Environment Variable at Runtime command: | source export_envs.sh echo \"$PATH\" echo \"$VERY_IMPORTANT\" #!/bin/bash set -xeuo pipefail echo \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV echo \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV # 環境変数を出力します． source $BASH_ENV ・ヒアドキュメントで作成したシェルスクリプトによる設定 ヒアドキュメントを使用して，環境変数を設定できるシェルスクリプトを作成し，これを読み込む．ヒアドキュメントでは，各行でechoが実行される．そのため，echoの実装が不要であることに注意する． ＊実装例＊ cat \"export_envs.sh\" #!/bin/bash set -xeuo pipefail \"export PATH=/path/to/foo/bin:$PATH\" >> $BASH_ENV \"export VERY_IMPORTANT=$(cat important_value)\" >> $BASH_ENV source $BASH_ENV EOF Containerレベル Bashレベルより参照範囲が大きく，job内のみで参照できる．environmentをimageと同じ階層で定義する． version: 2.1 jobs: build: docker: - image: postgres:9.4.1 # imageと同じ階層で定義（） environment: POSTGRES_USER: root Projectレベル Containerレベルより参照範囲が大きく，プロジェクト内，すなわちリポジトリ内のみで参照できる．Environment Variables機能を使用する．環境変数の値が４文字未満，または環境変数の値が true、True、false、False のいずれかの場合，CircleCIの処理で出力されるプロジェクトの環境変数はマスキングされないため，注意が必要である． Grobalレベル Projectレベルより参照範囲が大きく，異なるプロジェクト間，すなわちリポジトリ間で参照できる．Contexts機能を使用する． 02-08. Docker Compose in CircleCI docker-composeのインストール ・dockerタイプの場合 自分でdocker-composeをインストールする必要がある．実行環境としてのDockerコンテナと，ビルドしたDockerコンテナが入れ子にならないように，setup_remote_dockerを実行する必要がある．ただし，ボリュームマウントを使用できなくなるので注意する． version: 2.1 jobs: build: machine: image: circleci/classic:edge steps: - checkout - setup_remote_docker - run: name: Install Docker Compose command: | set -x curl -L https://github.com/docker/compose/releases/download/1.11.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose - run: name: docker-compose up command: | set -x docker-compose up --build -d ・machineタイプの場合（推奨） 実行環境にmachineタイプを選択した場合，すでにdocker-composeがインストールされている． 参考：https://circleci.com/docs/ja/2.0/configuration-reference/#%E4%BD%BF%E7%94%A8%E5%8F%AF%E8%83%BD%E3%81%AA-machine-%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8 docker-compose & dockerize ・docker/install-dockerize CircleCIでDocker Composeを使用する場合に必要である．Docker Composeは，コンテナの構築の順番を制御できるものの，コンテナ内のプロセスの状態を気にしない．そのため，コンテナの構築後に，プロセスが完全に起動していないのにもかかわらず，次のコンテナの構築を開始してしまう．これにより，プロセスが完全に起動していないコンテナに対して，次に構築されたコンテナが接続処理を行ってしまうことがある．これを防ぐために，プロセスの起動を待機してから，接続処理を行うようにする．dockerizeの代わりの方法として，sleepコマンドを使用してもよい． 参考：https://github.com/docker/compose/issues/374#issuecomment-126312313 ＊実装例＊ LaravelコンテナとMySQLコンテナの場合を示す．コンテナ内に対してコマンドを実行する時のディレクトリは，DockerfileのWORKDIRによって決まるので注意する． version: 2.1 orbs: docker: circleci/docker@x.y.z commands: restore_vendor: steps: - restore_cache: key: - v1-dependecies-{{ checksum composer.json }} - v1-dependencies- save_vendor: steps: - save_cache: key: v1-dependecies-{{ checksum composer.json }} paths: - /vendor jobs: build_and_test: # Docker Composeの時はmachineタイプを使用する machine: image: ubuntu-1604:201903-01 steps: - checkout - run: name: Make env file command: | echo $ENV | base64 --decode > .env - run: name: Make env docker file command: | cp .env.docker.example .env.docker - run: name: Docker config command: | docker-compose config - run: name: Docker compose up command: | set -xe docker network create foo-network docker-compose up --build -d - restore_vendor # Dockerコンテナに対してcomspoerコマンドを送信 - run: name: Composer install command: | docker-compose exec laravel-container composer install -n --prefer-dist - save_vendor # Dockerizeをインストール - docker/install-dockerize: version: v0.6.1 - run: name: Wait for MySQL to be ready command: | # 代わりにsleepコマンドでもよい． dockerize -wait tcp://localhost:3306 -timeout 1m # Dockerコンテナに対してマイグレーションコマンドを送信 - run: name: Run artisan migration command: | docker-compose exec laravel-container php artisan migrate --force # Dockerコンテナに対してPHP-Unitコマンドを送信 - run: name: Run unit test command: | dockercompose exec laravel-container ./vendor/bin/phpunit # Dockerコンテナに対してPHP-Stanコマンドを送信 - run: name: Run static test command: | docker-compose exec laravel-container ./vendor/bin/phpstan analyse --memory-limit=512M DLC：Docker Layer Cache ・DLCとは CircleCIでDockerイメージをビルドした後，各イメージレイヤーをDLCボリュームにキャッシュする．そして，次回以降のビルド時に，差分がないイメージレイヤーをDLCボリュームからプルして再利用する．これにより，Dockerイメージのビルド時間を短縮できる． ・使用例 machineタイプで使用する場合，machineキーの下でdocker_layer_cachingを使う． ＊実装例＊ version: 2.1 orbs: docker: circleci/docker@x.y.z jobs: build_and_test: # Docker Composeの時はmachineタイプを使用する machine: image: ubuntu-1604:201903-01 # DLCを有効化 docker_layer_caching: true steps: - checkout - run: name: Make env file command: | echo $ENV_TESTING | base64 --decode > .env - run: name: Make env docker file command: | cp .env.docker.example .env.docker - run: name: Docker compose up command: | set -xe docker network create foo-network docker-compose up --build -d dockerタイプで使用する場合，dockerキーの下でdocker_layer_cachingを使う． ＊実装例＊ version: 2.1 jobs: build_and_push: executor: docker/docker steps: - setup_remote_docker # DLCを有効化 docker_layer_caching: true - checkout - docker/check - docker/build: image: / - docker/push: image: / 02-09. CircleCIライブラリ orbs ・orbsとは CircleCIから提供される汎用的なパッケージの使用を読み込む． ＊実装例＊ version: 2.1 orbs: hello: circleci/hello-build@0.0.5 workflows: \"Hello Workflow\": jobs: - hello/hello-build ・jobs，commands，executors 構造 説明 jobs workflowsにて，Orbsからjobとして使用できる． commands jobにて，stepとして使用できる． executors exexutorにて，事前定義されたexecutorsとして使用できる． ・オプションへの引数の渡し方と注意点 AWS認証情報は，CircleCIのデフォルト名と同じ環境変数名で登録しておけば，オプションで渡さなくとも，自動で入力してくれる．オプションがenv_var_name型は，基本的に全てのスコープレベルの環境変数を受け付ける．ただしAlpineベースのイメージでは，『$BASH_ENV』を用いて，複数のrun間で環境変数を共有できず，orbsのステップに環境変数を渡せないため注意する． 参考：https://github.com/circleci/circleci-docs/issues/1650 ＊実装例＊ version: 2.1 orbs: aws-foo: circleci/aws-foo@x.y.z jobs: foo_bar_baz: docker: - image: circleci/python:x.y.z steps: - attach_workspace: at: . - setup_remote_docker: - aws-cli/install - aws-cli/setup - aws-foo/foo-bar-baz: # デフォルト名であれば，記述しなくても自動的に入力してくれる． account-url: $AWS_ECR_ACCOUNT_URL_ENV_VAR_NAME aws-access-key-id: $ACCESS_KEY_ID_ENV_VAR_NAME aws-secret-access-key: $SECRET_ACCESS_KEY_ENV_VAR_NAME region: $AWS_REGION_ENV_VAR_NAME aws-cli ・commands: install aws-cliコマンドのインストールを行う． ・commands: setup aws-cliコマンドのインストールと，Credentials情報の設定を行う．AWSリソースを操作するために使用する． ＊実装例＊ CloudFrontに保存されているCacheを削除する．フロントエンドをデプロイしたとしても，CloudFrontに保存されているCacheを削除しない限り，CacheがHitしたユーザには過去のファイルがレスポンスされてしまう．そのため，S3へのデプロイ後に，Cacheを削除する必要がある． version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 jobs: cloudfront_create_invalidation: docker: - image: cimg/python:3.9-node steps: - checkout - aws-cli/setup - run: name: Run create invalidation command: | echo $AWS_CLOUDFRONT_ID | base64 --decode | aws cloudfront create-invalidation --distribution-id $AWS_CLOUDFRONT_ID --paths \"/*\" workflows: # ステージング環境にデプロイ develop: jobs: # 直前に承認ジョブを挿入する - hold: name: hold_create_invalidation_stg type: approval - cloudfront_create_invalidation: name: cloudfront_create_invalidation_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: # 直前に承認ジョブを挿入する - hold: name: hold_create_invalidation_prd type: approval - cloudfront_create_invalidation: name: cloudfront_create_invalidation_prd filters: branches: only: - main ただし，credentialsファイルの作成では，orbsを使用しない方がより簡潔に条件分岐を実装できるかもしれない． #!/bin/bash set -xeuo pipefail case \"$APP_ENV\" in \"stg\") AWS_ACCESS_KEY_ID=$STG_AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=$STG_AWS_SECRET_ACCESS_KEY ;; \"prd\") AWS_ACCESS_KEY_ID=\"$PRD_AWS_ACCESS_KEY_ID\" AWS_SECRET_ACCESS_KEY=\"$PRD_AWS_SECRET_ACCESS_KEY\" ;; *) echo \"The parameter ${APP_ENV} is invalid.\" exit 1 ;; esac # defaultプロファイルにクレデンシャル情報を設定する． aws configure aws-ecr ・jobs：build-and-push-image CircleCIコンテナでDockerイメージをビルドし，ECRにデプロイする．remote-docker-layer-cachingを使用して，Docker Layer Cacheを有効化できる． ＊実装例＊ version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecr: circleci/aws-ecr@6.15.2 jobs: aws-ecr/build-and-push-image: name: ecr_build_and_push_image # Docker Layer Cacheを使用するかどうか（有料） remote-docker-layer-caching: true # リポジトリがない時に作成するかどうか． create-repo: true no-output-timeout: 20m # projectを作業ディレクトリとした時の相対パス dockerfile: ./infra/docker/Dockerfile path: \".\" profile-name: myProfileName repo: \"{$SERVICE}-repository\" # CircleCIのハッシュ値によるバージョニング tag: $CIRCLE_SHA1 # job内にて，attach_workspaceステップを実行． attach-workspace: true # attach_workspaceステップ実行時のrootディレクトリ workspace-root: aws-ecs ・jobs：deploy-update-service（ローリングアップデート使用時） ECRイメージを使用して，新しいリビジョン番号のタスク定義を作成し，またこれを使用してコンテナをデプロイする．verify-revision-is-deployedオプションを使用して，ECSサービスが更新された後，実行されているタスクがタスク定義に合致しているかを監視する．例えば，タスクが「Runnning」にならずに「Stopped」になってしまう場合や，既存のタスクが「Stopped」にならずに「Running」のままになってしまう場合，この状態はタスク定義に合致しないので，検知できる． 参考：https://circleci.com/docs/ja/2.0/ecs-ecr/#deploy-the-new-docker-image-to-an-existing-aws-ecs-service ＊実装例＊ version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecs: circleci/aws-ecs@2.2.1 jobs: aws-ecs/deploy-update-service: name: ecs_update_service_by_rolling_update # タスク定義名を指定 family: \"${SERVICE}-ecs-task-definition\" # クラスター名を指定 cluster-name: \"${SERVICE}-cluster\" # サービス名を指定 service-name: \"${SERVICE}-service\" # コンテナ定義のコンテナ名とイメージタグを上書き．イメージはCircleCIのハッシュ値でタグ付けしているので必須． container-image-name-updates: \"container=laravel,tag=${CIRCLE_SHA1},container=nginx,tag=${CIRCLE_SHA1}\" # サービス更新後のタスク監視 verify-revision-is-deployed: true workflows: # ステージング環境にデプロイ develop: jobs: - ecs_update_service_by_rolling_update: name: ecs_update_service_by_rolling_update_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - ecs_update_service_by_rolling_update: name: ecs_update_service_by_rolling_update_production filters: branches: only: - main ・jobs：deploy-update-service（B/Gデプロイメント使用時） ECSタスク定義を更新する．さらに，Blue/Greenデプロイメントがそのタスク定義を指定し，ECSサービスを更新する．ローリングアップデートと同様にして，verify-revision-is-deployedオプションを使用できる． ＊実装例＊ version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecs: circleci/aws-ecs@2.2.1 jobs: aws-ecs/deploy-update-service: name: ecs_update_service_by_code_deploy # タスク定義名を指定 family: \"${SERVICE}-ecs-task-definition\" # クラスター名を指定 cluster-name: \"${SERVICE}-cluster\" # サービス名を指定 service-name: \"${SERVICE}-service\" # CodeDeployにおけるデプロイの作成を設定 deployment-controller: CODE_DEPLOY codedeploy-application-name: $SERVICE codedeploy-deployment-group-name: \"${SERVICE}-deployment-group\" codedeploy-load-balanced-container-name: www-container codedeploy-load-balanced-container-port: 80 # コンテナ名とイメージタグを指定．イメージはCircleCIのハッシュ値でタグ付けしているので必須． container-image-name-updates: \"container=laravel,tag=${CIRCLE_SHA1},container=nginx,tag=${CIRCLE_SHA1}\" # サービス更新後のタスク監視 verify-revision-is-deployed: true workflows: # ステージング環境にデプロイ develop: jobs: - ecs_update_service_by_code_deploy: name: ecs_update_service_by_code_deploy_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - ecs_update_service_by_code_deploy: name: ecs_update_service_by_code_deploy_production filters: branches: only: - main ・jobs：run-task 現在起動中のECSタスクとは別に，新しいタスクを一時的に起動する．起動時に，overridesオプションを使用して，指定したタスク定義のコンテナ設定を上書きできる．正規表現で設定する必要があり，さらにJSONでは「\\」を「\\\\」にエスケープしなければならない．コマンドが実行された後に，タスクは自動的にStopped状態になる． 上書きできるキーの参照リンク：https://docs.aws.amazon.com/cli/latest/reference/ecs/run-task.html ＊実装例＊ 例えば，データベースに対してマイグレーションを実行するためのECSタスクを起動する．overridesオプションでコンテナ定義のコマンドを上書きする． version: 2.1 orbs: aws-cli: circleci/aws-cli@1.3.1 aws-ecs: circleci/aws-ecs@2.2.1 jobs: aws-ecs/run-task: name: ecs_run_task_for_migration cluster: \"${SERVICE}-ecs-cluster\" # LATESTとするとその時点の最新バージョンを自動で割り振られてしまう． platform-version: 1.4.0 awsvpc: true launch-type: FARGATE subnet-ids: $AWS_SUBNET_IDS security-group-ids: $AWS_SECURITY_GROUPS # タスク定義名．最新リビジョン番号が自動補完される． task-definition: \"${SERVICE}-ecs-task-definition\" # タスク起動時にマイグレーションコマンドを実行するように，Laravelコンテナの　commandキーを上書き overrides: \"{\\\\\\\"containerOverrides\\\\\\\":[{\\\\\\\"name\\\\\\\": \\\\\\\"laravel-container\\\\\\\",\\\\\\\"command\\\\\\\": [\\\\\\\"php\\\\\\\", \\\\\\\"artisan\\\\\\\", \\\\\\\"migrate\\\\\\\", \\\\\\\"--force\\\\\\\"]}]}\" workflows: # ステージング環境にデプロイ develop: jobs: - ecs_run_task_for_migration: name: ecs_run_task_for_migration_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - ecs_run_task_for_migration: name: ecs_run_task_for_migration_production filters: branches: only: - main aws-code-deploy ・jobs：deploy S3にソースコードとappspecファイルをデプロイできる．また，CodeDeployを用いて，これをEC2にデプロイできる． ＊実装例＊ version: 2.1 orbs: aws-code-deploy: circleci/aws-code-deploy@1.0.1 jobs: aws-code-deploy/deploy: name: code_deploy application-name: $SERVICE} # appspecファイルを保存するバケット名 bundle-bucket: \"${SERVICE}-bucket\" # appspecファイルのあるフォルダ bundle-source: ./infra/aws_codedeploy # appspecファイルをzipフォルダで保存 bundle-type: zip # zipフォルダ名 bundle-key: foo-bundle deployment-config: CodeDeployDefault.ECSAllAtOnce deployment-group: \"${SERVICE}-deployment-group\" # ECSにアクセスできるCodeDeployサービスロール service-role-arn: $CODE_DEPLOY_ROLE_FOR_ECS workflows: # ステージング環境にデプロイ develop: jobs: - code_deploy: name: code_deploy_stg filters: branches: only: - develop # 本番環境にデプロイ main: jobs: - code_deploy: name: code_deploy_production filters: branches: only: - main slack ・commands：notify ジョブの終了時に，成功または失敗に基づいて，ステータスを通知する．ジョブの最後のステップとして設定しなければならない． version: 2.1 orbs: slack: circleci/slack@4.1 commands: # 他のジョブ内で使用できるようにcommandとして定義 notify_of_failure: steps: - slack/notify: event: fail template: basic_fail_1 jobs: deploy: steps: # ～ 中略 ～ workflows: # ステージング環境にデプロイ develop: jobs: - deploy: name: deploy_stg filters: branches: only: - develop # 失敗時に通知 post-steps: - notify_of_failure: # 本番環境にデプロイ main: jobs: - deploy: name: deploy_production filters: branches: only: - main # 失敗時に通知 post-steps: - notify_of_failure: "},"public/ci_cd/ci_cd_capistrano.html":{"url":"public/ci_cd/ci_cd_capistrano.html","title":"📖 ︎Capistrano","keywords":"","body":"Capistrano はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ Capistranoとは ・仕組み 自身のパソコンからクラウドデプロイサーバにリモート接続する． クラウドデプロイサーバの自動デプロイツール（例：Capistrano）が，クラウドデプロイサーバからクラウドWebサーバにリモート接続する． 自動デプロイツールが，クラウドWebサーバのGitを操作し，pullあるいはcloneを実行する．その結果，GitHubからクラウドデプロイサーバに指定のブランチの状態が取り込まれる． "},"public/observability_monitering/observability.html":{"url":"public/observability_monitering/observability.html","title":"📖 ︎可観測性","keywords":"","body":"可観測性 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 可観測性 可観測性とは 『収集されたデータから，システムにおける想定外の不具合をどれだけ正確に推測できるか』を表す程度のこと．システムの想定内の不具合は『監視』や『テスト』によって検知できるが，想定外のものを検知できない．しかし，可観測性を高めることにより，想定外の不具合を表面化できる． 参考： https://blog.thundra.io/observability-driven-development-for-serverless https://sookocheff.com/post/architecture/testing-in-production/ https://www.sentinelone.com/blog/observability-production-systems-why-how/ 可観測性を高める方法 ・マイクロサービスアーキテクチャの場合 テレメトリーを十分に収集し，これらを紐付けて可視化する必要がある． ・モノリスにおける可観測性 可観測性は，基本的にマイクロサービスアーキテクチャの文脈で語られる．モノリシックにおいて，どのようにして可観測性を高めるのかを調査中...（情報が全然見つからない） 発表スライド 01-02. テレメトリー テレメトリーとは 可観測性を実現するために収集する必要のある３つのデータ要素（『メトリクス』『ログ』『分散トレース』）のこと．NewRelicやDatadogはテレメトリーの要素を全て持つ．また，AWSではCloudWatch（メトリクス＋ログ）とX-Ray（分散トレース）を両方利用すると，これらの要素を満たせたことになり，可観測性を実現できる． 参考： https://www.forbes.com/sites/andythurai/2021/02/02/aiops-vs-observability-vs-monitoringwhat-is-the-difference-are-you-using-the-right-one-for-your-enterprise/ https://knowledge.sakura.ad.jp/26395/ 02. メトリクス メトリクスとは とある分析にて，一定期間に発生した複数のデータポイントの集計値のこと．『平均』『合計』『最小／最大』『平方根』などを用いて，データポイントを集計する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Metric データポイント ・データポイントとは 分析対象から得られる最小単位の数値データのこと．データポイントは，分析ごとに存在している．例えば，とある分析で一分ごとに対象が測定される場合，一分ごとに得られる数値データがデータポイントとなる．一方で，一時間ごとの測定の場合，一時間ごとに得られる数値データがデータポイントである． 参考： https://whatis.techtarget.com/definition/data-point https://aws.amazon.com/jp/about-aws/whats-new/2017/12/amazon-cloudwatch-alarms-now-alerts-you-when-any-m-out-of-n-metric-datapoints-in-an-interval-are-above-your-threshold/ ４大シグナル ・４大シグナルとは 特に重要なメトリクス（トラフィック，レイテンシー，エラー，サチュレーション）のこと． ・トラフィック サーバ監視対象のメトリクスに属する． ・レイテンシー サーバ監視対象のメトリクスに属する． ・エラー サーバ監視対象のメトリクスに属する． 種類 説明 明示的エラー 400/500系のレスポンス 暗黙的エラー SLOに満たない200/300系のレスポンス，API仕様に合っていないレスポンス ・サチュレーション システム利用率（CPU利用率，メモリ理容室，ストレージ利用率，など）の飽和度のこと．例えば，以下の飽和度がある．60～70%で，警告ラインを設けておく必要がある．サーバ監視対象のメトリクスに属する． 03. ログ ログとは 特定の瞬間に発生したイベントが記載されたデータのこと． 参考：https://newrelic.com/jp/blog/how-to-relic/metrics-events-logs-and-traces 構造からみた種類 ・非構造化ログ イベントの値だけが表示されたログのこと．文字列データで定義される． 192.168.0.1 [2021-01-01 12:00:00] GET /foos/1 200 ・構造化ログ イベントの項目名と値が表示されたログのこと．JSON型で定義されることが多い． { \"client_ip\": \"192.168.0.1\", \"timestamp\": \"2021-01-01 12:00:00\", \"method\": \"GET\", \"url\": \"/foos/1\", \"status_code\": 200 } ロギング ・Distributed logging（分散ロギング） マイクロサービスアーキテクチャにおいて，各サービスから収集されたログを，バラバラに分析／管理する方法のこと． 参考：https://www.splunk.com/ja_jp/data-insider/what-is-distributed-tracing.html#centralized-logging ・Centralized logging（集中ロギング） マイクロサービスアーキテクチャにおいて，各サービスから収集されたログを，一元的に分析／管理する方法のこと． 参考：https://www.splunk.com/ja_jp/data-insider/what-is-distributed-tracing.html#centralized-logging 04. 分散トレース 分散トレースとは マイクロサービスアーキテクチャにおいて，複数のサービスから収集されたスパンのセットのこと．スパンを紐付けることによって，異なるサービスを横断する処理を，一繋ぎなものとして認識できるようになる． 参考： https://www.dynatrace.com/news/blog/open-observability-part-1-distributed-tracing-and-observability/ https://docs.newrelic.com/jp/docs/distributed-tracing/concepts/introduction-distributed-tracing/ https://medium.com/nikeengineering/hit-the-ground-running-with-distributed-tracing-core-concepts-ff5ad47c7058 分散トレースの読み方 上から下に読むと，上流サービス（上位スパン）が下流サービス（下位スパン）を処理をコールしていることを確認できる．下から上に読むと，下流サービス（下位スパン）から上流サービス（上位スパン）に結果を返却していることを確認できる． 参考：https://cloud.google.com/architecture/using-distributed-tracing-to-observe-microservice-latency-with-opencensus-and-stackdriver-trace モノリスにおける分散トレース モノリスなアプリケーションでは，システムが分散していないため，単なるトレースとなる． 参考：https://deepsource.io/blog/distributed-tracing/#monolithic-observability ＊例＊ （１）a1：クライアントがリクエストを送信する． （２）a1：リクエストがロードバランサ－に到達する． （３）a1～a2：ロードバランサ－で処理が実行される． （４）a2：ロードバランサ－がリクエストをアプリケーションに転送する． （５）a2：リクエストがアプリケーションに到達する． （６）a2～a3：アプリケーションで処理が実行される． （７）a3：アプリケーションがレスポンスをクライアントに返信する． スパン ・スパンとは マイクロサービスアーキテクチャにおいて，特定のサービスで発生したデータのセットのこと．JSON型で定義されることが多い．SaaSツールによってJSON型の構造が異なる． 参考： https://opentracing.io/docs/overview/spans/ https://docs.datadoghq.com/ja/tracing/guide/send_traces_to_agent_by_api/#%E3%83%A2%E3%83%87%E3%83%AB https://docs.newrelic.com/jp/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api/#new-relic-guidelines ・スパン間の紐付け リクエストヘッダーやボディにIDを割り当て，異なるサービスのスパン間を紐付ける．AWSを使用している場合，例えばALBがX-Amzn-Trace-IdヘッダーにリクエストIDを付与してくれるため，アプリケーションでリクエストIDを実装せずに分散トレースを実現できる． 参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-request-tracing.html ・データポイント化 スパンが持つデータをデータポイントとして集計することにより，メトリクスを収集できる． "},"public/observability_monitering/monitering.html":{"url":"public/observability_monitering/monitering.html","title":"📖 ︎監視","keywords":"","body":"監視 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 監視 監視とは 既知のメトリクスとログに基づいて，システムにおける想定内の不具合の発生を未然に防ぐこと．想定内という点で，可観測性と区別できる． 参考： https://en.wikipedia.org/wiki/Website_monitoring https://blog.thundra.io/observability-driven-development-for-serverless 監視の要素 監視は，以下の要素からなる． 参考：https://www.amazon.co.jp/dp/4873118646 アクション 説明 データの収集 監視対象からデータを収集する．データとしては，メトリクス，アプリケーションログ，ブラウザログ，ユーザトラフィック，などがある． ↓ 収集後，次のアクションに分岐する． データの保管 データをストレージに保管する． データの可視化 データを監視ダッシュボードに表示し，目視できるようにする． データの分析 データを数学的に分析し，結果を算出する． レポートの作成 算出値をグラフ化として，レポートを作成する． アラート データに異常がある場合，これをインシデントとして開発者に通知する．SLAに満たない場合，サービス利用者に利用料を返金する．また，インシデントを解決するためのタスクを作成し，これに対応する． フロントエンド監視 ・フロントエンド監視とは ブラウザに関するトラフィックを監視する． ・リアルユーザ監視（RUM） ブラウザは，Webページのロード時に，Navigation-timing-APIに対してリクエストを送信し，Webページパフォーマンスに関するメトリクスを収集する．リアルユーザ監視では，このメトリクスを監視する． 参考：https://developer.mozilla.org/ja/docs/Web/API/Navigation_timing_API ページロード時間は特に重要である．Amazonの自社調査では，ロード時間が100ms短くなるごとに，売り上げが1%増加することが明らかになった．4秒以下を目指すと良い． 参考：https://bit.ly/2y494hq ・合成監視（外部監視） 『外部監視』ともいう．SaaSは，実際のユーザの一連の操作を模したリクエストをアプリケーションに送信し，レスポンスに関するメトリクスを収集する．合成監視では，メトリクスを監視する．ユーザを模したリクエストを生成するという意味合いで，『合成』という．ユーザ視点で監視できる． 参考： https://takehora.hatenadiary.jp/entry/2019/07/05/012036 https://www.manageengine.jp/products/Applications_Manager/solution_synthetic-monitoring.html アプリケーション監視（APM） ・アプリケーション監視とは 『APM（アプリケーションパフォーマンス監視）』ともいう．アプリケーション内に常駐させたSaaSエージェントは，サーバ内で稼働中のアプリケーションのメトリクスやアプリケーションログを収集し，SaaSに送信する．アプリケーション監視では，これらのメトリクスやアプリケーションログを監視する．メトリクスの例は以下に示す． SQLにかかる時間 ビルドまたはデプロイの開始／終了時間 外部APIコールにかかる時間 リクエストの受信数 ログイン数 ・StatsDを用いたメトリクスの作成 サーバ内にStatsDを常駐させ，アプリケーションでStatsDライブラリを用いると，メトリクスを収集できる．このメトリクスをSaaSに送信する． 参考：https://github.com/statsd/statsd/wiki CloudWatchではStatsDからのメトリクスの送信がサポートされている． 参考： https://docs.aws.amazon.com/ja_jp/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-custom-metrics-statsd.html https://qiita.com/murata-tomohide/items/9bd1320865b2eba47538 サーバ／コンテナ監視 ・サーバ／コンテナ監視とは サーバ／コンテナのOSに関するメトリクスを収集し，これをSaaSに送信する．サーバ／コンテナ監視では，このメトリクスを監視する．メトリクスの例は以下に示す． CPU メモリ ロードアベレージ ネットワーク ディスク ネットワーク監視 セキュリティ監視 02. ポストモーテムの作成 ポストモーテムとは アラートで通知されたインシデントがビジネスに大きな影響を与えた場合，振り返りのために，ポストモーテムを作成する．ポストモーテムは，障害報告書とは異なり，原因特定とシステム改善に重きを置いた報告書である．障害報告書は，責任の報告の意味合いが強くなってしまう． テンプレート 参考：https://ueokande.github.io/incident-response-docs-ja/after/post_mortem_template/ # ポストモーテム ## タイトル ## 日付 ## 担当者 **※担当者を絶対に責めず，障害は誰のせいでもないという意識を強く持つ．** ## 原因と対応 **※原因特定とシステム改善に重きを置くこと．** ## システム的/収益的な影響範囲 ## 幸運だったこと ## 仕組みの改善策 **※「以後は注意する」ではなく，再発しない仕組み作りになるようにする．** ## 障害発生から対応までのタイムライン 他社事例 参考：https://ueokande.github.io/incident-response-docs-ja/after/post_mortem_process/#_6 サービス リンク AWS https://aws.amazon.com/jp/message/5467D2/ Heroku https://status.heroku.com/incidents/151 Twilio https://www.twilio.com/blog/2013/07/billing-incident-post-mortem-breakdown-analysis-and-root-cause.html 03. 監視に基づく意思決定 SLI：Service Level Indicator（サービスレベル指標） ・SLIとは サービスレベルの指標とするメトリクスのこと． ・SLIの例 サーバ稼働率 データベース稼働率 レイテンシー レスポンスタイム レスポンスのステータスコード率 スループット AWSで役立つメトリクス ・SLIに関連するメトリクス 指標 AWSリリース 関連するメトリクス 補足 サーバ稼働率 ECS ・RunningTaskCount ターゲット追跡スケーリングポリシーのECSサービスメトリクスも参考にせよ． データベース稼働率 RDS ・CPUUtilization・FreeableMemory レイテンシー API Gateway ・Latency・IntegrationLatency レスポンスのステータスコード率 API Gateway ・4XXError・5XXError ALB ・HTTPCode_ELB_4XX_Count・HTTPCode_ELB_5XX_Count・HTTPCode_TARGET_4XX_Count・HTTPCode_TARGET_5XX_Count・RejectedConnectionCount・HealthyHostCount・TargetConnectionErrorCount・TargetTLSNegotiationErrorCount 参考：https://docs.aws.amazon.com/ja_jp/elasticloadbalancing/latest/application/load-balancer-cloudwatch-metrics.html ・パフォーマンスに関するメトリクス 名前 AWSリリース 補足 パフォーマンスインサイト RDS RDSのパフォーマンスに関するメトリクスを収集し，SQLレベルで監視できるようになる．パラメータグループのperformance_schemaを有効化する必要がある．対応するエンジンバージョンとインスタンスタイプについては，以下のリンクを参考にせよ．参考：https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/USER_PerfInsights.Overview.Engines.htm Container インサイト ECS／EKS ECS／EKSのパフォーマンスに関するメトリクスを収集し，ECS／EKSのクラスター，サービス，タスク，インスタンス，単位で監視できるようになる．また，コンテナ間の繋がりをコンテナマップで視覚化できるようになる．ECS／EKSのアカウント設定でContainerインサイトを有効化する必要がある． Lambdaインサイト Lambda Lambdaのパフォーマンスに関するメトリクスを収集できるようになる． SLO：Service Level Objective（サービスレベル目標） ・SLOとは SLIとして採用した指標の目標値のこと．ユーザの視点で設定する必要がある．99.9%の成功率を目標とすることが多い． ・SLOの例 指標 目標値の例 サーバ稼働率 日当たり0.1%以下のダウンタイム データベース稼働率 日当たり0.1%以下のダウンタイム レイテンシー 日当たり0.1%以下のレイテンシー レスポンスのステータスコード率 日当たり99.9%以上の200ステータスコード スループット 日当たり0.1%以下のスループット低下 エラーバジェット ・エラーバジェットとは 年月当たりで許容するエラーやダウンタイムの程度のこと．エラーやダウンタイムの発生によってビジネスに影響を与える可能性があったとしても，SLOの閾値を超えない限りはこれを許容し，技術を優先する．ビジネスより技術を優先する時に，素早く意思決定できる． SLA：Service Level Agreement ・SLAとは サービスレベル合意と訳せる．インターネットサービスに最低限のサービスのレベルを保証し，これを下回った場合には返金できるように合意するもの．SLAとして，例えば以下がある． 項目 説明 レベル例 返金率 サーバ稼働率 サーバの時間当たりの稼働率 99.9%以上 10% 障害回復時間 障害が起こってから回復するまでの時間 2時間以内 10% 障害お問い合わせ 障害発生時のお問い合わせ可能時間帯 24時間365日 10% ・AWSのSLA AWSではサービスレベルの項目として，サーバ稼働率を採用している．これに対して，ほとんどのAWSリソースで，以下のSLAが設定されている．各リソースにSLAが定義されている． 参考：https://aws.amazon.com/jp/legal/service-level-agreements/ ＊例＊ EC2，EBS，ECS，EKS，の例を示す． 毎月の稼働率 発生したダウンタイム 返金率 99.0％以上，99.99%未満 87.6～0.876時間 10% 95.0％以上，99.0％未満 438～87.6時間 30% 95.0%未満 438時間以上 100% "},"public/observability_monitering/observability_fluentd_and_fluentbit.html":{"url":"public/observability_monitering/observability_fluentd_and_fluentbit.html","title":"📖 ︎Fluentd／FluentBit","keywords":"","body":"Fluentd／FluentBit はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Fluentd／FluentBitとは 概要 アプリケーションからログを収集し，これをフィルタリングした後，複数の宛先に転送する． 参考：https://docs.fluentbit.io/manual/about/fluentd-and-fluent-bit Fluentd vs. FluentBit Fluentd FluentBit スコープ コンテナ／サーバ 組み込みLinux／コンテナ／サーバ 言語 C & Ruby NS メモリ最大使用量 40MB 650KB 依存関係 標準プラグインで一定数のRuby gemに依存する． 標準プラグインではライブラリに依存しない． パフォーマンス 高 高 プラグイン数 1000個以上 70個 "},"public/observability_monitering/observability_fluentbit.html":{"url":"public/observability_monitering/observability_fluentbit.html","title":"📖 ︎FluentBit","keywords":"","body":"FluentBit 01. ログパイプライン ログパイプラインとは FluentBitにて，ログを処理する一連のセクションのこと． セクションの設定 ・confファイル confファイルでセクションを設定できる． 参考：https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/configuration-file 設定ファイルのバリデーションは以下から行う． 参考：https://cloud.calyptia.com/visualizer ・コマンド コマンドでセクションを実行できる． Available Options -b --storage_path=PATH specify a storage buffering path -c --config=FILE specify an optional configuration file -d, --daemon run Fluent Bit in background mode -D, --dry-run dry run -f, --flush=SECONDS flush timeout in seconds (default: 5) -F --filter=FILTER set a filter -i, --input=INPUT set an input -m, --match=MATCH set plugin match, same as '-p match=abc' -o, --output=OUTPUT set an output -p, --prop=\"A=B\" set plugin configuration property -R, --parser=FILE specify a parser configuration file -e, --plugin=FILE load an external plugin (shared lib) -l, --log_file=FILE write log info to a file -t, --tag=TAG set plugin tag, same as '-p tag=abc' -T, --sp-task=SQL define a stream processor task -v, --verbose increase logging verbosity (default: info) -w, --workdir set the working directory -H, --http enable monitoring HTTP server -P, --port set HTTP server TCP port (default: 2020) -s, --coro_stack_size set coroutines stack size in bytes (default: 24576) -q, --quiet quiet mode -S, --sosreport support report for Enterprise customers -V, --version show version number -h, --help print this help 02. セクション SERVICE ・SERVICEセクションとは パイプライン全体の設定やファイルの読み込みを定義する．各設定の頭文字は大文字とする． ＊実装例＊ [SERVICE] Flush 1 # 猶予時間 Grace 30 # FluentBit自体のログレベル Log_Level info # 読み込まれるParsers Multilineファイルの名前 Parsers_File parsers_multiline.conf # 読み込まれるStream Processorファイルの名前 Streams_File stream_processor.conf ・実行ログの確認 Log_Level値でFluentBitのログレベルを制御できる．debugを割り当てると，FluentBitのログがより詳細になり，各セクションの設定値を確認できるようになる． ＊実行ログ例＊ Fluent Bit v1.8.6 * Copyright (C) 2019-2021 The Fluent Bit Authors * Copyright (C) 2015-2018 Treasure Data * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd * https://fluentbit.io [2021/01/01 12:00:00] [ info] Configuration: [2021/01/01 12:00:00] [ info] flush time | 1.000000 seconds [2021/01/01 12:00:00] [ info] grace | 30 seconds [2021/01/01 12:00:00] [ info] daemon | 0 [2021/01/01 12:00:00] [ info] ___________ [2021/01/01 12:00:00] [ info] inputs: [2021/01/01 12:00:00] [ info] forward [2021/01/01 12:00:00] [ info] ___________ [2021/01/01 12:00:00] [ info] filters: [2021/01/01 12:00:00] [ info] stdout.0 [2021/01/01 12:00:00] [ info] ___________ [2021/01/01 12:00:00] [ info] outputs: [2021/01/01 12:00:00] [ info] null.0 [2021/01/01 12:00:00] [ info] ___________ [2021/01/01 12:00:00] [ info] collectors: [2021/01/01 12:00:00] [ info] [engine] started (pid=1) [2021/01/01 12:00:00] [debug] [engine] coroutine stack size: 24576 bytes (24.0K) [2021/01/01 12:00:00] [debug] [storage] [cio stream] new stream registered: forward.0 [2021/01/01 12:00:00] [ info] [storage] version=1.1.1, initializing... [2021/01/01 12:00:00] [ info] [storage] in-memory [2021/01/01 12:00:00] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128 [2021/01/01 12:00:00] [ info] [cmetrics] version=0.2.1 [2021/01/01 12:00:00] [debug] [in_fw] Listen='0.0.0.0' TCP_Port=24224 [2021/01/01 12:00:00] [ info] [input:forward:forward.0] listening on 0.0.0.0:24224 [2021/01/01 12:00:00] [debug] [null:null.0] created event channels: read=21 write=22 [2021/01/01 12:00:00] [debug] [router] match rule forward.0:null.0 [2021/01/01 12:00:00] [ info] [sp] stream processor started INPUT ・INPUTセクションとは ログのパイプラインへの入力方法を定義する． 参考：https://docs.fluentbit.io/manual/concepts/data-pipeline/input プラグインを用いて，ログの入力方法を指定する． 参考：https://docs.fluentbit.io/manual/pipeline/inputs コマンドの-iオプションでINPUT名を指定し，実行することもできる． Inputs cpu CPU Usage mem Memory Usage thermal Thermal kmsg Kernel Log Buffer proc Check Process health disk Diskstats systemd Systemd (Journal) reader netif Network Interface Usage docker Docker containers metrics docker_events Docker events node_exporter_metrics Node Exporter Metrics (Prometheus Compatible) fluentbit_metrics Fluent Bit internal metrics tail Tail files dummy Generate dummy data head Head Input health Check TCP server health http HTTP collectd collectd input plugin statsd StatsD input plugin serial Serial input stdin Standard Input syslog Syslog exec Exec Input tcp TCP mqtt MQTT, listen for Publish messages forward Fluentd in-forward random Random ・dummyプラグイン ダミーの構造化ログをパイプラインに入力する．非構造化ログは入力データとして使用できない．ローカル環境でパイプラインの動作を確認するために役立つ． 参考： https://docs.fluentbit.io/manual/pipeline/inputs/dummy https://docs.fluentbit.io/manual/local-testing/logging-pipeline { \"message\": \"dummy\" } ＊実装例＊ [INPUT] Name dummy # ダミーJSONデータ Dummy {\"message\":\"dummy\"} ＊コマンド例＊ fluent-bit/bin/fluent-bit -i dummy -o stdout ・forwardプラグイン 受信したログを指定されたポートでリッスンし，パイプラインに入力する． 参考：https://docs.fluentbit.io/manual/pipeline/inputs/forward ＊実装例＊ [INPUT] # プラグイン名 Name forward Listen 0.0.0.0 # プロセスのリッスンポート ＊実行ログ例＊ Fluent Bit v1.8.6 * Copyright (C) 2019-2021 The Fluent Bit Authors * Copyright (C) 2015-2018 Treasure Data * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd * https://fluentbit.io [2021/01/01 12:00:00] [ info] [engine] started (pid=1) [2021/01/01 12:00:00] [ info] [storage] version=1.1.1, initializing... [2021/01/01 12:00:00] [ info] [storage] in-memory [2021/01/01 12:00:00] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128 [2021/01/01 12:00:00] [ info] [cmetrics] version=0.2.1 [2021/01/01 12:00:00] [ info] [input:forward:forward.0] listening on 0.0.0.0:24224 [2021/01/01 12:00:00] [ info] [sp] stream processor started ＊コマンド例＊ $ fluent-bit/bin/fluent-bit \\ -i forward \\ -o stdout ・tailプラグイン 指定したパスに継続的に出力されるログファイルを順次結合し，パイプラインに入力する．あらかじめ，FluentBitコンテナ内にログファイルを配置する必要があり，Pathでこれを指定する．v1.8を境にオプションが変わっていることに注意する． 参考：https://docs.fluentbit.io/manual/pipeline/inputs/tail ＊実装例＊ [INPUT] # プラグイン名 Name tail # FluentBitコンテナ内のログファイルの場所．ワイルドカードを使用できる． Path /var/www/foo/storage/logs/*.log # 使用するパーサー名 multiline.parser laravel-multiline-parser log_router: container_name: fluentbit build: dockerfile: ./docker/fluentbit/Dockerfile context: . volumes: # アプリケーションのログファイルのVolumeマウント - ./storage/logs:/var/www/foo/storage/logs ＊コマンド例＊ 参考：https://docs.fluentbit.io/manual/pipeline/inputs/tail#command-line $ fluent-bit -i tail -p path=/var/www/foo/storage/logs/*.log -o stdout ＊実行ログ例＊ * Copyright (C) 2019-2021 The Fluent Bit Authors * Copyright (C) 2015-2018 Treasure Data * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd * https://fluentbit.io [2021/01/01 12:00:00] [ info] [engine] started (pid=1) [2021/01/01 12:00:00] [ info] [storage] version=1.1.1, initializing... [2021/01/01 12:00:00] [ info] [storage] in-memory [2021/01/01 12:00:00] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128 [2021/01/01 12:00:00] [ info] [cmetrics] version=0.2.1 [2021/01/01 12:00:00] [ info] [sp] stream processor started [2021/01/01 12:00:00] [ info] [input:tail:tail.0] inotify_fs_add(): inode=31621169 watch_fd=1 name=/var/www/foo/storage/logs/laravel.log [0] tail.0: [1634640932.010306200, {\"log\"=>\"[2021-01-01 12:00:00] local.INFO: メッセージ\"}] [1] tail.0: [1634640932.013139300, {\"log\"=>\"[2021-01-01 12:00:00] local.INFO: メッセージ\"}] [2] tail.0: [1634640932.013147300, {\"log\"=>\"[2021-01-01 12:00:00] local.INFO: メッセージ\"}] PARSE ・PARSEセクションとは ・MULTILINE_PARSERセクション 参考：https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/multiline-parsing ＊実装例＊ Laravelのスタックトレースを結合する． [MULTILINE_PARSER] # パーサー名 name laravel # パーサータイプ type regex flush_timeout 1000 # パーサールール．スタックトレースの文頭をstart_state，また以降に結合する文字列をcontで指定する． # [%Y-%m-%d %H:%M:%S] をスタックトレースの開始地点とする． rule \"start_state\" \"/\\[[12]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])\\s+([01]?\\d|2[0-3]):([0-5]\\d):([0-5]\\d)\\].*/\" \"cont\" # [stacktrace]，[previous exception]，#，行間，\"} ，で始まる文字の場合に結合する． rule \"cont\" \"/(\\[(stacktrace|previous exception)\\]|#|\\n\\n|\"\\}).*/\" \"cont\" FILTER ・FILTERセクションとは 特定の文字列を持つログのみをBUFFERセクションに転送する． ・multilineプラグイン 参考：https://docs.fluentbit.io/manual/pipeline/filters/multiline-stacktrace [FILTER] # プラグイン名 name multiline match * multiline.key_content log # 使用するパーサー名 multiline.parser laravel コマンドの-fオプションでINPUT名を指定し，実行することもできる． Filters alter_size Alter incoming chunk size aws Add AWS Metadata checklist Check records and flag them record_modifier modify record throttle Throttle messages using sliding window algorithm kubernetes Filter to append Kubernetes metadata modify modify records by applying rules multiline Concatenate multiline messages nest nest events by specified field values parser Parse events expect Validate expected keys and values grep grep events by specified field values rewrite_tag Rewrite records tags lua Lua Scripting Filter stdout Filter events to STDOUT geoip2 add geoip information to records ・stdoutプラグイン 参考：https://docs.fluentbit.io/manual/pipeline/filters/standard-output [FILTER] # プラグイン名 Name stdout Match * ＊コマンド例＊ $ fluent-bit/bin/fluent-bit \\ -i \\ -F stdout \\ -m '*' \\ -o null ＊実行ログ例＊ Fluent Bit v1.8.6 * Copyright (C) 2019-2021 The Fluent Bit Authors * Copyright (C) 2015-2018 Treasure Data * Fluent Bit is a CNCF sub-project under the umbrella of Fluentd * https://fluentbit.io [2021/01/01 06:18:52] [ info] [engine] started (pid=40) [2021/01/01 06:18:52] [ info] [storage] version=1.1.1, initializing... [2021/01/01 06:18:52] [ info] [storage] in-memory [2021/01/01 06:18:52] [ info] [storage] normal synchronization mode, checksum disabled, max_chunks_up=128 [2021/01/01 06:18:52] [ info] [cmetrics] version=0.2.1 [2021/01/01 06:18:52] [ info] [sp] stream processor started [0] cpu.0: [1634710733.114477665, {\"cpu_p\"=>0.166667, \"user_p\"=>0.000000, \"system_p\"=>0.166667, \"cpu0.p_cpu\"=>0.000000, \"cpu0.p_user\"=>0.000000, \"cpu0.p_system\"=>0.000000, \"cpu1.p_cpu\"=>1.000000, \"cpu1.p_user\"=>0.000000, \"cpu1.p_system\"=>1.000000, \"cpu2.p_cpu\"=>0.000000, \"cpu2.p_user\"=>0.000000, \"cpu2.p_system\"=>0.000000, \"cpu3.p_cpu\"=>0.000000, \"cpu3.p_user\"=>0.000000, \"cpu3.p_system\"=>0.000000, \"cpu4.p_cpu\"=>0.000000, \"cpu4.p_user\"=>0.000000, \"cpu4.p_system\"=>0.000000, \"cpu5.p_cpu\"=>0.000000, \"cpu5.p_user\"=>0.000000, \"cpu5.p_system\"=>0.000000}] [0] cpu.0: [1634710734.115201385, {\"cpu_p\"=>0.333333, \"user_p\"=>0.166667, \"system_p\"=>0.166667, \"cpu0.p_cpu\"=>0.000000, \"cpu0.p_user\"=>0.000000, \"cpu0.p_system\"=>0.000000, \"cpu1.p_cpu\"=>0.000000, \"cpu1.p_user\"=>0.000000, \"cpu1.p_system\"=>0.000000, \"cpu2.p_cpu\"=>0.000000, \"cpu2.p_user\"=>0.000000, \"cpu2.p_system\"=>0.000000, \"cpu3.p_cpu\"=>0.000000, \"cpu3.p_user\"=>0.000000, \"cpu3.p_system\"=>0.000000, \"cpu4.p_cpu\"=>0.000000, \"cpu4.p_user\"=>0.000000, \"cpu4.p_system\"=>0.000000, \"cpu5.p_cpu\"=>0.000000, \"cpu5.p_user\"=>0.000000, \"cpu5.p_system\"=>0.000000}] [0] cpu.0: [1634710735.114646610, {\"cpu_p\"=>1.500000, \"user_p\"=>0.666667, \"system_p\"=>0.833333, \"cpu0.p_cpu\"=>0.000000, \"cpu0.p_user\"=>0.000000, \"cpu0.p_system\"=>0.000000, \"cpu1.p_cpu\"=>3.000000, \"cpu1.p_user\"=>2.000000, \"cpu1.p_system\"=>1.000000, \"cpu2.p_cpu\"=>2.000000, \"cpu2.p_user\"=>1.000000, \"cpu2.p_system\"=>1.000000, \"cpu3.p_cpu\"=>1.000000, \"cpu3.p_user\"=>0.000000, \"cpu3.p_system\"=>1.000000, \"cpu4.p_cpu\"=>1.000000, \"cpu4.p_user\"=>0.000000, \"cpu4.p_system\"=>1.000000, \"cpu5.p_cpu\"=>2.000000, \"cpu5.p_user\"=>1.000000, \"cpu5.p_system\"=>1.000000}] BUFFERセクション ・BUFFERセクションとは ログはチャンク化され，メモリ／ファイルにあるバッファー内のキューに蓄えられる．チャンクはキューから取り出され，ターゲットに転送される．Fluentdから概念図を拝借した． 参考： https://docs.fluentbit.io/manual/administration/buffering-and-storage https://atmarkit.itmedia.co.jp/ait/articles/1402/06/news007.html ・メモリ上でバッファリング 参考：https://docs.fluentbit.io/manual/administration/buffering-and-storage#input-section-configuration ＊実装例＊ [SERVICE] flush 1 log_Level info [INPUT] name cpu # メモリ上でバッファリングが実行される（標準値）． storage.type memory ・ファイル上でバッファリング 参考：https://docs.fluentbit.io/manual/administration/buffering-and-storage#input-section-configuration ＊実装例＊ [SERVICE] flush 1 log_Level info # ファイルの場所 storage.path /var/log/fluentbit/ [INPUT] name cpu # ファイル上でバッファリングが実行される． storage.type filesystem 指定した場所にcpu.0ディレクトリが生成され，そこにあるflbファイル上でバッファリングが実行される． $ ls -ls /var/log/fluentbit/cpu.0 -rw------- 1 root root 4096 Oct 20 15:51 1-1634745095.575805200.flb STREAM_TASKセクション ・STREAM_TASKセクションとは チャンク化されたログにタグ付けを行う．タグ付けされたログは，パイプラインのINPUTセクションに再度取り込まれ，処理し直される． 参考：https://docs.fluentbit.io/manual/stream-processing/overview#stream-processor STREAM_TASKセッションは，ログSQLで定義される． 参考：https://docs.fluentbit.io/manual/stream-processing/getting-started/fluent-bit-sql [STREAM_TASK] Name foo Exec CREATE STREAM foo AS SELECT * FROM TAG:'foo'; OUTPUT ・OUTPUTセクションとは チャンクとして蓄えられたログの出力先を定義する．設定可能な出力先の種類については，以下を参考にせよ． 参考：https://docs.fluentbit.io/manual/pipeline/outputs コマンドの-oオプションでINPUT名を指定し，実行することもできる． Outputs azure Send events to Azure HTTP Event Collector azure_blob Azure Blob Storage bigquery Send events to BigQuery via streaming insert counter Records counter datadog Send events to DataDog HTTP Event Collector es Elasticsearch exit Exit after a number of flushes (test purposes) file Generate log file forward Forward (Fluentd protocol) http HTTP Output influxdb InfluxDB Time Series logdna LogDNA loki Loki kafka Kafka kafka-rest Kafka REST Proxy nats NATS Server nrlogs New Relic null Throws away events plot Generate data file for GNU Plot slack Send events to a Slack channel splunk Send events to Splunk HTTP Event Collector stackdriver Send events to Google Stackdriver Logging stdout Prints events to STDOUT syslog Syslog tcp TCP Output td Treasure Data flowcounter FlowCounter gelf GELF Output websocket Websocket cloudwatch_logs Send logs to Amazon CloudWatch kinesis_firehose Send logs to Amazon Kinesis Firehose kinesis_streams Send logs to Amazon Kinesis Streams prometheus_exporter Prometheus Exporter prometheus_remote_write Prometheus remote write s3 Send to S3 ・AWSの任意のリソースに出力 AWSから提供される他の全てのFluentBitイメージを束ねたベースイメージを使用する． 参考：https://github.com/aws/amazon-cloudwatch-logs-for-fluent-bit ・Cloudwatchログへの出力 cloudwatch_logsプラグインがあらかじめインストールされているベースイメージを使用する． 参考：https://github.com/aws/amazon-cloudwatch-logs-for-fluent-bit 設定ファイルに予約されたAWS変数については，以下のリンクを参考にせよ． 参考：https://github.com/aws/amazon-cloudwatch-logs-for-fluent-bit#templating-log-group-and-stream-names ######################### # CloudWatchログへの転送 ######################### [OUTPUT] # プラグイン名 Name cloudwatch_logs # 転送対象とするログのタグ Match laravel # アウトプットJSONのうち，宛先に転送するキー名 log_key log region ap-northeast-1 # 予約変数あり． log_group_name /prd-foo-ecs-container/laravel/log # ログストリーム名．予約変数あり．タスクIDなど出力できる． log_stream_name container/laravel/$(ecs_task_id) [OUTPUT] Name cloudwatch_logs Match nginx log_key log region ap-northeast-1 log_group_name /prd-foo-ecs-container/nginx/log log_stream_name container/nginx/$(ecs_task_id) CloudWatchログに送信されるデータはJSON型である．logキーにログが割り当てられている．特定のキーの値のみをCloudWatchログに送信する場合，log_keyオプションでキー名を指定する．例えば，logキーのみを送信する場合，『log』と指定する． 参考：https://blog.msysh.me/posts/2020/07/split_logs_into_multiple_target_with_firelens_and_rewrite_tag.html { \"container_id\": \"*****\", \"container_name\": \"prd-foo-ecs-container\", \"ecs_cluster\": \"prd-foo-ecs-cluster\", \"ecs_task_arn\": \"arn:aws:ecs:ap-northeast-1:****:task/cluster-name/*****\", \"ecs_task_definition\": \"prd-foo-ecs-task-definition:1\", \"log\": \"\", \"source\": \"stdout\", \"ver\": \"1.5\" } ・Datadogへの出力 全てのベースイメージに標準でdatadogプラグインがインストールされているため，datadogプラグインのインストールは不要である． 参考：https://github.com/DataDog/fluent-plugin-datadog ######################### # Datadogへの転送 ######################### [OUTPUT] # プラグイン名 Name datadog # 転送対象とするログのタグ Match laravel # 転送先ホスト Host http-intake.logs.datadoghq.com TLS on compress gzip # DatadogのAPIキー． apikey ***** # DatadogログエクスプローラーにおけるService名 dd_service prd-foo # DatadogログエクスプローラーにおけるSource名 dd_source prd-foo dd_message_key log # 追加タグ dd_tags env:prd-foo [OUTPUT] Name datadog Match nginx Host http-intake.logs.datadoghq.com TLS on compress gzip apikey ***** dd_service prd-foo dd_source prd-foo dd_message_key log dd_tags env:prd-foo 代わりに，同じ設定をFireLensのlogConfigurationキーとしても適用することもできる． 参考：https://github.com/aws-samples/amazon-ecs-firelens-examples/blob/mainline/examples/fluent-bit/datadog/README.md \"logConfiguration\": { \"logDriver\":\"awsfirelens\", \"options\": { \"Name\": \"datadog\", \"Host\": \"http-intake.logs.datadoghq.com\", \"TLS\": \"on\", \"apikey\": \"\", \"dd_service\": \"prd-foo\", \"dd_source\": \"prd-foo\", \"dd_tags\": \"env:prd-foo\", \"provider\": \"ecs\" } }, ・Kinesis Firehoseへの出力 kinesis_firehoseプラグインがあらかじめインストールされているベースイメージを使用する． 参考：https://github.com/aws/amazon-kinesis-firehose-for-fluent-bit ・Kinesis Streamsへの出力 kinesis_streamsプラグインがあらかじめインストールされているベースイメージを使用する． 参考：https://github.com/aws/amazon-kinesis-streams-for-fluent-bit ・NewRelicへの出力 newRelicプラグインがあらかじめインストールされているベースイメージを使用する． 参考：https://github.com/newrelic/newrelic-fluent-bit-output ・標準出力への出力 標準出力に出力する，FluentBitの実行ログでこれを確認できる． [OUTPUT] Name stdout match * ・破棄 出力を破棄する． 参考：https://docs.fluentbit.io/manual/pipeline/outputs/null ＊実装例＊ [OUTPUT] Name null match * ＊コマンド例＊ $ fluent-bit/bin/fluent-bit \\ -i \\ -F stdout \\ -m '*' \\ -o null 03. Fargateコンテナからのログ収集 FireLensコンテナ ・FireLensコンテナとは AWSが提供するFluentBit／Fluentdイメージによって構築されるコンテナであり，Fargateコンテナのサイドカーコンテナとして配置される．Fargateコンテナからログが送信されると，コンテナ内で稼働するFluentBit／Fluentdがこれを収集し，これを他のサービスに転送する．構築のための実装例については，以下のリンクを参考にせよ． 参考： https://github.com/aws-samples/amazon-ecs-firelens-examples https://aws.amazon.com/jp/blogs/news/announcing-firelens-a-new-way-to-manage-container-logs/ ・ログの転送先 FluentBit／Fluentdが対応する他のサービスにログを転送できる． 参考：https://docs.fluentbit.io/manual/pipeline/outputs サイドカーコンテナパターン ・サイドカーコンテナパターンとは サイドカーコンテナパターンを含むコンテナデザインパターンについては，以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/virtualization/virtualization_container_orchestration.html ・ログの収集／転送の仕組み 以下の順番でログの収集／転送を実行する． 参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-firelens-for-amazon-ecs-tasks/ awsfirelensドライバーはFluentdログドライバーをラッピングしたものであり，ログをFireLensコンテナに送信する．Fluentdログドライバーについては，以下を参考にせよ． 参考：https://docs.docker.com/config/containers/logging/fluentd/ FireLensコンテナは，これを受信する． コンテナ内で稼働するFluentBitのログパイプラインのINPUTに渡され，FluentBitはログを処理する． OUTPUTセクションに渡され，FluentBitは指定した外部サービスにログを転送する． ・ログ転送プロセス FireLensコンテナでは，FluentBitまたはFlunetdがログ転送プロセスとして稼働する．FireLensコンテナを使用せずに，独自のコンテナを構築して稼働させることも可能であるが，FireLensコンテナを使用すれば，主要なセットアップがされているため，より簡単な設定でFluentBitまたはFlunetdを使用できる．FluentBitの方がより低負荷で稼働するため，FluentBitが推奨されている． 参考： https://aws.amazon.com/jp/blogs/news/under-the-hood-firelens-for-amazon-ecs-tasks/ https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/using_firelens.html ベースイメージ ・FluentBitイメージ FireLensコンテナのベースイメージとなるFluentBitイメージがAWSから提供されている．AWSリソースにログを転送するためのプラグインがすでに含まれている．なお，DatadogプラグインはFluentBit自体にインストール済みである．パブリックECRリポジトリからプルしたイメージをそのまま使用する場合と，プライベートECRリポジトリで再管理してから使用する場合がある． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/firelens-using-fluentbit.html [/fluent-bit]$ ls -la -rw-r--r-- 1 root root 26624256 Sep 1 18:04 cloudwatch.so # 旧cloudwatch_logsプラグイン -rw-r--r-- 1 root root 26032656 Sep 1 18:04 firehose.so # kinesis_firehoseプラグイン -rw-r--r-- 1 root root 30016544 Sep 1 18:03 kinesis.so # kinesis_streamsプラグイン ... ・パブリックECRリポジトリを使用する場合 ECSのコンテナ定義にて，パブリックECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているconfファイルの設定をそのまま使用する場合は，こちらを採用する． 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/firelens-using-fluentbit.html#firelens-image-ecr ・プライベートECRリポジトリを使用する場合 あらかじめ，DockerHubからFluentBitイメージをプルするためのDockerfileを作成し，プライベートECRリポジトリにイメージをプッシュしておく．ECSのコンテナ定義にて，プライベートECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているconfファイルの設定を上書きしたい場合は，こちらを採用する． FROM amazon/aws-for-fluent-bit:latest 参考： https://hub.docker.com/r/amazon/aws-for-fluent-bit https://github.com/aws/aws-for-fluent-bit https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/developerguide/firelens-using-fluentbit.html#firelens-image-dockerhub 標準設定の上書き ・標準設定ファイルの種類 aws-for-fluent-bitイメージの/fluent-bit/etcディレクトリには標準で設定ファイルが用意されている．追加設定を実行するファイルはここに配置する． [/fluent-bit/etc]$ ls -la -rw-r--r-- 1 root root 251 Sep 1 17:57 fluent-bit.conf -rw-r--r-- 1 root root 1564 Sep 27 02:15 fluent-bit_custom.conf # 追加設定用 -rw-r--r-- 1 root root 4664 Sep 1 18:07 parsers.conf -rw-r--r-- 1 root root 584 Sep 1 18:07 parsers_ambassador.conf -rw-r--r-- 1 root root 226 Sep 1 18:07 parsers_cinder.conf -rw-r--r-- 1 root root 2798 Sep 1 18:07 parsers_extra.conf -rw-r--r-- 1 root root 240 Sep 1 18:07 parsers_java.conf -rw-r--r-- 1 root root 845 Sep 1 18:07 parsers_mult.conf -rw-r--r-- 1 root root 291 Sep 27 02:15 parsers_multiline.conf -rw-r--r-- 1 root root 2954 Sep 1 18:07 parsers_openstack.conf -rw-r--r-- 1 root root 579 Sep 27 02:15 stream_processor.conf # 追加設定用 FireLensコンテナの/fluent-bit/etc/fluent-bit.confファイルは以下の通りとなり，ローカルPCでFluentBitコンテナを起動した場合と異なる構成になっていることに注意する． 参考：https://dev.classmethod.jp/articles/check-fluent-bit-conf/ [INPUT] Name tcp Listen 127.0.0.1 Port 8877 Tag firelens-healthcheck [INPUT] Name forward unix_path /var/run/fluent.sock [INPUT] Name forward Listen 127.0.0.1 Port 24224 [FILTER] Name record_modifier Match * Record ecs_cluster sample-test-cluster Record ecs_task_arn arn:aws:ecs:ap-northeast-1:123456789012:task/sample-test-cluster/d4efc1a0fdf7441e821a3683836ad69a Record ecs_task_definition sample-test-webapp-taskdefinition:15 [OUTPUT] Name null Match firelens-healthcheck ・fluent-bit_custom.confファイル FireLensコンテナの/fluent-bit/etc/fluent-bit.confファイルを，コンテナ定義のconfig-file-valueキーで指定し，追加設定を実行する．これにより，FireLensコンテナにINCLUDE文が挿入される． 参考：https://dev.classmethod.jp/articles/check-fluent-bit-conf/ [INPUT] Name tcp Listen 127.0.0.1 Port 8877 Tag firelens-healthcheck [INPUT] Name forward unix_path /var/run/fluent.sock [INPUT] Name forward Listen 127.0.0.1 Port 24224 [FILTER] Name record_modifier Match * Record ecs_cluster prd-foo-ecs-cluster Record ecs_task_arn arn:aws:ecs:ap-northeast-1::task/prd-foo-ecs-cluster/***** Record ecs_task_definition prd-foo-ecs-task-definition:1 # INCLUDE文が挿入される．ユーザ定義の設定ファイルが読み込まれる． @INCLUDE /fluent-bit/etc/fluent-bit_custom.conf [OUTPUT] Name laravel Match laravel-firelens* [OUTPUT] Name nginx Match nginx-firelens* ちなみに，標準の設定ファイルには，INPUTセクションがすでに定義されているため，fluent-bit_custom.confファイルではINPUTセクションを定義しなくても問題ない． 参考：https://github.com/aws/aws-for-fluent-bit/blob/mainline/fluent-bit.conf [INPUT] Name forward Listen 0.0.0.0 Port 24224 [OUTPUT] Name cloudwatch Match ** region us-east-1 log_group_name fluent-bit-cloudwatch log_stream_prefix from-fluent-bit- auto_create_group true ・stream_processor.confファイル STREAM_TASKセクションにて，ログのタグ付けを定義する．FireLensコンテナのパイプラインでは，『-firelens-』という名前でログが処理されている．そのため，Stream Processorでログを抽出するためには，クエリで『FROM TAG:'*-firelens-*'』を指定する必要がある．ちなみに，STREAM_TASKセクションでタグ付けされたログは，INPUTセクションから再び処理し直される． 参考：https://aws.amazon.com/jp/blogs/news/under-the-hood-firelens-for-amazon-ecs-tasks/ # appコンテナのログへのタグ付け [STREAM_TASK] Name laravel Exec CREATE STREAM web WITH (tag='laravel') AS SELECT log FROM TAG:'*-firelens-*' WHERE container_name = 'laravel'; # webコンテナのログへのタグ付け [STREAM_TASK] Name nginx Exec CREATE STREAM web WITH (tag='nginx') AS SELECT log FROM TAG:'*-firelens-*' WHERE container_name = 'nginx'; # 全てのコンテナのログへのタグ付け [STREAM_TASK] Name containers Exec CREATE STREAM container WITH (tag='containers') AS SELECT * FROM TAG:'*-firelens-*'; [SERVICE] Flush 1 Grace 30 Log_Level info # ファイルを読み込む Parsers_File parsers_multiline.conf Streams_File stream_processor.conf ・parsers_multiline.confファイル MULTILINE_PARSERセクションにて，スタックトレースログの各行の結合を定義する． 参考：https://github.com/aws-samples/amazon-ecs-firelens-examples/blob/mainline/examples/fluent-bit/filter-multiline/README.md [MULTILINE_PARSER] name laravel type regex flush_timeout 1000 rule \"start_state\" \"/(Dec \\d+ \\d+\\:\\d+\\:\\d+)(.*)/\" \"cont\" rule \"cont\" \"/^\\s+at.*/\" \"cont\" [SERVICE] flush 1 log_level info parsers_file /parsers_multiline.conf [FILTER] name multiline match * multiline.key_content log # ファイルを読み込む．組み込みパーサ（goなど）を使用することも可能． multiline.parser go, laravel FireLensコンテナのコンテナ定義 ・全体 [ { \"name\": \"\", \"image\": \"\", \"essential\": true, \"portMappings\": [ { \"containerPort\": 80, \"hostPort\": 80, \"protocol\": \"tcp\" } ], \"logConfiguration\": { \"logDriver\": \"awsfirelens\", \"options\": { \"Name\": \"forward\" } } }, { # FireLensコンテナ名がlog_routerとなることは固定 \"name\": \"log_router\", \"image\": \"\", \"essential\": false, \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { # FireLensコンテナ自体がCloudWatchログにログ出力 \"awslogs-group\": \"\", \"awslogs-region\": \"\", \"awslogs-stream-prefix\": \"\" } }, \"firelensConfiguration\": { # FireLensコンテナでFluentBitを稼働させる \"type\": \"fluentbit\", \"options\": { \"config-file-type\": \"file\", # 設定上書きのため読み込み \"config-file-value\": \"/fluent-bit/etc/fluent-bit_custom.conf\" # ECSの情報をFireLensに送信するかどうか \"enable-ecs-log-metadata\": \"true\" } }, \"portMappings\": [], \"memoryReservation\": 50, \"secrets\": [ { \"name\": \"DD_API_KEY\", \"valueFrom\": \"\" }, { \"name\": \"DD_ENV\", \"valueFrom\": \"\" } ] } ] ・name FireLensコンテナをサイドカーとして構築するために，コンテナ定義を実装する．FireLensコンテナは『log_routeter』とする． ・logConfiguration 参考：https://docs.aws.amazon.com/ja_jp/AmazonECS/latest/userguide/firelens-example-taskdefs.html#firelens-example-forward 項目 説明 type メインコンテナからFireLensコンテナにログを送信できるように，ログドライバーのタイプとして『fluentbit』を設定する． config-file-type FluentBitの設定ファイルを読み込むために，fileとする． config-file-value optionsキーにて，ログ転送時の設定が可能であるが，それらはfluent-bit.confファイルにも設定可能であるため，転送の設定はできるだけfluent-bit.confファイルに実装する．FireLensコンテナ自体のログは，CloudWatchログに送信するように設定し，メインコンテナから受信したログは監視ツール（Datadogなど）に転送する． enable-ecs-log-metadata（標準で有効化） 有効にした場合，Datadogのログコンソールで，例えば以下のようなタグが付けられる．反対に無効にした場合，以下のようなタグが付けられる．参考：https://tech.spacely.co.jp/entry/2020/11/28/173356 environment，secrets コンテナ内のfluent-bit.confファイルに変数を出力できるように，コンテナの環境変数に値を定義する． "},"public/observability_monitering/observability_datadog_metrics.html":{"url":"public/observability_monitering/observability_datadog_metrics.html","title":"📖 ︎メトリクス収集","keywords":"","body":"メトリクス収集 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. Ec2におけるメトリクス収集 Datadogエージェント on EC2とは ・Datadogエージェント on EC2とは 常駐プログラムであり，アプリケーションをメトリクスを収集し，Datadogに転送する． 参考：https://docs.datadoghq.com/ja/agent/amazon_ecs/?tab=awscli 02. Fargateにおけるメトリクス収集 Datadogエージェント on Fargate ・Datadogエージェント on Fargateとは 常駐プログラムであり，アプリケーションからメトリクスをDatadogに転送する．EC2用のDatadogエージェントとは異なり，ログは転送しない． 参考：https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens#%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97 ・環境変数 グローバルオプションとして役立つ環境変数を以下に示す． 参考：https://docs.datadoghq.com/ja/agent/docker/?tab=%E6%A8%99%E6%BA%96#%E3%82%B0%E3%83%AD%E3%83%BC%E3%83%90%E3%83%AB%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3 変数名 説明 補足 DatadogコンソールURL DD_API_KEY DatadogコンテナがあらゆるデータをDatadogに送信するために必要である． DD_ENV APMを用いる場合に，サービスやトレース画面にて，envタグに値を設定する． サービス単位で絞り込めるように，prd-fooやstg-fooとした方が良い． https://app.datadoghq.com/apm/services DD_HOSTNAME コンテナのホスト名を設定する． Fargateを使用する場合は，これを使用しないようにする．参考：https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens#%E3%81%9D%E3%81%AE%E4%BB%96%E3%81%AE%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0 https://app.datadoghq.com/infrastructure/map ECS_FARGATE Fargateを用いる場合に，これを宣言する． 任意で選択できるメトリクスの収集として役立つ環境変数を以下に示す．一部のメトリクスは，標準では収集しないようになっており，収集するためにエージェントを有効化する必要がある． 参考：https://docs.datadoghq.com/ja/agent/docker/?tab=%E6%A8%99%E6%BA%96#%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E5%8F%8E%E9%9B%86-agent 変数名 説明 補足 DatadogコンソールURL DD_APM_ENABLED APMエージェントを有効化する． Fargateを使用している場合，APMエージェントを有効化するだけでなく，分散トレースを送信できるように，サービスにパッケージのインストールが必要である．参考：・https://app.datadoghq.com/apm/docs?architecture=host-based&framework=php-fpm&language=php・https://docs.datadoghq.com/ja/tracing/#datadog-%E3%81%B8%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B9%E3%82%92%E9%80%81%E4%BF%A1 https://app.datadoghq.com/apm/home DD_LOGS_ENABLED - DD_PROCESS_AGENT_ENABLED ライブプロセスを有効化し，実行中のプロセスを収集する．参考：https://docs.datadoghq.com/ja/infrastructure/process/?tab=linuxwindows https://app.datadoghq.com/containers カスタムメトリクスの収集として役立つ環境変数を以下に示す． 参考：https://docs.datadoghq.com/ja/agent/docker/?tab=%E6%A8%99%E6%BA%96#dogstatsd-%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%A0%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9 変数名 説明 DatadogコンソールURL DD_DOGSTATSD_NON_LOCAL_TRAFFIC Datadogコンテナのカスタムメトリクスの受信を有効化する． トレースエージェント ・トレースエージェントとは Dockerエージェントにて，DD_APM_ENABLEDの環境変数にtrueを割り当てると，トレースエージェントが有効になる．APMエージェントを有効化し，分散トレースを収集できる．APMでは，分散トレースを元にして，サービス間の依存関係をサービスマップとして確認できる． 参考： https://docs.datadoghq.com/ja/agent/docker/apm/?tab=linux https://docs.datadoghq.com/ja/tracing/#datadog-apm-%E3%81%AE%E7%A2%BA%E8%AA%8D ・環境変数 一部の環境変数は，Dockerエージェントの環境変数と重なる． 参考：https://docs.datadoghq.com/ja/agent/docker/apm/?tab=linux#docker-apm-agent-%E3%81%AE%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0 変数名 説明 補足 DD_LOG_LEVEL APMに送信するログレベルを設定する． Datadogコンテナ ・Datadogコンテナとは Datadogが提供するdatadogイメージによって構築されるコンテナであり，コンテナのサイドカーコンテナとして配置される．コンテナ内で稼働するDatadog Dockerエージェントが，コンテナからメトリクスを収集し，Datadogにこれを転送する． 参考：https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens#%E6%A6%82%E8%A6%81 ・Datadogコンテナの配置 [ { # laravelコンテナ }, { # nginxコンテナ }, { # datadogコンテナ \"name\": \"datadog\", \"image\": \"datadog/agent:latest\", \"essential\": false, \"portMappings\": [ { \"containerPort\": 8126, \"hostPort\": 8126, \"protocol\": \"tcp\" } ], \"logConfiguration\": { \"logDriver\": \"awslogs\", \"options\": { \"awslogs-group\": \"/prd-foo/laravel/log\", \"awslogs-region\": \"ap-northeast-1\" \"awslogs-stream-prefix\": \"/container\" } }, \"cpu\": 10, \"memory\": 256, \"environment\": [ { \"name\": \"ECS_FARGATE\", \"value\": \"true\" }, { \"name\": \"DD_PROCESS_AGENT_ENABLED\", \"value\": \"true\" }, { \"name\": \"DD_DOGSTATSD_NON_LOCAL_TRAFFIC\", \"value\": \"true\" }, { \"name\": \"DD_APM_ENABLED\", \"value\": \"true\" }, { \"name\": \"DD_LOGS_ENABLED\", \"value\": \"true\" }, { # アプリケーションに対するenvタグ \"name\": \"DD_ENV\", \"value\": \"foo\" }, { # アプリケーションに対するserviceタグ \"name\": \"DD_SERVICE\", \"value\": \"foo\" }, { # アプリケーションに対するversionタグ \"name\": \"DD_VERSION\", \"value\": \"latest\" } ], \"secrets\": [ { \"name\": \"DD_API_KEY\", \"valueFrom\": \"/prd-foo/DD_API_KEY\" } ], \"dockerLabels\": { # ECSコンテナに対するenvタグ \"com.datadoghq.tags.env\": \"prd\", # ECSコンテナに対するserviceタグ \"com.datadoghq.tags.service\": \"foo\", # ECSコンテナに対するversionタグ \"com.datadoghq.tags.version\": \"1.0.0\" } } ] ・IAMロール Datadogコンテナがコンテナからメトリクスを収集できるように，ECSタスク実行ロールにポリシーを追加する必要がある． 参考：https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens#iam-%E3%83%9D%E3%83%AA%E3%82%B7%E3%83%BC%E3%81%AE%E4%BD%9C%E6%88%90%E3%81%A8%E4%BF%AE%E6%AD%A3 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"ecs:ListClusters\", \"ecs:ListContainerInstances\", \"ecs:DescribeContainerInstances\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" } ] } 03. メトリクスインテグレーション メトリクスインテグレーションとは 言語／フレームワーク／ツール，などに関して，専用のメトリクスを収集できるようになる．アプリケーションとして使用される言語／フレームワークの場合，Datadogエージェントがインテグレーション処理を持つため，サーバ／コンテナへのインストールは不要である．Datedogエージェントがコンテナ／サーバで稼働する言語／フレームワーク／ツールを自動で認識してくれる． 種類 ・PHP-FPMの場合 PHP-FPMインテグレーションを有効化した場合，以下の専用メトリクスを収集できるようになる． 参考：https://docs.datadoghq.com/ja/integrations/php_fpm/?tab=host#%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9 ・Nginxの場合 Nginxインテグレーションを有効化した場合，以下の専用メトリクスを収集できるようになる． 参考：https://docs.datadoghq.com/ja/integrations/nginx/?tab=host#%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9 04. メトリクス送信 設定方法 いくつかの方法で，収集されたメトリクスを送信できる． 参考：https://docs.datadoghq.com/ja/metrics/#datadog-%E3%81%B8%E3%81%AE%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9%E3%81%AE%E9%80%81%E4%BF%A1 インテグレーションのセットアップ Datadogでインテグレーションを有効化すると同時に，アプリケーションにエージェントをインストールする． メトリクスの削除 Datadogに送信されなくなったメトリクスは，時間経過とともにDatadogから削除される． 参考：https://docs.datadoghq.com/ja/dashboards/faq/historical-data/ 05. 他テレメトリーとの相関付け 参考：https://docs.datadoghq.com/ja/logs/guide/correlate-logs-with-metrics/ "},"public/observability_monitering/observability_datadog_log.html":{"url":"public/observability_monitering/observability_datadog_log.html","title":"📖 ︎ログ収集","keywords":"","body":"ログ収集 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ログ収集の仕組み バックエンド （１）サーバの場合，稼働するDatadogエージェントが，Datadog-APIにアプリケーションログを送信する．コンテナの場合，FluentBitが代わりにアプリケーションログを送信する． （２）Datadogにて，ログはパイプラインで処理され，構造化ログになる． （３）ユーザは，ログの属性値に基づいて，ログを検索できるようになる． 参考：https://developers.cyberagent.co.jp/blog/archives/12565/ フロントエンド （１）ブラウザのコンソールに出力されるログを収集する． （２）Datadogにて，ログはパイプラインで処理され，構造化ログになる． （３）ユーザは，ログの属性値に基づいて，ログを検索できるようになる． 参考：https://qiita.com/komtaki/items/a2d3f06e2265e55b0c08#2-js%E3%83%AD%E3%82%AC%E3%83%BC%E3%81%AE%E6%A7%8B%E7%AF%89 02. Ec2におけるログ収集 Datadogエージェント on EC2とは ・Datadogエージェント on EC2とは 常駐プログラムであり，アプリケーションログを収集し，Datadogに転送する． 参考：https://docs.datadoghq.com/ja/agent/amazon_ecs/?tab=awscli ・ログ収集の有効化 ログの収集は標準で無効化されている．/etc/datadog-agent/datadog.yamlファイルにて，これを有効化する． logs_enabled: true 03. Fargateにおけるログ収集 FireLensコンテナ ・FireLensコンテナとは Datadogコンテナはコンテナからログを収集できないため，代わりにFireLensコンテナを用いる必要がある．以下のリンクを参考にせよ． 参考： https://docs.datadoghq.com/ja/integrations/ecs_fargate/?tab=fluentbitandfirelens https://hiroki-it.github.io/tech-notebook-gitbook/public/summary.html?q=firelens FireLensコンテナのベースイメージ ・Datadogイメージ DatadogコンテナのベースイメージとなるDatadogイメージがDatadog公式から提供されている．パブリックECRリポジトリからプルしたイメージをそのまま用いる場合と，プライベートECRリポジトリで再管理してから用いる場合がある． ・パブリックECRリポジトリを用いる場合 ECSのコンテナ定義にて，パブリックECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているyamlファイルの設定をそのまま用いる場合は，こちらを採用する． 参考： https://gallery.ecr.aws/datadog/agent https://github.com/DataDog/datadog-agent ・プライベートECRリポジトリを用いる場合 あらかじめ，DockerHubからdatadogイメージをプルするためのDockerfileを作成し，プライベートECRリポジトリにイメージをプッシュしておく．ECSのコンテナ定義にて，プライベートECRリポジトリのURLを指定し，ECRイメージのプルを実行する．標準で内蔵されているyamlファイルの設定を上書きしたい場合は，こちらを採用する． 参考：https://hub.docker.com/r/datadog/agent FROM data/agent:latest 標準設定の上書き 参考：https://github.com/DataDog/datadog-agent/blob/main/pkg/config/config_template.yaml 04. ログの識別子 attribute（属性） ・予約済み属性 参考：https://docs.datadoghq.com/ja/logs/log_configuration/attributes_naming_convention/ 属性名 説明 補足 例 host ログの生成元のホスト名を示す． ログが生成元とは別の場所から送信されている場合に役立つ．Datadogコンテナの環境変数にて，DD_HOSTNAMEを用いてhost属性を設定する．これにより，ホストマップでホストを俯瞰できるようになるだけでなく，ログエクスプローラでホストタグが属性として付与される．他にAWSインテグレーションでは，送信元のロググループ名やバケット名が付与される． ・foo・foo-backend・foo-frontend・foo-log-group・foo-bucket source ログの生成元の名前を示す． ベンダー名を使用するとわかりやすい． ・laravel・nginx・redis status ログのレベルを示す． service ログの生成元のアプリケーション名を示す． ログとAPM分散トレースを紐付けるため，両方に同じ名前を割り当てる必要がある． ・foo・bar-backend・baz-frontend trace_id ログを分散トレースやスパンと紐付けるIDを示す． message ログメッセージを示す． ・標準属性 標準で用意された属性． 参考：https://docs.datadoghq.com/ja/logs/log_configuration/attributes_naming_convention/#%E6%A8%99%E6%BA%96%E5%B1%9E%E6%80%A7 ＊例＊ Laravelの場合 { \"container_id\": \"*****\", \"container_name\": \"/prd-foo-ecs-container\", \"date\": 12345, \"log_status\": \"NOTICE\", \"service\": \"foo\", \"source\": \"laravel\", \"timestamp\": 12345 } ＊例＊ Nginxの場合 { \"content\": { \"attributes\": { \"date_access\": 12345, \"http\": { \"method\": \"GET\", \"referer\": \"-\", \"status_category\": \"info\", \"status_code\": 200, \"url\": \"/healthcheck\", \"url_details\": { \"path\": \"/healthcheck\" }, \"useragent\": \"ELB-HealthChecker/2.0\", \"useragent_details\": { \"browser\": { \"family\": \"Other\" }, \"device\": { \"category\": \"Other\", \"family\": \"Other\" }, \"os\": { \"family\": \"Other\" } }, \"version\": \"1.1\" }, \"network\": { \"bytes_written\": 17, \"client\": { \"ip\": \"nn.nnn.nn.nnn\" } }, \"service\": \"foo\", \"timestamp\": 12345 }, \"message\": \"nn.nnn.nn.nnn - - [01/Sep/2021:00:00:00 +0000] \\\"GET /healthcheck HTTP/1.1\\\" 200 17 \\\"-\\\" \\\"ELB-HealthChecker/2.0\\\"\", \"service\": \"foo\", \"tags\": [ \"source:nginx\", \"env:prd\" ], \"timestamp\": \"2021-09-01T00:00:00.000Z\" }, \"id\": \"*****\" } ・スタックトレース属性 スタックトレースログを構成する要素に付与される属性のこと． 参考：https://docs.datadoghq.com/ja/logs/log_collection/?tab=host#%E3%82%B9%E3%82%BF%E3%83%83%E3%82%AF%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B9%E3%81%AE%E5%B1%9E%E6%80%A7 属性名 説明 logger.name ログライブラリの名前を示す． logger.thread_name スレッド名を示す． error.stack スタックトレースログ全体を示す． error.message スタックトレースログのメッセージ部分を示す． error.kind エラーの種類（Exception，OSError，など）を示す． タグ 属性名 env 05. 収集されたログの送信 EC2におけるログの送信 ・PHP Monologの場合 LogライブラリにMonologを使用している場合，/etc/datadog-agent/conf.d/php.dディレクトリ下にconf.yamlファイルを作成する．ここに，Datadogにログを送信するための設定を行う． 参考：https://docs.datadoghq.com/ja/logs/log_collection/php/?tab=phpmonolog#agent-%E3%81%AE%E6%A7%8B%E6%88%90 ＊実装例＊ init_config: instances: ## Log section logs: - type: file path: \"/path/to/laravel.log\" service: php source: php sourcecategory: sourcecode Fargateにおけるログの送信 FireLensコンテナで稼働するFluentBitが，Datadogにログを送信する．以下のリンクを参考にせよ． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability_fluentd_and_fluentbit.html 06. ログパイプライン ログパイプラインとは Datadogに送信されたログのメッセージから値を抽出し，構造化ログの各属性に割り当てる．パイプラインのルールに当てはまらなかったされなかったログは，そのまま流入する．属性ごとにファセットに対応しており，各ファセットの値判定ルールに基づいて，ログコンソール画面に表示される． リマッパー系 ・リマッパー 指定した属性／タグに割り当てられた値を，別の属性に割り当て直す．再割り当て時に，元々のデータ型を変更できる． ＊例＊ CloudWatchログから，以下のようなAPI Gatewayアクセスログの構造化ログを受信するとする． { \"content\": { \"attributes\": { \"aws\": { \"awslogs\": { \"logGroup\": \"prd-foo-api-access-log\", \"logStream\": \"be4fcfca38da39f3ad4190e2f325e5d8\", \"owner\": \"123456789\" }, \"function_version\": \"$LATEST\", \"invoked_function_arn\": \"arn:aws:lambda:ap-northeast-1:123456789:function:datadog-ForwarderStack-*****-Forwarder-*****\" }, \"caller\": \"-\", \"host\": \"prd-foo-api-access-log\", \"httpMethod\": \"GET\", \"id\": \"36472822677180929652719686832176844832038235205288853504\", \"ip\": \"nnn.nn.nnn.nnn\", \"protocol\": \"HTTP/1.1\", \"requestId\": \"4d0c0105-7c89-4384-8b3b-fcc63f701652\", \"requestTime\": \"01/Jan/2021:12:00:00 +0000\", \"resourcePath\": \"/users/{userId}\", \"responseLength\": \"26\", \"service\": \"apigateway\", \"status\": 200, \"timestamp\": 1635497933028, \"user\": \"-\" }, \"host\": \"prd-foo-api-access-log\", \"service\": \"apigateway\", \"tags\": [ \"forwardername:datadog-forwarderstack-*****-forwarder-*****\", \"source:apigateway\", \"sourcecategory:aws\", \"forwarder_memorysize:1024\", \"forwarder_version:3.39.0\" ], \"timestamp\": \"2021-01-01T12:00:00.000Z\" }, \"id\": \"AQAAAXzLRfjkXhzqsgAAAABBWHpMUmxPM0FBQTFWVnRrNTVXbkx3QUE\" } これに対して，リマッパーのルールを定義する．例えば，リクエストに関する属性値をhttp属性内の各属性に割り当て直す． { \"content\": { \"attributes\": { \"aws\": { \"awslogs\": { \"logGroup\": \"prd-foo-api-access-log\", \"logStream\": \"be4fcfca38da39f3ad4190e2f325e5d8\", \"owner\": \"123456789\" }, \"function_version\": \"$LATEST\", \"invoked_function_arn\": \"arn:aws:lambda:ap-northeast-1:123456789:function:datadog-ForwarderStack-*****-Forwarder-*****\" }, \"date_access\": \"01/Jan/2021:12:00:00 +0000\", \"host\": \"prd-foo-api-access-log\", \"http\": { \"auth\": \"-\", \"ident\": \"-\", \"method\": \"GET\", \"request_id\": \"4d0c0105-7c89-4384-8b3b-fcc63f701652\", \"status_category\": \"OK\", \"status_code\": 200, \"url\": \"/users/{userId}\", \"url_details\": { \"path\": \"/users/{userId}\" }, \"version\": \"HTTP/1.1\" }, \"id\": \"36472822677180929652719686832176844832038235205288853504\", \"network\": { \"bytes_written\": \"26\", \"client\": { \"ip\": \"nnn.nn.nnn.nnn\" } }, \"service\": \"apigateway\", \"timestamp\": 1635497933028 }, \"host\": \"prd-foo-api-access-log\", \"service\": \"apigateway\", \"tags\": [ \"forwardername:datadog-forwarderstack-*****-forwarder-*****\", \"source:apigateway\", \"sourcecategory:aws\", \"forwarder_memorysize:1024\", \"forwarder_version:3.39.0\" ], \"timestamp\": \"2021-01-01T12:00:00.000Z\" }, \"id\": \"AQAAAXzLRfjkXhzqsgAAAABBWHpMUmxPM0FBQTFWVnRrNTVXbkx3QUE\" } ・ログステータスリマッパー 指定した属性／タグに割り当てられた値を，ルールに基づいて，ステータスファセットの各ステータス（INFO，WARNING，ERROR，など）として登録する．ログコンソール画面にて，ステータスファセットとして表示される．判定ルールについては，以下のリンクを参考にせよ． 参考：https://docs.datadoghq.com/logs/log_configuration/processors/?tab=ui#log-status-remapper ・サービスリマッパー 指定した属性／タグに割り当てられた値を，サービスファセットのサービス名として登録する． 参考：https://docs.datadoghq.com/logs/log_configuration/processors/?tab=ui#service-remapper パーサー系 ・Grokパーサー パースルール（%{MATCHER:EXTRACT:FILTER}）を用いて，属性にログ値を割り当てる． 参考： https://docs.datadoghq.com/ja/logs/processing/parsing/?tab=matcher https://docs.datadoghq.com/logs/log_configuration/processors/?tab=ui#grok-parser Laravelから，以下のような非構造化ログを受信するとする． [2021-01-01 00:00:00] staging.ERROR: ログのメッセージ [2021-01-01 00:00:00] production.ERROR: ログのメッセージ 以下のようなGrokパーサールールを定義する．dateマッチャーを用いて，date属性にタイムスタンプ値を割り当てる．また，wordマッチャーを用いて，log_statusカスタム属性にステータス値を割り当てる．任意のルール名を設定できる． FooRule \\[%{date(\"yyyy-MM-dd HH:mm:ss\"):date}\\]\\s+(production|staging).%{word:log_status}\\:.+ これにより，構造化ログの各属性に値が割り当てられる． { \"date\": 1630454400000, \"log_status\": \"INFO\" } ・Urlパーサー 構造化ログのURL値からパスパラメータやクエリパラメータを検出し，詳細な属性として新しく付与する． 参考：https://docs.datadoghq.com/ja/logs/processing/processors/?tab=ui#url-%E3%83%91%E3%83%BC%E3%82%B5%E3%83%BC ＊例＊ とあるアプリケーションから，以下のような非構造化ログを受信するとする． 192.168.0.1 [2021-01-01 12:00:00] GET /users?paginate=10&fooId=1 200 以下のようなGrokパーサのルールを定義する．各マッチャーでカスタム属性に値を割り当てる． FooRule %{ipv4:network.client.ip}\\s+\\[%{date(\"yyyy-MM-dd HH:mm:ss\"):date}\\]\\s+%{word:http.method}\\s+%{notSpace:http.url}\\s+%{integer:http.status_code} これにより，構造化ログの各属性に値が割り当てられる． { \"date\": 1609502400000, \"http\": { \"method\": \"GET\", \"status_code\": 200, \"url\": \"/users?paginate=10&fooId=1\" }, \"network\": { \"client\": { \"ip\": \"192.168.0.1\" } } } これに対して，Urlパーサのルールを定義する．http.url属性からパスパラメータやクエリパラメータを検出し，http.url_details属性として新しく付与する． { \"date\": 1609502400000, \"http\": { \"method\": \"GET\", \"status_code\": 200, \"url\": \"/users?paginate=10&fooId=1\", \"url_details\": { \"path\": \"/users\", \"queryString\": { \"fooId\": 1, \"paginate\": 10 } } }, \"network\": { \"client\": { \"ip\": \"192.168.0.1\" } } } ＊例＊ CloudWatchログから，以下のようなAPI Gatewayアクセスログの構造化ログを受信するとする． { \"content\": { \"attributes\": { \"aws\": { \"awslogs\": { \"logGroup\": \"prd-foo-api-access-log\", \"logStream\": \"be4fcfca38da39f3ad4190e2f325e5d8\", \"owner\": \"123456789\" }, \"function_version\": \"$LATEST\", \"invoked_function_arn\": \"arn:aws:lambda:ap-northeast-1:123456789:function:datadog-ForwarderStack-*****-Forwarder-*****\" }, \"caller\": \"-\", \"host\": \"prd-foo-api-access-log\", \"httpMethod\": \"GET\", \"id\": \"36472822677180929652719686832176844832038235205288853504\", \"ip\": \"nnn.nn.nnn.nnn\", \"protocol\": \"HTTP/1.1\", \"requestId\": \"4d0c0105-7c89-4384-8b3b-fcc63f701652\", \"requestTime\": \"01/Jan/2021:12:00:00 +0000\", \"resourcePath\": \"/users/{userId}\", \"responseLength\": \"26\", \"service\": \"apigateway\", \"status\": 200, \"timestamp\": 1635497933028, \"user\": \"-\" }, \"host\": \"prd-foo-api-access-log\", \"service\": \"apigateway\", \"tags\": [ \"forwardername:datadog-forwarderstack-*****-forwarder-*****\", \"source:apigateway\", \"sourcecategory:aws\", \"forwarder_memorysize:1024\", \"forwarder_version:3.39.0\" ], \"timestamp\": \"2021-01-01T12:00:00.000Z\" }, \"id\": \"AQAAAXzLRfjkXhzqsgAAAABBWHpMUmxPM0FBQTFWVnRrNTVXbkx3QUE\" } これに対して，以下のようなカテゴリパーサーのルールを定義する．aws.invoked_function_arn属性のLambdaのARN応じて，service属性にサービス値（foo-apigateway，bar-apigateway，baz-apigateway）を付与するようにする．この属性を使用する理由は，様々なAWSリソースの構造化ログが持っているためである（owner属性でもよい．ただし，おそらくS3からログを収集する場合はこれがない？）．元の構造化ログにすでにservice属性があるため，この値が上書きされる． foo-apigateway @aws.invoked_function_arn:\"arn:aws:lambda:ap-northeast-1:123456789:function:datadog-ForwarderStack-*****-Forwarder-*****\" bar-apigateway @aws.invoked_function_arn:\"arn:aws:lambda:ap-northeast-1:987654321:function:datadog-ForwarderStack-*****-Forwarder-*****\" baz-apigateway @aws.invoked_function_arn:\"arn:aws:lambda:ap-northeast-1:192837465:function:datadog-ForwarderStack-*****-Forwarder-*****\" これにより，構造化ログのservice属性にサービス値が割り当てられる．なお，service属性以外は元の構造化ログと同じため，省略している． { \"content\": { # ～ 中略 ～ \"service\": \"foo-apigateway\", # ～ 中略 ～ }, # ～ 中略 ～ } これに対して，サービスリマッパーのルールを定義する．service属性のサービス値が，サービスファセットとして登録されるようにする． ・ユーザエージェントパーサー ＊例＊ Nginxから，以下のような非構造化ログを受信するとする． nn.nnn.nn.nn - - [01/Sep/2021:00:00:00 +0000] \"GET /healthcheck HTTP/1.1\" 200 17 \"-\" \"ELB-HealthChecker/2.0\" これに対して，以下のようなGrokパーサールールを定義する．http.useragent属性にユーザエージェント値を割り当てる． access.common %{_client_ip} %{_ident} %{_auth} \\[%{_date_access}\\] \"(?>%{_method} |)%{_url}(?> %{_version}|)\" %{_status_code} (?>%{_bytes_written}|-) access.combined %{access.common} (%{number:duration:scale(1000000000)} )?\"%{_referer}\" \"%{_user_agent}\"( \"%{_x_forwarded_for}\")?.* error.format %{date(\"yyyy/MM/dd HH:mm:ss\"):date_access} \\[%{word:level}\\] %{data:error.message}(, %{data::keyvalue(\": \",\",\")})? これにより，構造化ログの各属性に値が割り当てられる． { \"date_access\": 12345, \"http\": { \"method\": \"GET\", \"referer\": \"-\", \"status_code\": 200, \"url\": \"/healthcheck\", \"useragent\": \"ELB-HealthChecker/2.0\", \"version\": \"1.1\" }, \"network\": { \"bytes_written\": 17, \"client\": { \"ip\": \"nn.nnn.nnn.nn\" } } } これに対して，ユーザエージェントパーサーのルールを定義する．http.useragent属性の値を分解し，useragent_details属性に振り分けるようにする．これにより，構造化ログの各属性に値が割り当てられる． { # ～ 中略 ～ \"useragent_details\": { \"browser\": { \"family\": \"Chrome\" }, \"device\": { \"category\": \"Other\", \"family\": \"Other\" }, \"os\": { \"family\": \"Linux\" } } # ～ 中略 ～ } プロセッサー系 ・カテゴリプロセッサー 検索条件に一致する属性を持つ構造化ログに対して，属性を新しく付与する． ＊例＊ Nginxから，以下のような非構造化ログを受信するとする． nn.nnn.nn.nn - - [01/Sep/2021:00:00:00 +0000] \"GET /healthcheck HTTP/1.1\" 200 17 \"-\" \"ELB-HealthChecker/2.0\" 以下のようなGrokパーサールールを定義する．http.status_code属性にステータスコード値を割り当てる． access.common %{_client_ip} %{_ident} %{_auth} \\[%{_date_access}\\] \"(?>%{_method} |)%{_url}(?> %{_version}|)\" %{_status_code} (?>%{_bytes_written}|-) access.combined %{access.common} (%{number:duration:scale(1000000000)} )?\"%{_referer}\" \"%{_user_agent}\"( \"%{_x_forwarded_for}\")?.* error.format %{date(\"yyyy/MM/dd HH:mm:ss\"):date_access} \\[%{word:level}\\] %{data:error.message}(, %{data::keyvalue(\": \",\",\")})? これにより，構造化ログの各属性に値が割り当てられる． { \"date_access\": 12345, \"http\": { \"method\": \"GET\", \"referer\": \"-\", \"status_code\": 200, \"url\": \"/healthcheck\", \"useragent\": \"ELB-HealthChecker/2.0\", \"version\": \"1.1\" }, \"network\": { \"bytes_written\": 17, \"client\": { \"ip\": \"nn.nnn.nnn.nn\" } } } これに対して，以下のようなカテゴリパーサーのルールを定義する．http.status_code属性のステータスコード値に応じて，http.status_category属性にステータスレベル値（info，notice，warning，error）を付与するようにする． info @http.status_code:[200 TO 299] notice @http.status_code:[300 TO 399] warning @http.status_code:[400 TO 499] error @http.status_code:[500 TO 599] これにより，構造化ログのhttp.status_category属性にステータスレベル値が割り当てられる．なお，http.status_category属性以外は元の構造化ログと同じため，省略している． { # ～ 中略 ～ \"http\": { # ～ 中略 ～ status_category: \"info\" }, # ～ 中略 ～ } これに対して，ステータスリマッパーのルールを定義する．http.status_category属性のステータスレベル値が，ステータスファセット（INFO，WARNING，ERROR，など）として登録されるようにする． パースルールの構成 ・マッチャー 参考：https://docs.datadoghq.com/ja/logs/processing/parsing/?tab=matcher#%E3%83%9E%E3%83%83%E3%83%81%E3%83%A3%E3%83%BC%E3%81%A8%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%83%BC ・フィルター 参考：https://docs.datadoghq.com/ja/logs/processing/parsing/?tab=filter#%E3%83%9E%E3%83%83%E3%83%81%E3%83%A3%E3%83%BC%E3%81%A8%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%83%BC 06-02. ログインテグレーション ログインテグレーションとは アプリケーション，ミドルウェア，クラウドインフラ，などのログを集約的に収集しやすくなるインテグレーションパイプラインライブラリを提供する． インテグレーションパイプラインライブラリ ・インテグレーションパイプラインライブラリとは ログの生成元に合わせて，プロセッサーのセットが組み込まれたパイプラインを提供してくれる． 参考： https://docs.datadoghq.com/logs/log_configuration/pipelines/?tab=source#integration-pipelines https://docs.datadoghq.com/integrations/#cat-log-collection ・AWSの場合 AWSリソースで生成されたログをDaadogに転送できるようにし，また構造化ログとして検索できるようにする．次の方法でセットアップする． （１）DatadogのAWSアカウントの登録画面で，CloudFormationによる自動セットアップを選択する． 参考：https://app.datadoghq.com/account/settings#integrations/amazon-web-services （２）CloudFormationにより，メトリクス／ログ／分散トレースを転送するLambdaやIAMロールを構築する．構築されたIAMロール（DatadogIntegrationRole）をDatadogのIAMユーザ（464622532012）に委譲できるように，アカウントIDとロール名をDatadogの設定画面に入力する． 参考：https://app.datadoghq.com/account/settings#integrations/amazon-web-services （３）ここではログを転送できるように，LambdaのトリガーとしてCloudWatchログやS3を設定する．トリガーとして設定せずに，自動で転送することも可能であるが，自動認識されるログの種類が少ないので，手動で設定した方が良い． 参考：https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/?tab=awsconsole#automatically-set-up-triggers （４）送信元のAWSリソースの命名によって，ログのservice属性の値が変わる．例えば，CloudWatchログのロググループ名が『api-gateway-***』から始まる場合，属性値はapigatewayになる． 06-03. ログパイプラインの後処理 標準属性の付与 06-04. オプション処理 ログのメトリクス ・ログのメトリクスとは パイプラインで処理を終えたログに関して，属性／タグに基づくメトリクスを作成する．メトリクスを作成しておくと，ログのレポートとして使用できる． 参考：https://www.amazon.co.jp/dp/1800568738 インデックス ・インデックスとは パイプラインで処理を終えたログをグループ化し，ログの破棄ルールや保管期間をグループごとに定義できる．インデックスを使用すれば，Datadogのログ保管のネックになる保管料金を抑えられる． 参考： https://docs.datadoghq.com/ja/logs/indexes/ https://tech-blog.abeja.asia/entry/why-datadog アーカイブ セキュリティルール 07. ログエクスプローラ Live Tail ・Live Tailとは ログパイプライン処理後のログをリアルタイムで確認できる． 参考：https://docs.datadoghq.com/ja/logs/explorer/live_tail/ ログクエリ ・ログクエリ 構造化ログの属性名と値に基づいて，ログを絞り込める． 参考：https://docs.datadoghq.com/ja/logs/explorer/search_syntax/ ・オートコンプリート 入力欄右のアイコンで切り替える．検索条件として属性名と値を補完入力できる．オートコンプリートをの使用時は，小文字で入力した属性名の頭文字が画面上で大文字に変換される． ＊例＊ 『service:foo』をオートコンプリートで入力する． ・非オートコンプリート 入力欄右のアイコンで切り替える．検索条件として属性名と値をそのまま入力する． ＊例＊ 『service:foo』を非オートコンプリートで入力する． ファセット ・ファセットとは 属性／タグの値に基づいて，ログをグルーピングしたもの． 参考：https://docs.datadoghq.com/ja/logs/explorer/facets/#%E3%83%AD%E3%82%B0%E3%82%B5%E3%82%A4%E3%83%89%E3%83%91%E3%83%8D%E3%83%AB ・属性のファセット化 Pathの値に属性までのアクセスを『@』から入力すると，ログの属性がファセットの値に登録される． ・タグのファセット化 Pathの値にタグ名をそのまま入力すると，タグがファセットの値に登録される． "},"public/observability_monitering/observability_datadog_distributed_trace.html":{"url":"public/observability_monitering/observability_datadog_distributed_trace.html","title":"📖 ︎分散トレース収集","keywords":"","body":"分散トレース収集 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. トレーサー トレーサーとは APM機能を用いる時に，トレースエージェントが稼働するDatadogコンテナに分散トレースを送信できるよう，サービスのコンテナでトレーサーをインストールする必要がある．パッケージはアプリケーションによって読み込まれた後，『http://localhost:8126』を指定して，分散トレースを送信するようになる． 参考：https://docs.datadoghq.com/ja/tracing/#datadog-%E3%81%B8%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B9%E3%82%92%E9%80%81%E4%BF%A1 パッケージ一覧 参考：https://docs.datadoghq.com/ja/developers/libraries/#apm-%E3%81%A8%E5%88%86%E6%95%A3%E5%9E%8B%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%B3%E3%82%B0%E3%82%AF%E3%83%A9%E3%82%A4%E3%82%A2%E3%83%B3%E3%83%88%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA PHPトレーサー ・インストール 各サービスのDockerfileにて，パッケージをインストールする． 参考：https://docs.datadoghq.com/tracing/setup_overview/setup/php/?tab=containers ENV DD_TRACE_VERSION=0.63.0 # GitHubからパッケージをダウンロード RUN curl -Lo https://github.com/DataDog/dd-trace-php/releases/download/${DD_TRACE_VERSION}/datadog-php-tracer_${DD_TRACE_VERSION}_amd64.deb \\ # 解凍 && dpkg -i datadog-php-tracer.deb \\ # 残骸ファイルを削除 && rm datadog-php-tracer.deb アプリケーションがパッケージを読み込んだか否かをコマンドで確認できる． # 成功の場合 root@*****:/ php --ri=ddtrace ddtrace Datadog PHP tracer extension For help, check out the documentation at https://docs.datadoghq.com/tracing/languages/php/ (c) Datadog 2020 ... まだまだ続く # 失敗の場合 root@*****:/ php --ri=ddtrace Extension 'ddtrace' not present. ・環境変数 環境変数を使用できる．分散トレースのタグ名に反映される．環境変数については，以下のリンクを参考にせよ． 参考：https://docs.datadoghq.com/ja/tracing/setup_overview/setup/php/?tab=%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A#%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%82%B3%E3%83%B3%E3%83%95%E3%82%A3%E3%82%AE%E3%83%A5%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3 変数名 説明 画面 DD_SERVICE_MAPPING 分散トレースにサービス名を設定する．サービス名は標準のでインテグレーション名になるが，これを上書きできる（例）laravel:foo-laravel,pdo:foo-pdo https://app.datadoghq.com/apm/services DD_SERVICE_NAME 分散トレースにサービス名を設定する．DD_SERVICE_MAPPINGがnullの場合，この環境変数の値が代わりにサービス名になる（仕組みがよくわからん）． DD_TRACE__ENABLED 有効化するインテグレーション名を設定する．標準で全てのインテグレーションが有効化されているため，設定は不要である．Datadogのインテグレーションを無効化する場合は DD__DISABLED 無効化するインテグレーション名を設定する． トレーサーの設定の状態は，php --ri=ddtraceコマンドの結果得られるJSONを整形することで確認できる． root@*****:/ php --ri=ddtrace Datadog tracing support => enabled Version => 0.57.0 DATADOG TRACER CONFIGURATION => { ..... } # Node.jsトレーサー ・TypeScriptやモジュールバンドルを使っている場合 エントリポイントとなるnuxt.config.jsファイルにて，一番最初にDatadogのトレースパッケージを読み込み，初期化する． 参考：https://docs.datadoghq.com/ja/tracing/setup_overview/setup/nodejs/?tab=%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A#typescript-%E3%81%A8%E3%83%90%E3%83%B3%E3%83%89%E3%83%A9%E3%83%BC import 'dd-trace/init' // フレームワークを含むパッケージのインポートが続く また，初期化時に設定した環境変数を使用できる．APMのサービスのタグ名に反映される． 参考：https://docs.datadoghq.com/ja/tracing/setup_overview/setup/nodejs/?tab=%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A#%E3%82%B3%E3%83%B3%E3%83%95%E3%82%A3%E3%82%AE%E3%83%A5%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3 02. 分散トレースの生成 分散トレース ・分散トレースとは 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability.html ・構造 Datadogにおいて，分散トレースはスパンを持つ配列データとして定義される． 参考：https://docs.datadoghq.com/tracing/guide/send_traces_to_agent_by_api/ [ span1, span2, span3 ] また，複数の分散トレースを配列データとして定義できる． [ trace1, trace2, trace3 ] スパン ・スパンとは 参考：https://hiroki-it.github.io/tech-notebook-gitbook/public/observability_monitering/observability.html ・構造 Datadogにおいて，スパンはJSON型データとして定義される．アプリケーション内のトレーサーにおいて，指定されたJSON型のスパンが作成され，スパンはDatadog-APIに送信される． 参考：https://docs.datadoghq.com/tracing/guide/send_traces_to_agent_by_api/ ＊実装例＊ [ [ { \"duration\": 123, # 処理の所要時間 \"error\": 0, # エラーの有無 \"meta\": { \"env\": \"prd\" # タグのり }, \"metrics\": { \"baz-sum\": 123 # サービスのメトリクス }, \"name\": \"laravel.request\", # スパン名 \"parent_id\": 123, # 親スパンID \"resource\": \"/foos\", # アクセスされたリソース \"service\": \"laravel\", # サービス名 \"span_id\": 123456789, # スパンID \"start\": 0, # 処理開始時間 \"trace_id\": 123456789, # トレースID \"type\": \"web\" # サービスのタイプ } ] ] ・メタデータ スパンのmetaキーにメタデータのセットを割り当てられる．メタデータはタグとして機能する． ＊実装例＊ PHPトレーサーでlaravel内からタグを収集した例 { \"env\": \"prd\", \"http\": { \"host\": \"example.co.jp\", \"method\": \"GET\", \"path_group\": \"/foos\", \"status_code\": 200, \"url\": \"https://example.co.jp/foos/1\" }, \"laravel\": { \"route\": { \"action\": \"App\\Http\\Controllers\\Foo\\FooController@get\", \"name\": \"foos.get\" } }, \"php\" : { \"compilation\": { \"total_time_ms\": 123.45 } }, \"process_id\": 100 } スパンのメトリクス ・スパンのデータポイント化 スパンの持つデータをデータポイントとして集計すると，メトリクスを収集できる． 参考：https://docs.datadoghq.com/ja/tracing/generate_metrics/ ・メトリクス名の構成要素 メトリクス名は『trace..』の名前で構成される． 参考：https://docs.datadoghq.com/ja/tracing/guide/metrics_namespace/ ・メトリクスのスパン名 データポイントとなったスパン名が割り当てられる． ＊例＊ trace.web.request. trace.db.query. trace.db.commit. ・メトリクスのメトリクスサフィックス名 メトリクスの種類に応じたサフィックス名が割り当てられる． 参考：https://docs.datadoghq.com/ja/tracing/guide/metrics_namespace/#%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9%E3%82%B5%E3%83%95%E3%82%A3%E3%83%83%E3%82%AF%E3%82%B9 ＊例＊ trace..hits.***（該当スパンのヒット数） trace..duration（該当スパンの処理時間） trace..duration.by.***（該当スパンの処理時間の割合） trace..errors.***（該当スパンにおけるエラー数） 03. サービスの識別 サービスタイプ ・サービスタイプとは トレーサによって，サービスは『Web』『DB』『Cache』『Cache』の４つに分類される．各サービスのspan.type属性に割り当てられるタイプ名から自動的に割り振られる．タイプ名の種類については，以下のリンクを参考にせよ． 参考： https://github.com/DataDog/dd-trace-php/blob/master/src/api/Type.php https://docs.datadoghq.com/ja/tracing/visualization/services_list/#%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%BF%E3%82%A4%E3%83%97 サービスのタグ ・サービスのタグとは トレーサによって，サービスにタグを追加できる．PHPトレーサの各インテグレーションのソースコードについては以下のリンクを参考にせよ．ソースコードから，PHPトレーサーがアプリケーションからどのように情報を抜き出し，分散トレースのタグの値を決定しているかがわかる． 参考： https://github.com/DataDog/dd-trace-php/tree/master/src/DDTrace/Integrations https://github.com/DataDog/dd-trace-php/blob/master/src/api/Tag.php 04. 分散トレースインテグレーション 分散トレースインテグレーションとは 言語／フレームワーク／ツール，などに関して，専用の分散トレースを収集できるようになる．アプリケーションとして使用される言語／フレームワークの場合，トレースエージェントがインテグレーション処理を持つため，サーバ／コンテナへのインストールは不要である．については，以下のリンクを参考にせよ． 参考：https://github.com/DataDog/dd-trace-php/tree/master/src/DDTrace/Integrations "},"public/observability_monitering/observability_datadog_telemetry_association.html":{"url":"public/observability_monitering/observability_datadog_telemetry_association.html","title":"📖 ︎テレメトリー間の紐づけ","keywords":"","body":"テレメトリー間の紐付け 01. タグ タグの種類 参考： https://docs.datadoghq.com/ja/getting_started/tagging/ https://www.datadoghq.com/ja/blog/tagging-best-practices/ タグ名 説明 host メトリクス，ログ，分散トレースの送信元のホスト名を示す．テレメトリーが生成元とは別の場所から送信されている場合に役立つ． device source ログの生成元のベンダー名を示す． service メトリクス，ログ，分散トレースの生成元のアプリケーション名を示す． env メトリクス，ログ，分散トレースの生成元の実行環境名を示す． version メトリクス，ログ，分散トレースの生成元のバージョン名を示す． 統合タグ付け 統合タグ（service，env，version）に同じ値を割り当てると，テレメトリー間を紐づけられる． 参考：https://docs.datadoghq.com/ja/getting_started/tagging/unified_service_tagging/?tab=kubernetes 各コンソール画面での使い方 参考：https://docs.datadoghq.com/ja/getting_started/tagging/using_tags/ 02. 構造化ログと他テレメトリー間の紐付け 分散トレース全体との紐付け スパンと構造化ログの統合タグ（service，env，version）に同じ値を割り当てると，分散トレース全体と構造化ログ間を紐付けられる． 参考：https://docs.datadoghq.com/ja/tracing/connect_logs_and_traces/ スパンとの紐付け スパンと構造化ログに，同じトレースIDとスパンIDを割り当てると，スパンと構造化ログ間を紐付けられる．これにより，その構造化ログが，いずれのサービスで，またどのタイミングで発生したものかを確認できる． 参考：https://docs.datadoghq.com/tracing/visualization/trace/?tab=logs 03. メトリクスと他テレメトリー間の紐付け サーバ／コンテナのメトリクスとの紐付け スパンとコンテナのDockerLabelの統合タグ（service，env，version）に，同じ値を割り当てると，分散トレースとサーバ／コンテナのOSに関するメトリクスを紐付けられる． "},"public/observability_monitering/observability_datadog_monitering.html":{"url":"public/observability_monitering/observability_datadog_monitering.html","title":"📖 ︎監視","keywords":"","body":"監視 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. モニター モニターとは メトリクス／ログを監視し，システムの予測可能な不具合の発生を未然に防ぐ． ログモニター ・ログクエリの動作確認 ログモニターのクエリは，ログコンソールと同じ仕組みで機能する．そのため，最初はログコンソールで必要なログを絞り込めるかを確認し，問題なければログモニターのクエリを設定する． 参考：https://docs.datadoghq.com/ja/monitors/monitor_types/log/#%E6%A4%9C%E7%B4%A2%E3%82%AF%E3%82%A8%E3%83%AA%E3%82%92%E5%AE%9A%E7%BE%A9%E3%81%99%E3%82%8B ・シングルアラート ・マルチアラート ログクエリでgroup by句を定義すると，選択できるようになる． 01-02. 通知内容の定義 テンプレート変数 参考：https://docs.datadoghq.com/ja/monitors/notify/variables/?tab=is_alert#template-variables マルチアラート変数 ・マルチアラート変数とは クエリのgroup by句に割り当てたタグやファセットを変数として出力する．マルチアラートモニターを使用する場合のみ，使用できる． タグ変数 ・タグ変数とは 構造化ログの属性値またはタグ値を変数として出力する．{{log.attributes.}} または{{log.tags.}}として実装する． 参考：https://docs.datadoghq.com/ja/monitors/notify/variables/?tab=is_alert#matching-attributetag-variables コンポジットモニター変数 ・コンポジットモニター変数とは 参考：https://docs.datadoghq.com/ja/monitors/notify/variables/?tab=is_alert#composite-monitor-variables 条件変数 参考：https://docs.datadoghq.com/ja/monitors/notify/variables/?tab=is_alert#conditional-variables メッセージの構成 ・タイトル 通知先にタイトルとして表示するテキストを定義する．タイトルに変数を出力できる． 【{{log.attributes.service}}】ｈ環境でエラーを検知しました ・本文 通知先とテキストを定義する．マークダウン記法を使用できる． 参考：https://www.datadoghq.com/ja/blog/tagging-best-practices/#%e3%83%81%e3%83%bc%e3%83%a0%e7%94%a8%e3%81%ae%e8%87%aa%e5%8b%95%e7%9a%84%e3%81%8b%e3%81%a4%e5%8b%95%e7%9a%84%e3%81%aa%e3%82%a2%e3%83%a9%e3%83%bc%e3%83%88%e3%82%92%e4%bd%9c%e6%88%90%e3%81%99%e3%82%8b {{#is_alert}} @ 環境名：{{log.attributes.env}} アプリケーション名：{{log.attributes.service}} ソース名：{{log.tags.source}} リージョン名：{{log.attributes.region}} {{/is_alert}} 02. リアルユーザ監視（RUM） ブラウザエラー ・ブラウザエラーとは Datadogにおいて，ブラウザのエラーは以下に分類される． 参考：https://docs.datadoghq.com/real_user_monitoring/browser/collecting_browser_errors/?tab=npm エラーのソース エラーの例 ソースコード上 ・ハンドリングされずにソースコード上に表示された例外・ハンドリングされずにソースコード上に表示されたPromiseオブジェクトのrejectメソッドの結果 ブラウザコンソール上 console.errorメソッドによって，コンソール上に出力されたテキスト カスタム @datadog/browser-rumパッケージのaddErrorメソッドによって，Datadog-APIに送信されたテキスト 03. 合成監視 ブラウザテスト ・送信元IPアドレス Datadog社のサーバからリクエストが送信される．サーバ自体はAWSやAzureによって管理されており，使用するサーバのリージョンを選択できる．リージョンごとに数個ずつサーバが存在しているため，もし合成監視対象のアプリケーションでIP制限が行われている場合は，これらのサーバのIPからのリクエストを許可する必要がある． 参考：https://docs.datadoghq.com/synthetics/guide/identify_synthetics_bots/?tab=singleandmultistepapitests ・ヘッダー 参考： https://docs.datadoghq.com/synthetics/guide/identify_synthetics_bots/?tab=singleandmultistepapitests#default-headers https://docs.datadoghq.com/synthetics/apm/#how-are-traces-linked-to-tests ヘッダー 値 user-agent ブラウザテストで設定したブラウザが割り当てられる． sec-datadog ブラウザテストのIDが割り当てられる． x-datadog-trace-id バックエンドがマイクロサービスアーキテクチャの場合に，収集できる分散トレースを紐付けるIDが割り当てられる． x-datadog-parent-id バックエンドがマイクロサービスアーキテクチャの場合に，分散トレースのルートスパンとして，0が割り当てられる． x-datadog-origin バックエンドがマイクロサービスアーキテクチャの場合に，分散トレースがAPMクオータに影響しないように，synthetics-browserが割り当てられる． x-datadog-sampling-priority バックエンドがマイクロサービスアーキテクチャの場合に，分散トレースが収集される優先度として，1が割り当てれる． APIテスト マルチステップAPIテスト 04. グラフ 図の種類 スケールの種類 ・log（対数）スケール ・linear（線形）スケール ・２の累乗スケール ・sqrt（平方根）スケール "},"public/system_development_methodology/system_development_methodology.html":{"url":"public/system_development_methodology/system_development_methodology.html","title":"📖 ︎システム開発手法論","keywords":"","body":"システム開発手法論 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. ウォーターフォール型開発 ウォーターフォール型開発とは 外部設計の詳細 外部設計では，ユーザ向けのシステム設計が行われる． 02. プロトタイプ型開発 プロトタイプ型開発とは システム設計に入るまでに試作品を作り，要件定義をより正確にする開発方法． 03. レビュー レビューとは 各工程が完了した段階で，レビューを行う開発方法． 04. RAD（Rapid Application Development） RADとは Visual Basicなどの開発支援ツールを用いて，短期間で設計～テストまでを繰り返す開発方法． 05. スパイラル型開発 スパイラル型開発とは システムをいくつかのサブシステムに分割し，ウォーターフォール型開発で各サブシステムを開発していく方法． 06. アジャイル型開発 アジャイル型開発とは スパイラルモデルの派生型．スパイラルモデルよりも短い期間で，設計～テストまでを繰り返す開発方法． 07. CASEツール：Computer Aided Software Enginnering CASEツールとは システム開発をサポートするツール群のこと． 上流CASEツール データフロー図，ER図 下流CASEツール テスト支援ツール 保守CASEツール リバースエンジニアリング "},"public/system_development_methodology/system_development_methodology_project_management.html":{"url":"public/system_development_methodology/system_development_methodology_project_management.html","title":"📖 ︎プロジェクト管理","keywords":"","body":"プロジェクト管理 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. プロジェクト管理 管理指標 『開発規模（か）』，『工数（こ）』，『生産性（せ）』の単位間の関係は，『みはじ』と同じである． ・開発規模（か） （プログラム本数による開発規模）＝（プログラム本数） （プログラム行数による開発規模）＝（ｋステップ行数） ・工数（こ） （人時による工数）＝（人数・時）＝（人数 × 時間） （人時による標準工数）＝（プログラム一本当たりの人数・時）＝（人数・時／本） 一期開発 外部設計 内部設計 開発 結合テスト 総合テスト 工数 42（時間） 70 140 52.5 42.0 配分月数 3（ヶ月） 3 5 2 3 A社動員数 12（人） 20 0 12 12 B社動員数 2（人） 4 28 15 2 ・生産性（せ） （プログラム本数の生産性） ＝（プログラム本数／人時） ＝（プログラム本数による開発規模）÷（工数） （kステップ行数の生産性） ＝（ｋステップ行数／人時） ＝（ｋステップ行数による開発規模）÷（工数） ・進捗率 Arrow ダイアグラム ・プロジェクトに必要な日数 全体的な工程に必要な日数は，所要日数が最も多い経路に影響される．この経路を，Critical Path という． ・最早結合点時刻 全体的な工程の中で，任意の結合点に取り掛かるために必要な最少日数のこと．Critical Path に影響されるので，注意． ・最遅結合点時刻 全体的な工程の中で，任意の結合点に取り掛かるために必要な最多日数のこと． "},"public/system_development_methodology/system_development_methodology_github.html":{"url":"public/system_development_methodology/system_development_methodology_github.html","title":"📖 ︎GitHub","keywords":"","body":"GitHub はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. 作業者の場合 Issue ・作成 テンプレートを元に，Issueを作成する． ・削除 リポジトリの管理者権限があれば削除できる． PullReq ・作成 テンプレートを元に，PullReqを作成する． ・削除 不可能のため，クローズするしかない．犯した罪は背負って生きていかなければならない． 参照：https://stackoverflow.com/questions/18318097/delete-a-closed-pull-request-from-github 02. レビュアーの場合 レビュー観点 ・ビジネスルールや仕様通りか 実装の条件文や，コメントから，ビジネスルールや仕様を理解する． 条件文でvar_dump() を行う． どういった入力がされた場合に，true として判断しているのかを確認．例えば，受注済区分値が設定されているときに，それが失注区分値に変わった場合に，値を返却しているならば，そこから，『失注』のビジネスルールが垣間見える． 定数に添えられたコメントから，仕様を理解． ・バリデーションは適切か empty() ，isset() などを正しく区別して使えているかを確認する ・冗長になっていないか 重複する処理をforeach()にまとめられないかを確認する．また，変数の格納が重複していないかを確認する． 03. テンプレート 配置場所 リポジトリの直下に.githubディレクトリを配置し，ISSUE_TEMPLATE.mdやPULL_REQUEST_TEMPLATE.mdの名前でファイルを置く．Issueのテンプレートに関して，代わりにISSUE_TEMPLATEディレクトリを置き，任意の名前のmdファイルを置くと，複数のテンプレートを作成できる． 参考：https://qiita.com/nyamogera/items/3fe6985b45fbd5377184 project/ └── .github ├── ISSUE_TEMPLATE.md └── PULL_REQUEST_TEMPLATE.md project/ └── .github ├── ISSUE_TEMPLATE | ├── FIX.md | └── UPDATE.md | └── PULL_REQUEST_TEMPLATE.md Issue ・Issueの分割 一つのIssueとブランチにたくさんの実装をCommitすることは望ましくない．そこで，大きな対応を個々の対応に分割する．そして，大きな対応に関する基点Issueと基点ブランチを作成し，個々の対応に関連する子Issueと子ブランチを作成していく．個別の対応が終わったら，親ブランチへマージしていく． ・タイトル タイトルは『〇〇する．』とする．句読点の有無は好み． ・内容 内容は『背景』と『対応方針』さえ伝われば，文言自体はそのリポジトリのルールに合わせる． ＊例＊ # 背景 # 対応方針 PullReq ・タイトル タイトルは『〇〇した．』とする．句読点の有無は好み． ・WIP 実装途中のPullReqであり，実装方法などを質問したい場合に，タイトルに『WIP』とつけておく．レビューしてもらいたくなったら，これをはずす．レビュー修正時に，実装に時間がかかりそうであったら，再び付けても良い． ・内容 内容は『対応内容』と『レビューしてほしいところ』さえ伝われば，文言自体はそのリポジトリのルールに合わせる．もし，レビュー期限や動作確認手順を知らせる必要があれば『レビュー期限』『確認手順』の項目を設ける． ＊例＊ # リリース予定日 # 対応内容 # レビューしていただきたいところ 04. Tips 基点ブランチから二回派生するブランチマージする時の注意点 （１）基点ブランチから，一つ目のブランチにマージし，これをpushする．ここでpushしないと，2番目のブランチが一つ目のブランチとの差分を検出してしまい，大量の差分コミットがgithubに表示されてしまう． （２）一つ目のブランチから二つ目のブランチにマージし．これをpushする． Conflictの解決方法とマージコミットの作成 （１）git statusを行い，特定のファイルでのコンフリクトが表示される． Unmerged paths: (use \"git restore --staged ...\" to unstage) (use \"git add ...\" to mark resolution) both modified: XXX/YYY.twig （２）コンフリクトしていたコード行を取捨選択する． （３）一度addを行い，コンフリクトの修正をGitに認識させる． $ git add XXX/YYY.twig （４）git statusを行い，以下が表示される．コンフリクトが解決されたが，マージされていないと出力される．差分のファイルがたくさん表示される場合があるが，問題ない． All conflicts fixed but you are still merging. Changes to be committed: modified: XXX modified: XXX （５）git commit（-mはつけてはいけない）を行い，vimエディタが表示される． Merge branch \"ブランチ名\" into ブランチ名 （６）:wqでエディタを終了すれば，コンフリクトを解消したマージコミットが作成される． （７）git statusを行う．場合によっては，差分のコミット数が表示されるが問題ない． Your branch is ahead of \"origin/feature/XXXX\" by 10 commits. （８）pushする．この時，マージコミットを作成する時，基点ブランチ以外からマージしていると，差分のコミットが一つにまとまらず， 参考：http://www-creators.com/archives/1938 Commitの粒度 データベースからフロント出力までに至る実装をCommitする場合，以下の3つを意識する． （１）データベースからCommit （２）関連性のある実装をまとめてCommit （３）一回のCommitがもつコード量が少なくなるようにCommit hotfixブランチの作成 リリース後に修正点が見つかった場合に，修正用ブランチを作成し，これを速やかにリリースする必要がある． （１）Issueを作成する． （２）mainブランチから，『hotfix/』の名前でブランチを作成する． （３）プルリクを作成し，マージの向き先をmainブランチとする． （４）速攻でapproveをもらい，mainブランチにマージする．この時，hotfixブランチは後でdevelopブランチにマージするため，削除しないようにする． （５）パッチ番号を一つ増やしたタグを付与し，再リリースする． （６）リリース後，エラーが解消されたら，ローカルPCでhotfixブランチをdevelopブランチにマージする． "},"public/system_development_methodology/system_development_methodology_git_command.html":{"url":"public/system_development_methodology/system_development_methodology_git_command.html","title":"📖 ︎Gitコマンド","keywords":"","body":"Gitコマンド はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ 01. セットアップ系コマンド clone ・clone 一番，クローンの速度が速く，コマンドの引数も簡単． $ git clone https://github.com//.git ・clone サーバ接続名は，，SSH接続の設定ファイル（~/.ssh/config）に記載されている．デフォルトでは，Githubの接続名は，「github.com」になっている． $ git clone git@:/.git config ・ 設定の影響範囲の種類 影響範囲 意味 上書き順 設定ファイルの場所 system 全PCユーザの全リポジトリ 1 /etc/gitconfig global 現在のPCユーザーの全リポジトリ 2 ~/.gitconfig local 現在のリポジトリ 3 /.git/config ・config -- --list 指定した影響範囲で適用されている設定値を表示する．--localで設定されていない項目は，--globalの設定値が適用される． $ git config --local --list Macでは，一つのPCで二つのGutHubアカウントを使用する場合に，キーチェーンという機能で設定が必要になる． 参考：https://sy-base.com/myrobotics/others/git-push_403error/ ・config -- user.name AuthorとCommitterの名前を設定する．localが一番最後に上書きされ，適用される． $ git config --local user.name \"hiroki-it\" ・config -- user.email AuthorとCommitterのメールアドレスを設定する．localが一番最後に上書きされ，適用される． $ git config --local user.email \"example@gmail.com\" Authorの情報は，コミット時に反映される．（Committerは表示されない） $ git log commit ee299250a4741555eb5027ad3e56ce782fe90ccb Author: hiroki-it Date: Sat Sep 12 00:00:00 2020 +0900 add ◯◯を実装した． ・config --global core.autocrlf 改行コードを，特定のタイミングで自動変換するように設定する．inputとしておくのが良い． $ git config --global core.autocrlf 設定値 チェックアウト時 コミット時 input 変換しない CRLF -> LF true LF -> CRLF CRLF -> LF false 変換しない 変換しない ・config --global core.editor gitのデフォルトエディタを設定する．ここでは，Vimをデフォルトとする． $ git config --global core.editor \"vim -c \"set fenc=utf-8\"\" remote ・remote set-url origin プライベートリポジトリに接続する．configファイルに記述されたユーザ名と接続名を設定する．一つのPCで複数のGitHubアカウントを使用している場合，設定が必須である． $ git remote set-url origin @:/.git # リポジトリ１ Host User Port 22 HostName IdentityFile # リポジトリ２ Host User Port 22 HostName IdentityFile リポジトリに対してpushを実行してエラーが出た場合，異なる接続名が選ばれている場合は，URLの『接続名』の部分が正しく設定されているかを確認する． $ git push ERROR: Permission to hiroki-it/*****.git denied to Foo. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 02. 開発系コマンド add ・add --all 変更した全てのファイルをaddする． branch ・branch --all 作業中のローカルブランチとリモート追跡ブランチを表示． ・branch --delete --force ローカルブランチ名} プッシュとマージの状態に関係なく，ローカルブランチを削除． ・branch --move 作業中のローカルブランチの名前を変更． ・branch --delete --remote origin/ リモート追跡ブランチを削除． （１）まず，branch --allで作業中のローカルブランチとリモート追跡ブランチを表示． $ git branch --all * master remotes/origin/2019/Symfony_Nyumon/master remotes/origin/master （２）remotes/origin/2019/Symfony_Nyumon/masterを削除． $ git branch -d -r origin/2019/Symfony_Nyumon/master Deleted remote-tracking branch origin/2019/Symfony_Nyumon/master (was 18a31b5). （３）再び，branch --allで削除されたことを確認． $ git branch --all * master remotes/origin/master ・branch checkout -b $ git checkout -b feature/3 d7e49b04 指定のコミットから新しいブランチを生やすことができる． cherry-pick ・cherry-pick -m 1 現在のブランチに対して，指定したコミットそれ単体をマージする． $ git cherry-pick 1d0ddeb9e52 プルリクのマージによるマージコミットを指定すると，そのプルリクで変更されたファイルのみがコミットの内容として取得できる．これにより，developブランチ上の必要な変更のみをリリースすることも可能である．ただし，マージコミットを指定する時はmオプションを有効化しないとエラーになることに注意する． # mオプションがないとエラー $ git cherry-pick d7e49b04 error: commit d7e49b04 is a merge but no -m option was given. fatal: cherry-pick failed # mオプションを有効化する $ git cherry-pick -m 1 d7e49b04 [master a9ebcb4] Merge pull request #276 from feature/123 Author: hiroki-it Date: Wed Sep 15 00:00:00 2021 +0900 1 file changed, 7 insertions(+) stash ・stashとは ファイルが，『インデックス』（=add）あるいは『HEAD』（=commit）に存在している状態で，異なるローカルブランチをcheckoutしようとすると，以下のエラーが出る． $ git checkout 2019/Symfony2_Ny umon/master error: Your local changes to the following files would be overwritten by checkout: app/config/config.yml src/AppBundle/Entity/Inquiry.php Please commit your changes or stash them before you switch branches. Aborting この場合，一度stashを行い，『インデックス』（=add）あるいは『HEAD』（=commit）を横に置いておく必要がある． ・stash -u --include-untracked トラッキングされていないファイルも含めて，全てのファイルを退避． git statusをしたところ，修正ファイルが３つ，トラックされていないファイルが１つある． $ git status On branch 2019/Symfony2_Nyumon/feature/6 Your branch is up to date with \"origin/2019/Symfony2_Nyumon/feature/6\". Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git checkout -- ...\" to discard changes in working directory) modified: app/Resources/views/Inquiry/index.html.twig modified: app/config/config.yml modified: src/AppBundle/Entity/Inquiry.php Untracked files: (use \"git add ...\" to include in what will be committed) app/Resources/views/Toppage/menu.html.twig no changes added to commit (use \"git add\" and/or \"git commit -a\") これを，stash -uする $ git stash -u Saved working directory and index state WIP on 2019/Symfony2_Nyumon/feature/6: 649995e update #6 xxx これらのファイルの変更点を一時的に退避できる． ・stash -- 特定のディレクトリやファイルのみstashできる． git stash -- src/... ・stash list 退避している『ファイル番号ブランチ親コミットとコミットメッセージ』を一覧で表示． $ git stash list stash@{0}: WIP on 2019/Symfony2_Nyumon/feature/6: 649995e update #6 xxx ・stash pop stash@{} 退避している指定のファイルを復元． $ git stash pop stash@{0} On branch 2019/Symfony2_Nyumon/feature/8 Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git checkout -- ...\" to discard changes in working directory) modified: app/Resources/views/Inquiry/index.html.twig modified: app/config/config.yml modified: src/AppBundle/Entity/Inquiry.php Untracked files: (use \"git add ...\" to include in what will be committed) app/Resources/views/Toppage/menu.html.twig no changes added to commit (use \"git add\" and/or \"git commit -a\") ・stash drop stash@{} 退避している指定のファイルを復元せずに削除． $ git stash drop stash@{0} Dropped refs/stash@{0} (1d0ddeb9e52a737dcdbff7296272080e9ff71815) ・stash clear 退避している全てのファイルを復元せずに削除． $ git stash clear revert ・revertとは 作業中のローカルブランチにおいて，指定の履歴を削除． ・revert --no-edit 指定したコミットのみを打ち消す新しいコミットを作成する．コミットメッセージは，打ち消すコミットと同じものになる．リリース後に元に戻したい時に役立つ． $ git revert --no-edit ・revert --edit 指定したコミットのみを打ち消す新しいコミットを作成する．vimが起動するので，コミットメッセージを新しいものに変更する． $ git revert --edit ・revert -m 指定したマージコミットのみを打ち消す新しいコミットを作成する．コミットメッセージは，打ち消すコミットと同じものになる．マージナンバーを事前に確認しておく必要がある． $ git show commit xyz Merge: 1a1a1a 2b2b2b #ここに注目 Author: xxxx xxxx Date: Thu Jul 13 09:00:00 2017 +0000 Merge commit $ git revert -m 1 xyz reset ・resetとは 作業中のローカルブランチにおいて，指定の履歴まで戻し，それ以降を削除． ・reset HEAD インデックスから，指定したファイルを削除． $ git reset HEAD ・reset --soft 作業中のローカルブランチにおいて，最新のHEAD（=commit後）を指定の履歴まで戻し，それ以降を削除する．commitのみを取り消したい場合はこれ． $ git reset --soft ・reset --mixed 作業中のローカルブランチにおいて，インデックス（=add後），HEAD（=commit後）を指定の履歴まで戻し，それ以降を削除．addとcommitを取り消したい場合はこれ． $ git reset --mixed ・reset --hard 作業中のローカルブランチにおいて，最新のワークツリー（=フォルダ），インデックス（=add後），HEAD（=commit後）を指定の履歴まで戻し，それ以降を削除． **ワークツリー（=フォルダ）内のファイルの状態も戻ってしまうので，取り扱い注意！！** $ git reset --hard ・resetの使用例 まず，logコマンドで，作業中のローカルブランチにおけるコミットIDを確認． $ git log commit f17f68e287b7d84318b4c49e133b2d1819f6c3db (HEAD -> master, 2019/Symfony2_Nyumon/master) Merge: 41cc21b f81c813 Author: hiroki-it Date: Wed Mar 20 22:56:32 2019 +0900 Merge remote-tracking branch \"refs/remotes/origin/master\" commit 41cc21bb53a8597270b5deae3259751df18bce81 Author: hiroki-it Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_2を追加 commit f81c813a1ead9a968c109671e6d83934debcab2e Author: hiroki-it Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_1を追加 指定のコミットまで履歴を戻す． $ git reset --soft f81c813a1ead9a968c109671e6d83934debcab2e logコマンドで，正しく変更されているか確認． $ git log commit f81c813a1ead9a968c109671e6d83934debcab2e (HEAD -> master) Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add 新しいREADMEを追加 push --forceでローカルリポジトリの変更をリモートリポジトリに強制的に反映．**『強制的にpushした』というログも，リモート側には残らない．** $ git push --force Total 0 (delta 0), reused 0 (delta 0) To github.com:hiroki-it/Symfony2_Nyumon.git + f0d8b1a...f81c813 master -> master (forced update) rebase ・rebaseとは（注意点あり） 作業中のローカルブランチにおいて，ブランチの派生元を変更．リモートブランチにpushした後は使ってはならず，他のコマンドを使う． ・rebase --interactive 派生元を変更する機能を応用して，過去のコミットのメッセージ変更，削除，統合などを行う． ＊コマンド例（コミットメッセージの変更）＊ まず，logコマンドで，作業中のローカルブランチにおけるコミットIDを確認． $ git log commit f17f68e287b7d84318b4c49e133b2d1819f6c3db (HEAD -> master, 2019/Symfony2_Nyumon/master) Merge: 41cc21b f81c813 Author: Hiroki Hasegawa Date: Wed Mar 20 22:56:32 2019 +0900 Merge remote-tracking branch \"refs/remotes/origin/master\" commit 41cc21bb53a8597270b5deae3259751df18bce81 Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_2を追加 commit f81c813a1ead9a968c109671e6d83934debcab2e Author: Hiroki Hasegawa Date: Wed Mar 20 20:54:34 2019 +0900 add #0 xxxさんのREADME_1を追加 指定した履歴の削除 $ git rebase --interactive 41cc21bb53a8597270b5deae3259751df18bce81 とすると，タブが表示され，指定のコミットIDの履歴が表示される pick b1b5c0f add #0 xxxxxxxxxx 『挿入モード』に変更し，この一行のpickをeditに変更．その後， :w として保存．その後，エディタ上で『Ctrl+C』を押し， :qa! で終了． commit --amendにmオプションを付けて，メッセージを変更． $ git commit --amend -m=\"\" rebase --continueを実行し，変更を反映させる． $ git rebase --continue Successfully rebased and updated refs/heads/develop. pushしようとすると，![rejected] develop -> develop (non-fast-forward)とエラーが出るので， $ git merge --allow-unrelated-histories で解決し，pushする． ＊コマンド例（Author名とCommiter名の変更）＊ ハッシュ値を指定して，rebaseコマンドを実行する． $ git rebase --interactive 41cc21bb53a8597270b5deae3259751df18bce81 commit --amendにreset-authorオプションを付けて，configで設定した名前をAuthor名とComitter名に適用する． $ git commit --amend --reset-author rebase --continueを実行し，変更を反映させる． $ git rebase --continue Successfully rebased and updated refs/heads/develop. 過去の全てのコミットに対して，Author名とCommitter名を適用するコマンドもある．しかし，危険な方法であるため，個人利用のリポジトリのみで使用するようにするべきである． #!/bin/bash git filter-branch -f --env-filter \" # Author名かCommitter名のいずれかが誤っていれば適用します． if [ ${GIT_AUTHOR_NAME}=\"Hiroki-Hasegawa\" -o ${GIT_COMMITTER_NAME}=\"Hiroki-Hasegawa\" ] ; then export GIT_AUTHOR_NAME=\"hiroki-it\" export GIT_AUTHOR_EMAIL=\"example@gmail.com\" export GIT_COMMITTER_NAME=\"hiroki-it\" export GIT_COMMITTER_EMAIL=\"example@gmail.com\" fi\" ・rebase --onto 作業中のローカルブランチの派生元を変更． $ git rebase --onto ・rebase --interactive --root 一番古い，最初の履歴を削除． （１）変更タブの表示 $ git rebase --interactive --root とすると，最初の履歴が記述されたタブが表示される pick b1b5c0f add #0 xxxxxxxxxx （２）pick b1b5c0f add #0 xxxxxxxxxxの行を削除して保存し，タブを閉じ，エディタ上で『Ctrl+C』を押す． :qa! ここで未知のエラー CONFLICT (modify/delete): README.md deleted in HEAD and modified in 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載 した. Version 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載した of README.md left in tree. error: could not apply 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載した Resolve all conflicts manually, mark them as resolved with \"git add/rm \", then run \"git rebase --continue\". You can instead skip this commit: run \"git rebase --skip\". To abort and get back to the state before \"git rebase\", run \"git rebase --abort\". Could not apply 37bee65... update #0 README.mdに本レポジトリのタイトルと引用を記載した ・rebase --abort やりかけのrebaseを取り消し． 作業中のローカルブランチにおける(master|REBASE-i)が，(master)に変更されていることからも確認可能． hasegawahiroki@Hiroki-Fujitsu MINGW64 /c/Projects/Symfony2_Nyumon $ git rebase --interactive hasegawahiroki@Hiroki-Fujitsu MINGW64 /c/Projects/Symfony2_Nyumon (master|REBASE-i) $ git rebase --abort hasegawahiroki@Hiroki-Fujitsu MINGW64 /c/Projects/Symfony2_Nyumon (master) $ pull ・コマンド組み合わせ 全てのリモートブランチをpullする． $ git branch -r \\ | grep -v \"\\->\" \\ | grep -v main \\ | while read remote; do git branch --track \"${remote#origin/}\" \"$remote\"; done $ git fetch --all $ git pull --all push ・push -u origin ローカルで作成したブランチを，リモートにpushする．コミットは無くても良い． ・push origin :master トラウマコマンド ・push --delete origin リモートブランチのタグを削除する． $ git push --delete origin v1.0.0 なお，ローカルのタグは別に削除する必要がある． $ git tag -d v1.0.0 ・push --tags ローカルのコミットに付与したタグをリモートにpushする． show-branch 作業ブランチの派生元になっているブランチを確認． $ git show-branch \\ | grep \"*\" \\ | grep -v \"$(git rev-parse --abbrev-ref HEAD)\" \\ | head -1 \\ | awk -F\"[]~^[]\" \"{print $2}\" filter-branch ・filter-branch -f --env-filter 全てのコミットの名前とメールアドレスを上書きする． $ git filter-branch -f --env-filter \\ \"GIT_AUTHOR_NAME=\"hiroki-it\"; \\ GIT_AUTHOR_EMAIL=\"example@gmail.com\"; \\ GIT_COMMITTER_NAME=\"hiroki-it\"; \\ GIT_COMMITTER_EMAIL=\"example@gmail.com\";\" \\ HEAD ・filter-branch -f --tree-filter 全てのコミットに対して，指定した処理を実行する． ＊例＊ 全てのコミットに対して，特定のファイルを削除する処理を実行する．加えて，ローカルリポジトリに対してガーベジコレクションを実行すると，ローカルリポジトリから完全に削除できる． $ git filter-branch -f --tree-filter \\ 'rm -f ' HEAD # ガベージコレクションを実行 $ git gc --aggressive --prune=now "},"public/statistic_analysis/statistic_analysis_r.html":{"url":"public/statistic_analysis/statistic_analysis_r.html","title":"📖 ︎R言語","keywords":"","body":"統計解析 はじめに 本サイトにつきまして，以下をご認識のほど宜しくお願いいたします． 参考：https://hiroki-it.github.io/tech-notebook-gitbook/ データ解析で気をつけること データ分析によって，何を明らかにしたいのか． 明らかにすることのために，どのデータ分析が必要なのか． 必要なデータ分析のために，どんな形式のデータを用意する必要があるのか． 01. 相関分析 データに，どの程度の直線的関係があるかを検出する分析手法．回帰分析を行うか否かの判断材料になる． ＊実装例＊ # データを読み込む． sample 02. 線形回帰分析 因果関係がありそうなデータに対して，横軸を原因，また縦軸を結果とし，最も当てはまりの良い線形モデルを推定する分析手法．モデルの精度が高ければ因果関係の証明になり，またモデルに原因を代入することで結果を予測できる． 単回帰分析 原因と結果が一つずつと仮定した時に，最も当てはまりの良い線形モデルを推定できる． ・回帰方程式 ＊実装例＊ # データを読み込む． sample |t|) # (Intercept) 1.099e+01 2.405e+00 4.571 3.11e-05 *** # 純広告 2.239e-05 2.927e-05 0.765 0.448 # // 純広告の回帰係数のp値 > 0.05 より，因果関係がない可能性． 重回帰分析 原因が二つ以上で結果が一つと仮定した時に，最も当てはまりの良い線形モデルを推定できる．ただし，グラフでは，モデルは平面で表される． ・回帰方程式 ＊実装例＊ # データを読み込む． sample |t|) # (Intercept) 8.857 1.007 8.797 1.69e-11 *** # days.月曜日 5.286 1.744 3.031 0.003957 ** # days.火曜日 4.893 1.670 2.930 0.005212 ** # days.水曜日 6.143 1.670 3.679 0.000601 *** # days.木曜日 5.893 1.670 3.529 0.000944 *** # days.金曜日 4.393 1.670 2.631 0.011479 * # // 月，水，金の回帰係数のp値 02-02. 非線形回帰分析 因果関係がありそうなデータに対して，横軸を原因，また縦軸を結果とし，最も当てはまりの良い非線形モデルを推定する分析手法．モデルの精度が高ければ因果関係の証明になり，またモデルに原因を代入することで結果を予測できる．非線形モデルを推定するためには，モデルを一般化し，一般化線形モデルとして処理する必要がある． ロジスティック回帰分析 説明変数が質的変数の場合に，最も当てはまりの良い非線形モデル（ロジスティック分布）を推定する． ・回帰方程式 ＊実装例＊ # データを読み込む． sample 03. 決定木分析 データに対して，最も当てはまりの良い決定木モデルを推定する分析手法． 分類木分析 決定木モデルを分類モデルとして用いる場合の決定木分析． ・図解例 赤い点：被験者が暑いと感じた日 青い点：被験者が暑くないと感じた日 ＊実装例＊ # データを読み込む． sample 04. 階層クラスタ分析 データを，似ている順に階層的にグループ化（クラスタリング）していく分析手法．データ間の同一性を明らかにできる． ＊実装例＊ # データを読み込む． sample1 05. グラフ生成関数 ggplot() ggplot()：グラフのキャンバスを準備 geom_XXX()：グラフをプロット theme()：グラフを追加加工 "}}